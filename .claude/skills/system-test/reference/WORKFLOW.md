<!-- prettier-ignore-start -->
**Document Version:** 1.0
**Last Updated:** 2026-02-18
**Status:** ACTIVE
<!-- prettier-ignore-end -->

# Comprehensive Audit â€” Complete Interactive Workflow

Full reference for the 23-domain interactive comprehensive audit skill (v4.0).
This document describes every step, every decision point, and every interaction
in the audit lifecycle.

---

## Table of Contents

- [0. Invocation](#0-invocation)
- [1. Initialization](#1-initialization)
- [2. Pre-Flight](#2-pre-flight-domains-0-1)
- [3. Domain Execution Loop](#3-domain-execution-loop-domains-2-19)
  - [3a. Announce](#3a-announce)
  - [3b. Execute](#3b-execute)
  - [3c. Present Findings](#3c-present-findings)
  - [3d. Individual Finding Review](#3d-individual-finding-review)
  - [3e. Domain Summary](#3e-domain-summary)
  - [3f. Session Boundary Check](#3f-session-boundary-check)
- [4. Cross-Domain Analysis](#4-cross-domain-analysis-domain-20-part-1)
- [5. Self-Audit](#5-self-audit-domain-21)
- [6. Deferred Finding Revisit](#6-deferred-finding-revisit)
- [7. Final Report](#7-final-report-domain-20-part-2)
- [8. TDMS Sync](#8-tdms-sync)
- [9. Sentry Verification](#9-sentry-verification-domain-22)
- [10. Wrap-Up](#10-wrap-up)
- [Edge Cases & Recovery](#edge-cases--recovery)
- [Finding JSONL Schema](#finding-jsonl-schema)
- [Glossary](#glossary)

---

## 0. Invocation

```
/system-test                     # Fresh audit â€” full run from Domain 0
/system-test --resume            # Resume from PLAN_INDEX.md checkpoint
/system-test --domain 7          # Run single domain (re-runs)
/system-test --from 5 --to 11    # Run a range (session-scoped)
/system-test --dry-run           # Show checks without executing
/system-test --batch             # Accept all findings without review
```

### Flag Reference

| Flag              | Behavior                                                |
| ----------------- | ------------------------------------------------------- |
| _(none)_          | Fresh audit â€” full run from Domain 0                    |
| `--resume`        | Read PLAN_INDEX.md, pick up from last completed domain  |
| `--domain N`      | Run single domain only (for re-runs or targeted checks) |
| `--from N --to M` | Run a range (for session-scoped work)                   |
| `--dry-run`       | Show what would be checked, don't execute               |
| `--batch`         | Accept all findings without individual review           |

---

## 1. Initialization

Runs on **every invocation** regardless of mode.

### Steps

```
1a. Detect mode (fresh / resume / targeted)
1b. If resume:
    â†’ Read PLAN_INDEX.md
    â†’ Show progress summary
    â†’ INTERACTIVE DECISION 1: Confirm resume point
1c. Create/verify directory structure:
    docs/audits/comprehensive/audit-YYYY-MM-DD/
    â”œâ”€â”€ PLAN_INDEX.md             (master tracking â€” recovery anchor)
    â”œâ”€â”€ SUMMARY.md                (final report â€” written at end)
    â”œâ”€â”€ unified-findings.jsonl    (merged â€” written at end)
    â””â”€â”€ domains/
        â”œâ”€â”€ d00-self-validation.jsonl
        â”œâ”€â”€ d01-prerequisites.jsonl
        â”œâ”€â”€ d02-build.jsonl
        â”œâ”€â”€ ...
        â””â”€â”€ d22-sentry.jsonl
1d. Write PLAN_INDEX.md skeleton (all 23 domains, status: pending)
1e. Commit: "system-test: initialize audit-YYYY-MM-DD"
```

### INTERACTIVE DECISION 1 â€” Session Context

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Comprehensive Audit â€” 23 Domains, ~100 checks  â”‚
â”‚                                                  â”‚
â”‚  Recommended session allocation:                 â”‚
â”‚  Session 1: Domains 0-4   (foundation)           â”‚
â”‚  Session 2: Domains 5-7   (lint, UI, functions)  â”‚
â”‚  Session 3: Domains 8-11  (security, rules)      â”‚
â”‚  Session 4: Domains 12-16 (perf, docs, PWA)      â”‚
â”‚  Session 5: Domains 17-19 (prior audits, admin)  â”‚
â”‚  Session 6: Domains 20-22 (report, self-audit)   â”‚
â”‚                                                  â”‚
â”‚  Which session are we running?                   â”‚
â”‚  â—‹ Session 1 (Domains 0-4)  [Recommended]        â”‚
â”‚  â—‹ Session 2 (Domains 5-7)                       â”‚
â”‚  â—‹ Session 3 (Domains 8-11)                      â”‚
â”‚  â—‹ Full run (all 23 â€” long session)              â”‚
â”‚  â—‹ Other                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Pre-Flight (Domains 0-1)

### Domain 0: Self-Validation

Always runs, even on resume. No findings generated â€” this is a meta-check.

```
Check 0.1: Skill loaded correctly (all 23 domains defined)
Check 0.2: Output directory exists and is writable
Check 0.3: TDMS accessible (can read MASTER_DEBT.jsonl)
Check 0.4: Git working tree clean (or warn)
Check 0.5: Required tools available (next, tsc, npm, firebase)
Check 0.6: PLAN_INDEX.md written (skeleton created successfully)
```

Output: Pass/fail table displayed to user.

### Domain 1: Prerequisites

```
Check 1.1: next build exits 0 (with timing)
Check 1.2: tsc --noEmit exits 0 (no type errors)
Check 1.3: npm audit (capture severity counts)
Check 1.4: Node version matches engines field in package.json
Check 1.5: Firebase CLI available and project configured
```

### INTERACTIVE DECISION 2 â€” Pre-Flight Results

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pre-Flight Results                          â”‚
â”‚                                              â”‚
â”‚  âœ… Self-validation: 5/5 passed              â”‚
â”‚  âœ… next build: exit 0 (47s)                 â”‚
â”‚  âœ… tsc --noEmit: exit 0                     â”‚
â”‚  âš ï¸  npm audit: 2 high, 10 moderate          â”‚
â”‚  âœ… Node v22.22.0 matches engines            â”‚
â”‚                                              â”‚
â”‚  Findings from pre-flight: 1                 â”‚
â”‚  â†’ D01-001 [S1] npm audit: 2 high-severity   â”‚
â”‚    vulnerabilities in production deps         â”‚
â”‚                                              â”‚
â”‚  Suggestion: The 2 high vulns are in         â”‚
â”‚  nth-check (ReDoS) and postcss (path         â”‚
â”‚  traversal). Both are build-time only.       â”‚
â”‚  Recommend S2 if not in production bundle.   â”‚
â”‚                                              â”‚
â”‚  â—‹ Continue to domain execution              â”‚
â”‚  â—‹ Fix issues first, then retry              â”‚
â”‚  â—‹ Abort audit                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

â†’ Commit checkpoint after pre-flight.

---

## 3. Domain Execution Loop (Domains 2-19)

This is the core loop. Repeats for each domain in sequence.

### 3a. Announce

Display domain header with context to help the user understand what's coming.

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  Domain 7: Cloud Functions                 [8/23]

  Risk Level: HIGH
  Reason: Largest subsystem (5000+ lines), handles all server-side logic
  Expected Findings: 5-10

  Checks planned:
  7.1  Rate limiter constant drift (client vs server values)
  7.2  Soft-delete TOCTOU race condition
  7.3  Missing return-after-throw patterns
  7.4  Input validation completeness (all onCall functions)
  7.5  Admin authorization consistency (role checks)
  7.6  Error response information leakage
  7.7  Scheduled function error handling
  7.8  Migration function edge cases

  Key files:
  â€¢ functions/src/index.ts (486 lines)
  â€¢ functions/src/admin.ts (3100+ lines)
  â€¢ functions/src/scheduled.ts
  â€¢ functions/src/security-logger.ts
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### INTERACTIVE DECISION 3 â€” Domain Start

```
â—‹ Proceed with Domain 7  [Recommended]
â—‹ Skip this domain (mark skipped in PLAN_INDEX.md)
â—‹ Reorder (run a different domain first)
```

### 3b. Execute

For each check in the domain:

1. **Read** relevant files
2. **Run** relevant commands (build, lint, grep, static analysis)
3. **Analyze** output against expected behavior
4. **Generate** raw findings with evidence

Each finding gets a preliminary assignment:

```jsonl
{
  "id": "COMP-2026-02-18-D07-003",
  "domain": 7,
  "domain_name": "Cloud Functions",
  "check_id": "7.2",
  "severity": "S1",
  "effort": "E2",
  "title": "Soft-delete race: read-then-write without transaction",
  "description": "softDeleteJournalEntry reads the document to check isDeleted, then writes the update in a separate operation. Two concurrent calls could both pass the isDeleted guard.",
  "file": "functions/src/index.ts",
  "line": 287,
  "evidence": "Lines 287-310: const doc = await docRef.get(); ... await docRef.update({isDeleted: true})",
  "category": "correctness"
}
```

### 3c. Present Findings

Show summary table, then offer review mode choice.

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  Domain 7 Results: 7 findings

  ğŸ”´ S0 (critical):  0
  ğŸŸ¡ S1 (high):      3
  ğŸ”µ S2 (medium):    2
  âšª S3 (low):       2

  ID       Sev  Title                              File:Line
  D07-001  S1   Rate limiter constant drift         index.ts:45
  D07-002  S1   Missing return after throw           index.ts:162
  D07-003  S1   Soft-delete TOCTOU race             index.ts:287
  D07-004  S2   Admin auth check inconsistency      admin.ts:89
  D07-005  S2   Scheduled fn swallows errors        scheduled.ts:34
  D07-006  S3   Unused import in admin.ts           admin.ts:3
  D07-007  S3   Console.log left in migration fn    index.ts:510
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### INTERACTIVE DECISION 4 â€” Review Mode

```
How would you like to review these 7 findings?

â—‹ Individual review (one-by-one with full detail)  [Recommended]
â—‹ Batch accept all
â—‹ Batch accept, flag exceptions (name the ones to discuss)
â—‹ Show full detail for all, then decide
```

### 3d. Individual Finding Review

For each finding, present **full context with suggestion and options**.

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  Finding D07-003                           [3/7]

  Severity: S1 (high)     Effort: E2 (hours)
  Category: correctness   Check: 7.2

  Title: Soft-delete race: read-then-write without transaction

  Description:
  softDeleteJournalEntry reads the document to check isDeleted,
  then writes the update in a separate operation. Two concurrent
  calls could both pass the isDeleted guard and both attempt to
  soft-delete, potentially causing duplicate Sentry events or
  incorrect audit trail entries.

  File: functions/src/index.ts:287-310

  Evidence:
  â”‚ 287 â”‚ const docRef = db.collection("users").doc(uid)...
  â”‚ 288 â”‚ const doc = await docRef.get();
  â”‚ 289 â”‚ if (!doc.exists) throw new HttpsError(...);
  â”‚ 290 â”‚ const data = doc.data();
  â”‚ 291 â”‚ if (data.isDeleted) throw new HttpsError(...);
  â”‚ ...
  â”‚ 310 â”‚ await docRef.update({ isDeleted: true, ... });

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  SUGGESTION                                 â”‚
  â”‚                                             â”‚
  â”‚  Recommendation: ACCEPT at S1               â”‚
  â”‚                                             â”‚
  â”‚  Reasoning: This is a real TOCTOU race.     â”‚
  â”‚  While unlikely in normal usage (users      â”‚
  â”‚  don't double-click delete rapidly), it     â”‚
  â”‚  could be triggered by:                     â”‚
  â”‚  â€¢ Network retry logic                      â”‚
  â”‚  â€¢ Malicious concurrent requests            â”‚
  â”‚  â€¢ Mobile app backgrounding/resuming        â”‚
  â”‚                                             â”‚
  â”‚  Suggested fix: Wrap lines 287-310 in a     â”‚
  â”‚  Firestore transaction:                     â”‚
  â”‚    await db.runTransaction(async (t) => {   â”‚
  â”‚      const doc = await t.get(docRef);       â”‚
  â”‚      if (doc.data().isDeleted) throw ...;   â”‚
  â”‚      t.update(docRef, {isDeleted: true});   â”‚
  â”‚    });                                      â”‚
  â”‚                                             â”‚
  â”‚  Counter-argument: If this function is      â”‚
  â”‚  only called from UI with debounce, the     â”‚
  â”‚  practical risk is low. Could be S2.        â”‚
  â”‚                                             â”‚
  â”‚  Similar pattern found in:                  â”‚
  â”‚  â€¢ saveJournalEntry (line 163) â€” same issue â”‚
  â”‚  â€¢ saveDailyLog (line 77) â€” already uses tx â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### INTERACTIVE DECISION 5 â€” Per-Finding Verdict

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  What would you like to do with D07-003?        â”‚
â”‚                                                  â”‚
â”‚  â—‹ Accept as-is (S1, E2)  [Recommended]          â”‚
â”‚  â—‹ Accept, change severity                       â”‚
â”‚    â†’ S0 (critical) / S2 (medium) / S3 (low)     â”‚
â”‚  â—‹ Accept, change effort                         â”‚
â”‚    â†’ E0 (minutes) / E1 (<1hr) / E3 (days)       â”‚
â”‚  â—‹ Reject (false positive)                       â”‚
â”‚  â—‹ Defer (revisit later)                         â”‚
â”‚  â—‹ Discuss (tell me more about this finding)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**If user chooses "Reject":**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Why is D07-003 a false positive?                â”‚
â”‚                                                  â”‚
â”‚  â—‹ Already fixed in a pending PR                 â”‚
â”‚  â—‹ By design â€” explain:                          â”‚
â”‚  â—‹ Not applicable to our use case because:       â”‚
â”‚  â—‹ Duplicate of another finding:                 â”‚
â”‚  â—‹ Other (free text)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**If user chooses "Discuss":**

The skill provides additional context:

- More surrounding code (expanded line range)
- Detailed risk scenario walkthrough
- Whether other projects commonly have this pattern
- Links to relevant documentation or OWASP references
- Related TDMS entries if they exist

Then re-presents the same decision.

**Running tally after each decision:**

```
  Progress: 3/7 reviewed  â”‚  âœ… 2 accepted  â”‚  âŒ 0 rejected  â”‚  â¸ 1 deferred
```

### 3e. Domain Summary

After all findings in a domain are reviewed:

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  Domain 7: Cloud Functions â€” COMPLETE

  Total findings:  7
  Accepted:        5  (2Ã—S1, 2Ã—S2, 1Ã—S3)
  Rejected:        1  (D07-006 â€” unused import already in lint backlog)
  Deferred:        1  (D07-004 â€” needs design discussion first)

  Written to: domains/d07-cloud-functions.jsonl

  Cumulative audit progress:
  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  8/23 domains (35%)
  Total accepted findings:  31

  Time spent on Domain 7: ~12 minutes
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### INTERACTIVE DECISION 6 â€” Post-Domain

```
â—‹ Continue to Domain 8: Security Headers & CSP  [Recommended]
â—‹ Re-review Domain 7 (change some decisions)
â—‹ Pause here (save checkpoint, end session)
```

â†’ Commit: `system-test: Domain 7 â€” Cloud Functions [8/23]` â†’ Update
PLAN_INDEX.md (mark Domain 7 as âœ… Complete, update counts)

### 3f. Session Boundary Check

After every domain, the skill checks:

- Have we reached the session's planned endpoint?
- Have we completed 15+ domains without a push? (git hygiene)
- Is the conversation getting long? (compaction risk)

If any trigger fires:

### INTERACTIVE DECISION 7 â€” Session Boundary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Session 2 planned endpoint reached              â”‚
â”‚                                                  â”‚
â”‚  Completed this session: Domains 5, 6, 7         â”‚
â”‚  Findings this session:  18 accepted              â”‚
â”‚  Cumulative:             43 accepted (8/23)       â”‚
â”‚                                                  â”‚
â”‚  Suggestion: Good stopping point. Domain 7 was   â”‚
â”‚  the heaviest domain. Session 3 (security) is    â”‚
â”‚  best started fresh with full context.           â”‚
â”‚                                                  â”‚
â”‚  â—‹ End session here (commit + push)  [Recommended]â”‚
â”‚  â—‹ Continue into Session 3 domains               â”‚
â”‚  â—‹ Re-run a domain from this session             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

If ending session:

```
  âœ… Checkpoint committed: abc1234
  âœ… Pushed to remote branch
  âœ… PLAN_INDEX.md updated

  Resume next session with:
    /system-test --resume

  Next session starts at: Domain 8 (Security Headers & CSP)
```

---

## 4. Cross-Domain Analysis (Domain 20, Part 1)

After all execution domains (2-19) are complete, scan for patterns.

```
Scanning 150+ accepted findings across 18 domains...

Cross-Cutting Patterns Detected:

Pattern 1: "Missing validation at boundaries" (8 findings, 4 domains)
  â†’ D07-001, D07-004, D08-002, D09-003, D09-005, D10-001, D11-002, D11-004
  â†’ Systemic: Input validation is inconsistent between client and server
  â†’ Suggestion: Create a shared validation schema (Zod) used by both sides
  â†’ Estimated effort if addressed systemically: E3 (days) vs E2Ã—8 individually

Pattern 2: "Inconsistent error handling" (5 findings, 3 domains)
  â†’ D07-002, D07-005, D08-004, D12-001, D12-003
  â†’ Systemic: Some errors swallowed, some thrown, some logged â€” no strategy
  â†’ Suggestion: Adopt a unified error handling pattern (already partially exists
    in callable-errors.ts â€” extend it)
  â†’ Estimated effort: E2 (hours)

Pattern 3: "Documentation drift" (6 findings, 2 domains)
  â†’ D14-001 through D14-006
  â†’ Systemic: Docs reference old patterns the code has evolved past
  â†’ Suggestion: Run doc-optimizer skill after code changes
  â†’ Estimated effort: E1 (< 1 hour)
```

### INTERACTIVE DECISION 8 â€” Cross-Cutting Findings

For each pattern:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pattern 1: Missing validation at boundaries    â”‚
â”‚  8 findings across 4 domains                     â”‚
â”‚                                                  â”‚
â”‚  Suggestion: Promote to a standalone "systemic" â”‚
â”‚  finding. Addressing this as one unit (shared   â”‚
â”‚  Zod schemas) is more efficient than 8 separate â”‚
â”‚  fixes.                                         â”‚
â”‚                                                  â”‚
â”‚  â—‹ Promote to standalone finding  [Recommended]  â”‚
â”‚  â—‹ Note only (mention in report, not a finding)  â”‚
â”‚  â—‹ Dismiss (these are coincidental, not systemic)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. Self-Audit (Domain 21)

The skill audits **its own execution** for completeness and quality.

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  Domain 21: Post-Test Self-Audit

  Checking audit completeness...

  âœ… All 23 domains executed (0 skipped)
  âœ… Every check ID in the skill was actually run
  âš ï¸  Domain 15 (PWA) had 0 findings â€” suspicious?
  âœ… Severity distribution reasonable (bell curve, not all S3)
  âœ… No duplicate finding IDs
  âœ… All JSONL files are valid JSON Lines format
  âš ï¸  3 deferred findings never revisited (D04-002, D07-004, D09-003)
  âœ… PLAN_INDEX.md matches actual file state on disk
  âœ… Total finding count matches sum of domain files

  Self-audit findings: 2

  SA-001 [S3] Domain 15 had 0 findings
    Suggestion: PWA manifest has known issues (JPG icons, no maskable
    icon, no service worker). Zero findings suggests checks may have
    been too shallow. Consider re-running Domain 15 with expanded checks.

  SA-002 [S3] 3 deferred findings never revisited
    Suggestion: Present these now for final disposition before the
    report is generated. They'll appear as "deferred" in the report
    otherwise, which leaves open items.
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### INTERACTIVE DECISION 9 â€” Self-Audit Results

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Self-audit found 2 items. What would you like? â”‚
â”‚                                                  â”‚
â”‚  â—‹ Accept both, move to final report             â”‚
â”‚  â—‹ Re-run Domain 15 with deeper checks           â”‚
â”‚  â—‹ Revisit the 3 deferred findings now           â”‚
â”‚  â—‹ Both: re-run D15 AND revisit deferred         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. Deferred Finding Revisit

If deferred findings exist and the user chose to revisit them:

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  Deferred Findings: 3 items

  1. D04-002 [S2] Three-way version mismatch (firebase packages)
     Deferred in Session 1. Reason: "Need to check if upgrade is safe"

     Update since deferral: Domain 7 (Cloud Functions) found no
     issues caused by the version mismatch. This may be cosmetic.

     Suggestion: Downgrade to S3 and accept.
     â—‹ Accept at S2 (original)
     â—‹ Accept at S3 (downgraded)
     â—‹ Reject (cosmetic, not actionable)

  2. D07-004 [S2] Admin auth check inconsistency
     Deferred in Session 2. Reason: "Needs design discussion"

     Update since deferral: Domain 11 (Auth) confirmed all admin
     routes do check isAdmin. The inconsistency is in HOW they
     check (some use helper, some inline). Functional but messy.

     Suggestion: Accept at S3 (style issue, not security).
     â—‹ Accept at S2 (original)
     â—‹ Accept at S3 (downgraded)
     â—‹ Reject (acceptable variation)

  3. D09-003 [S1] Firestore rule allows wider read than intended
     Deferred in Session 3. Reason: "Need to verify with production data"

     No new information available. This finding stands as-is.

     Suggestion: Accept at S1. This is a real permission over-grant.
     â—‹ Accept at S1 (original)
     â—‹ Accept at S2 (downgraded)
     â—‹ Reject (intended behavior)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

Each deferred finding gets the full verdict flow (same as section 3d).

---

## 7. Final Report (Domain 20, Part 2)

Generate `SUMMARY.md` with the following structure:

```markdown
# Comprehensive Audit Report â€” 2026-02-18

## Executive Summary

- 23 domains audited across N sessions
- **XXX findings** accepted (XX S0, XX S1, XX S2, XX S3)
- **XX findings** rejected as false positives
- **XX findings** deferred (XX later resolved, XX remain open)
- **X cross-cutting patterns** identified
- Estimated total remediation effort: ~XX hours

## Severity Distribution

S0 â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ XX (XX%) S1 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ XX (XX%) S2 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ XX
(XX%) S3 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ XX (XX%)

## Risk Matrix

| Domain           | Risk Level | Finding Count | Critical Path? |
| ---------------- | ---------- | ------------- | -------------- |
| Cloud Functions  | HIGH       | XX            | Yes            |
| Firestore Rules  | HIGH       | XX            | Yes            |
| Security Headers | MEDIUM     | XX            | No             |
| ...              | ...        | ...           | ...            |

## Top 10 Priority Findings

(Ranked by severity Ã— effort Ã— cross-domain impact)

1. ...

## Cross-Cutting Patterns

1. Missing validation at boundaries (8 findings, 4 domains)
2. ...

## Per-Domain Breakdown

| #   | Domain          | Findings | S0  | S1  | S2  | S3  | Effort |
| --- | --------------- | -------- | --- | --- | --- | --- | ------ |
| 0   | Self-Validation | 0        | -   | -   | -   | -   | -      |
| ... | ...             | ...      | ..  | ..  | ..  | ..  | ...    |

## Recommendations (Priority Order)

1. [S0/S1] Fix critical security findings first (list)
2. [Systemic] Address cross-cutting validation pattern
3. [Quick wins] S3/E0 items that take minutes
4. [Planned] Schedule S2/E2+ items for next sprint

## Rejected Findings (Transparency Log)

| ID  | Title | Reason | Decided By |
| --- | ----- | ------ | ---------- |

## Self-Audit Results

(From Domain 21 â€” audit quality metrics)

## Appendix

- Links to individual domain JSONL files
- PLAN_INDEX.md final state
- Session timeline
```

### INTERACTIVE DECISION 10 â€” Final Report

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Final report generated: SUMMARY.md             â”‚
â”‚  XXX findings, XX pages                          â”‚
â”‚                                                  â”‚
â”‚  â—‹ Approve report as-is  [Recommended]           â”‚
â”‚  â—‹ Edit executive summary                        â”‚
â”‚  â—‹ Add/remove sections                           â”‚
â”‚  â—‹ Add notes before finalizing                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

â†’ Commit: `system-test: final report â€” XXX findings across 23 domains`

---

## 8. TDMS Sync

Preview what would change in MASTER_DEBT.jsonl, then ask.

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  TDMS Sync Preview

  New findings to add:           XXX
  Already in TDMS (duplicates):  XX   (will skip)
  Would update existing:         XX   (severity changed)

  Current TDMS: 2656 items (298 resolved)
  After sync:   ~XXXX items

  Deduplication method:
  Match on file + title similarity (>80% fuzzy match) to avoid
  creating duplicate entries for issues already tracked.

  Sample new entry:
  {"id":"COMP-2026-02-18-D07-003","severity":"S1","effort":"E2",
   "title":"Soft-delete TOCTOU race","source":"system-test",
   "domain":"cloud-functions","file":"functions/src/index.ts:287"}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### INTERACTIVE DECISION 11 â€” TDMS Sync

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sync findings to TDMS?                          â”‚
â”‚                                                  â”‚
â”‚  â—‹ Sync all new findings  [Recommended]          â”‚
â”‚  â—‹ Preview full diff first, then decide          â”‚
â”‚  â—‹ Sync S0+S1 only (critical/high)              â”‚
â”‚  â—‹ Skip sync (findings stay in JSONL only)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 9. Sentry Verification (Domain 22)

Optional domain â€” requires network access to Sentry.

```
Checks:
22.1  Sentry DSN configured in environment
22.2  Client logger (lib/logger.ts) connects to Sentry
22.3  Server logger (functions/src/security-logger.ts) connects to Sentry
22.4  PII redaction equivalence: client SENSITIVE_KEYS vs server SENSITIVE_KEYS
22.5  Dual-logger architecture consistency (same Sentry project?)
22.6  Source maps uploaded for production debugging
22.7  Alert rules configured for S0/S1 error patterns
```

### INTERACTIVE DECISION 12 â€” Sentry Access

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Domain 22 requires Sentry access for some      â”‚
â”‚  checks. Others can run offline.                â”‚
â”‚                                                  â”‚
â”‚  Suggestion: Run offline checks (code analysis) â”‚
â”‚  now. Network checks can be done separately     â”‚
â”‚  if/when Sentry credentials are available.      â”‚
â”‚                                                  â”‚
â”‚  â—‹ Run offline checks only  [Recommended]        â”‚
â”‚  â—‹ Run all checks (need DSN access)              â”‚
â”‚  â—‹ Skip Domain 22 entirely                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 10. Wrap-Up

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  COMPREHENSIVE AUDIT COMPLETE

  Duration:   N sessions over N days
  Domains:    23/23 âœ…
  Findings:   XXX accepted, XX rejected, XX deferredâ†’resolved

  Report:
    docs/audits/comprehensive/audit-2026-02-18/SUMMARY.md

  Data:
    docs/audits/comprehensive/audit-2026-02-18/unified-findings.jsonl
    docs/audits/comprehensive/audit-2026-02-18/domains/ (23 files)

  TDMS:
    XXX items synced to MASTER_DEBT.jsonl

  All files committed and pushed.
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## Edge Cases & Recovery

| Situation                        | Behavior                                                                                                  |
| -------------------------------- | --------------------------------------------------------------------------------------------------------- |
| Build fails in Domain 2          | Offer: fix first, skip dependent domains, or abort. Domain 3 (tests) cannot run without successful build. |
| Domain has 0 findings            | Self-audit (Domain 21) flags as suspicious. User decides if genuinely clean or checks need deepening.     |
| User rejects ALL findings        | All recorded as rejected with reasons. Domain still counts as complete. Noted in report transparency log. |
| Compaction mid-domain            | Read PLAN_INDEX.md. Last complete domain is checkpoint. Current domain re-runs from scratch.              |
| User wants to re-run a domain    | Allowed. Clears that domain's JSONL. Re-executes all checks, re-presents for review.                      |
| Finding duplicates existing TDMS | Skipped during sync with note. Shown in sync preview so user is aware.                                    |
| User says "stop" mid-review      | Remaining findings in current domain marked as deferred. Commit what's reviewed. Resume later.            |
| Network error on git push        | Retry 4Ã— with exponential backoff (2s, 4s, 8s, 16s). If all fail, save locally and advise manual push.    |
| Check requires network we lack   | Run offline analysis only. Finding notes "network check skipped" with limitation documented.              |
| TDMS file is locked or corrupt   | Skip sync, write findings to JSONL only. Advise user to fix TDMS and run sync manually.                   |
| User disagrees with suggestion   | User decision is always final. Skill records the override with original suggestion for transparency.      |

---

## Anti-Compaction Guardrails

### Layer 1: File-First Architecture

Every piece of content goes to disk immediately. Nothing exists only in context.
The conversation is a coordination layer; the files ARE the audit.

### Layer 2: Incremental Git Commits

Commit after every completed domain. Each commit is a checkpoint. Worst case:
lose 1 domain of in-progress work. Pattern:
`system-test: Domain N â€” <name> [M/23]`

### Layer 3: PLAN_INDEX.md as Recovery Anchor

Single file tracks all progress. After compaction, read this one file to know
exactly where to resume. Updated after every domain.

### Layer 4: Domain Independence

Each domain is self-contained. No domain depends on reading another domain's
findings to execute. Cross-references use stable IDs only.

### Recovery Protocol

```
1. Read PLAN_INDEX.md â†’ identify last âœ… Complete domain
2. Read last completed domain's JSONL â†’ verify it's intact
3. Resume from next domain number
4. No re-reading of already-completed domains needed
```

---

## Finding JSONL Schema

Every finding across all domains uses this schema:

```jsonl
{
  "id": "COMP-2026-02-18-D07-003",
  "domain": 7,
  "domain_name": "Cloud Functions",
  "check_id": "7.2",
  "severity": "S1",
  "effort": "E2",
  "category": "correctness",
  "title": "Soft-delete race: read-then-write without transaction",
  "description": "Full description of the finding...",
  "file": "functions/src/index.ts",
  "line": 287,
  "evidence": "Relevant code or command output...",
  "suggested_fix": "Wrap in Firestore transaction",
  "status": "accepted",
  "original_severity": "S1",
  "user_severity_override": null,
  "rejection_reason": null,
  "deferral_reason": null,
  "user_notes": null,
  "suggestion_text": "Accept at S1. Real TOCTOU race...",
  "counter_argument": "Low practical risk with UI debounce...",
  "related_findings": [
    "D07-001"
  ],
  "detected_at": "2026-02-18T14:32:00Z",
  "reviewed_at": "2026-02-18T14:33:15Z"
}
```

### Field Reference

| Field                    | Type     | Required | Description                                                                                       |
| ------------------------ | -------- | -------- | ------------------------------------------------------------------------------------------------- |
| `id`                     | string   | Yes      | Unique ID: `COMP-{date}-D{NN}-{NNN}`                                                              |
| `domain`                 | number   | Yes      | Domain number (0-22)                                                                              |
| `domain_name`            | string   | Yes      | Human-readable domain name                                                                        |
| `check_id`               | string   | Yes      | Which check found this (e.g., "7.2")                                                              |
| `severity`               | string   | Yes      | Final severity after user review: S0/S1/S2/S3                                                     |
| `effort`                 | string   | Yes      | Estimated fix effort: E0/E1/E2/E3                                                                 |
| `category`               | string   | Yes      | One of: security, correctness, performance, maintainability, accessibility, config, documentation |
| `title`                  | string   | Yes      | Short title (< 80 chars)                                                                          |
| `description`            | string   | Yes      | Full description                                                                                  |
| `file`                   | string   | Yes      | File path relative to repo root                                                                   |
| `line`                   | number   | No       | Line number (if applicable)                                                                       |
| `evidence`               | string   | Yes      | Code snippet or command output proving the issue                                                  |
| `suggested_fix`          | string   | No       | How to fix it                                                                                     |
| `status`                 | string   | Yes      | `accepted` / `rejected` / `deferred`                                                              |
| `original_severity`      | string   | No       | If user changed severity, what it was originally                                                  |
| `user_severity_override` | string   | No       | User's chosen severity if different                                                               |
| `rejection_reason`       | string   | No       | Why rejected (if status=rejected)                                                                 |
| `deferral_reason`        | string   | No       | Why deferred (if status=deferred)                                                                 |
| `user_notes`             | string   | No       | Any notes the user added                                                                          |
| `suggestion_text`        | string   | No       | The recommendation shown to user                                                                  |
| `counter_argument`       | string   | No       | The counter-argument shown to user                                                                |
| `related_findings`       | string[] | No       | IDs of related findings in other domains                                                          |
| `detected_at`            | string   | Yes      | ISO 8601 timestamp of detection                                                                   |
| `reviewed_at`            | string   | No       | ISO 8601 timestamp of user review                                                                 |

---

## Severity & Effort Scales

### Severity

| Level | Name     | Meaning                                        | Response Time   |
| ----- | -------- | ---------------------------------------------- | --------------- |
| S0    | Critical | Security breach, data loss, app crash          | Fix immediately |
| S1    | High     | Significant bug, security risk, major UX issue | Fix this sprint |
| S2    | Medium   | Moderate issue, tech debt, minor UX problem    | Schedule fix    |
| S3    | Low      | Cosmetic, optimization, nice-to-have           | Backlog         |

### Effort

| Level | Name    | Meaning                        |
| ----- | ------- | ------------------------------ |
| E0    | Minutes | Quick fix, config change       |
| E1    | < 1 hr  | Small code change, one file    |
| E2    | Hours   | Multi-file change, some design |
| E3    | Days    | Major refactor, new subsystem  |

---

## Glossary

| Term   | Meaning                                                     |
| ------ | ----------------------------------------------------------- |
| TDMS   | Technical Debt Management System (`MASTER_DEBT.jsonl`)      |
| S0-S3  | Severity scale: S0=critical â†’ S3=low                        |
| E0-E3  | Effort scale: E0=minutes â†’ E3=days                          |
| JSONL  | JSON Lines â€” one JSON object per line                       |
| TOCTOU | Time-of-check-to-time-of-use race condition                 |
| DSN    | Data Source Name (Sentry connection string)                 |
| CANON  | Canonical decision document (CANON-XXXX references in code) |
| PWA    | Progressive Web App                                         |
| CSP    | Content Security Policy                                     |
| PII    | Personally Identifiable Information                         |
| ReDoS  | Regular Expression Denial of Service                        |
| SBOM   | Software Bill of Materials                                  |
| OWASP  | Open Web Application Security Project                       |
| WCAG   | Web Content Accessibility Guidelines                        |
| oklch  | CSS color function (Oklab Lightness, Chroma, Hue)           |

---

## Session Allocation Reference

| Session | Domains | Focus Area              | Risk Level | Est. Findings | Notes                              |
| ------- | ------- | ----------------------- | ---------- | ------------- | ---------------------------------- |
| 1       | 0-4     | Foundation              | LOW        | 5-15          | Build/test/deps â€” mostly automated |
| 2       | 5-7     | Lint, UI, Cloud Fns     | HIGH       | 20-35         | Domain 7 is the heaviest           |
| 3       | 8-11    | Security, Rules, Auth   | HIGH       | 15-25         | Security-critical domains          |
| 4       | 12-16   | Perf, Config, Docs, PWA | MEDIUM     | 15-25         | Broad coverage, moderate depth     |
| 5       | 17-19   | Prior Audits, Admin     | MEDIUM     | 10-20         | Cross-referencing + admin panel    |
| 6       | 20-22   | Report, Self-Audit      | LOW        | 5-10          | Synthesis + quality check          |

---

## Dependency Graph

```
Domain 0 (Self-Validation)
  â””â†’ Domain 1 (Prerequisites)
       â””â†’ Domain 2 (Build) â”€â”€â”€ must pass before â”€â”€â†’ Domain 3 (Tests)
            â”‚
            â”œâ†’ Domain 4 (Dependencies)     â† independent
            â”œâ†’ Domain 5 (Lint)             â† independent
            â”œâ†’ Domain 6 (UI)              â† independent
            â”œâ†’ Domain 7 (Cloud Functions)  â† independent
            â”œâ†’ Domain 8 (Security Headers) â† independent
            â”œâ†’ Domain 9 (Firestore Rules)  â† independent
            â”œâ†’ Domain 10 (Env/Config)      â† independent
            â”œâ†’ Domain 11 (Auth)            â† independent
            â”œâ†’ Domain 12 (Performance)     â† independent
            â”œâ†’ Domain 13 (Config Files)    â† independent
            â”œâ†’ Domain 14 (Documentation)   â† independent
            â”œâ†’ Domain 15 (PWA)             â† independent
            â”œâ†’ Domain 16 (TDMS)            â† independent
            â”œâ†’ Domain 17 (Prior Audits)    â† independent
            â”œâ†’ Domain 18 (Admin Panel)     â† independent
            â””â†’ Domain 19 (Data Integrity)  â† independent

Domain 20 (Report) â† depends on Domains 2-19 complete
Domain 21 (Self-Audit) â† depends on Domain 20
Domain 22 (Sentry) â† independent, can run anytime after Domain 0
```

---

## Version History

| Version | Date       | Description                                                |
| ------- | ---------- | ---------------------------------------------------------- |
| 1.0     | 2026-02-18 | Initial workflow document for v4.0 (23-domain interactive) |
