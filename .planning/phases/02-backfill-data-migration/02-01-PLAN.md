---
phase: 02-backfill-data-migration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - scripts/reviews/lib/parse-review.ts
  - scripts/reviews/__tests__/parse-review.test.ts
autonomous: true

must_haves:
  truths:
    - "Heading-format archives (#1-40, #42-60, etc.) produce correctly numbered
      ParsedEntry objects with title, date, and content"
    - "Table-only archive (REVIEWS_101-136.md) produces stub-tier entries with
      correct review IDs"
    - "Field extractors pull PR number, severity counts, fixed/deferred/rejected
      counts, patterns, and learnings from raw markdown"
    - "Within-file duplicates (e.g., #21 4x, #30 5x) are deduplicated to single
      best entry per ID"
    - "Known-skipped IDs (64 total) are recognized and excluded from gap
      detection"
  artifacts:
    - path: "scripts/reviews/lib/parse-review.ts"
      provides:
        "Markdown review parser with heading + table modes, field extractors, v2
        record builder"
      exports:
        - "parseArchiveFile"
        - "parseTableArchive"
        - "toV2ReviewRecord"
        - "KNOWN_SKIPPED_IDS"
        - "KNOWN_DUPLICATE_IDS"
    - path: "scripts/reviews/__tests__/parse-review.test.ts"
      provides: "Unit tests for parser against real archive format samples"
      min_lines: 100
  key_links:
    - from: "scripts/reviews/lib/parse-review.ts"
      to: "scripts/reviews/lib/schemas/review.ts"
      via: "import ReviewRecord schema for validation"
      pattern: "import.*ReviewRecord.*from.*schemas"
    - from: "scripts/reviews/lib/parse-review.ts"
      to: "scripts/reviews/lib/schemas/shared.ts"
      via: "import CompletenessTier for tier assignment"
      pattern: "import.*CompletenessTier|completeness"
---

<!-- prettier-ignore-start -->
**Document Version:** 1.1
**Last Updated:** 2026-02-28
**Status:** ACTIVE
<!-- prettier-ignore-end -->

<objective>
Build the markdown-to-v2-record parser module that handles all observed archive formats.

Purpose: This is the core extraction engine that every other Phase 2 script
depends on. It must handle 5+ markdown format variations across 13 archives
spanning 2 months of format evolution. Output: `parse-review.ts` module
exporting parser functions + comprehensive tests. </objective>

<execution_context> @~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md </execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-backfill-data-migration/02-RESEARCH.md
@scripts/reviews/lib/schemas/review.ts
@scripts/reviews/lib/schemas/shared.ts
@scripts/reviews/lib/schemas/retro.ts
@scripts/sync-reviews-to-jsonl.js
@scripts/check-review-archive.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create parse-review.ts with heading parser, table parser, and field extractors</name>
  <files>scripts/reviews/lib/parse-review.ts</files>
  <action>
Create `scripts/reviews/lib/parse-review.ts` that exports:

1. **`ParsedEntry` interface**:
   `{ reviewNumber: number, date: string | null, title: string, rawLines: string[], sourceFile: string }`

2. **`KNOWN_SKIPPED_IDS`**: Set of 64 IDs from `check-review-archive.js` (import
   or duplicate the constant). These IDs were never assigned and should not
   generate records.

3. **`KNOWN_DUPLICATE_IDS`**: Set of [366, 367, 368, 369] -- legitimately appear
   in two archives with different content.

4. **`parseArchiveFile(filePath: string, content: string): ParsedEntry[]`**:
   Heading-based parser.
   - Match headers: `/^#{2,4}\s+Review\s+#(\d+):?\s*(.*)/` (reuse pattern from
     sync-reviews-to-jsonl.js line 183)
   - Extract date from header: `\((\d{4}-\d{2}-\d{2})\)` at end of title
   - Handle em-dash variant: `#### Review #N -- Title`
   - Track code fences (``` toggles) to avoid matching inside code blocks
   - Collect all lines between headers as rawLines for the entry
   - After parsing: deduplicate within-file by reviewNumber, keeping the entry
     with the most rawLines content

5. **`parseTableArchive(filePath: string, content: string): ParsedEntry[]`**:
   Table-format parser for REVIEWS_101-136.md.
   - Match table rows: `/\|\s*#?(\d+)\s*\|/` pattern
   - Extract whatever columns exist (ID, date, title at minimum)
   - These produce minimal entries (stub-tier candidates)

6. **Field extractors** (reuse logic from sync-reviews-to-jsonl.js):
   - `extractPR(raw: string): number | null` -- looks for `**PR:** #N`,
     `**PR:** branch-name`, `PR #N`, `pr/N`
   - `extractTotal(raw: string): number | null` -- looks for `**Total:** N`,
     `**Items:** N`, `N total`
   - `extractCount(raw: string, label: string): number | null` -- for
     fixed/deferred/rejected counts
   - `extractPatterns(raw: string): string[]` -- bullet list items under
     `**Patterns**` or `**Key Patterns**`
   - `extractLearnings(raw: string): string[]` -- bullet list items under
     `**Learnings**` or `**Key Learnings**`
   - `extractSeverity(raw: string): { critical, major, minor, trivial } | null`
     -- handles both `N LABEL` and `Label: N` formats

7. **`toV2ReviewRecord(entry: ParsedEntry): ReviewRecordType`**: Converts
   ParsedEntry to v2 schema record.
   - ID format: `rev-{reviewNumber}` (stable, idempotent)
   - Completeness assignment: full (has title + pr + total + at least one of
     fixed/deferred), partial (has title + at least total or pr), stub (only
     id/date)
   - Track missing fields in `completeness_missing` array
   - Origin: `{ type: "backfill", tool: "backfill-reviews.ts" }`
   - Use `ReviewRecord.parse()` to validate output -- this catches schema
     violations immediately

**Important anti-patterns to avoid:**

- Do NOT use `any` type anywhere -- strict TypeScript
- Do NOT parse PR numbers from retro tables as review IDs
- Do NOT use numeric IDs as the v2 `id` field (must be string like `rev-123`)
- Do NOT hand-roll JSON validation -- use Zod schema.parse()

**Reference:** Study `scripts/sync-reviews-to-jsonl.js` lines 180-350 for the
field extraction patterns. Adapt them to TypeScript with proper types. The
patterns there are battle-tested against the actual archive data. </action>
<verify> Run: `cd scripts/reviews && npx tsc --noEmit` -- no TypeScript errors.
Verify exports: the module should export parseArchiveFile, parseTableArchive,
toV2ReviewRecord, KNOWN_SKIPPED_IDS, KNOWN_DUPLICATE_IDS. </verify> <done>
parse-review.ts compiles cleanly, exports all 5 named items, uses Phase 1
schemas for validation, handles both heading and table archive formats. </done>
</task>

<task type="auto">
  <name>Task 2: Create parse-review tests using real archive format samples</name>
  <files>scripts/reviews/__tests__/parse-review.test.ts</files>
  <action>
Create `scripts/reviews/__tests__/parse-review.test.ts` with tests covering:

1. **Heading parser tests:**
   - Parse a sample with `#### Review #42: Title (2026-01-15)` format -- verify
     reviewNumber=42, date, title extracted
   - Parse em-dash variant: `#### Review #42 -- Title (2026-01-15)`
   - Parse header without date: `#### Review #42: Title` -- date should be null
   - Parse `## Review #N` (double-hash) and `### Review #N` (triple-hash)
     variants
   - Code fence exclusion: content inside ```blocks with`# Review #999` should
     NOT create an entry
   - Within-file dedup: input with reviewNumber appearing 3 times, output should
     have 1 entry (the one with most content)

2. **Table parser tests:**
   - Parse a sample table row `| #105 | 2026-01-20 | Security review |` --
     verify ID extraction
   - Multiple table rows produce multiple entries
   - Non-review table rows (headers, separators) are skipped

3. **Field extractor tests:**
   - extractPR: `**PR:** #389` returns 389, `**PR:** feature/auth` returns null
     (branch name not a number), `PR #42` returns 42
   - extractTotal: `**Total:** 12` returns 12, `**Items:** 5` returns 5
   - extractCount: `**Fixed:** 3` returns 3 for label "fixed"
   - extractPatterns: bullet list under `**Patterns**` heading returns string
     array
   - extractSeverity: `2 Critical, 5 Major, 3 Minor, 1 Trivial` parsed correctly

4. **toV2ReviewRecord tests:**
   - Full entry (has all fields) produces completeness: "full"
   - Entry missing pr and patterns produces completeness: "partial"
   - Minimal entry (only ID + date) produces completeness: "stub"
   - ID format is `rev-{number}` string
   - Output passes ReviewRecord.parse() (Zod validation)

5. **Known IDs tests:**
   - KNOWN_SKIPPED_IDS contains 64 entries (or verify a few known ones like 41)
   - KNOWN_DUPLICATE_IDS contains exactly [366, 367, 368, 369]

**Test approach:** Use inline markdown strings as test fixtures (NOT reading
real archive files). This keeps tests fast and deterministic. Copy small
representative snippets from actual archives to use as test data.

Follow the project pattern: tests compile via tsconfig.json in scripts/reviews/,
run with `node --test` from dist-tests. </action> <verify> Run:
`cd scripts/reviews && npx tsc && node --test dist-tests/__tests__/parse-review.test.js`
-- all tests pass. </verify> <done> All parser tests pass including heading
variants, table parsing, field extraction, completeness tier assignment, and
known-ID sets. Zero TypeScript errors. </done> </task>

</tasks>

<verification>
1. `cd scripts/reviews && npx tsc --noEmit` passes with zero errors
2. `cd scripts/reviews && npx tsc && node --test dist-tests/__tests__/parse-review.test.js` -- all tests pass
3. parse-review.ts exports: parseArchiveFile, parseTableArchive, toV2ReviewRecord, KNOWN_SKIPPED_IDS, KNOWN_DUPLICATE_IDS
4. toV2ReviewRecord output passes ReviewRecord.parse() for full/partial/stub tiers
</verification>

<success_criteria> The parser module correctly extracts structured v2 records
from all observed markdown archive formats (heading-based and table-based),
deduplicates within-file entries, assigns correct completeness tiers, and
produces Zod-valid ReviewRecord objects. All tests pass. </success_criteria>

<output>
After completion, create `.planning/phases/02-backfill-data-migration/02-01-SUMMARY.md`
</output>
