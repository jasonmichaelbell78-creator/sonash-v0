{"source_id":"audit:SYST-2026-02-19-D22-001","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d22-sentry.jsonl","original_id":"SYST-2026-02-19-D22-001","category":"security","severity":"S1","type":"vulnerability","file":"lib/logger.ts","line":7,"title":"Dual-logger SENSITIVE_KEYS mismatch — client missing 7 PII keys, server missing 2 identity keys","description":"The client logger (lib/logger.ts:7) has 9 SENSITIVE_KEYS: token, authorization, password, uid, email, auth, idToken, accessToken, refreshToken. The server logger (functions/src/security-logger.ts:161) has 16 SENSITIVE_KEYS: token, authorization, password, secret, cookie, apikey, email, phone, ssn, credit, card, bearer, session, refresh, access, error. The client is missing 7 server keys including PII-critical ones: phone, ssn, credit, card. If client-side error context includes these keys, PII leaks to Sentry unredacted. The server is missing uid and auth keys, meaning user IDs in server log context may not be redacted.","recommendation":"Extract SENSITIVE_KEYS to a shared module or ensure both lists cover all PII-relevant keys. At minimum, add phone, ssn, credit, card to the client list.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["Client SENSITIVE_KEYS (lib/logger.ts:7-17): token, authorization, password, uid, email, auth, idToken, accessToken, refreshToken — 9 keys","Server SENSITIVE_KEYS (functions/src/security-logger.ts:161-178): token, authorization, password, secret, cookie, apikey, email, phone, ssn, credit, card, bearer, session, refresh, access, error — 16 keys","Client MISSING: secret, cookie, apikey, phone, ssn, credit, card, bearer, session, refresh, access, error — 12 keys not redacted on client","Server MISSING: uid, auth, idToken, accessToken, refreshToken — 5 keys not redacted on server","Different redaction algorithms: client uses looksLikeSensitiveId heuristic, server uses isSensitiveKey key-name matching"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D22-002","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d22-sentry.jsonl","original_id":"SYST-2026-02-19-D22-002","category":"code-quality","severity":"S2","type":"code-smell","file":"next.config.mjs","line":1,"title":"No source map upload to Sentry — production stack traces are minified and unreadable","description":"next.config.mjs does not use withSentryConfig wrapper or any Sentry webpack plugin. No source map upload configuration exists. @sentry/nextjs v10.30.0 is installed and provides the withSentryConfig wrapper, but it's not being used. Production JavaScript is minified, so all error stack traces in Sentry show minified function names and line numbers, making debugging production errors significantly harder.","recommendation":"Wrap next.config.mjs export with withSentryConfig to enable automatic source map upload during builds.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"next.config.mjs — no withSentryConfig wrapper, no Sentry webpack plugin\n@sentry/nextjs v10.30.0 installed (includes withSentryConfig)\nNo .sentryclirc or sentry.properties file\nProduction stack traces will show minified code","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D22-003","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d22-sentry.jsonl","original_id":"SYST-2026-02-19-D22-003","category":"security","severity":"S2","type":"vulnerability","file":"functions/src/security-logger.ts","line":119,"title":"Server logger (security-logger.ts) does not strip control characters — log injection possible","description":"The client logger (lib/logger.ts:85-87) strips control characters using regex /[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]/g before logging, preventing log injection attacks. The server logger (functions/src/security-logger.ts) has no equivalent control character stripping. Malicious input containing ANSI escape codes or null bytes could be injected into GCP Cloud Logging, potentially manipulating log viewers, hiding entries, or exploiting log parsing tools.","recommendation":"Add control character stripping to the server logger's message formatting, matching the client logger's approach.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"lib/logger.ts:85-87 — strips control characters: message.replace(/[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]/g, '')\nfunctions/src/security-logger.ts — grep for control/strip/sanitize: 0 matches\nServer logs go to GCP Cloud Logging + Sentry + Firestore security_logs","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D21-001","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d21-self-audit.jsonl","original_id":"SYST-2026-02-19-D21-001","category":"code-quality","severity":"S3","type":"code-smell","file":"docs/audits/system-test/audit-2026-02-19/domains/d18-admin.jsonl","line":1,"title":"Domain 18 (Admin Panel, MEDIUM risk) produced 0 findings — potential under-scrutiny","description":"Domain 18 was rated MEDIUM risk with expected finding count of 3-8, but all 5 checks (18.1-18.5) passed with no issues found. The admin panel uses consistent requireAdmin() authorization, all 17 tabs map to corresponding Cloud Functions, CRUD operations use proper soft-delete patterns, and input validation uses Zod schemas via withSecurityChecks(). While a clean domain is possible, 0 findings in a MEDIUM-risk domain warrants flagging for transparency.","recommendation":"No action required — flagged for self-audit transparency. The admin panel's clean implementation reflects the withSecurityChecks() wrapper pattern applied consistently across all admin functions.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Domain 18 checks: 18.1 (tab inventory) PASS, 18.2 (tab-function mapping) PASS, 18.3 (auth uniformity) PASS, 18.4 (CRUD completeness) PASS, 18.5 (soft-delete consistency) PASS\nExpected findings: 3-8, Actual findings: 0\nAll admin Cloud Functions use requireAdmin() wrapper\nAll admin operations validated via withSecurityChecks() with Zod schemas","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D21-002","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d21-self-audit.jsonl","original_id":"SYST-2026-02-19-D21-002","category":"code-quality","severity":"S3","type":"code-smell","file":"docs/audits/system-test/audit-2026-02-19/PLAN_INDEX.md","line":1,"title":"7 checks across 3 domains not fully executable in static analysis context","description":"Several SKILL.md checks require runtime testing or browser-based verification that cannot be performed in a static analysis audit session: Check 15.2 (service worker registration behavior) requires a running browser. Check 6.3 (keyboard navigation) requires interactive testing. Check 8.1 (security headers at runtime) requires HTTP response inspection. Check 12.1 (Lighthouse performance score) requires running Lighthouse. These checks were assessed via code review and configuration analysis rather than runtime verification, which may miss runtime-only issues.","recommendation":"Supplement this audit with runtime testing using /test-suite or Playwright MCP for checks requiring browser interaction.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Checks assessed via static analysis only (no runtime verification):\n- 6.3 Keyboard navigation — assessed via code review, not interactive testing\n- 8.1 Security headers — assessed via firebase.json config, not HTTP response\n- 12.1 Lighthouse score — assessed via code patterns, not actual Lighthouse run\n- 15.2 Service worker — confirmed missing via code search, runtime test unnecessary\n- 22.1 Client Sentry config — assessed via code, not runtime initialization check\nAll findings from these checks are valid but runtime testing would increase confidence","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D20-001","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d20-report.jsonl","original_id":"SYST-2026-02-19-D20-001","category":"code-quality","severity":"S2","type":"code-smell","file":"functions/src/security-wrapper.ts","line":1,"title":"Cross-cutting pattern: validation and security boundary gaps span 6 domains","description":"A recurring pattern of validation gaps at system boundaries appears across domains 7, 8, 9, 11, 19, and 22. Domain 7 found Cloud Functions missing App Check enforcement. Domain 8 found no Content-Security-Policy header. Domain 9 found no field-level validation in Firestore rules. Domain 11 found missing reCAPTCHA on sign-in/sign-up. Domain 19 found non-transactional migration without idempotency. Domain 22 found inconsistent PII redaction between loggers. These share a common root cause: security controls are implemented in some layers but not uniformly across all boundaries.","recommendation":"Address as a systemic initiative: create a security boundary checklist and audit all entry points (client API calls, Cloud Functions, Firestore rules, auth flows) for consistent validation depth.","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"D07-001: App Check enforceAppCheck disabled in production\nD08-002: No Content-Security-Policy header\nD09-002: No field-level validation in admin-writable Firestore rules\nD11-003: Sign-in/sign-up lack reCAPTCHA protection\nD19-002: Migration lacks idempotency tracking\nD22-001: Dual-logger SENSITIVE_KEYS mismatch (9 vs 16 keys)","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D20-002","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d20-report.jsonl","original_id":"SYST-2026-02-19-D20-002","category":"code-quality","severity":"S2","type":"code-smell","file":"public/manifest.json","line":1,"title":"Cross-cutting pattern: incomplete observability pipeline — gaps in monitoring, backups, and offline resilience","description":"Multiple domains reveal a pattern of incomplete operational readiness: Domain 15 found no service worker despite PWA manifest and install prompt. Domain 15 also found no Firestore offline persistence. Domain 19 found no automated backup strategy. Domain 22 found no source map upload for production debugging. These share a common theme: the app has good application-level code quality but lacks operational infrastructure for resilience, recovery, and production debugging.","recommendation":"Create an operational readiness checklist covering: backups, offline support, source maps, monitoring alerts, and disaster recovery. Prioritize based on user impact.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"D15-001: No service worker — PWA installable but broken offline\nD15-002: No Firestore offline persistence despite offline indicator\nD19-001: No automated Firestore backup/export strategy\nD22-002: No source map upload — production stack traces minified","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D19-001","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d19-data.jsonl","original_id":"SYST-2026-02-19-D19-001","category":"code-quality","severity":"S2","type":"code-smell","file":"firebase.json","line":72,"title":"No automated Firestore backup/export strategy — recovery depends entirely on Google infrastructure","description":"No automated Firestore export, backup schedule, or disaster recovery configuration exists. There are no backup scripts in scripts/, no Cloud Functions for scheduled exports, and no GCS backup bucket configured. The INCIDENT_RESPONSE.md covers cost spikes, security events, and outages but does not document backup/restore procedures or define RTO/RPO targets. Recovery journals, daily logs, and inventory entries have no point-in-time recovery capability beyond Google's built-in multi-zone replication.","recommendation":"Configure scheduled Firestore exports to Cloud Storage using gcloud firestore export or a Cloud Function. Define RTO/RPO targets in INCIDENT_RESPONSE.md.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"firebase.json — no backup configuration\nNo gcloud firestore export commands in scripts/\nNo Cloud Functions for scheduled Firestore exports\nINCIDENT_RESPONSE.md — no backup/restore section, no RTO/RPO targets\nAll user data (journals, daily_logs, inventoryEntries) has no point-in-time recovery","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D19-002","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d19-data.jsonl","original_id":"SYST-2026-02-19-D19-002","category":"code-quality","severity":"S2","type":"code-smell","file":"functions/src/index.ts","line":486,"title":"Anonymous user migration uses batch writes without transactions — partial migration possible","description":"migrateAnonymousUserData (functions/src/index.ts:486-765) migrates journal, daily_logs, and inventoryEntries using paginated batch writes (100-doc pages, 499-op batches). While this approach handles Firestore's 500-op transaction limit correctly, it means a failure partway through leaves data partially migrated. The client-side account-linking.ts handles this by returning success:true with a warning ('Some data may not have transferred'), but the user's anonymous account data could become orphaned if the anonymous account is later cleaned up.","recommendation":"Add a migration status document that tracks which collections were successfully migrated, enabling retry of failed collections without re-migrating completed ones.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"functions/src/index.ts:486-765 — migrateAnonymousUserData uses batch writes, not transactions\nBatch size: 499 operations (just under Firestore 500 limit)\nPage size: 100 documents per page\nlib/auth/account-linking.ts:355-361 — returns success:true with warning on migration failure\nNo migration status tracking document for retry capability","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D17-001","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d17-prior.jsonl","original_id":"SYST-2026-02-19-D17-001","category":"process","severity":"S2","type":"process-gap","file":"docs/technical-debt/MASTER_DEBT.jsonl","line":1,"title":"19 non-resolved S0 critical items and 383 open S1 items in TDMS backlog","description":"MASTER_DEBT.jsonl contains 40 S0 items of which only 19 are resolved and 2 are false positives — leaving 19 open S0 critical items (15 VERIFIED + 4 NEW). Additionally, 383 S1 items remain in VERIFIED status. Key open S0 items include: App Check disabled in production (DEBT-0853), CI security vulnerability with pull_request_target (DEBT-1878), 57 AI Instructions sections adding ~4,500 unnecessary lines (DEBT-2381), and multiple cognitive complexity violations in admin.ts and component files.","recommendation":"Prioritize S0 triage: resolve or re-classify the 19 open S0 items. Schedule a sprint to address the top 10 S1 items by impact.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Total TDMS items: 2672\nS0 breakdown: 40 total — 19 RESOLVED, 2 FALSE_POSITIVE, 15 VERIFIED, 4 NEW\nS1 breakdown: 439 total — 383 VERIFIED (open)\nResolution rate: 11% overall\nOpen critical items include DEBT-0853 (App Check disabled), DEBT-1878 (CI security), DEBT-2381 (AI Instructions bloat)","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D17-002","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d17-prior.jsonl","original_id":"SYST-2026-02-19-D17-002","category":"process","severity":"S3","type":"process-gap","file":"docs/audits/multi-ai/maa-2026-02-17-182d43/final/UNIFIED-FINDINGS.jsonl","line":1,"title":"Multi-AI audit (maa-2026-02-17) incomplete — 65 unified findings never triaged","description":"The multi-AI audit session maa-2026-02-17-182d43 generated 65 unified findings in final/UNIFIED-FINDINGS.jsonl but the workflow never progressed past the 'starting' phase. All 9 category audits remain in PENDING status. The 65 findings have not been triaged, reviewed, or synced to MASTER_DEBT.jsonl, meaning potential consensus findings from multiple AI reviewers are sitting unprocessed.","recommendation":"Either complete the multi-AI audit workflow (triage the 65 findings) or mark the session as abandoned and sync high-confidence findings manually.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Session status: IN_PROGRESS, phase: starting\nAll 9 categories: PENDING (0 findings processed)\n65 unified findings generated but untriaged\nLast updated: 2026-02-17T20:33:13.075Z (2 days ago, no progress)","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D16-001","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d16-tdms.jsonl","original_id":"SYST-2026-02-19-D16-001","category":"code-quality","severity":"S2","type":"code-smell","file":"docs/technical-debt/MASTER_DEBT.jsonl","line":1,"title":"172 duplicate source_ids in MASTER_DEBT.jsonl — deduplication needed","description":"MASTER_DEBT.jsonl contains 2672 items but only 2500 unique source_ids. 172 items share source_ids with other entries, indicating duplicate imports from audit sources. Duplicates inflate severity counts and make triage unreliable.","recommendation":"Run deduplication script to merge or remove duplicate source_ids, keeping the most recent or most detailed version.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Total items: 2672, Unique source_ids: 2500, Duplicates: 172\nDuplicate entries likely from overlapping audit imports or re-syncs\nStatus breakdown: VERIFIED: 2019, RESOLVED: 298, FALSE_POSITIVE: 272, NEW: 83","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D16-002","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d16-tdms.jsonl","original_id":"SYST-2026-02-19-D16-002","category":"code-quality","severity":"S3","type":"code-smell","file":"docs/technical-debt/MASTER_DEBT.jsonl","line":1,"title":"144 TDMS items with empty descriptions and 1 untitled item","description":"MASTER_DEBT.jsonl contains 144 items where the description field is empty string, and 1 item with title 'Untitled'. These items lack the context needed for triage and resolution. Empty descriptions make it impossible to understand the issue without reading the source audit file.","recommendation":"Backfill empty descriptions from source audit files, or mark items as FALSE_POSITIVE if they lack actionable detail.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Empty descriptions: 144 items with description == ''\nUntitled: 1 item with title == 'Untitled'\nTotal items: 2672","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D16-003","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d16-tdms.jsonl","original_id":"SYST-2026-02-19-D16-003","category":"code-quality","severity":"S3","type":"code-smell","file":"docs/technical-debt/MASTER_DEBT.jsonl","line":1,"title":"298 RESOLVED items missing resolved_at timestamp","description":"MASTER_DEBT.jsonl has 298 items with status RESOLVED but none have a resolved_at timestamp field populated. This makes it impossible to track resolution velocity or calculate time-to-resolve metrics.","recommendation":"Add resolved_at timestamps to RESOLVED items based on git history of when status changed, or set to current date as approximation.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"RESOLVED items: 298\nItems with resolved_at field: 0\nMissing data prevents resolution velocity tracking","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D15-001","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d15-pwa.jsonl","original_id":"SYST-2026-02-19-D15-001","category":"code-quality","severity":"S1","type":"code-smell","file":"public/manifest.json","line":1,"title":"No service worker — app cannot function offline despite PWA manifest and install prompt","description":"The app has a manifest.json, install prompt (components/pwa/install-prompt.tsx), and offline indicator (components/status/offline-indicator.tsx), but no service worker exists. No sw.js, service-worker.js, or workbox config found. No PWA packages (workbox, next-pwa) in dependencies. Users who install the PWA cannot use it offline — they get a blank/error page.","recommendation":"Implement a service worker using Workbox or Serwist for precaching the app shell and providing offline fallback.","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["No service worker files found (sw.js, service-worker.js — 0 results)","No navigator.serviceWorker registration code in codebase","No workbox, next-pwa, or serwist packages in package.json","manifest.json exists with display: standalone — installable but not offline-capable","components/pwa/install-prompt.tsx exists and uses beforeinstallprompt correctly"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D15-002","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d15-pwa.jsonl","original_id":"SYST-2026-02-19-D15-002","category":"code-quality","severity":"S2","type":"code-smell","file":"lib/firebase.ts","line":54,"title":"No Firestore offline persistence — offline indicator promises sync that cannot happen","description":"Firebase Firestore is initialized without enableIndexedDbPersistence() or enablePersistence(). The offline indicator component displays 'Offline - changes will sync when reconnected' but there is no persistence layer to queue offline writes. Any Firestore writes attempted while offline will fail silently or throw errors.","recommendation":"Enable Firestore offline persistence with enableIndexedDbPersistence(db) or the newer persistentLocalCache config.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"lib/firebase.ts — _db = getFirestore(_app) with no enableIndexedDbPersistence() call\nGrep for enablePersistence: 0 results\nGrep for enableIndexedDbPersistence: 0 results\ncomponents/status/offline-indicator.tsx:45-51 — displays 'changes will sync when reconnected'","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D15-003","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d15-pwa.jsonl","original_id":"SYST-2026-02-19-D15-003","category":"code-quality","severity":"S3","type":"code-smell","file":"public/manifest.json","line":11,"title":"PWA manifest icon sizes mismatch — declares 192x192/512x512 but file is 1024x1024 JPEG","description":"public/manifest.json declares icon sizes '192x192 512x512' but references a single file /pwa-icon.jpg. The actual file is 1024x1024 pixels. Browsers expect the declared sizes to match actual file dimensions. Additionally, using JPEG instead of PNG means no transparency support. Best practice is separate files for each size.","recommendation":"Generate properly-sized icon files (192x192.png and 512x512.png) and update manifest.json to reference them separately.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"manifest.json:11-15 — sizes: '192x192 512x512' but file is /pwa-icon.jpg (single 1024x1024 file)\nmanifest.json:16-19 — second entry with sizes: 'any' also references same file\nJPEG format lacks transparency — PNG preferred for PWA icons","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D14-001","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d14-docs.jsonl","original_id":"SYST-2026-02-19-D14-001","category":"documentation","severity":"S3","type":"tech-debt","file":"docs/templates/CANON_QUICK_REFERENCE.md","line":1,"title":"CANON system uses JSONL output model — templates reference CANON-*.md files that don't exist as standalone docs","description":"The CANON system is implemented as JSONL-formatted audit outputs (e.g., docs/audits/multi-ai/*/canon/CANON-AI-OPTIMIZATION.jsonl) and canonical document templates (CANONICAL_DOC_TEMPLATE.md, CANON_QUICK_REFERENCE.md). However, no dedicated CANON-*.md files exist in a standard location. The templates reference a pattern (CANON-NNNN numbered entries) that maps to Firestore validation schemas rather than standalone markdown docs. This dual interpretation could confuse new contributors.","recommendation":"Add a brief note in CANON_QUICK_REFERENCE.md clarifying that CANON entries are JSONL audit outputs, not standalone markdown files.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"docs/templates/CANONICAL_DOC_TEMPLATE.md exists (469 lines) — template for canonical documents\ndocs/templates/CANON_QUICK_REFERENCE.md exists (171 lines) — references CANON-NNNN pattern\ndocs/audits/multi-ai/maa-2026-02-17-182d43/canon/ — contains JSONL CANON files\nNo standalone CANON-*.md files exist in docs/reviews/CANON/ or similar","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D13-001","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d13-config.jsonl","original_id":"SYST-2026-02-19-D13-001","category":"code-quality","severity":"S2","type":"code-smell","file":"firebase.json","line":68,"title":"Node.js runtime mismatch — firebase.json says nodejs24, functions/package.json says node 20","description":"firebase.json sets functions runtime to nodejs24 but functions/package.json engines.node is set to '20'. This mismatch means Cloud Functions deploy to Node 24 runtime but the package.json claims Node 20 compatibility. Developers running locally with Node 20 may not encounter issues that appear in production on Node 24.","recommendation":"Align both files to the same Node.js version — either update functions/package.json engines to '24' or change firebase.json runtime to 'nodejs20'.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"firebase.json:68 — \"runtime\": \"nodejs24\"\nfunctions/package.json:13-14 — \"engines\": { \"node\": \"20\" }\nLocal Node.js: v22.22.0 (yet another version)","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D13-002","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d13-config.jsonl","original_id":"SYST-2026-02-19-D13-002","category":"code-quality","severity":"S3","type":"code-smell","file":"functions/tsconfig.dev.json","line":1,"title":"Stale functions/tsconfig.dev.json references non-existent .eslintrc.js","description":"functions/tsconfig.dev.json contains { \"include\": [\".eslintrc.js\"] } but .eslintrc.js does not exist — the project migrated to ESLint flat config (eslint.config.mjs). This is a dead config file that serves no purpose.","recommendation":"Delete functions/tsconfig.dev.json — it's a leftover from the ESLint legacy config migration.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"functions/tsconfig.dev.json:2 — \"include\": [\".eslintrc.js\"]\nfunctions/.eslintrc.js does not exist (confirmed via ls)\nfunctions/eslint.config.mjs exists (flat config migration completed)","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D13-003","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d13-config.jsonl","original_id":"SYST-2026-02-19-D13-003","category":"code-quality","severity":"S3","type":"code-smell","file":"package.json","line":1,"title":"Root package.json has no engines field — no Node.js version constraint","description":"Root package.json does not specify an engines field. Developers can use any Node.js version without warning. functions/package.json specifies engines.node: '20' but the root project has no constraint, creating inconsistency.","recommendation":"Add engines field to root package.json specifying the minimum Node.js version (e.g., '>=20').","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Root package.json — no 'engines' field found\nfunctions/package.json:13-14 — \"engines\": { \"node\": \"20\" }\nLocal Node.js: v22.22.0 — works fine but no enforcement","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D12-001","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d12-perf.jsonl","original_id":"SYST-2026-02-19-D12-001","category":"performance","severity":"S2","type":"code-smell","file":"next.config.mjs","line":14,"title":"Image optimization disabled — no alternative optimization for static export","description":"next.config.mjs sets images.unoptimized: true which disables all Next.js Image Optimization (responsive sizing, WebP conversion, lazy loading optimization). This is required for output: 'export' (Firebase Hosting static deployment) because Next.js Image Optimization needs a server. However, no alternative image optimization pipeline exists — images are served at original size on all devices.","recommendation":"Add a build-time image optimization step using sharp or next-optimized-images, or use a CDN with image transformation (e.g., Firebase Extensions Image Resizing).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"next.config.mjs:14-16 — images: { unoptimized: true } disables all Next.js image optimization\noutput: 'export' (line 13) requires unoptimized: true since no server for on-demand optimization\ncomponents/notebook/book-cover.tsx uses next/image with fill and sizes props but optimization is bypassed","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D12-002","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d12-perf.jsonl","original_id":"SYST-2026-02-19-D12-002","category":"performance","severity":"S2","type":"code-smell","file":"lib/db/meetings.ts","line":133,"title":"Multiple unbounded Firestore queries without limit() — deprecated getAllMeetings still accessible","description":"Several Firestore queries fetch entire collections without limit(): (1) MeetingsService.getAllMeetings() fetches all meetings (marked @deprecated but still exported), (2) SoberLivingService.getAllHomes() fetches all sober_living docs, (3) GlossaryService.getAllTerms() fetches all glossary docs. While paginated alternatives exist for meetings, the deprecated method is still importable and the other services have no pagination.","recommendation":"Remove deprecated getAllMeetings() or make it private. Add limit() to getAllHomes() and getAllTerms() queries.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"lib/db/meetings.ts:133-155 — getAllMeetings() uses getDocs(meetingsRef) with no limit (marked @deprecated)\nlib/db/sober-living.ts:30-34 — getAllHomes() uses query(collection(db, COLLECTION)) with no limit\nlib/db/glossary.ts:25-29 — getAllTerms() uses query(collection(db, COLLECTION)) with no limit\nContrast: meetings.ts:165-214 — getAllMeetingsPaginated() properly uses limit(pageSize)","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D12-003","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d12-perf.jsonl","original_id":"SYST-2026-02-19-D12-003","category":"performance","severity":"S3","type":"code-smell","file":"components/notebook/book-cover.tsx","line":246,"title":"Inline SVG data URIs in style props for book texture effects","description":"book-cover.tsx and notebook-shell.tsx embed large SVG noise textures as data URIs in inline style props. These are re-serialized on every render and increase component size. The SVGs generate fractalNoise patterns used for paper texture effects.","recommendation":"Extract SVG textures to static CSS classes or separate .svg files in /public. Reference via className instead of inline style. This avoids re-serialization and enables browser caching.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"book-cover.tsx:246-251 — backgroundImage: url(data:image/svg+xml,...) with fractalNoise SVG\nnotebook-shell.tsx:223-228 — similar inline SVG texture pattern\nBoth use style props causing new object creation per render","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D12-004","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d12-perf.jsonl","original_id":"SYST-2026-02-19-D12-004","category":"performance","severity":"S3","type":"code-smell","file":"components/notebook/book-cover.tsx","line":1,"title":"All 117+ components marked 'use client' — redundant when parent is already client component","description":"Every component file includes 'use client' directive at line 1, even leaf components rendered inside already-client parent components. When a parent component is 'use client', all its children are automatically client components. The redundant directives add noise and prevent any future optimization with Server Components.","recommendation":"Informational. With output: 'export', Server Components are not available anyway. If migrating to SSR in the future, audit and remove redundant 'use client' directives from leaf components that don't use hooks or browser APIs.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"All 117+ component files start with 'use client' directive\nbook-cover.tsx:1 — 'use client' (parent of dynamic child components)\nnotebook-shell.tsx:1 — 'use client' (child of book-cover)\nAll leaf components like enhanced-mood-selector.tsx:1 — 'use client' (already inside client tree)","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D11-001","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d11-auth.jsonl","original_id":"SYST-2026-02-19-D11-001","category":"security","severity":"S2","type":"vulnerability","file":"lib/firebase.ts","line":54,"title":"Implicit localStorage persistence — no session management for shared devices","description":"Firebase Auth is initialized without explicit setPersistence() call. The SDK defaults to browserLocalPersistence (localStorage), meaning sessions survive browser close and device restart. For a recovery community app where users may share devices, this means User B could access User A's data without re-authenticating.","recommendation":"Configure explicit session persistence (browserSessionPersistence) or add re-auth prompt on app launch.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"lib/firebase.ts:54 → _auth = getAuth(_app); // No setPersistence call\nGrep for setPersistence: 0 results in app code\nGrep for browserSessionPersistence: 0 results\nFirebase default = browserLocalPersistence (sessions survive browser close)","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D11-002","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d11-auth.jsonl","original_id":"SYST-2026-02-19-D11-002","category":"code-quality","severity":"S2","type":"code-smell","file":"functions/src/index.ts","line":688,"title":"Anonymous-to-auth migration has partial failure risk with inconsistent success reporting","description":"The migrateAnonymousUserData Cloud Function uses multiple Firestore batch writes that are not atomic across batches. If batch 3 of 5 fails, batches 1-2 are permanently committed with no rollback. Additionally, the Google OAuth migration path in account-linking.ts returns success: true even when migration fails, potentially misleading the user about their data state.","recommendation":"Add migration status tracking and change Google OAuth error path to return success: false when migration fails.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"functions/src/index.ts:688-722 → Non-atomic batch loop: for (let i = 0; i < batches.length; i++) { await batches[i].commit(); } — catch logs PARTIAL_MIGRATION_FAILURE\naccount-linking.ts:351-361 → Google path catch: returns { success: true, user: result.user, warning: 'Some data may not have transferred' }","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D11-003","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d11-auth.jsonl","original_id":"SYST-2026-02-19-D11-003","category":"security","severity":"S1","type":"vulnerability","file":"components/auth/sign-in-modal.tsx","line":49,"title":"Sign-in and sign-up lack reCAPTCHA protection — primary auth surface unprotected","description":"RECAPTCHA_ACTIONS in secure-caller.ts covers journal, daily log, inventory, and account linking operations. However, sign-in-modal.tsx calls Firebase Auth SDK directly (signInWithEmailAndPassword, createUserWithEmailAndPassword) without any reCAPTCHA token. This leaves the primary authentication surface unprotected against brute force attacks and automated account creation.","recommendation":"Add reCAPTCHA Enterprise to sign-in and sign-up flows via Cloud Function wrapper or Firebase App Check's built-in reCAPTCHA integration.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["sign-in-modal.tsx:49 — await createUserWithEmailAndPassword(auth, email, password) with no reCAPTCHA","sign-in-modal.tsx:51 — await signInWithEmailAndPassword(auth, email, password) with no reCAPTCHA","lib/utils/secure-caller.ts:23-36 — RECAPTCHA_ACTIONS has no sign_in or sign_up action","Contrast: account-linking.ts:201 — getRecaptchaToken('migrate_user_data') — linking IS protected"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D11-004","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d11-auth.jsonl","original_id":"SYST-2026-02-19-D11-004","category":"security","severity":"S2","type":"vulnerability","file":"components/auth/account-link-modal.tsx","line":45,"title":"Password requirements minimal — 6 characters only, no complexity enforcement","description":"Email/password authentication enforces only a 6-character minimum (Firebase default + client validation in account-link-modal.tsx). No complexity requirements are enforced: no uppercase, numbers, or special characters required. For a recovery community app storing sensitive personal data, this allows trivially guessable passwords.","recommendation":"Enforce minimum 8 characters with mixed case and numbers for email/password authentication.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"account-link-modal.tsx:45-54 → if (password.length < 6) { setError('Password must be at least 6 characters'); }\nlib/utils/errors.ts:71 → 'auth/weak-password': 'Password should be at least 6 characters'\nNo complexity regex, no strength meter, no server-side validation beyond Firebase 6-char minimum","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D11-005","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d11-auth.jsonl","original_id":"SYST-2026-02-19-D11-005","category":"security","severity":"S2","type":"vulnerability","file":"lib/auth/account-linking.ts","line":82,"title":"Account linking error messages reveal user existence for enumeration","description":"The account linking flow in account-linking.ts returns specific error messages that reveal whether an email is registered: 'This email is already registered. Try signing in instead.' This enables user enumeration attacks. The sign-in flow correctly uses generic 'Invalid email or password' messages, but the linking flow is inconsistent.","recommendation":"Change account linking error messages to generic text that does not reveal user existence.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"account-linking.ts:82-85 → 'auth/email-already-in-use': { message: 'This email is already registered. Try signing in instead.' }\naccount-linking.ts:80 → 'auth/credential-already-in-use': { message: 'This email or Google account is already linked to another user.' }\nContrast: sign-in-modal.tsx:59 → 'Invalid email or password.' (generic, correct)","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D10-001","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d10-env.jsonl","original_id":"SYST-2026-02-19-D10-001","category":"security","severity":"S2","type":"vulnerability","file":".env.production","line":1,"title":".env.production tracked in git with Firebase config and Sentry DSN","description":".env.production is committed to the repository containing NEXT_PUBLIC_FIREBASE_API_KEY, NEXT_PUBLIC_FIREBASE_APPCHECK_RECAPTCHA_SITE_KEY, and NEXT_PUBLIC_SENTRY_DSN. While Firebase client config is designed to be public, tracking a .env.production file normalizes the pattern of committing env files and makes it easy to accidentally add secrets in the future.","recommendation":"Move .env.production values to CI vars/secrets and remove file from git tracking.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"git ls-files .env.production → tracked\nContains: NEXT_PUBLIC_FIREBASE_API_KEY=AIzaSy..., NEXT_PUBLIC_FIREBASE_APPCHECK_RECAPTCHA_SITE_KEY=6Lde..., NEXT_PUBLIC_SENTRY_DSN=https://f585...","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D10-002","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d10-env.jsonl","original_id":"SYST-2026-02-19-D10-002","category":"security","severity":"S2","type":"vulnerability","file":".gitignore","line":34,"title":".gitignore pattern doesn't cover .env.production","description":".gitignore has '.env*.local' pattern which covers .env.local but .env.production does not match this glob. The file is intentionally tracked but should have an explicit decision comment in .gitignore explaining why.","recommendation":"Add .env.production to .gitignore or add an explicit comment explaining why it is tracked.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":".gitignore:34 → .env*.local\nThis covers: .env.local, .env.development.local, .env.test.local\nDoes NOT cover: .env.production (tracked in git)","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D10-003","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d10-env.jsonl","original_id":"SYST-2026-02-19-D10-003","category":"security","severity":"S3","type":"vulnerability","file":".env.production","line":20,"title":"Sentry DSN committed in .env.production","description":"NEXT_PUBLIC_SENTRY_DSN is hardcoded in .env.production (committed to git). While Sentry DSNs are semi-public (they end up in client-side JavaScript anyway), best practice is to source from CI environment only to maintain separation of config from code.","recommendation":"Move to GitHub Actions variable (add NEXT_PUBLIC_SENTRY_DSN to vars in deploy workflow). Remove from .env.production.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":".env.production:20 → NEXT_PUBLIC_SENTRY_DSN=https://f585a8353ec50d104e5484fedca6c2f2@o4510530873589760.ingest.us.sentry.io/4510711416094720","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D09-001","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d09-rules.jsonl","original_id":"SYST-2026-02-19-D09-001","category":"code-quality","severity":"S1","type":"code-smell","file":"firestore.rules","line":98,"title":"Admin CRUD for sober_living broken — rules block all client writes","description":"The sober-living admin tab uses direct Firestore client SDK writes (addDoc, updateDoc, deleteDoc via SoberLivingService), but firestore.rules sets 'allow write: if false' for the sober_living collection. All admin write operations for sober living homes will be denied by Firestore in production. The meetings tab correctly uses Cloud Functions (httpsCallable → adminSaveMeeting) which bypass rules via Admin SDK.","recommendation":"Migrate sober-living-tab to use Cloud Functions like meetings-tab (preferred — consistent pattern), or change rules to allow write: if isAdmin() with field validation.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["firestore.rules:98 — allow write: if false; for sober_living collection","components/admin/sober-living-tab.tsx:126-131 uses SoberLivingService (direct client addDoc/updateDoc/deleteDoc)","Contrast: components/admin/meetings-tab.tsx:309 uses cloudFunctions: { saveFunctionName, deleteFunctionName }"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D09-002","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d09-rules.jsonl","original_id":"SYST-2026-02-19-D09-002","category":"security","severity":"S2","type":"vulnerability","file":"firestore.rules","line":104,"title":"No field-level validation in rules for admin-writable public collections","description":"Collections daily_quotes, glossary, slogans, quick_links, and prayers allow 'write: if isAdmin()' without any field-level validation. An admin user could write arbitrary fields, incorrect data types, or oversized documents. While admin is trusted, missing validation allows accidental data corruption.","recommendation":"Add field-level validation (keys, types) to admin-writable collection rules.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"firestore.rules:104 → allow write: if isAdmin(); // daily_quotes\nfirestore.rules:112 → allow write: if isAdmin(); // glossary\nfirestore.rules:117 → allow write: if isAdmin(); // slogans\nfirestore.rules:124 → allow write: if isAdmin(); // quick_links\nfirestore.rules:130 → allow write: if isAdmin(); // prayers\nNone have request.resource.data field validation.","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D09-003","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d09-rules.jsonl","original_id":"SYST-2026-02-19-D09-003","category":"security","severity":"S2","type":"vulnerability","file":"firestore.rules","line":34,"title":"Soft-deleted documents still readable via Firestore rules","description":"Firestore rules for journal, daily_logs, and inventoryEntries allow read access to all documents owned by the user regardless of isDeleted status. Soft-deleted documents remain accessible until the scheduled hard-delete job runs. A client-side bug could display deleted entries to users.","recommendation":"Add isDeleted != true condition to read rules for journal, daily_logs, and inventoryEntries.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"firestore.rules:34 → allow read: if isOwner(userId); // journal — no isDeleted filter\nfirestore.rules:48 → allow read: if isOwner(userId); // daily_logs — no isDeleted filter\nfirestore.rules:62 → allow read: if isOwner(userId); // inventoryEntries — no isDeleted filter\nNo where clause equivalent in rules to filter isDeleted == true.","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D09-004","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d09-rules.jsonl","original_id":"SYST-2026-02-19-D09-004","category":"performance","severity":"S2","type":"code-smell","file":"components/growth/DailySloganWidget.tsx","line":26,"title":"Unbounded reads on public collections (slogans, sober_living)","description":"DailySloganWidget.tsx fetches all slogans via getDocs(slogansRef) with no limit(). SoberLivingService.getAllHomes() fetches all sober_living docs. While these are currently small admin-managed collections, there is no guard against growth. Public collections with 'allow read: if true' are accessible to any authenticated or unauthenticated user.","recommendation":"Add limit() to slogans and sober_living queries to prevent unbounded reads.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"DailySloganWidget.tsx:26 → const snapshot = await getDocs(slogansRef); // No limit\nlib/db/sober-living.ts:31 → const q = query(collection(db, COLLECTION)); // No limit\nBoth are public collections (allow read: if true) fetched without limit().","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D09-005","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d09-rules.jsonl","original_id":"SYST-2026-02-19-D09-005","category":"security","severity":"S3","type":"vulnerability","file":"firestore.rules","line":1,"title":"No rate limiting at Firestore rules level","description":"Firestore rules do not implement any rate limiting. All rate limiting is handled in Cloud Functions via the security wrapper. Public collections with 'allow read: if true' (meetings, sober_living, daily_quotes, glossary, slogans, quick_links, prayers) have no read-side rate limiting, making them vulnerable to read storms from unauthenticated clients.","recommendation":"Informational. Firestore rules-level rate limiting is complex and has limited support. Consider App Check enforcement at the rules level: allow read: if request.auth != null || firebase.appCheck.valid; This at least ensures reads come from verified app instances.","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"All public collections use 'allow read: if true' with no rate limiting functions.\nRate limiting exists in functions/src/security-wrapper.ts for write operations only.\nrate_limits collection exists (line 148) but only used by Cloud Functions server-side.","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D08-001","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d08-security.jsonl","original_id":"SYST-2026-02-19-D08-001","category":"security","severity":"S1","type":"vulnerability","file":"firebase.json","line":53,"title":"Permissions-Policy blocks microphone despite voice-text-area feature","description":"firebase.json sets Permissions-Policy: microphone=() which blocks the Web Speech Recognition API used by voice-text-area.tsx. The header actively prevents a shipped feature from working.","recommendation":"Change to microphone=(self) in firebase.json Permissions-Policy header value to allow self-origin microphone access while blocking third-party access.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["firebase.json:53 — Permissions-Policy value: geolocation=(), microphone=(), camera=(), payment=(), usb=()","components/ui/voice-text-area.tsx uses Web Speech Recognition API (SpeechRecognition) which requires microphone permission","microphone=() denies all origins including self — blocks webkitSpeechRecognition"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D08-002","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d08-security.jsonl","original_id":"SYST-2026-02-19-D08-002","category":"security","severity":"S2","type":"vulnerability","file":"firebase.json","line":30,"title":"No Content-Security-Policy header configured","description":"No CSP header found in firebase.json hosting configuration. The app loads external scripts (reCAPTCHA Enterprise from google.com, Sentry monitoring) without CSP restrictions, allowing potential XSS vectors to load arbitrary external resources.","recommendation":"Add Content-Security-Policy header to firebase.json with script-src, connect-src, and style-src directives.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"firebase.json hosting.headers[] contains X-Frame-Options, X-Content-Type-Options, HSTS, Referrer-Policy, Permissions-Policy — but no Content-Security-Policy header.","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D08-003","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d08-security.jsonl","original_id":"SYST-2026-02-19-D08-003","category":"security","severity":"S2","type":"vulnerability","file":"firebase.json","line":37,"title":"HSTS missing preload and includeSubDomains directives","description":"firebase.json sets Strict-Transport-Security: max-age=63072000 but omits includeSubDomains and preload directives. Without includeSubDomains, subdomains can be served over HTTP. Without preload, the domain cannot be submitted to the HSTS preload list.","recommendation":"Add includeSubDomains and preload directives to HSTS header in firebase.json.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"firebase.json:37 — Strict-Transport-Security: max-age=63072000 (missing includeSubDomains; preload)","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D08-004","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d08-security.jsonl","original_id":"SYST-2026-02-19-D08-004","category":"security","severity":"S3","type":"vulnerability","file":"firebase.json","line":49,"title":"Referrer-Policy set to strict-origin could be stricter","description":"firebase.json sets Referrer-Policy: strict-origin which sends the origin on cross-origin requests. For a recovery community app handling sensitive data, strict-origin-when-cross-origin or no-referrer would provide stronger privacy protection by not leaking the origin to external services.","recommendation":"Change to Referrer-Policy: strict-origin-when-cross-origin (preserves path info for same-origin, origin-only for cross-origin) or no-referrer for maximum privacy.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"firebase.json:49 — Referrer-Policy: strict-origin","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D07-001","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d07-functions.jsonl","original_id":"SYST-2026-02-19-D07-001","category":"security","severity":"S1","type":"vulnerability","file":"functions/src/index.ts","line":84,"title":"App Check globally disabled on all 5 user-callable functions via requireAppCheck: false","description":"Every user-callable function (saveDailyLog, saveJournalEntry, softDeleteJournalEntry, saveInventoryEntry, migrateAnonymousUserData) has requireAppCheck: false with comment 'TEMPORARILY DISABLED'. migrateAnonymousUserData has entire App Check block commented out. Security wrapper defaults requireAppCheck to true but all callers override it.","recommendation":"Re-enable App Check on all user-callable functions. Investigate throttle issue that caused temporary disable.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["index.ts:84 — requireAppCheck: false, // TEMPORARILY DISABLED","index.ts:170,269,363 — same pattern on all user functions","index.ts:506-511 — App Check block commented out in migrateAnonymousUserData"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D07-002","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d07-functions.jsonl","original_id":"SYST-2026-02-19-D07-002","category":"security","severity":"S1","type":"vulnerability","file":"functions/src/index.ts","line":486,"title":"migrateAnonymousUserData bypasses security wrapper — reCAPTCHA optional, internal errors leaked","description":"migrateAnonymousUserData is the only user-callable function not using withSecurityChecks. reCAPTCHA is silently optional (logs WARNING and continues). Rate limit catch block passes raw rateLimitError.message to HttpsError (leaks internals). Zod error path at line 545 exposes raw validation messages to client.","recommendation":"Refactor migrateAnonymousUserData to use withSecurityChecks wrapper. Replace raw error messages with generic client-safe messages.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["index.ts:499-503 — throw new HttpsError('resource-exhausted', errorMessage) with raw internal message","index.ts:516-527 — reCAPTCHA missing → logs warning, continues without protection","index.ts:545 — throw new HttpsError('invalid-argument', 'Validation failed: ' + errorMessages)"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D07-003","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d07-functions.jsonl","original_id":"SYST-2026-02-19-D07-003","category":"code-quality","severity":"S1","type":"code-smell","file":"functions/package.json","line":14,"title":"Node.js engine version mismatch — package.json says node 20, firebase.json deploys nodejs24","description":"functions/package.json engines.node is '20' but firebase.json runtime is 'nodejs24'. Functions run on Node 24 in production but local dev/CI validates against Node 20. Behavior differences between versions may cause silent bugs.","recommendation":"Align engine version. Update functions/package.json to engines.node: '24'.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["functions/package.json:14 — engines: { node: '20' }","firebase.json:68 — runtime: 'nodejs24'"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D07-004","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d07-functions.jsonl","original_id":"SYST-2026-02-19-D07-004","category":"code-quality","severity":"S1","type":"code-smell","file":"functions/src/firestore-rate-limiter.ts","line":149,"title":"Rate limiter reset() uses wrong Firestore document key — rate limit clears never work","description":"consume() calls consumeByKey('user_${userId}', operation) producing doc key 'user_${userId}_${operation}'. But reset() constructs key as '${userId}_${operation}' — missing the 'user_' prefix. reset() deletes a non-existent document. Admin panel 'Clear Rate Limit' feature does nothing.","recommendation":"Fix reset() to use 'user_${userId}_${operation}' key matching consume().","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["consume() → consumeByKey('user_${userId}', operation) → doc key 'user_abc123_saveDailyLog'","reset() → docId = '${userId}_${operation}' → key 'abc123_saveDailyLog' — WRONG prefix"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D07-005","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d07-functions.jsonl","original_id":"SYST-2026-02-19-D07-005","category":"security","severity":"S2","type":"vulnerability","file":"functions/src/recaptcha-verify.ts","line":66,"title":"reCAPTCHA site key hard-coded as fallback literal in recaptcha-verify.ts","description":"Production reCAPTCHA site key committed in source code as a fallback. While site keys are public-facing, embedding in repo makes it unrotatable without code change.","recommendation":"Remove fallback literal. Require RECAPTCHA_SITE_KEY env var with fail-closed behavior.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["const siteKey = process.env.RECAPTCHA_SITE_KEY || '6LdeazosAAAAAMDNCh1hTUDKh_UeS6xWY1-85B2O'"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D07-006","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d07-functions.jsonl","original_id":"SYST-2026-02-19-D07-006","category":"code-quality","severity":"S2","type":"code-smell","file":"functions/src/index.ts","line":356,"title":"saveInventoryEntry uses wrong TypeScript generic — typeof schema instead of inferred type","description":"saveInventoryEntry declared as onCall<typeof inventoryEntrySchema> instead of onCall<InventoryEntryInput>. typeof inventoryEntrySchema is the Zod schema object type, not the validated output type. TypeScript provides no compile-time safety for request.data properties.","recommendation":"Change to onCall<InventoryEntryInput> using z.infer<typeof inventoryEntrySchema>.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["onCall<typeof inventoryEntrySchema> — wrong: schema type, not data type","Other functions use correct pattern: onCall<DailyLogData>"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D07-007","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d07-functions.jsonl","original_id":"SYST-2026-02-19-D07-007","category":"security","severity":"S2","type":"vulnerability","file":"functions/src/schemas.ts","line":32,"title":"Zod data fields are unbounded z.record — saveJournalEntry writes unsanitized data to Firestore","description":"journalEntrySchema and inventoryEntrySchema define data as z.record(z.string(), z.unknown()) with no size/depth limits. saveJournalEntry writes entryData directly to Firestore without sanitization. A malicious user can send megabytes of deeply nested JSON.","recommendation":"Add z.record constraints: max keys, max depth. Apply sanitizeData() to saveJournalEntry.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["schemas.ts:32,51 — data: z.record(z.string(), z.unknown()) — no limits","index.ts:196-213 — saveJournalEntry writes entryData directly without sanitization","saveInventoryEntry has sanitizeData() with MAX_DEPTH=50 but saveJournalEntry does not"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D07-008","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d07-functions.jsonl","original_id":"SYST-2026-02-19-D07-008","category":"security","severity":"S2","type":"vulnerability","file":"functions/src/admin.ts","line":707,"title":"Admin functions have no enforceAppCheck in onCall config","description":"All admin functions use onCall(async (request) => { requireAdmin() ... }) without enforceAppCheck option. Firebase Functions v2 supports onCall({ enforceAppCheck: true }, handler). An attacker with a valid admin token but no App Check token can call admin endpoints.","recommendation":"Add { enforceAppCheck: true } to all admin onCall declarations.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["admin.ts:707,765,797,859,897,987,1038,1166 — onCall without enforceAppCheck","requireAdmin checks auth claim but not request.app"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D07-009","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d07-functions.jsonl","original_id":"SYST-2026-02-19-D07-009","category":"security","severity":"S2","type":"vulnerability","file":"functions/src/firestore-rate-limiter.ts","line":108,"title":"Rate limiter console.warn leaks un-hashed user ID in logs","description":"When rate limit is exceeded, consumeByKey logs the Firestore doc key containing raw user_${userId} to console.warn. GCP Cloud Logging captures this. Rest of codebase hashes user IDs via hashUserId() before logging.","recommendation":"Hash the userId portion before logging. Use hashUserId() consistently.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["console.warn('Rate limit exceeded for ${docId}:', { requests, limit, ... })","docId = 'user_<rawUserId>_saveDailyLog' — raw UID in log"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D07-010","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d07-functions.jsonl","original_id":"SYST-2026-02-19-D07-010","category":"security","severity":"S2","type":"vulnerability","file":"functions/src/index.ts","line":556,"title":"migrateAnonymousUserData logs raw UIDs to Sentry (PII in third-party telemetry)","description":"Multiple logSecurityEvent calls include raw anonymousUid and targetUid in metadata without hashing. redactSensitiveMetadata only strips keys matching SENSITIVE_KEYS list — anonymousUid/targetUid are not on that list. Raw Firebase Auth UIDs are sent to Sentry.","recommendation":"Hash anonymousUid and targetUid before including in metadata. Or add to SENSITIVE_KEYS list.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["index.ts:555-560 — metadata: { anonymousUid: validatedData.anonymousUid, targetUid: validatedData.targetUid }","index.ts:724-738 — success log also includes raw UIDs","captureToSentry not set to false → goes to Sentry with raw UIDs"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D06-001","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d06-ui.jsonl","original_id":"SYST-2026-02-19-D06-001","category":"code-quality","severity":"S1","type":"code-smell","file":"app/layout.tsx","line":92,"title":"Single root ErrorBoundary — no granular error boundaries in page sections","description":"Only one ErrorBoundary exists in app/layout.tsx wrapping all children. No route-specific error.tsx, loading.tsx, or not-found.tsx files exist. No component-level error boundaries around Today tab, Journal feed, Growth cards, Admin tables, or Resource pages. A runtime error in any deeply nested component collapses the entire page.","recommendation":"Add granular ErrorBoundary wrappers around major page sections and add Next.js error.tsx/loading.tsx files to each route.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["Only boundary: <ErrorBoundary>{children}</ErrorBoundary> in layout.tsx:92","grep -r ErrorBoundary components/ returns 0 usages inside feature components","No error.tsx, loading.tsx, or not-found.tsx files in any app/ route"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D06-002","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d06-ui.jsonl","original_id":"SYST-2026-02-19-D06-002","category":"code-quality","severity":"S1","type":"code-smell","file":"components/notebook/pages/today-page.tsx","line":533,"title":"any type on Firestore DocumentSnapshot in today-page.tsx:533","description":"handleSnapshotUpdate callback uses (docSnap: any) bypassing TypeScript type safety. All subsequent property accesses are untyped.","recommendation":"Type as DocumentSnapshot<DocumentData> from firebase/firestore.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["(docSnap: any, isMounted: boolean) => { — line 533","All docSnap.exists(), docSnap.data() calls are untyped"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D06-003","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d06-ui.jsonl","original_id":"SYST-2026-02-19-D06-003","category":"security","severity":"S1","type":"vulnerability","file":"components/providers/auth-context.tsx","line":100,"title":"Direct client-side Firestore write in auth-context.tsx — bypasses Cloud Functions","description":"AuthProvider directly calls updateDoc() on the users collection to set lastActive timestamp on every auth state change. This bypasses Cloud Functions middleware, server-side validation, and requires the client to hold direct write permissions.","recommendation":"Move lastActive update to a Cloud Function triggered via onAuthStateChanged or a callable function.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["import { doc, updateDoc, serverTimestamp } from 'firebase/firestore'","await updateDoc(doc(db, 'users', currentUser.uid), { lastActive: serverTimestamp() })"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D06-004","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d06-ui.jsonl","original_id":"SYST-2026-02-19-D06-004","category":"code-quality","severity":"S2","type":"code-smell","file":"components/notebook/pages/today-page.tsx","line":639,"title":"Console.log/error debug statements in production component today-page.tsx","description":"4 console.log/error calls in today-page.tsx guarded by NODE_ENV===development. Inconsistent with codebase logger usage. Comment confirms these are debug scaffolding.","recommendation":"Replace with logger.debug/logger.error calls.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["console.log('Attempting to save:', saveData) — line 639","console.error('Save failed:', error) — line 665","Comment: '// DEBUG: Log what we're about to save'"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D06-005","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d06-ui.jsonl","original_id":"SYST-2026-02-19-D06-005","category":"code-quality","severity":"S2","type":"code-smell","file":"components/notebook/pages/today-page.tsx","line":740,"title":"useEffect async fetch without cleanup — memory leak in today-page.tsx and DailySloganWidget","description":"fetchWeeklyStats useEffect (line 740) and DailySloganWidget.tsx have no AbortController or isMounted guard. If component unmounts during async fetch, setState executes on unmounted component. DailySloganWidget also has setLoading(false) unreachable on error path — permanent spinner on fetch failure.","recommendation":"Add AbortController or isMounted flag to all async useEffect operations.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["useEffect with async loadWeeklyStats — no cleanup return","DailySloganWidget.tsx:37-40 — setLoading(false) unreachable on error"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D06-006","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d06-ui.jsonl","original_id":"SYST-2026-02-19-D06-006","category":"performance","severity":"S2","type":"code-smell","file":"components/notebook/pages/today-page.tsx","line":605,"title":"Firestore onSnapshot listener churns on every keystroke — journalEntry in dependency array","description":"today-page.tsx:605 lists journalEntry state in the onSnapshot useEffect dependency array. Every keystroke tears down and re-subscribes the real-time listener. journalEntry is not used inside the listener setup — added only for ESLint exhaustive-deps.","recommendation":"Remove journalEntry from dependency array. Use useRef for collision detection instead.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["[referenceDate, user, journalEntry, handleSnapshotUpdate] — line 605","Comment: 'journalEntry added for exhaustive-deps'"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D06-007","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d06-ui.jsonl","original_id":"SYST-2026-02-19-D06-007","category":"code-quality","severity":"S2","type":"code-smell","file":"components/widgets/meeting-countdown.tsx","line":19,"title":"Hardcoded magic numbers and placeholder content in meeting-countdown.tsx","description":"Production widget embeds hardcoded 7 PM meeting time, 24*60*60*1000 magic number, and fake 'Evening AA - Downtown' meeting name as real UI.","recommendation":"Extract to configuration. Use real meeting data from Firestore.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["today7PM.setHours(19, 0, 0, 0) — hardcoded 7 PM","'Evening AA - Downtown' — fake placeholder in production UI"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D06-008","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d06-ui.jsonl","original_id":"SYST-2026-02-19-D06-008","category":"code-quality","severity":"S2","type":"code-smell","file":"components/notebook/pages/today-page.tsx","line":903,"title":"Hardcoded external URLs duplicated across 5 files","description":"External URLs (AA daily reflections, NA meditations, Google Maps directions template) are hardcoded directly in JSX without centralized constants. Google Maps template duplicated in 3 files.","recommendation":"Extract URLs to a constants/urls.ts file.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["AA/NA URLs in today-page.tsx:903,911","Google Maps template duplicated in meeting-map.tsx:141, meeting-details-dialog.tsx:98, resources-page.tsx:492"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D06-009","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d06-ui.jsonl","original_id":"SYST-2026-02-19-D06-009","category":"code-quality","severity":"S3","type":"code-smell","file":"components/growth/SpotCheckCard.tsx","line":207,"title":"Missing or unstable key props in map renders","description":"SpotCheckCard.tsx:207 renders array without key props. quick-actions-fab.tsx:77 uses array index as key.","recommendation":"Use unique string values as keys for inline arrays. Use action.id for dynamic lists.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["['Selfish','Dishonest',...].map((abs) => <label>{abs}</label>) — no key","actions.map((action, index) => <button key={index}>) — unstable key"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D05-001","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d05-lint.jsonl","original_id":"SYST-2026-02-19-D05-001","category":"code-quality","severity":"S2","type":"code-smell","file":"eslint.config.mjs","line":0,"title":"1360 ESLint warnings (0 errors) across root codebase","description":"ESLint reports 1360 warnings with 0 errors. Majority are: security/detect-non-literal-fs-filename (expected in Node.js scripts), unused eslint-disable directives, and complexity warnings. 10 warnings are auto-fixable.","recommendation":"Run eslint --fix for 10 auto-fixable warnings. Triage remaining by category: suppress detect-non-literal-fs-filename for scripts/ via eslint config, remove unused disable directives.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["✖ 1360 problems (0 errors, 1360 warnings)","0 errors and 10 warnings potentially fixable with --fix"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D05-002","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d05-lint.jsonl","original_id":"SYST-2026-02-19-D05-002","category":"code-quality","severity":"S1","type":"code-smell","file":"functions/src/admin.ts","line":2163,"title":"functions/src/admin.ts has 1 ESLint error — unused variable _startTimeMillis","description":"Cloud Functions lint fails with 1 error: '_startTimeMillis' is assigned a value but never used in admin.ts:2163. This blocks functions CI lint step.","recommendation":"Remove the unused _startTimeMillis assignment or use the variable for timing metrics as intended.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["2163:15 error '_startTimeMillis' is assigned a value but never used @typescript-eslint/no-unused-vars","cd functions && npm run lint exits with code 1"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D05-003","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d05-lint.jsonl","original_id":"SYST-2026-02-19-D05-003","category":"documentation","severity":"S2","type":"tech-debt","file":"docs/","line":0,"title":"30 markdownlint errors across docs/ — broken links, emphasis style, blockquote formatting","description":"markdownlint reports 30 errors in docs: MD051 (broken link fragments in TESTING_PLAN.md, TRIGGERS.md), MD053 (unused link references in templates), MD049 (emphasis style in audit summaries), MD037 (space in emphasis), MD028 (blank line in blockquote in ROADMAP files).","recommendation":"Fix broken link fragments first (most user-impactful), then emphasis/blockquote formatting. Template MD053 errors may need markdownlint-disable comments.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["30 markdownlint errors total","TESTING_PLAN.md: 4 broken link fragments (MD051)","TRIGGERS.md: 3 broken fragments + 2 emphasis errors","ROADMAP.md: 2 blockquote errors (MD028)","Templates: 11 unused link references (MD053)"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D05-004","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d05-lint.jsonl","original_id":"SYST-2026-02-19-D05-004","category":"code-quality","severity":"S3","type":"code-smell","file":"lib/","line":0,"title":"76 madge warnings during circular dependency check (no circular deps found)","description":"madge reports 76 warnings while processing 164 files (likely unresolved imports or path aliases). No actual circular dependencies found.","recommendation":"Investigate madge warnings — likely TypeScript path aliases or dynamic imports that madge can't resolve.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["Processed 164 files (4.6s) (76 warnings)","✔ No circular dependency found!"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D05-005","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d05-lint.jsonl","original_id":"SYST-2026-02-19-D05-005","category":"code-quality","severity":"S3","type":"code-smell","file":"scripts/check-pattern-compliance.js","line":0,"title":"Pattern compliance --all reports 1137 new warnings across 29+ files","description":"check-pattern-compliance.js --all detects 1137 warnings on first scan of all files. These are informational on first occurrence but will block on subsequent checks of the same file.","recommendation":"Triage by category: dismiss false positives (test files with mock API keys), fix encoding warnings, address real pattern violations.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["⚠️ 1137 new warning(s) (first occurrence - fix before next check)","Files affected: hooks (17), skills (1), workflows (1), app components (5+), scripts (various)"],"sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D04-001","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d04-deps.jsonl","original_id":"SYST-2026-02-19-D04-001","category":"code-quality","severity":"S3","type":"code-smell","file":"functions/package.json","line":0,"title":"ESLint ecosystem version drift between root and functions — 3 packages behind","description":"Root and functions share eslint, @eslint/js, and typescript-eslint but at different versions. Root: eslint ^9.39.2, @eslint/js ^9.39.1, typescript-eslint ^8.49.0. Functions: eslint ^9.17.0, @eslint/js ^9.17.0, typescript-eslint ^8.18.0.","recommendation":"Update functions eslint ecosystem to match root versions: npm update eslint @eslint/js typescript-eslint in functions/","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"@eslint/js: root=^9.39.1, functions=^9.17.0\neslint: root=^9.39.2, functions=^9.17.0\ntypescript-eslint: root=^8.49.0, functions=^8.18.0","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D04-002","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d04-deps.jsonl","original_id":"SYST-2026-02-19-D04-002","category":"code-quality","severity":"S2","type":"code-smell","file":"package.json","line":0,"title":"5 packages behind by major version — recharts 2→3, react-resizable-panels 2→4, tailwind-merge 2→3, lucide-react 0.454→0.574, @types/node 22→25","description":"5 packages have major version gaps. recharts (2.15.4→3.7.0), react-resizable-panels (2.1.9→4.6.4), and tailwind-merge (2.6.0→3.5.0) are all major bumps. lucide-react jumped 120 minor versions. @types/node 22→25 may affect TypeScript types.","recommendation":"Upgrade one at a time with testing. Start with tailwind-merge (lowest risk), then lucide-react, then recharts (highest risk — API changes).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"react-resizable-panels: 2.1.9 → 4.6.4\nrecharts: 2.15.4 → 3.7.0\ntailwind-merge: 2.6.0 → 3.5.0\nlucide-react: 0.454.0 → 0.574.0\n@types/node: 22.19.7 → 25.3.0","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D04-003","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d04-deps.jsonl","original_id":"SYST-2026-02-19-D04-003","category":"code-quality","severity":"S3","type":"code-smell","file":"package.json","line":0,"title":"Firebase client/server version alignment is correct — different packages by design","description":"Root uses firebase ^12.6.0 (client SDK). Functions uses firebase-admin ^13.6.0 and firebase-functions ^7.0.0 (server SDKs). These are different packages with independent version cadences — this is the expected setup.","recommendation":"No action needed. Document the version relationship for clarity.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Root: firebase ^12.6.0\nFunctions: firebase-admin ^13.6.0, firebase-functions ^7.0.0","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D04-004","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d04-deps.jsonl","original_id":"SYST-2026-02-19-D04-004","category":"code-quality","severity":"S3","type":"code-smell","file":"package.json","line":0,"title":"Zod version consistent between root and functions — both ^4.2.1","description":"Both root and functions package.json specify zod ^4.2.1. npm outdated shows root has 4.3.5 installed (latest 4.3.6) — minor patch available.","recommendation":"Update both to ^4.3.6 for latest patches.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Root zod: ^4.2.1 (installed 4.3.5)\nFunctions zod: ^4.2.1","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D03-001","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d03-tests.jsonl","original_id":"SYST-2026-02-19-D03-001","category":"code-quality","severity":"S1","type":"code-smell","file":"functions/src/","line":0,"title":"Cloud Functions have zero test coverage — 5000+ lines of server code untested","description":"functions/src/ contains 9 TypeScript files (index.ts ~486 lines, admin.ts ~3100 lines, scheduled.ts, security-logger.ts, etc.) with no corresponding test files. This is the highest-risk untested code: auth, data mutations, admin operations, soft-delete, migration.","recommendation":"Start with unit tests for validation logic in functions/src/schemas.ts and security-wrapper.ts. Integration tests require Firebase emulator setup.","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Glob functions/src/**/*.test.ts: 0 files. Test runner output shows 294 tests across 20 test files, ALL in tests/ directory (client-side code only).","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D03-002","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d03-tests.jsonl","original_id":"SYST-2026-02-19-D03-002","category":"code-quality","severity":"S3","type":"code-smell","file":"tests/firestore-service.test.ts","line":149,"title":"1 skipped test without linked issue — integration test for Cloud Function","description":"Test 'saves merged daily log calls Cloud Function' is skipped with comment 'Requires Firebase Cloud Functions - integration test'. No linked issue tracking when this will be addressed.","recommendation":"Create a tracking issue for Cloud Functions integration test setup, reference it in the skip comment.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"﹣ saves merged daily log calls Cloud Function (1.3638ms) # Requires Firebase Cloud Functions - integration test","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D03-003","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d03-tests.jsonl","original_id":"SYST-2026-02-19-D03-003","category":"code-quality","severity":"S2","type":"code-smell","file":"package.json","line":0,"title":"No coverage configuration or thresholds — coverage is not measured","description":"No vitest.config.ts file exists (tests use Node.js native test runner via tsconfig.test.json + tsc). No coverage tooling is configured. Cannot determine what percentage of code is tested.","recommendation":"Add c8 for coverage: 'c8 node --test dist-tests/tests/**/*.test.js'. Set threshold at 50% minimum.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"vitest.config.ts does not exist. Test command: 'node --test dist-tests/tests/**/*.test.js'. No coverage flags or c8/v8 coverage config.","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D03-004","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d03-tests.jsonl","original_id":"SYST-2026-02-19-D03-004","category":"code-quality","severity":"S2","type":"code-smell","file":"lib/firebase/account-linking.ts","line":0,"title":"Security utilities partially tested — secure-caller tested, account-linking not","description":"secure-caller.ts has tests (secure-caller.test.ts, firestore-validation.test.ts). However, account-linking.ts (handles anonymous-to-auth migration) has no corresponding tests despite being a critical security path.","recommendation":"Create tests/security/account-linking.test.ts covering: successful link, data preservation, error states, race conditions.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"tests/secure-caller.test.ts exists. tests/security/firestore-validation.test.ts exists. No test file for account-linking.ts.","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D02-001","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d02-build.jsonl","original_id":"SYST-2026-02-19-D02-001","category":"performance","severity":"S2","type":"code-smell","file":"out/images/","line":0,"title":"Total bundle size 15.5MB — 8.2MB from unoptimized images","description":"The out/ directory is 15.5MB. Top 4 files are images (2.7MB PNG, 2.1MB PNG, 2.0MB PNG, 1.4MB JPEG) totaling 8.2MB. These are unoptimized PNGs that could be compressed to WebP/AVIF.","recommendation":"Convert PNGs to WebP (60-80% size reduction). Use sharp or squoosh CLI to batch convert.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"2725 KB images/gemini-generated-image-n61yzln61yzln61y.png\n2129 KB images/notebook-cover-transparent.png\n1965 KB images/notebook-cover-blank.png\n1389 KB images/gemini-generated-image-gj5efogj5efogj5e.jpeg","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D02-002","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d02-build.jsonl","original_id":"SYST-2026-02-19-D02-002","category":"performance","severity":"S2","type":"code-smell","file":"out/_next/static/chunks/9d44679c11cfa7b4.js","line":0,"title":"JS chunk at 625KB — likely contains heavy library (Leaflet or charting)","description":"Largest JS chunk is 625KB (_next/static/chunks/9d44679c11cfa7b4.js). This is likely a heavy library bundled without code splitting. Second largest is 357KB.","recommendation":"Identify the library in the chunk (likely Leaflet, chart.js, or Sentry). Use next/dynamic to lazy-load.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"625 KB _next/static/chunks/9d44679c11cfa7b4.js\n357 KB _next/static/chunks/8043a15616e02fa5.js","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D02-003","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d02-build.jsonl","original_id":"SYST-2026-02-19-D02-003","category":"security","severity":"S2","type":"vulnerability","file":"out/_next/static/chunks/a6dad97d9634a72d.js.map","line":0,"title":"Source map file present in production build output","description":"One .js.map file found in out/_next/static/chunks/. Source maps in production expose original source code to anyone inspecting the deployed site.","recommendation":"Add productionBrowserSourceMaps: false to next.config.mjs (default is false, but verify). Or exclude .map files from Firebase hosting deploy.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"1 source map: out/_next/static/chunks/a6dad97d9634a72d.js.map","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D02-004","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d02-build.jsonl","original_id":"SYST-2026-02-19-D02-004","category":"code-quality","severity":"S3","type":"code-smell","file":"next.config.mjs","line":15,"title":"images.unoptimized: true — expected for static export but limits performance","description":"next.config.mjs sets images.unoptimized: true. Required for output: 'export' since Next.js Image optimization needs a server. All images served as-is without resizing or format conversion.","recommendation":"Pre-optimize images at build time using a script (sharp, squoosh). This gives the benefits of optimization without needing a server.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"images: { unoptimized: true }","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D01-001","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d01-prereqs.jsonl","original_id":"SYST-2026-02-19-D01-001","category":"code-quality","severity":"S3","type":"code-smell","file":"next.config.ts","line":0,"title":"Next.js build warns about workspace root detection","description":"Next.js inferred workspace root from C:\\Users\\jason\\pnpm-lock.yaml instead of the project's package-lock.json. Warning: 'We detected multiple lockfiles'. Non-blocking but noisy.","recommendation":"Set turbopack.root in next.config.ts, or remove the stale pnpm-lock.yaml from home directory","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Warning: Next.js inferred your workspace root, but it may not be correct. We detected multiple lockfiles and selected the directory of C:\\Users\\jason\\pnpm-lock.yaml as the root directory.","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D01-002","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d01-prereqs.jsonl","original_id":"SYST-2026-02-19-D01-002","category":"security","severity":"S2","type":"vulnerability","file":"functions/package.json","line":0,"title":"fast-xml-parser DoS via entity expansion (high severity) in @google-cloud/storage","description":"npm audit reports high severity DoS vulnerability in fast-xml-parser 4.1.3-5.3.5, pulled in by @google-cloud/storage (Cloud Functions dependency). Entity expansion in DOCTYPE without limit.","recommendation":"npm audit fix in functions/ directory, or pin fast-xml-parser >= 5.3.6","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"fast-xml-parser 4.1.3-5.3.5: DoS through entity expansion in DOCTYPE (GHSA-jmr7-xgp7-cmfj). Dep chain: @google-cloud/storage -> fast-xml-parser","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D01-003","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d01-prereqs.jsonl","original_id":"SYST-2026-02-19-D01-003","category":"security","severity":"S3","type":"vulnerability","file":"package.json","line":0,"title":"26 high-severity vulns in dev/build dependencies (eslint, sentry, lighthouse, madge)","description":"npm audit reports 26 high-severity vulnerabilities, all in development/build tooling: eslint ecosystem (minimatch ReDoS, ajv ReDoS), @sentry/* (minimatch via glob), lighthouse, madge, markdownlint-cli. None are in production client bundles.","recommendation":"npm audit fix for non-breaking fixes. Breaking fix requires eslint@10 upgrade.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"29 vulnerabilities (2 moderate, 27 high). All transitive via: eslint, @typescript-eslint/*, @sentry/*, lighthouse, madge, markdownlint-cli, c8","sources":[],"merged_from":[]}
{"source_id":"audit:SYST-2026-02-19-D01-004","source_file":"docs\\audits\\system-test\\audit-2026-02-19\\domains\\d01-prereqs.jsonl","original_id":"SYST-2026-02-19-D01-004","category":"code-quality","severity":"S3","type":"code-smell","file":"package.json","line":0,"title":"No engines field in package.json — Node version not pinned","description":"package.json has no engines field. Running Node v24.11.1 but no version constraint prevents accidental use of incompatible versions.","recommendation":"Add engines: { node: '>=22' } to package.json","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"node -v: v24.11.1, package.json engines: {}","sources":[],"merged_from":[]}
{"source_id":"audit:hash-QVJDSElURUNU","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"documentation","severity":"S1","type":"tech-debt","file":"ARCHITECTURE.md","line":210,"title":"ARCHITECTURE.md Firestore rules diagram contradicts actual if-false rules","description":"ARCHITECTURE.md shows stale Firestore rules permitting direct client writes to journal — contradicts actual 'if false' rules. DEBT-1444 captures general staleness; COMP-002 is specifically about the rules diagram.","recommendation":"Update ARCHITECTURE.md Section 4 to show allow create, update: if false with Cloud Functions explanation","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-VG9kYXlQYWdl","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"code-quality","severity":"S1","type":"code-smell","file":"components/notebook/pages/today-page.tsx","line":0,"title":"TodayPage stale referenceDate after midnight — not covered by existing DEBT","description":"1,138-line component with 42 hooks. COMP-003 includes the stale referenceDate after midnight — not covered by any DEBT entry. The keystroke re-subscription is tracked in DEBT-0063 and DEBT-3158 but the stale midnight date is genuinely new.","recommendation":"Fix referenceDate with midnight refresh timer; extract useHaltCheck, useWeeklyStats, useMilestoneCheck, useAutoSave hooks","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U3VwcG9ydCBj","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"enhancements","severity":"S1","type":"code-smell","file":"components/notebook/pages/support-page.tsx","line":0,"title":"Support circle contacts are hardcoded demo data; Call/Text/Directions buttons non-functional","description":"Support circle contacts are hardcoded demo data; Call/Text/Directions buttons have no onClick handlers. DEBT entries for the file are superficial SonarCloud noise (array-index keys, new Array()), not the functional bug.","recommendation":"Implement Firestore CRUD for contacts; wire href=tel:, href=sms:, href=https://maps.google.com/...","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-T25ib2FyZGlu","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"enhancements","severity":"S1","type":"code-smell","file":"components/onboarding/onboarding-wizard.tsx","line":419,"title":"Onboarding promises data export/deletion that don't exist — GDPR/CCPA risk","description":"Onboarding screen explicitly promises 'Export or delete your data anytime from Settings.' Neither data export nor account deletion exists in Settings. GDPR/CCPA risk.","recommendation":"Add Cloud Function for JSON data export; add account deletion flow with confirmation modal","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-VGFiIG5hdmln","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"enhancements","severity":"S1","type":"code-smell","file":"components/notebook/tab-navigation.tsx","line":0,"title":"Tab navigation keyboard inaccessible — no role=tablist, aria-selected, keyboard nav","description":"Tab ribbon has no role=tablist, no role=tab, no aria-selected, no aria-label — keyboard inaccessible. DEBT-0773 is SonarCloud noise (read-only props); full accessibility overhaul (ARIA roles, keyboard nav) not captured.","recommendation":"Add role/aria attributes; wrap container with role=tablist aria-label=Notebook sections; implement keyboard arrow-key navigation","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Tm8gY3Jpc2lz","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"enhancements","severity":"S1","type":"code-smell","file":"components/notebook/pages/today-page.tsx","line":0,"title":"No crisis/SOS emergency button in recovery app — resources buried 3 taps deep","description":"No crisis/emergency SOS button — crisis resources buried 3 taps deep in a recovery app. No DEBT entry covers this feature gap.","recommendation":"Add persistent crisis button on Today page linking to 988 / SAMHSA / Nashville Crisis Line","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Y2hlY2stcGF0","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"refactoring","severity":"S1","type":"code-smell","file":"scripts/check-pattern-compliance.js","line":0,"title":"check-pattern-compliance.js god script — 1917 lines, eslint-disable complexity","description":"Most-changed file in codebase (125 commits/90d) has eslint-disable complexity and no structural decomposition. 72 DEBT entries on this file are mostly SonarCloud noise. The extract-to-JSON-config structural fix is not captured.","recommendation":"Extract pattern config to scripts/config/anti-patterns.json; split reporter + graduation tracker","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-UGxheXdyaWdo","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"process","severity":"S1","type":"process-gap","file":"playwright.config.ts","line":0,"title":"Playwright installed but zero E2E tests — no config, no test files, no npm scripts","description":"Playwright installed as devDependency but zero config, zero test files, zero npm scripts for E2E. DEBT-2141 mentions 'no visual regression testing' but the full E2E gap is not captured.","recommendation":"Create playwright.config.ts, add 3-5 smoke tests for login + entry creation + data load","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-RGVwbG95IHdv","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"process","severity":"S1","type":"process-gap","file":".github/workflows/deploy-firebase.yml","line":0,"title":"Deploy workflow has no needs: dependency on CI — can deploy before tests pass","description":"Deploy workflow has no needs: dependency on CI — deployment can complete before tests pass. DEBT-2098 covers post-deploy validation; this is about the missing needs: lint-typecheck-test pre-deploy gate.","recommendation":"Add needs: lint-typecheck-test to the deploy job","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U2Vzc2lvbi1z","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"ai-optimization","severity":"S1","type":"code-smell","file":".claude/hooks/session-start.js","line":0,"title":"Session-start hook 7 blocking synchronous subprocess calls — 3-8 min cold start","description":"7 blocking synchronous subprocess calls at session start cause 3-8 min cold start. DEBT-1938 mentions 2-5s latency for hooks in general; COMP-020 identifies 7 specific blocking calls and async solutions.","recommendation":"Move npm install/build async; gate test compile on file hash; make pattern check non-blocking","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-OCBza2lsbHMg","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"ai-optimization","severity":"S1","type":"code-smell","file":".claude/skills/","line":0,"title":"8 skills exceed 500 lines; 9 audit skills with unclear differentiation","description":"8 skills exceed 500 lines; 9 audit skills with unclear differentiation; /audit-comprehensive subsumes all. DEBT entries for skill files are broken-link findings in SKILL.md, not the oversized/redundant skill structural problem.","recommendation":"Split oversized skills into thin entry + referenced sub-docs; make domain skills internal modules","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-YWdncmVnYXRl","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"refactoring","severity":"S2","type":"code-smell","file":"scripts/aggregate-audit-findings.js","line":0,"title":"aggregate-audit-findings.js god script — 25+ functions, no decomposition","description":"God script with 25+ functions including Levenshtein dedup, scoring, PR bucketing — no explicit complexity guard. DEBT-1141 is a trivial parseInt finding; the decomposition finding is new.","recommendation":"Split into pipeline stages: parse, normalize, dedup, score, generate","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Q2xvdWQgRnVu","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"documentation","severity":"S2","type":"tech-debt","file":"ARCHITECTURE.md","line":479,"title":"Cloud Functions structure in ARCHITECTURE.md shows non-existent subdirectories","description":"Cloud Functions structure in ARCHITECTURE.md shows non-existent journal/, admin/, utils/ subdirectories — actual structure is flat 8-file directory. No DEBT entry captures this specific inaccuracy.","recommendation":"Replace with actual flat structure: index.ts, admin.ts, firestore-rate-limiter.ts, schemas.ts, security-logger.ts, security-wrapper.ts, jobs.ts, recaptcha-verify.ts","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-VGVzdCBwaXBl","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"engineering-productivity","severity":"S2","type":"code-smell","file":"package.json","line":0,"title":"Test pipeline requires 3 compilation steps — 10-20s overhead; Vitest migration needed","description":"Test pipeline requires 3 compilation steps (tsc + tsc-alias + node --test), 10-20s overhead; inconsistent with pattern tests using Vitest. DEBT-1931 covers test rebuilds TypeScript but not the Vitest migration fix.","recommendation":"Migrate to Vitest (already used for pattern tests) — eliminates compile step entirely","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-TGFyZ2UgVGV4","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"enhancements","severity":"S2","type":"code-smell","file":"components/settings/settings-page.tsx","line":0,"title":"Large Text preference saves to Firestore but is never read — dead setting","description":"Large Text preference toggle saves to Firestore but is never read by any component — dead setting. No DEBT entry found.","recommendation":"Read profile.preferences.largeText in root layout; apply text-lg or CSS class conditionally","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-UkVBRE1FIHRl","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"documentation","severity":"S2","type":"tech-debt","file":"README.md","line":111,"title":"README test count stale: 89/91 vs actual 293/294","description":"Test count '89/91 passing' is stale — actual is 293/294. No DEBT entry matches.","recommendation":"Update README test status line","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-UkVBRE1FIGFn","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"documentation","severity":"S2","type":"tech-debt","file":"README.md","line":117,"title":"README agent/skill counts wrong: 24/23 vs actual 25/59","description":"Agent/skill counts wrong: '24 agents / 23 skills' vs actual 25/59. No DEBT entry matches.","recommendation":"Update counts; consider auto-generation via npm run docs:update-readme","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-UkVBRE1FIEdy","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"documentation","severity":"S2","type":"tech-debt","file":"README.md","line":239,"title":"README Growth tab marked Planned/feature-flagged but fully implemented","description":"Growth tab marked 'Planned/feature-flagged' but fully implemented. No DEBT entry matches.","recommendation":"Update Roadmap Module Mapping table to show Growth as Available","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-REVWRUxPUE1F","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"documentation","severity":"S2","type":"tech-debt","file":"DEVELOPMENT.md","line":169,"title":"DEVELOPMENT.md lib/ structure shows only 3 entries — missing 5 subdirectories","description":"lib/ structure shows only 3 entries — missing contexts/, db/, hooks/, types/, utils/. DEBT-1787 is about missing TOC; not about the wrong lib/ structure listing.","recommendation":"Update project structure section with all 8 lib/ subdirectories","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-RHVwbGljYXRl","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"documentation","severity":"S2","type":"tech-debt","file":"claude.md","line":0,"title":"Duplicate claude.md is byte-for-byte copy of CLAUDE.md — wastes 1600 tokens/session","description":"Duplicate files — claude.md is byte-for-byte copy of CLAUDE.md, wasting ~1,600 tokens/session. The duplicate-file issue itself is not tracked as open.","recommendation":"Delete claude.md; update all references to uppercase CLAUDE.md","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-RE9DVU1FTlRB","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"documentation","severity":"S2","type":"tech-debt","file":"docs/DOCUMENTATION_STANDARDS.md","line":178,"title":"DOCUMENTATION_STANDARDS.md references non-existent MULTI_AI_REVIEW_COORDINATOR.md","description":"References non-existent MULTI_AI_REVIEW_COORDINATOR.md. DEBT entries for broken links don't specifically name this file.","recommendation":"Remove entry or replace with docs/audits/multi-ai/COORDINATOR.md","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Uk9BRE1BUC5t","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"documentation","severity":"S2","type":"tech-debt","file":"ROADMAP.md","line":6,"title":"ROADMAP.md Last Updated uses session number not date — 29+ sessions stale","description":"Last Updated: Session #151 — 29+ sessions stale; uses session number not date. DEBT-1438 covers COMMAND_REFERENCE.md version format inconsistency, not ROADMAP.md's session-numbered Last Updated.","recommendation":"Replace with date 2026-02-22; switch to date-based versioning","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-ZnJhbWVyLW1v","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"performance","severity":"S2","type":"code-smell","file":"lib/firebase.ts","line":0,"title":"framer-motion imported directly in 36 non-lazy client components — 130KB gzipped eager","description":"framer-motion imported directly in 36 non-lazy client components (~130 KB gzipped loaded eagerly). No open DEBT tracks the framer-motion eager-load specifically.","recommendation":"Extract animation wrappers to dynamic-imported AnimatedWrapper; use CSS transitions for simple animations","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-d29vZC10YWJs","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"performance","severity":"S2","type":"code-smell","file":"app/layout.tsx","line":0,"title":"wood-table.jpg LCP image not preloaded — browser can't prioritize","description":"wood-table.jpg set via CSS backgroundImage — browser can't preload it; no <link rel=preload>.","recommendation":"Add <link rel=preload as=image href=/images/wood-table.jpg> in app/layout.tsx","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-MyBQTkcgaW1h","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"performance","severity":"S2","type":"code-smell","file":"public/images/","line":0,"title":"3 PNG images 2.0-2.8 MB served uncompressed — WebP conversion needed","description":"3 PNG images: 2.0 MB, 2.2 MB, 2.8 MB served uncompressed. DEBT-3140 covers total bundle size but does not prescribe the WebP conversion fix specifically. Actionable resolution steps not in DEBT-3140.","recommendation":"Convert to WebP at 80% quality; delete unused gemini-generated-image-*.png","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-TW9vZFNwYXJr","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"performance","severity":"S2","type":"code-smell","file":"components/notebook/visualizations/mood-sparkline.tsx","line":16,"title":"MoodSparkline fires separate 30-doc Firestore read on every Today page visit","description":"MoodSparkline fires a separate 30-doc Firestore read on every Today page visit. Only DEBT-0372 (array-index keys) hits the file — no entry for the redundant read issue.","recommendation":"Pass history as prop from today-page.tsx; or cache in sessionStorage","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-UHJldmlldyBk","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"process","severity":"S2","type":"process-gap","file":".github/workflows/deploy-firebase.yml","line":0,"title":"Preview deploy channel commented out — no PR-level staging environment","description":"Preview deploy channel commented out — no PR-level staging environment. DEBT-1891 is related but distinct.","recommendation":"Configure GitHub repo vars and re-enable; or remove dead preview-deploy job","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-MTgxIEVTTGlu","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"engineering-productivity","severity":"S2","type":"code-smell","file":"","line":0,"title":"181 ESLint warning baseline — warning noise masks real issues","description":"181 ESLint warning baseline — warning noise masks real issues. DEBT-0781 and DEBT-1866 cover pattern-check false-positives, not the ESLint warning count itself.","recommendation":"Add per-line eslint-disable with justification on confirmed false positives; target 0-warning baseline","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-UG9zdFRvb2xV","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/settings.json","line":0,"title":"PostToolUse hooks fire on every Read/Write/Edit/Bash — 18s/session overhead","description":"PostToolUse hooks fire on every Read/Write/Edit/Bash — estimated 18s/session cumulative overhead. DEBT-1938 mentions session hook latency generally; COMP-051 identifies specific hooks and merging/caching fixes.","recommendation":"Merge commit-tracker + commit-failure-reporter; cache config in post-write-validator; make post-read-handler opt-in","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-RGV2IHNlcnZl","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"engineering-productivity","severity":"S2","type":"code-smell","file":"package.json","line":0,"title":"Dev server uses webpack by default — no Turbopack flag","description":"Dev server uses webpack by default — no Turbopack flag on a large TypeScript project. No DEBT entry found.","recommendation":"Change next dev to next dev --turbopack; test compatibility with Leaflet, Framer Motion","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-QUlfV09SS0ZM","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":"AI_WORKFLOW.md","line":0,"title":"AI_WORKFLOW.md 874 lines mandated reading every session — 7600 tokens overhead","description":"AI_WORKFLOW.md (874 lines / ~7,600 tokens) mandated reading every session. Most content only needed for doc-update sessions. No DEBT covers the mandatory-read token overhead or the split-into-quick-start fix.","recommendation":"Split into 50-line Quick Start + on-demand reference; remove Read at session start mandate","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-LmNsYXVkZS9z","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/state/","line":0,"title":".claude/state/ and .claude/tmp/ unbounded growth — 76KB + 283KB stale files","description":"76 KB agent-research-results.md with no rotation; 283 KB stale audit JSON in .claude/tmp/; stale in_progress multi-ai-audit session state. DEBT-2538 covers state JSONL files; no DEBT covers agent-research-results.md cap or .claude/tmp/ cleanup.","recommendation":"Implement 20 KB cap on agent-research-results; delete .claude/tmp/audit-result*.json; mark stale session as abandoned","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-c2V0dGluZ3Mu","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/settings.local.json","line":0,"title":"settings.local.json 250+ permission entries — unreadable and unauditable","description":"250+ permission entries including multi-line commit messages — unreadable and unauditable. DEBT-2256-2259 cover specific MCP-related stale permissions, not the overall 250+ entry bloat problem.","recommendation":"Remove one-time commit approvals; keep only pattern-based entries; document rotation policy","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Z2V0RnVuY3Rp","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"refactoring","severity":"S2","type":"code-smell","file":"components/admin/admin-crud-table.tsx","line":0,"title":"getFunctions() + httpsCallable pattern repeated 28 times across admin layer","description":"getFunctions() + httpsCallable pattern repeated 28 times across 8 admin tab files. No DEBT entry found for this specific refactoring.","recommendation":"Create lib/utils/admin-caller.ts typed callAdminFunction<TInput, TOutput>() helper","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-bGlua3MtdGFi","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"refactoring","severity":"S2","type":"code-smell","file":"components/admin/links-tab.tsx","line":0,"title":"links-tab.tsx and prayers-tab.tsx ~90% code duplication","description":"~90% code duplication between two CRUD tab files. No DEBT entry found.","recommendation":"Create generic AdminContentTab HOC or useAdminCrud hook parameterized by entity config","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-d2luZG93LmNv","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"refactoring","severity":"S2","type":"code-smell","file":"","line":0,"title":"window.confirm() used for 10 destructive actions — non-styleable, blocks UI","description":"window.confirm() used for 10 destructive actions across admin — non-styleable, blocks UI thread. DEBT-2164 covers copy quality, not the window.confirm() replacement.","recommendation":"Create reusable ConfirmationDialog using existing components/ui/dialog.tsx","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U2lnbi1pbiBt","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"enhancements","severity":"S2","type":"code-smell","file":"components/auth/sign-in-modal.tsx","line":0,"title":"Sign-in modal lacks role=dialog, aria-modal, focus trap — screen reader inaccessible","description":"Modal lacks role=dialog, aria-modal, aria-labelledby, focus trap. DEBT-3183 covers reCAPTCHA protection missing; no DEBT covers the ARIA/focus-trap accessibility gap.","recommendation":"Add dialog semantics; add close button aria-label; implement focus trap","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Tm8gZGF0YSBl","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"enhancements","severity":"S2","type":"code-smell","file":"components/settings/settings-page.tsx","line":0,"title":"No data export or account deletion despite onboarding promise","description":"No data export or account deletion despite onboarding promise. Duplicate angle to COMP-008.","recommendation":"Cloud Function for JSON export; account deletion with Firestore purge","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Tm8gbm9zY3Jp","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"enhancements","severity":"S2","type":"code-smell","file":"app/layout.tsx","line":0,"title":"No noscript fallback — JavaScript-disabled users see blank page","description":"No <noscript> fallback — JavaScript-disabled users see blank page. No DEBT entry found.","recommendation":"Add basic <noscript> message","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-T25seSA3LWRh","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"enhancements","severity":"S2","type":"code-smell","file":"components/notebook/visualizations/mood-sparkline.tsx","line":0,"title":"Only 7-day mood sparkline — no 30/90-day history visualization","description":"Only 7-day mood sparkline — no 30/90-day history visualization. No DEBT entry found.","recommendation":"Implement mood trend charts on History tab; use cached daily_logs data","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Rml4ZWQgbm90","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"enhancements","severity":"S2","type":"code-smell","file":"components/notebook/notebook-shell.tsx","line":200,"title":"Fixed notebook width 340px/800px breaks at 428-767px viewport range","description":"Fixed notebook width 340px/800px breaks at 428-767px viewport range (tablets, landscape phones). No DEBT entry found.","recommendation":"Replace hard breakpoint with fluid responsive width using container queries or clamp()","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-VGFwIHRvIHNl","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"enhancements","severity":"S2","type":"code-smell","file":"components/notebook/pages/today-page.tsx","line":877,"title":"Tap to set clean date has cursor-pointer but no onClick handler","description":"'Tap to set clean date' has cursor-pointer but no onClick handler — clicking does nothing. No DEBT entry found.","recommendation":"Wire to navigate to Settings clean-date input","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U2hhcmUgbWVl","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"enhancements","severity":"S2","type":"code-smell","file":"components/notebook/pages/resources-page.tsx","line":497,"title":"Share meeting button toasts success without calling clipboard.writeText()","description":"Share meeting button toasts 'Link copied!' but never calls navigator.clipboard.writeText(). No DEBT entry found.","recommendation":"Add navigator.clipboard.writeText(shareUrl) before toast.success()","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Tm8gRm9yZ290","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"enhancements","severity":"S2","type":"code-smell","file":"components/auth/sign-in-modal.tsx","line":0,"title":"No Forgot password flow — email users have no recovery path","description":"No 'Forgot password?' flow — email users who forget password have no recovery path. No DEBT entry found.","recommendation":"Add sendPasswordResetEmail() link in sign-in form","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-V0NBRyAyLjEg","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"enhancements","severity":"S2","type":"code-smell","file":"","line":0,"title":"WCAG 2.1 AA contrast unverified — amber-on-amber may fail 4.5:1 ratio","description":"WCAG 2.1 AA contrast unverified — text-amber-900/60 on bg-amber-50 may fail 4.5:1 ratio. No DEBT entry found.","recommendation":"Run Axe/Lighthouse contrast audit; fix failing combinations","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Tm8gc2tpcC10","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"enhancements","severity":"S2","type":"code-smell","file":"app/layout.tsx","line":0,"title":"No skip-to-content link — keyboard users must tab through entire nav","description":"No skip-to-content link — keyboard users must tab through entire nav on every page. No DEBT entry found.","recommendation":"Add visually-hidden skip link as first focusable element","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U3RlcCA0IElu","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"enhancements","severity":"S2","type":"code-smell","file":"components/growth/growth-page.tsx","line":88,"title":"Step 4 Inventory and Step 8 List buttons are motion.button with no onClick","description":"Step 4 Inventory and Step 8 List buttons are motion.button elements with no onClick — appear interactive but do nothing. No DEBT entry found.","recommendation":"Wire to feature or add Coming Soon visual indicator","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-SGlzdG9yeSB0","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"enhancements","severity":"S2","type":"code-smell","file":"components/notebook/pages/history-page.tsx","line":131,"title":"History tab hard-limited to 7 days — older entries invisible","description":"History tab hard-limited to 7 days; older entries exist in Firestore but are invisible. No DEBT entry found.","recommendation":"Implement Load more pagination or date-picker on History tab","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Z3NkLXBsYW5u","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/agents/global/gsd-planner.md","line":0,"title":"gsd-planner.md and gsd-debugger.md ~125K tokens per 4-agent wave","description":"gsd-planner.md (1,476 lines), gsd-debugger.md (1,300 lines) — ~125,000 tokens per concurrent wave of 4 GSD agents. No DEBT entry found.","recommendation":"Extract shared gsd-base.md; use @file references; target max 400 lines per agent","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-c2VjdXJpdHkt","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/agents/security-engineer.md","line":0,"title":"security-engineer.md contains irrelevant Terraform/HCL examples — 20K token waste","description":"security-engineer.md (985 lines) contains Terraform/HCL examples irrelevant to Firebase project — inflates invocations by ~20,000 tokens. No DEBT entry found.","recommendation":"Trim to 80 lines of project-relevant content; consolidate into security-auditor.md","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-VkFMSURBVElP","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"security","severity":"S2","type":"vulnerability","file":"functions/src/security-logger.ts","line":371,"title":"VALIDATION_FAILURE severity mapped to INFO — attack probing invisible","description":"VALIDATION_FAILURE severity mapped to INFO — not persisted to Firestore security_logs; attack probing invisible in admin panel. No DEBT entry found.","recommendation":"Change to WARNING severity in SEVERITY_MAP","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Tm90ZWJvb2tT","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"performance","severity":"S2","type":"code-smell","file":"components/notebook/notebook-shell.tsx","line":0,"title":"NotebookShell SVG data URL recomputed every render","description":"NotebookShell mixes animation + tab + modal state; spine SVG data URL recomputed every render. DEBT-3188 covers book-cover.tsx; no DEBT covers notebook-shell.tsx. Same anti-pattern, different component.","recommendation":"Memoize spine texture as module-level const; use useReducer for direction + activeTab","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Tm8gQ0hBTkdF","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"process","severity":"S2","type":"process-gap","file":"package.json","line":0,"title":"No CHANGELOG, no versioning strategy, no release tagging","description":"No CHANGELOG, no versioning strategy, no release tagging. DEBT-2029 is about commit message validation hook — related workflow area but different issue.","recommendation":"Add release-please-action workflow for automatic changelog and release tags","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-MzU2LWxpbmUg","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"refactoring","severity":"S2","type":"code-smell","file":"components/growth/Step1WorksheetCard.tsx","line":124,"title":"356-line FORM_SECTIONS config embedded in Step1WorksheetCard component","description":"356-line FORM_SECTIONS config embedded in component file — pure data with no React dependencies. No DEBT specifically covers extracting the config.","recommendation":"Extract to components/growth/step1-worksheet-config.ts","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U3RhbGUgLy8g","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"code-quality","severity":"S3","type":"code-smell","file":"app/layout.tsx","line":66,"title":"Stale // ... existing metadata ... comment — code-generation artifact","description":"Stale '// ... existing metadata ...' comment — code-generation artifact in layout. No DEBT entry found.","recommendation":"Remove the comment","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-X2NoZWNrSW5T","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"code-quality","severity":"S3","type":"code-smell","file":"components/notebook/pages/today-page.tsx","line":332,"title":"_checkInSteps computed via useMemo but never consumed — wasted computation","description":"_checkInSteps computed via useMemo but never consumed — wasted computation. No DEBT entry found.","recommendation":"Remove the useMemo or render via CheckInProgress component","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-TWlzc2luZyB1","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"code-quality","severity":"S3","type":"code-smell","file":"components/journal/entry-wizard.tsx","line":1,"title":"Missing use client directive in entry-wizard.tsx","description":"Missing 'use client' directive — uses useState + event handlers but not self-declaring. No DEBT entry found.","recommendation":"Add 'use client' as first line","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-bWVldGluZy1j","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"code-quality","severity":"S3","type":"code-smell","file":"components/widgets/meeting-countdown.tsx","line":0,"title":"meeting-countdown.tsx is dead code — superseded by CompactMeetingCountdown, never imported","description":"Dead code — superseded by CompactMeetingCountdown, not imported anywhere. DEBT-0454 (setInterval issue) and DEBT-3159 (hardcoded placeholder) are code quality issues in the file but don't identify it as dead/delete-worthy. Stronger claim that supersedes these.","recommendation":"Delete file after confirming zero imports; closes DEBT-0454 and DEBT-3159","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-VGhyZWUgdW5k","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"refactoring","severity":"S3","type":"code-smell","file":"components/notebook/pages/resources-page.tsx","line":596,"title":"Three underscore-prefixed dead functions in resources-page.tsx","description":"Three underscore-prefixed dead functions (_loadMoreMeetings, _availableNeighborhoods, _handleTimeJump) never called. No DEBT entry found.","recommendation":"Remove all three dead functions","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-TG9jYWwgaXNT","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"refactoring","severity":"S3","type":"code-smell","file":"components/notebook/pages/resources-page.tsx","line":78,"title":"Local isSameDay reimplemented — date-fns already imported","description":"Local isSameDay reimplemented — date-fns (already imported) exports this function. No DEBT entry found.","recommendation":"Remove local implementation; import { isSameDay } from 'date-fns'","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-RGVidWcgY29u","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"code-quality","severity":"S3","type":"code-smell","file":"components/notebook/pages/today-page.tsx","line":639,"title":"Debug console.log in today-page.tsx dev guard — specific lines not in existing DEBT","description":"Debug console.log('Attempting to save:') in dev guard at lines 639/665. DEBT-0436 covers debug logs broadly but doesn't pinpoint these specific lines.","recommendation":"Remove 3-line debug block; production logger.info 3 lines above is sufficient","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-X2FwcENoZWNr","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"refactoring","severity":"S3","type":"code-smell","file":"lib/firebase.ts","line":40,"title":"_appCheck exported but always undefined in lib/firebase.ts","description":"let _appCheck: AppCheck | undefined declared and exported but always undefined — silently returns undefined. No DEBT entry found.","recommendation":"Remove once App Check re-enabled (COMP-001)","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-VHdvIHBhcmFs","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"refactoring","severity":"S3","type":"code-smell","file":"lib/utils/errors.ts","line":0,"title":"Two parallel error utilities — merge errors.ts and callable-errors.ts","description":"Two parallel error utilities; errors.ts consumed only by storage.ts. DEBT-0843 covers console statements in callable-errors.ts but not the merge refactor. Different root-cause framing.","recommendation":"Merge into lib/utils/error-utils.ts","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-QWRtaW4gcGFz","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"security","severity":"S3","type":"vulnerability","file":"functions/src/admin.ts","line":3374,"title":"Admin password reset returns distinct No user found — user enumeration","description":"Admin password reset returns distinct 'No user found' error — user enumeration in admin panel. No DEBT entry found.","recommendation":"Return generic 'If user exists, reset sent' response; always call Firebase API","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-TWlzc2luZyBD","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"security","severity":"S3","type":"vulnerability","file":"firebase.json","line":0,"title":"Missing COEP header — document intentional absence due to reCAPTCHA","description":"Missing Cross-Origin-Embedder-Policy header. DEBT-0088 covers missing security headers generally but may not include COEP. This documents the intentional COEP absence due to reCAPTCHA iframe incompatibility.","recommendation":"Document intentional COEP absence; note reCAPTCHA iframe incompatibility","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-UmF0ZSBsaW1p","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"security","severity":"S3","type":"vulnerability","file":"functions/src/firestore-rate-limiter.ts","line":39,"title":"Rate limit document IDs contain raw Firebase UID and IP — should be hashed","description":"Rate limit document IDs contain raw Firebase UID and raw IP address — hashed in logs but not in doc IDs. DEBT-3169 covers console.warn leaking un-hashed UID which is related but different vector.","recommendation":"Hash UID and IP before using as document IDs (SHA-256 truncated)","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-TW9iaWxlIGJs","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"security","severity":"S3","type":"vulnerability","file":"app/admin/page.tsx","line":36,"title":"Mobile block via user-agent — security theater; needs clarifying comment","description":"Mobile block via user-agent string — security theater; real security is Firebase admin claim check. No DEBT entry found.","recommendation":"Add code comment: UX only — security enforced at line 68 via Firebase admin claim","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-c2VhcmNoVXNl","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"security","severity":"S3","type":"vulnerability","file":"functions/src/admin.ts","line":286,"title":"searchUsersByNickname prefix query has no input length validation","description":"searchUsersByNickname prefix query has no input length validation. No DEBT entry found.","recommendation":"Add z.string().min(1).max(100).trim() to input schema","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-SG9vayBsb2cg","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"process","severity":"S3","type":"process-gap","file":".husky/pre-commit","line":0,"title":"Hook log file .git/hook-output.log grows unboundedly","description":"Hook log file .git/hook-output.log grows unboundedly with every commit. DEBT-2538 covers .claude/state/reviews.jsonl. Same unbounded log growth pattern, different file.","recommendation":"Add tail -n 500 rotation at top of hook before exec redirect","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-cmVxdWlyZV9z","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"process","severity":"S3","type":"process-gap","file":".husky/pre-commit","line":0,"title":"require_skip_reason() function duplicated verbatim in pre-commit and pre-push","description":"require_skip_reason() function (40+ lines) duplicated verbatim in both hook files. No DEBT entry found.","recommendation":"Extract to .husky/lib/skip-reason-guard.sh; source in both hooks","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-OTYtMTAxIG5w","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"engineering-productivity","severity":"S3","type":"code-smell","file":"package.json","line":0,"title":"96-101 npm scripts with no grouping, no help, no discoverability","description":"No npm run help, no grouping, no discoverability for 96-101 npm scripts. No DEBT entry found.","recommendation":"Add npm run help script; add Common Scripts Quick Reference to README","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-bmV4dCBkZXYg","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"engineering-productivity","severity":"S3","type":"code-smell","file":"package.json","line":0,"title":"next dev without --turbopack flag","description":"next dev without --turbopack — webpack used on large TypeScript project. Identical fix to COMP-052.","recommendation":"Change to next dev --turbopack; test compatibility","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-My1zdGVwIHRl","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"engineering-productivity","severity":"S3","type":"code-smell","file":"package.json","line":0,"title":"3-step test compilation adds 10-20s overhead — full Vitest migration needed","description":"3-step test compilation (tsc + tsc-alias + node --test) adds 10-20s overhead — inconsistent: pattern tests already use Vitest. DEBT-1931 covers TypeScript rebuild overhead; COMP-107 proposes full Vitest migration.","recommendation":"Migrate all tests to Vitest; eliminate tsc to dist-tests compile step","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Tm8gdHlwZS1j","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"engineering-productivity","severity":"S3","type":"code-smell","file":"package.json","line":0,"title":"No type-check npm script alias — DEVELOPMENT.md references it but doesn't exist","description":"No type-check npm script alias. DEVELOPMENT.md references npm run type-check but it doesn't exist. No DEBT entry found.","recommendation":"Add type-check: tsc --noEmit to package.json scripts","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-bnVsIFdpbmRv","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"engineering-productivity","severity":"S3","type":"code-smell","file":"nul","line":0,"title":"nul Windows artifact file committed to repo","description":"nul file (Windows artifact from redirecting to NUL) committed to repo. No DEBT entry found.","recommendation":"Delete nul; add to .gitignore","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-dHNjb25maWcu","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"engineering-productivity","severity":"S3","type":"code-smell","file":"tsconfig.json","line":0,"title":"tsconfig.json incremental: true with noEmit: true — redundant","description":"incremental: true with noEmit: true — incremental build info not used; redundant with Next.js internal compilation. No DEBT entry found.","recommendation":"Remove incremental: true","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Tm8gaTE4biBp","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"enhancements","severity":"S3","type":"code-smell","file":"","line":0,"title":"No i18n infrastructure — all strings hardcoded in English","description":"No i18n infrastructure — all strings hardcoded in English; Nashville has ~15% Spanish-speaking population. No DEBT entry found.","recommendation":"Install next-intl; extract strings to locale files","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Sm91cm5hbCBs","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"enhancements","severity":"S3","type":"code-smell","file":"components/journal/lock-screen.tsx","line":0,"title":"Journal lock screen component exists but is never imported or rendered","description":"Journal lock screen component exists but is never imported or rendered. No DEBT entry found.","recommendation":"Wire to journal flow or delete if deferred","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U3dpcGUgbmF2","source_file":"docs\\audits\\comprehensive\\audit-2026-02-22\\intake.jsonl","original_id":null,"category":"enhancements","severity":"S3","type":"code-smell","file":"components/notebook/notebook-shell.tsx","line":1132,"title":"Swipe navigation has no visual affordance — only hint is small footer text","description":"Swipe navigation has no visual affordance — only hint is small footer text. No DEBT entry found.","recommendation":"Add subtle swipe indicator animation or onboarding tooltip","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/lib::missing-readme","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/lib::missing-readme","category":"process","severity":"S3","type":"process-gap","file":"scripts/lib/","line":1,"title":"Docs: Missing README in scripts/lib/","description":"The lib/ directory contains shared utilities used across multiple scripts. Without a README, developers cannot quickly understand what utilities are available, their purpose, or usage patterns. This increases onboarding time and risk of code duplication.","recommendation":"Create scripts/lib/README.md documenting each utility module: ai-pattern-checks.js (AI pattern detection), sanitize-error.js (error sanitization), security-helpers.js (security utilities), validate-paths.js (path validation).","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/config::missing-readme","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/config::missing-readme","category":"process","severity":"S3","type":"process-gap","file":"scripts/config/","line":1,"title":"Docs: Missing README in scripts/config/","description":"The config/ directory contains JSON configuration files used by multiple scripts. Without documentation explaining the schema and purpose of each config file, developers may misuse configs or fail to update them when requirements change.","recommendation":"Create scripts/config/README.md documenting each config file: audit-schema.json (valid audit field values), audit-config.json (category thresholds), ai-patterns.json (AI pattern detection rules), skill-config.json (skill definitions), and load-config.js (config loader utility).","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/debt::missing-readme","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/debt::missing-readme","category":"process","severity":"S3","type":"process-gap","file":"scripts/debt/","line":1,"title":"Docs: Missing README in scripts/debt/","description":"The debt/ directory contains 17 technical debt management scripts. Without a README, developers cannot understand the debt workflow, which scripts to run in which order, or how to properly intake and resolve debt items.","recommendation":"Create scripts/debt/README.md documenting the technical debt workflow: intake scripts (intake-audit.js, intake-manual.js, intake-pr-deferred.js), processing scripts (normalize-all.js, consolidate-all.js, dedup-multi-pass.js), and resolution scripts (resolve-item.js, resolve-bulk.js). Include usage examples and workflow diagrams.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/audit::missing-readme","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/audit::missing-readme","category":"process","severity":"S3","type":"process-gap","file":"scripts/audit/","line":1,"title":"Docs: Missing README in scripts/audit/","description":"The audit/ directory contains audit-related scripts without documentation. Developers need to understand what these scripts do and when to use them as part of the audit process.","recommendation":"Create scripts/audit/README.md documenting: transform-jsonl-schema.js (schema transformation) and validate-audit-integration.js (audit validation). Include usage examples and integration points with the main audit workflow.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/enrich-addresses.ts::no-header","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/enrich-addresses.ts::no-header","category":"process","severity":"S3","type":"process-gap","file":"scripts/enrich-addresses.ts","line":1,"title":"Docs: No header comment in enrich-addresses.ts","description":"Script lacks header comment explaining purpose, making it difficult for developers to understand what it does without reading the implementation. Header comments serve as quick documentation.","recommendation":"Add JSDoc header comment explaining: Purpose (enrich meeting addresses with geocoding data from Nominatim/OSM), Usage (npx tsx scripts/enrich-addresses.ts), Prerequisites (Firebase service account, internet connection), and Rate limits (OSM Nominatim 1req/sec).","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/test-geocode.ts::no-header","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/test-geocode.ts::no-header","category":"process","severity":"S3","type":"process-gap","file":"scripts/test-geocode.ts","line":1,"title":"Docs: No header comment in test-geocode.ts","description":"Test script lacks header comment explaining purpose and usage. Without documentation, developers don't know this is a test utility or what it validates.","recommendation":"Add JSDoc header comment explaining: Purpose (test Google Maps Geocoding API connectivity and credentials), Usage (npx tsx scripts/test-geocode.ts), Prerequisites (NEXT_PUBLIC_FIREBASE_API_KEY environment variable), and Expected output.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/sync-geocache.ts::no-header","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/sync-geocache.ts::no-header","category":"process","severity":"S3","type":"process-gap","file":"scripts/sync-geocache.ts","line":1,"title":"Docs: No header comment in sync-geocache.ts","description":"Script lacks header comment. Developers cannot quickly understand this script syncs geocoding results from Firestore to a local cache file for performance optimization.","recommendation":"Add JSDoc header comment explaining: Purpose (sync meeting coordinates from Firestore to local geocoding_cache.json), Usage (npx tsx scripts/sync-geocache.ts), Prerequisites (Firebase service account, meetings collection with coordinates), and Output (geocoding_cache.json with sorted address-to-coordinate mappings).","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/retry-failures.ts::no-header","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/retry-failures.ts::no-header","category":"process","severity":"S3","type":"process-gap","file":"scripts/retry-failures.ts","line":1,"title":"Docs: No header comment in retry-failures.ts","description":"Script lacks header comment. Developers need to understand this retries failed geocoding operations from enrichment_failures.json.","recommendation":"Add JSDoc header comment explaining: Purpose (retry failed geocoding operations from enrichment_failures.json), Usage (npx tsx scripts/retry-failures.ts), Prerequisites (enrichment_failures.json, Firebase service account, OSM Nominatim access), Dependencies (requires prior run of enrich-addresses.ts), and Rate limits (2.5 second delay between requests).","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/migrate-library-content.ts::no-header","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/migrate-library-content.ts::no-header","category":"process","severity":"S3","type":"process-gap","file":"scripts/migrate-library-content.ts","line":1,"title":"Docs: No header comment in migrate-library-content.ts","description":"Migration script lacks header comment. Developers need to know this is a one-time migration from hardcoded library links to Firestore, when to run it, and side effects.","recommendation":"Add JSDoc header comment explaining: Purpose (one-time migration of library quick links from hardcoded array to Firestore), Usage (npx tsx scripts/migrate-library-content.ts), Prerequisites (Firebase service account), Warning (one-time use only, idempotent), and Output (populates library_content collection).","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/seed-real-data.ts::no-header","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/seed-real-data.ts::no-header","category":"process","severity":"S3","type":"process-gap","file":"scripts/seed-real-data.ts","line":1,"title":"Docs: No header comment in seed-real-data.ts","description":"Data seeding script lacks header comment. Developers need to understand this imports meeting data from CSV with geocoding, when to use it, and potential performance implications.","recommendation":"Add JSDoc header comment explaining: Purpose (import meeting data from SoNash_Meetings__cleaned.csv with geocoding), Usage (npx tsx scripts/seed-real-data.ts), Prerequisites (CSV file, Firebase service account, Google Maps API key or Nominatim access), Performance notes (rate limited 1.1s per request), and Output (populates meetings collection with geocoded addresses).","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/dedupe-quotes.ts::minimal-header","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/dedupe-quotes.ts::minimal-header","category":"process","severity":"S3","type":"process-gap","file":"scripts/dedupe-quotes.ts","line":1,"title":"Docs: Inadequate header in dedupe-quotes.ts","description":"Script has only 2-line header comment that doesn't explain purpose, usage, or expected workflow. Makes it difficult to understand when/how to use this deduplication utility.","recommendation":"Expand header comment to explain: Purpose (deduplication of recovery quotes from recovery_quotes_50.md), Usage, Expected input/output format, and Integration with the quote management system. Current comment 'Deduplication Script for Recovery Quotes' is too terse.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/config/ai-patterns.json::no-schema-docs","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/config/ai-patterns.json::no-schema-docs","category":"process","severity":"S3","type":"process-gap","file":"scripts/config/ai-patterns.json","line":1,"title":"Docs: Config file ai-patterns.json lacks inline documentation","description":"Configuration file defines AI pattern detection rules without schema documentation. Developers modifying patterns need to understand the structure: pattern object format, severity levels, regex descriptor format.","recommendation":"Add JSON comment block at top (or convert to .jsonc) documenting schema: {patterns: {[key]: {name, severity, patterns: [{source, flags}], description}}}. Explain that 'source' is regex pattern string, 'flags' are regex flags, 'severity' is S0-S3.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/config/audit-config.json::no-schema-docs","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/config/audit-config.json::no-schema-docs","category":"process","severity":"S3","type":"process-gap","file":"scripts/config/audit-config.json","line":1,"title":"Docs: Config file audit-config.json lacks inline documentation","description":"Configuration file defines audit category thresholds without documentation. Developers tuning thresholds need to understand units (commit counts vs file counts), regex descriptor format, and threshold semantics.","recommendation":"Add documentation explaining: categoryThresholds structure (commits=count, files=count, filePattern=regex descriptor, excludePattern=regex descriptor), multiAiThresholds (totalCommits threshold, daysSinceAudit threshold), categoryHeaders (regex to find category sections in AUDIT_TRACKER.md). Document that regex descriptors use {source, flags} format.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/config/audit-schema.json::no-schema-docs","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/config/audit-schema.json::no-schema-docs","category":"process","severity":"S3","type":"process-gap","file":"scripts/config/audit-schema.json","line":1,"title":"Docs: Config file audit-schema.json lacks inline documentation","description":"Configuration file defines valid audit field values without explanation. Developers need to understand when to use each category, severity, type, status, and effort level.","recommendation":"Add documentation explaining: validCategories (what each category means: security, performance, code-quality, documentation, process, refactoring, engineering-productivity), validSeverities (S0=critical, S1=high, S2=medium, S3=low), validTypes (bug, code-smell, vulnerability, hotspot, tech-debt, process-gap), validStatuses (lifecycle), validEfforts (E0=days, E1=hours, E2=30min, E3=5min), requiredFields.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/config/skill-config.json::no-schema-docs","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/config/skill-config.json::no-schema-docs","category":"process","severity":"S3","type":"process-gap","file":"scripts/config/skill-config.json","line":1,"title":"Docs: Config file skill-config.json lacks inline documentation","description":"Configuration file defines skill sections and patterns without documentation. Developers adding or modifying skills need to understand the schema structure and pattern format.","recommendation":"Add documentation explaining: requiredSections structure (audit vs session skill types), deprecatedPatterns array format ({pattern: {source, flags}, message}), topicAliases mapping (canonical topic to related terms). Explain regex descriptor format and how aliases improve search accuracy.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/aggregate-audit-findings.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/aggregate-audit-findings.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/aggregate-audit-findings.js","line":1,"title":"Docs: Excessively long file aggregate-audit-findings.js (1934 lines)","description":"File is 1934 lines (nearly 4x recommended 500-line limit). Large files are harder to understand, test, and maintain. Indicates multiple responsibilities that should be separated.","recommendation":"Split into modules: parsers.js (parseCanonItems, parseSingleSessionAudit, parseRoadmapItems, parseTechDebtItems, parseBacklogIssues), deduplication.js (deduplication logic, similarity scoring, shouldMerge), formatters.js (markdown formatting, JSONL output), and main orchestrator (aggregate-audit-findings.js). Move configuration constants to config files.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/analyze-learning-effectiveness.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/analyze-learning-effectiveness.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/analyze-learning-effectiveness.js","line":1,"title":"Docs: Excessively long file analyze-learning-effectiveness.js (1271 lines)","description":"File is 1271 lines (2.5x recommended limit). Contains analysis, reporting, and interactive CLI logic that should be separated for maintainability and testability.","recommendation":"Split into modules: pattern-analyzer.js (pattern detection and recurrence analysis), metrics-calculator.js (effectiveness scoring and statistics), report-generator.js (dashboard and detailed reports), cli-interface.js (readline prompts and interactive mode), and main orchestrator (analyze-learning-effectiveness.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/audit/validate-audit-integration.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/audit/validate-audit-integration.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/audit/validate-audit-integration.js","line":1,"title":"Docs: Excessively long file validate-audit-integration.js (1242 lines)","description":"File is 1242 lines (2.5x recommended limit). Validation script contains schema validation, false positive checking, evidence validation, and reporting that should be modular.","recommendation":"Split into modules: schema-validator.js (JSONL schema validation), false-positive-checker.js (FP database lookup), evidence-validator.js (file:line verification), tool-integrator.js (npm audit, ESLint, patterns:check), report-generator.js (validation reports), and main orchestrator (validate-audit-integration.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-review-needed.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/check-review-needed.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/check-review-needed.js","line":1,"title":"Docs: Excessively long file check-review-needed.js (1056 lines)","description":"File is 1056 lines (2x recommended limit). Contains git analysis, threshold checking, SonarCloud integration, and reporting that should be modular.","recommendation":"Split into modules: git-analyzer.js (commit counting, file change detection), threshold-checker.js (per-category threshold logic), sonarcloud-client.js (API integration), category-rules.js (category-specific thresholds), report-generator.js (human and JSON output), and main orchestrator (check-review-needed.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/multi-ai/normalize-format.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/multi-ai/normalize-format.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/multi-ai/normalize-format.js","line":1,"title":"Docs: Excessively long file multi-ai/normalize-format.js (1014 lines)","description":"File is 1014 lines (2x recommended limit). Format normalization script handles multiple input formats (JSONL, JSON, markdown, plain text) that should be separate parser modules.","recommendation":"Split into modules: jsonl-parser.js, json-parser.js, markdown-parser.js (tables, lists, headers), text-parser.js, format-detector.js (auto-detection), schema-normalizer.js (output normalization), and main orchestrator (normalize-format.js). Each parser should export parse() function.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/validate-audit.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/validate-audit.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/validate-audit.js","line":1,"title":"Docs: Excessively long file validate-audit.js (980 lines)","description":"File is 980 lines (nearly 2x recommended limit). Post-audit validation contains multiple validation types, external tool integration, and confidence scoring that should be modular.","recommendation":"Split into modules: false-positive-validator.js (FP database checking), evidence-validator.js (file:line verification, code snippet validation), tool-validator.js (npm audit, ESLint, patterns:check cross-reference), confidence-scorer.js (confidence level validation), duplicate-detector.js, and main orchestrator (validate-audit.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/generate-documentation-index.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/generate-documentation-index.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/generate-documentation-index.js","line":1,"title":"Docs: Excessively long file generate-documentation-index.js (980 lines)","description":"File is 980 lines (nearly 2x recommended limit). Documentation indexer combines file traversal, markdown parsing, hierarchy building, and output formatting that should be separated.","recommendation":"Split into modules: file-traverser.js (recursive directory traversal with excludes), markdown-parser.js (frontmatter extraction, header parsing), hierarchy-builder.js (tree structure generation), output-formatter.js (JSON and markdown formatting), and main orchestrator (generate-documentation-index.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-docs-light.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/check-docs-light.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/check-docs-light.js","line":1,"title":"Docs: Excessively long file check-docs-light.js (866 lines)","description":"File is 866 lines (1.7x recommended limit). Documentation checker combines multiple validation types (frontmatter, links, structure, coverage) that should be separate modules.","recommendation":"Split into modules: frontmatter-validator.js, link-checker.js (internal and external), structure-validator.js (heading hierarchy, required sections), coverage-analyzer.js (undocumented files), report-generator.js, and main orchestrator (check-docs-light.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-pattern-compliance.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/check-pattern-compliance.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/check-pattern-compliance.js","line":1,"title":"Docs: Excessively long file check-pattern-compliance.js (834 lines)","description":"File is 834 lines (1.7x recommended limit). Pattern compliance checker combines pattern loading, file scanning, pattern matching, and reporting that should be modular.","recommendation":"Split into modules: pattern-loader.js (load from ai-patterns.json), file-scanner.js (recursive scanning with excludes), pattern-matcher.js (regex matching with performance limits), violation-reporter.js (format violations for output), and main orchestrator (check-pattern-compliance.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/debt/sync-sonarcloud.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/debt/sync-sonarcloud.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/debt/sync-sonarcloud.js","line":1,"title":"Docs: Excessively long file debt/sync-sonarcloud.js (770 lines)","description":"File is 770 lines (1.5x recommended limit). SonarCloud sync combines API client logic, data transformation, deduplication, and persistence that should be separated.","recommendation":"Split into modules: sonarcloud-client.js (API requests, authentication, pagination), issue-transformer.js (SonarCloud to internal schema mapping), deduplicator.js (match existing debt items), persistence.js (JSONL writing), and main orchestrator (sync-sonarcloud.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/audit/transform-jsonl-schema.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/audit/transform-jsonl-schema.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/audit/transform-jsonl-schema.js","line":1,"title":"Docs: Excessively long file audit/transform-jsonl-schema.js (761 lines)","description":"File is 761 lines (1.5x recommended limit). Schema transformation combines parsing, validation, field mapping, and output generation that should be modular.","recommendation":"Split into modules: jsonl-parser.js (parse JSONL with error handling), schema-mapper.js (field mapping rules), field-validator.js (validate transformed output), output-generator.js (write transformed JSONL), and main orchestrator (transform-jsonl-schema.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/run-consolidation.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/run-consolidation.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/run-consolidation.js","line":1,"title":"Docs: Excessively long file run-consolidation.js (743 lines)","description":"File is 743 lines (1.5x recommended limit). Consolidation orchestrator combines workflow logic, file I/O, validation, and reporting that should be separated.","recommendation":"Split into modules: consolidation-workflow.js (step orchestration), file-manager.js (read/write JSONL files), validation-runner.js (schema validation), report-generator.js (consolidation reports), and main entry point (run-consolidation.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/multi-ai/unify-findings.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/multi-ai/unify-findings.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/multi-ai/unify-findings.js","line":1,"title":"Docs: Excessively long file multi-ai/unify-findings.js (716 lines)","description":"File is 716 lines (1.4x recommended limit). Finding unification combines parsing, similarity detection, merging, and conflict resolution that should be modular.","recommendation":"Split into modules: finding-parser.js (parse multiple formats), similarity-detector.js (detect duplicate findings), finding-merger.js (merge logic), conflict-resolver.js (handle disagreements), and main orchestrator (unify-findings.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/archive-doc.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/archive-doc.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/archive-doc.js","line":1,"title":"Docs: Excessively long file archive-doc.js (712 lines)","description":"File is 712 lines (1.4x recommended limit). Document archival combines file moving, content transformation, index updating, and git operations that should be separated.","recommendation":"Split into modules: file-archiver.js (move files to archive), content-transformer.js (add archive metadata), index-updater.js (update documentation indexes), git-operations.js (stage and commit), and main orchestrator (archive-doc.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-external-links.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/check-external-links.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/check-external-links.js","line":1,"title":"Docs: Excessively long file check-external-links.js (701 lines)","description":"File is 701 lines (1.4x recommended limit). Link checker combines link extraction, HTTP requests, caching, retry logic, and reporting that should be modular.","recommendation":"Split into modules: link-extractor.js (parse markdown for links), http-checker.js (validate URLs with retries), cache-manager.js (link validation cache), rate-limiter.js (throttle requests), report-generator.js, and main orchestrator (check-external-links.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/phase-complete-check.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/phase-complete-check.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/phase-complete-check.js","line":1,"title":"Docs: Excessively long file phase-complete-check.js (690 lines)","description":"File is 690 lines (1.4x recommended limit). Phase completion checker combines requirement parsing, status checking, dependency validation, and reporting that should be separated.","recommendation":"Split into modules: requirement-parser.js (parse phase requirements), status-checker.js (check completion criteria), dependency-validator.js (validate phase dependencies), blocking-analyzer.js (identify blockers), report-generator.js, and main orchestrator (phase-complete-check.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-doc-placement.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/check-doc-placement.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/check-doc-placement.js","line":1,"title":"Docs: Excessively long file check-doc-placement.js (616 lines)","description":"File is 616 lines (1.2x recommended limit). Document placement checker combines rules loading, file scanning, rule evaluation, and reporting that should be modular.","recommendation":"Split into modules: placement-rules.js (load and parse placement rules), file-scanner.js (find documents), rule-evaluator.js (check documents against rules), violation-detector.js (identify misplaced docs), report-generator.js, and main orchestrator (check-doc-placement.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/multi-ai/fix-schema.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/multi-ai/fix-schema.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/multi-ai/fix-schema.js","line":1,"title":"Docs: Excessively long file multi-ai/fix-schema.js (615 lines)","description":"File is 615 lines (1.2x recommended limit). Schema fixing combines validation, field correction, migration, and output that should be separated.","recommendation":"Split into modules: schema-validator.js (detect schema issues), field-fixer.js (correction rules for each field type), migration-rules.js (schema version migrations), output-writer.js (write corrected JSONL), and main orchestrator (fix-schema.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/multi-ai/aggregate-category.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/multi-ai/aggregate-category.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/multi-ai/aggregate-category.js","line":1,"title":"Docs: Excessively long file multi-ai/aggregate-category.js (603 lines)","description":"File is 603 lines (1.2x recommended limit). Category aggregation combines parsing, grouping, statistics, and output formatting that should be modular.","recommendation":"Split into modules: category-parser.js (parse findings by category), grouping-engine.js (group related findings), statistics-calculator.js (compute category metrics), output-formatter.js (generate reports), and main orchestrator (aggregate-category.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/verify-sonar-phase.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/verify-sonar-phase.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/verify-sonar-phase.js","line":1,"title":"Docs: Excessively long file verify-sonar-phase.js (597 lines)","description":"File is 597 lines (1.2x recommended limit). SonarCloud verification combines API calls, phase validation, issue tracking, and reporting that should be separated.","recommendation":"Split into modules: sonarcloud-client.js (API integration), phase-requirements.js (load phase criteria), issue-tracker.js (track verification issues), validation-engine.js (check requirements), report-generator.js, and main orchestrator (verify-sonar-phase.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/update-readme-status.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/update-readme-status.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/update-readme-status.js","line":1,"title":"Docs: Excessively long file update-readme-status.js (597 lines)","description":"File is 597 lines (1.2x recommended limit). README updater combines status collection, badge generation, markdown formatting, and file writing that should be modular.","recommendation":"Split into modules: status-collector.js (gather status from multiple sources), badge-generator.js (create status badges), markdown-formatter.js (format status sections), file-updater.js (in-place README updates), and main orchestrator (update-readme-status.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/debt/intake-audit.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/debt/intake-audit.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/debt/intake-audit.js","line":1,"title":"Docs: Excessively long file debt/intake-audit.js (586 lines)","description":"File is 586 lines (1.2x recommended limit). Audit intake combines parsing, validation, ID generation, deduplication, and persistence that should be separated.","recommendation":"Split into modules: audit-parser.js (parse audit JSONL), item-validator.js (schema validation), id-generator.js (generate debt IDs), deduplicator.js (detect duplicates), persister.js (write to MASTER_DEBT.jsonl), and main orchestrator (intake-audit.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/generate-detailed-sonar-report.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/generate-detailed-sonar-report.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/generate-detailed-sonar-report.js","line":1,"title":"Docs: Excessively long file generate-detailed-sonar-report.js (561 lines)","description":"File is 561 lines (1.1x recommended limit). SonarCloud report generator combines API calls, data aggregation, HTML generation, and file writing that should be modular.","recommendation":"Split into modules: sonarcloud-client.js (API integration), data-aggregator.js (aggregate issues by type/severity), html-generator.js (create HTML report), markdown-generator.js (create MD report), and main orchestrator (generate-detailed-sonar-report.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/lib/ai-pattern-checks.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/lib/ai-pattern-checks.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/lib/ai-pattern-checks.js","line":1,"title":"Docs: Excessively long file lib/ai-pattern-checks.js (554 lines)","description":"File is 554 lines (1.1x recommended limit). AI pattern library combines pattern loading, matching, reporting, and multiple specific pattern checkers that should be separated.","recommendation":"Split into modules: pattern-loader.js (load ai-patterns.json), pattern-matcher.js (core matching engine), pattern-checks/ directory with specific checkers (happy-path.js, trivial-assertions.js, todo-markers.js, etc.), and main exports (ai-pattern-checks.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/migrate-existing-findings.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/migrate-existing-findings.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/migrate-existing-findings.js","line":1,"title":"Docs: Excessively long file migrate-existing-findings.js (541 lines)","description":"File is 541 lines (1.1x recommended limit). Migration script combines multiple source parsing, schema transformation, deduplication, and output that should be separated.","recommendation":"Split into modules: source-parsers.js (parse old formats), schema-transformer.js (old to new schema), deduplicator.js (detect duplicates across sources), output-writer.js (write migrated JSONL), and main orchestrator (migrate-existing-findings.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-content-accuracy.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/check-content-accuracy.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/check-content-accuracy.js","line":1,"title":"Docs: Excessively long file check-content-accuracy.js (516 lines)","description":"File is 516 lines (1.0x recommended limit). Content accuracy checker combines reference validation, fact checking, staleness detection, and reporting that should be modular.","recommendation":"Split into modules: reference-validator.js (check cross-references), fact-checker.js (validate claims), staleness-detector.js (identify outdated content), accuracy-scorer.js (compute accuracy metrics), report-generator.js, and main orchestrator (check-content-accuracy.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/sync-claude-settings.js::excessive-length","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6c-documentation.jsonl","original_id":"process::scripts/sync-claude-settings.js::excessive-length","category":"process","severity":"S3","type":"process-gap","file":"scripts/sync-claude-settings.js","line":1,"title":"Docs: Excessively long file sync-claude-settings.js (501 lines)","description":"File is 501 lines (exactly at limit). Settings sync combines parsing, validation, merging, and persistence that should be separated for better maintainability.","recommendation":"Split into modules: settings-parser.js (parse .claude/ settings), settings-validator.js (validate schema), settings-merger.js (merge strategies), settings-writer.js (atomic writes), and main orchestrator (sync-claude-settings.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::automation::consolidate-flagged-scripts","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6b-improvements.jsonl","original_id":"process::automation::consolidate-flagged-scripts","category":"process","severity":"S3","type":"process-gap","file":"package.json","line":1,"title":"Improve: Consolidate duplicate script patterns into single script with flags","description":"8+ script pairs use pattern 'script:action' + 'script:action-variant' calling same script with different flags -> Single consolidated script reduces maintenance and testing surface","recommendation":"Replace script pairs (learning:analyze/dashboard/detailed, patterns:check/check-all, security:check/check-all, session:gaps/gaps:fix, override:log/list, agents:check/check-strict) with single scripts that accept flags via npm -- syntax (e.g., 'npm run learning -- --dashboard')","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::automation::hook-ci-duplication","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6b-improvements.jsonl","original_id":"process::automation::hook-ci-duplication","category":"process","severity":"S3","type":"process-gap","file":".husky/pre-commit","line":1,"title":"Improve: Reduce pre-commit hook check duplication with CI","description":"Pattern compliance runs 3x (pre-commit, pre-push, CI), type checking runs 2x (pre-push, CI), tests run 2x (pre-commit conditional, CI) -> Wastes developer time and CI resources","recommendation":"Move expensive checks (type checking, full test suite) exclusively to CI. Keep only fast checks (<5s each) in pre-commit: ESLint, lint-staged, pattern compliance on staged files only. Add --staged flag to pattern compliance script for faster pre-commit checks.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::automation::hook-output-inefficiency","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6b-improvements.jsonl","original_id":"process::automation::hook-output-inefficiency","category":"process","severity":"S3","type":"process-gap","file":".husky/pre-commit","line":9,"title":"Improve: Eliminate redundant npm run then re-run pattern in hooks","description":"Multiple hooks run 'npm run cmd > /dev/null 2>&1' to check exit code, then re-run 'npm run cmd 2>&1 | tail' to show output on failure -> Doubles execution time for failing checks","recommendation":"Capture output to temp file once: 'npm run cmd > $tmpfile 2>&1; code=$?; if [ $code -ne 0 ]; then tail $tmpfile; exit 1; fi'. Already used correctly for tests (line 56-66).","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::automation::ci-cache-test-build","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6b-improvements.jsonl","original_id":"process::automation::ci-cache-test-build","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/ci.yml","line":114,"title":"Improve: Add CI caching for test build artifacts","description":"test:build compiles TypeScript to dist-tests/ on every CI run, taking 20-30s -> No caching means repeated compilation","recommendation":"Add GitHub Actions cache for dist-tests/ directory keyed on hash of src/tests/ and tsconfig.test.json. Skip test:build if cache hit and source unchanged.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::automation::redundant-tsc-invocations","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6b-improvements.jsonl","original_id":"process::automation::redundant-tsc-invocations","category":"process","severity":"S3","type":"process-gap","file":"package.json","line":11,"title":"Improve: Combine test:build and type check into single tsc invocation","description":"CI runs 'npm run test:build' (tsc -p tsconfig.test.json) AND 'tsc --noEmit' separately -> Redundant TypeScript compilation (40-60s total)","recommendation":"Refactor test compilation to use 'tsc --noEmit' for type checking, then use esbuild or tsx for faster test execution. OR ensure test:build also validates non-test types and remove separate type check step.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::automation::ci-parallelization","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6b-improvements.jsonl","original_id":"process::automation::ci-parallelization","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/ci.yml","line":1,"title":"Improve: Parallelize independent CI jobs","description":"lint-typecheck-test job runs 15+ steps sequentially, many are independent (lint, format:check, deps:circular, deps:unused) -> Sequential execution adds 2-3 minutes","recommendation":"Split CI into parallel jobs: 1) Lint & Format (eslint, prettier, markdown) 2) Dependencies (circular, unused) 3) Type Check & Test 4) Build. Use needs: to sequence only what's required.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::automation::scheduled-npm-audit","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6b-improvements.jsonl","original_id":"process::automation::scheduled-npm-audit","category":"process","severity":"S3","type":"process-gap","file":".husky/pre-push","line":92,"title":"Improve: Make npm audit scheduled instead of on every push","description":"npm audit runs on every git push (non-blocking, 3-8s) checking for vulnerabilities -> Slows down push, security issues rarely change between pushes","recommendation":"Remove npm audit from pre-push hook. Add scheduled workflow (daily/weekly) to run npm audit and create GitHub issue if high/critical vulnerabilities found. Faster feedback loop for developers.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::automation::auto-update-doc-index","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6b-improvements.jsonl","original_id":"process::automation::auto-update-doc-index","category":"process","severity":"S3","type":"process-gap","file":".husky/pre-commit","line":134,"title":"Improve: Auto-update DOCUMENTATION_INDEX.md in pre-commit hook","description":"Pre-commit hook BLOCKS if .md files changed but DOCUMENTATION_INDEX.md not updated, requiring manual 'npm run docs:index && git add' -> Friction in commit workflow","recommendation":"Auto-run 'npm run docs:index' and auto-stage DOCUMENTATION_INDEX.md when .md files are in commit. Show diff and ask for confirmation, or make it automatic with override flag SKIP_DOC_INDEX_AUTO=1.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::automation::consolidate-docs-workflow","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6b-improvements.jsonl","original_id":"process::automation::consolidate-docs-workflow","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/docs-lint.yml","line":1,"title":"Improve: Combine docs-lint.yml checks into main CI workflow","description":"docs-lint.yml and ci.yml both trigger on PRs touching docs, both run documentation checks -> Duplicate workflow runs and maintenance burden","recommendation":"Move docs-lint functionality into ci.yml as a separate job that runs conditionally (if: contains(changed-files, '*.md')). Reduces workflows from 10 to 9, single place for doc linting logic.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::automation::task-runner-migration","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6b-improvements.jsonl","original_id":"process::automation::task-runner-migration","category":"process","severity":"S3","type":"process-gap","file":"package.json","line":1,"title":"Improve: Use task runner (turbo/nx) for script orchestration","description":"70+ npm scripts with complex dependencies, no dependency caching, sequential execution in hooks/CI -> Slow execution, hard to maintain, no incremental builds","recommendation":"Introduce turbo or nx for: 1) Dependency graph (test depends on test:build) 2) Caching (hash-based) 3) Parallel execution 4) Incremental rebuilds. Start with test pipeline, expand to lint/build.","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::automation::firebase-deploy-simplification","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6b-improvements.jsonl","original_id":"process::automation::firebase-deploy-simplification","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/deploy-firebase.yml","line":73,"title":"Improve: Simplify Firebase deployment workflow","description":"Deploy workflow has 3 sequential deployment steps (functions, rules, hosting) that could run in parallel -> Adds 2-3 minutes to deployment time","recommendation":"Use 'firebase deploy --only functions,firestore:rules,hosting' single command OR parallelize as separate jobs with proper sequencing. Also remove deprecated function deletion step (line 131-138) which is continue-on-error anyway.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::automation::backlog-stale-reference","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6b-improvements.jsonl","original_id":"process::automation::backlog-stale-reference","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/backlog-enforcement.yml","line":32,"title":"Improve: Backlog enforcement workflow references archived file","description":"Workflow checks AUDIT_FINDINGS_BACKLOG.md which was archived in TDMS Phase 2 -> Workflow always exits early, provides no value, maintenance burden","recommendation":"Either: 1) Update workflow to check docs/technical-debt/MASTER_DEBT.jsonl for backlog health (count open items, S0/S1 thresholds) OR 2) Archive/remove workflow if backlog-health is checked elsewhere.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::automation::hook-timing-visibility","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6b-improvements.jsonl","original_id":"process::automation::hook-timing-visibility","category":"process","severity":"S3","type":"process-gap","file":".husky/pre-commit","line":1,"title":"Improve: Add hook timing instrumentation","description":"Pre-commit has 13 check steps (280 lines), pre-push has 7 steps (155 lines), but no visibility into which steps are slow -> Can't identify optimization opportunities","recommendation":"Add timing instrumentation: 'START=$(date +%s); ... ; echo \"  ⏱️  Took $(($(date +%s) - START))s\"' for each major step. OR use time command. Log slow steps (>3s) to .git/hooks/timing.log for analysis.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::automation::consolidate-security-checks","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6b-improvements.jsonl","original_id":"process::automation::consolidate-security-checks","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/backlog-enforcement.yml","line":103,"title":"Improve: Consolidate security checking into single workflow","description":"Security patterns checked in pre-push hook (files being pushed) AND backlog-enforcement workflow (all files or PR files) -> Duplication and potential inconsistency","recommendation":"Remove security-patterns job from backlog-enforcement.yml. Keep security check in pre-push hook only. Add scheduled workflow (weekly) for full-repo security audit with GitHub Security tab integration.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::automation::expand-lint-staged","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6b-improvements.jsonl","original_id":"process::automation::expand-lint-staged","category":"process","severity":"S3","type":"process-gap","file":"package.json","line":78,"title":"Improve: Use lint-staged for more than just formatting","description":"lint-staged only runs prettier (formatting) on staged files -> ESLint, pattern compliance, and other checks run on ALL files even if not staged","recommendation":"Expand lint-staged config: '*.{ts,tsx,js,jsx}': ['eslint --fix', 'prettier --write'], '*.md': ['markdownlint --fix', 'prettier --write']. Moves ESLint to lint-staged for automatic fixes and faster execution (staged files only).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::automation::add-commit-msg-hook","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6b-improvements.jsonl","original_id":"process::automation::add-commit-msg-hook","category":"process","severity":"S3","type":"process-gap","file":".husky/_/commit-msg","line":1,"title":"Improve: Add commit message validation hook","description":"No commit message validation enforced -> Inconsistent commit messages make changelog generation and git log navigation harder","recommendation":"Add .husky/commit-msg hook to validate conventional commits format (feat:, fix:, docs:, chore:, etc). Use commitlint or simple regex. Block commits with bad format or provide helpful error message.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::automation::workflow-caching-strategy","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6b-improvements.jsonl","original_id":"process::automation::workflow-caching-strategy","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/ci.yml","line":22,"title":"Improve: Add GitHub Actions workflow caching strategy","description":"All workflows use 'cache: npm' which only caches npm packages, not build artifacts or script outputs -> Miss opportunity for faster CI runs","recommendation":"Add composite caching: 1) npm packages (already cached) 2) Next.js .next/ cache 3) TypeScript build cache 4) test:build dist-tests/ output. Use cache-dependency-path for all package-lock.json files.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::automation::automate-doc-maintenance","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6b-improvements.jsonl","original_id":"process::automation::automate-doc-maintenance","category":"process","severity":"S3","type":"process-gap","file":"package.json","line":14,"title":"Improve: Migrate manual documentation tasks to automated triggers","description":"3 documentation maintenance scripts require manual invocation: docs:update-readme, docs:archive, docs:index -> Leads to stale documentation","recommendation":"1) docs:index - already has pre-commit check, make it auto-run and stage 2) docs:update-readme - add to sync-readme.yml workflow trigger 3) docs:archive - add scheduled workflow (monthly) to identify docs that should be archived (no updates in 6+ months, marked obsolete)","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::automation::stale-branch-cleanup","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6b-improvements.jsonl","original_id":"process::automation::stale-branch-cleanup","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/*","line":1,"title":"Improve: Add workflow for stale branch cleanup","description":"No automated branch cleanup -> Old feature branches accumulate, clutter repository, cause confusion","recommendation":"Add scheduled workflow using actions/stale to: 1) Label branches with no commits in 30 days as 'stale' 2) Delete branches with no commits in 60 days (excluding main, develop, release/*) 3) Post comment on associated PR before deletion","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::automation::simplify-trigger-checks","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6b-improvements.jsonl","original_id":"process::automation::simplify-trigger-checks","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/ci.yml","line":42,"title":"Improve: Replace manual trigger checks with GitHub Actions expressions","description":"Workflows use tj-actions/changed-files then bash scripts to check patterns -> Extra action dependency, slower execution, more complex logic","recommendation":"Use GitHub Actions native path filters and expressions: 'if: contains(github.event.head_commit.modified, '.md')' or combine with paths: filter in workflow trigger. Reduces external dependencies.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::N/A::shell-script-no-lint","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6a-coverage-gaps.jsonl","original_id":"process::N/A::shell-script-no-lint","category":"process","severity":"S2","type":"process-gap","file":".claude/hooks/analyze-user-request.sh","line":1,"title":"Gap: Shell scripts not linted or validated","description":"6 shell scripts in .claude/hooks/ (and additional ones in skills/) can be committed with syntax errors, runtime bugs, or security issues. ShellCheck would catch common mistakes like unquoted variables, incorrect conditionals, and unsafe patterns. Shell scripts run at critical points (session start, pre-commit checks) so bugs can break development workflow.","recommendation":"Add ShellCheck validation: 1) Install shellcheck as devDependency, 2) Add npm script 'shellcheck:check' that runs on .claude/hooks/*.sh and .claude/skills/**/*.sh, 3) Add to pre-commit hook before other checks, 4) Add to CI workflow as blocking step, 5) Create .shellcheckrc to configure rules.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::N/A::mjs-config-no-lint","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6a-coverage-gaps.jsonl","original_id":"process::N/A::mjs-config-no-lint","category":"process","severity":"S3","type":"process-gap","file":"eslint.config.mjs","line":25,"title":"Gap: Config .mjs files excluded from linting","description":"eslint.config.mjs explicitly excludes '*.config.mjs' from linting. These are critical configuration files (Next.js, PostCSS, ESLint itself) that affect build and development. Syntax errors or security issues in these files can break builds or introduce vulnerabilities. Currently they can be committed without any validation.","recommendation":"Remove '*.config.mjs' from ignores array in eslint.config.mjs. If specific rules need to be relaxed for config files, create a separate configuration block with adjusted rules (e.g., allow 'export default' without explicit types). Verify all config files pass linting before making change blocking.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::N/A::scripts-no-tests","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6a-coverage-gaps.jsonl","original_id":"process::N/A::scripts-no-tests","category":"process","severity":"S2","type":"process-gap","file":"scripts/","line":1,"title":"Gap: Scripts directory missing test coverage","description":"89 JavaScript files in scripts/ directory but only 5 have test coverage (check-docs-light, phase-complete-check, surface-lessons-learned, update-readme-status, validate-audit-s0s1). These scripts handle critical automation: debt management, audit validation, security checks, hook health, document sync. Bugs in these scripts can corrupt data, break CI, or cause incorrect validation results. Scripts like validate-audit.js, security-check.js, and debt/validate-schema.js are used as blocking gates in pre-commit/pre-push.","recommendation":"Prioritize test coverage for blocking scripts: 1) Start with security-check.js (blocks pre-push), 2) Add tests for debt/validate-schema.js (blocks commits), 3) Cover validate-audit.js (blocks S0/S1), 4) Add tests for check-pattern-compliance.js (blocks commits), 5) Expand to other critical scripts. Create tests/scripts/__helpers__ for common test utilities. Aim for 60%+ coverage of blocking scripts, 30%+ for others.","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::N/A::functions-no-integration-tests","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6a-coverage-gaps.jsonl","original_id":"process::N/A::functions-no-integration-tests","category":"process","severity":"S2","type":"process-gap","file":"functions/src/admin.ts","line":1,"title":"Gap: Firebase functions lack integration tests","description":"8 TypeScript files in functions/src/ contain Cloud Functions (admin operations, recaptcha verification, scheduled jobs, security wrappers) but no integration tests exist in functions/ directory. While unit tests exist for the main app, Firebase functions interact with Firestore, authentication, and external APIs. Integration tests would catch: incorrect Firestore rules interactions, auth token validation issues, rate limiting failures, scheduled job execution problems. Functions are deployed to production and handle sensitive operations.","recommendation":"Set up Firebase Functions integration test framework: 1) Install firebase-functions-test (already in devDeps), 2) Create functions/test/ directory, 3) Add test files for each function module (admin.test.ts, recaptcha-verify.test.ts, jobs.test.ts), 4) Use Firebase emulators for Firestore/Auth, 5) Add 'test' script to functions/package.json, 6) Run function tests in CI after main tests, 7) Document test setup in functions/README.md.","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::N/A::skills-no-usage-docs","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6a-coverage-gaps.jsonl","original_id":"process::N/A::skills-no-usage-docs","category":"process","severity":"S3","type":"process-gap","file":".claude/skills/","line":1,"title":"Gap: Skills missing usage documentation","description":"56 skills exist but 0 have USAGE.md documentation, only 1 has README.md. SKILL_INDEX.md shows skills organized by category (Audit & Code Quality, Session Management, Development Roles, etc.) but individual skills lack: usage examples, parameter documentation, expected outputs, common use cases, troubleshooting tips. This makes skills harder to use correctly and increases likelihood of misuse. New team members or AI agents using these skills lack guidance.","recommendation":"Create standardized skill documentation template: 1) Add USAGE.md template to skill-creator skill, 2) Document top 10 most-used skills first (check MCP logs for frequency), 3) Include sections: Synopsis, Parameters, Examples, Expected Output, Common Issues, Related Skills, 4) Add skills:check-docs npm script to validate USAGE.md exists and has required sections, 5) Add to pre-commit check when skill files are modified, 6) Generate missing USAGE.md files in batch using doc-optimizer skill.","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::N/A::yaml-no-lint","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6a-coverage-gaps.jsonl","original_id":"process::N/A::yaml-no-lint","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/ci.yml","line":1,"title":"Gap: YAML workflow files not linted","description":"10 GitHub workflow YAML files exist (.github/workflows/*.yml) but no YAML linting is configured. Workflow files control CI/CD, deployments, security checks, and automation. YAML syntax errors break CI/CD pipelines. Invalid workflow syntax might not be caught until push, wasting time. Indentation errors, incorrect anchors, or invalid keys can cause silent failures or unexpected behavior.","recommendation":"Add YAML linting: 1) Install yamllint as devDependency, 2) Create .yamllint.yml config (set line-length to 120, indent to 2, allow comments), 3) Add npm script 'yaml:lint' that checks .github/workflows/*.yml and .serena/project.yml, 4) Add to pre-commit hook (non-blocking warning first), 5) Add to CI as blocking step, 6) Fix any existing issues before making blocking.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::N/A::env-no-validation","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6a-coverage-gaps.jsonl","original_id":"process::N/A::env-no-validation","category":"process","severity":"S2","type":"process-gap","file":".env.local.example","line":1,"title":"Gap: Environment files not validated","description":"Multiple .env files exist (.env.local.example, functions/.env.local.example, .env.production) but no validation of required variables or format. Missing required env vars cause runtime errors. Incorrect env var formats (URLs without protocols, invalid API keys) fail late. Example files can become stale and missing new required variables. No check that actual .env files match the example structure.","recommendation":"Create environment validation: 1) Add scripts/validate-env.js that reads .env.local.example and checks actual .env files have required keys, 2) Validate format (URLs, numeric values, required prefixes like NEXT_PUBLIC_), 3) Add npm script 'env:validate', 4) Run in pre-push as non-blocking warning (can't block since .env is gitignored), 5) Add to CI for production builds, 6) Check functions/.env separately with functions-specific requirements, 7) Document required env vars in README.md.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::N/A::functions-no-type-check-pre-push","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6a-coverage-gaps.jsonl","original_id":"process::N/A::functions-no-type-check-pre-push","category":"process","severity":"S3","type":"process-gap","file":".husky/pre-push","line":82,"title":"Gap: Firebase functions TypeScript not type-checked in pre-push","description":"Pre-push hook (line 82-90) runs 'npx tsc --noEmit' for type checking but only for the main project, not for functions/. Firebase functions have their own TypeScript config (functions/tsconfig.json) and can have type errors that slip through. Type errors in functions are only caught during 'npm run build' in functions/ which might not be run before push. CI doesn't explicitly type-check functions directory either (only runs functions build during deploy workflow).","recommendation":"Add functions type check to pre-push: 1) After main type check in .husky/pre-push (line 90), add functions type check, 2) Run 'cd functions && npx tsc --noEmit' (or use absolute path), 3) Show appropriate error message if functions type check fails, 4) Consider adding to CI workflow as explicit step before build, 5) Ensure functions TypeScript errors are visible and block push.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::N/A::ci-no-shell-syntax-check","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6a-coverage-gaps.jsonl","original_id":"process::N/A::ci-no-shell-syntax-check","category":"process","severity":"S2","type":"process-gap","file":".github/workflows/ci.yml","line":1,"title":"Gap: No syntax validation for committed shell scripts in CI","description":"CI workflow checks many things (ESLint, TypeScript, tests, patterns, security) but doesn't validate shell script syntax. Pre-commit hook is itself a shell script (.husky/pre-commit) - if it has syntax errors, commits can become blocked or validation can silently fail. .claude/hooks/ contains 6 critical shell scripts that run during development. A shell syntax error could break session-start.sh or pattern-check.sh, disrupting development flow. While these might work on developer's machine, different shell versions or environments could expose issues.","recommendation":"Add shell script validation to CI: 1) Install ShellCheck in CI environment (add to CI job steps), 2) Add step after 'Checkout code' named 'Validate shell scripts', 3) Run 'shellcheck .husky/pre-commit .husky/pre-push .claude/hooks/*.sh .claude/skills/**/*.sh', 4) Make blocking (don't use continue-on-error), 5) Add corresponding pre-commit check so issues are caught earlier, 6) Document shell script standards in CONTRIBUTING.md.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::N/A::new-files-coverage-check","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-6a-coverage-gaps.jsonl","original_id":"process::N/A::new-files-coverage-check","category":"process","severity":"S3","type":"process-gap","file":".husky/pre-commit","line":1,"title":"Gap: No validation that new files are covered by appropriate checks","description":"When new file types are added to the project (e.g., .proto files, .graphql, .tf for Terraform), there's no check that they're covered by linting, validation, or security checks. Pre-commit checks specific file types (.md for doc index, .jsonl for debt, .ts/.js for ESLint) but doesn't ensure NEW file types have appropriate validation. Could add Terraform files without terraform validate, GraphQL without schema validation, Protocol Buffers without protolint, etc. Gap would only be noticed during PR review or when issues occur.","recommendation":"Create new-file-type detection: 1) Add scripts/check-file-coverage.js that detects file extensions in repo, 2) Maintain config/known-file-types.json mapping extensions to their validators (e.g., .ts->ESLint+TypeScript, .sh->ShellCheck, .yml->yamllint), 3) Check if any committed files have extensions not in known list, 4) Warning in pre-commit (non-blocking), 5) Add 'coverage:files' npm script for manual checking, 6) Run in CI as informational (continue-on-error: true), 7) Prompt to add validation for new file types.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts::module-system-mix","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5c-consistency.jsonl","original_id":"process::scripts::module-system-mix","category":"process","severity":"S3","type":"process-gap","file":"scripts/append-hook-warning.js","line":1,"title":"Inconsistent: Mixed CommonJS and ESM module systems","description":"Mixing CommonJS (require) and ESM (import) makes codebase harder to maintain and can cause confusion about module resolution. Standardizing on one approach improves consistency and reduces cognitive load.","recommendation":"Standardize on ESM (import/export) for all new scripts. Create migration plan for remaining CommonJS scripts. ESM is the modern standard and provides better static analysis.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts::node-prefix-inconsistency","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5c-consistency.jsonl","original_id":"process::scripts::node-prefix-inconsistency","category":"process","severity":"S3","type":"process-gap","file":"scripts/validate-audit.js","line":18,"title":"Inconsistent: node: prefix usage in imports","description":"Some scripts use 'node:fs' prefix for built-in modules, others use 'fs', and some use aliases like 'node_fs'. This inconsistency makes code reviews harder and creates unnecessary variation in import style.","recommendation":"Standardize on using 'node:' prefix for all Node.js built-in modules (node:fs, node:path, etc.) without aliases. This is the modern Node.js convention and makes built-in modules explicit.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts::emoji-consistency","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5c-consistency.jsonl","original_id":"process::scripts::emoji-consistency","category":"process","severity":"S3","type":"process-gap","file":"scripts/seed-commit-log.js","line":105,"title":"Inconsistent: Emoji usage in console output","description":"Most scripts use emojis for visual feedback (✅, ❌, ⚠️) but some don't, creating inconsistent UX across automation tools. Users expect consistent output formatting.","recommendation":"Establish emoji usage standard: use emojis for all user-facing scripts (✅ success, ❌ error, ⚠️ warning, 📊 info). Create shared constants file for emoji mappings to ensure consistency.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts::exit-code-patterns","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5c-consistency.jsonl","original_id":"process::scripts::exit-code-patterns","category":"process","severity":"S3","type":"process-gap","file":"scripts/check-agent-compliance.js","line":192,"title":"Inconsistent: Exit code handling patterns","description":"Scripts use different patterns for setting exit codes: some use process.exit() directly, others use process.exitCode assignment. This inconsistency makes error handling patterns harder to learn and maintain.","recommendation":"Standardize on process.exitCode assignment pattern (not direct process.exit()) to allow cleanup handlers to run. Reserve process.exit() for truly fatal errors only. Document pattern in CONTRIBUTING.md.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts::verbose-logging","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5c-consistency.jsonl","original_id":"process::scripts::verbose-logging","category":"process","severity":"S3","type":"process-gap","file":"scripts/archive-doc.js","line":72,"title":"Inconsistent: Verbose/debug logging approaches","description":"Some scripts have verbose() helper functions for debug output, others don't, leading to inconsistent debug capabilities. Makes troubleshooting harder when scripts don't expose internal state consistently.","recommendation":"Create shared logging utility (scripts/lib/logger.js) with consistent verbose/debug/info/warn/error methods. All scripts should import and use this utility for standardized output levels.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts::error-message-format","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5c-consistency.jsonl","original_id":"process::scripts::error-message-format","category":"process","severity":"S3","type":"process-gap","file":"scripts/check-agent-compliance.js","line":163,"title":"Inconsistent: Error message formatting","description":"Error messages use different formats: some use boxed separators (===, ---), some use simple prefixes. This creates inconsistent UX and makes it harder to parse errors programmatically.","recommendation":"Standardize error message format: [SCRIPT_NAME] LEVEL: message. Use consistent separator styles (=== for major sections, --- for subsections). Create error formatting utility function.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts::arg-parsing","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5c-consistency.jsonl","original_id":"process::scripts::arg-parsing","category":"process","severity":"S3","type":"process-gap","file":"scripts/check-agent-compliance.js","line":29,"title":"Inconsistent: Command line argument parsing","description":"Scripts parse command line arguments differently: some use simple includes() checks, others have custom parseArgs() functions, creating inconsistent CLI interfaces and duplicated parsing logic.","recommendation":"Adopt a standard CLI parsing library (e.g., commander.js or yargs) for all scripts with complex arguments. For simple flags, use consistent pattern. Create shared argument parsing utilities.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts::path-validation","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5c-consistency.jsonl","original_id":"process::scripts::path-validation","category":"process","severity":"S2","type":"process-gap","file":"scripts/archive-doc.js","line":83,"title":"Inconsistent: File path validation and sanitization","description":"Path validation and sanitization logic is duplicated across scripts with slightly different implementations, risking security vulnerabilities if one implementation is weaker. Validation should be centralized.","recommendation":"Create shared path validation utilities in scripts/lib/validate-paths.js. Implement validatePathWithinRepo(), sanitizePath(), isSafeFilePath() once and reuse. Add comprehensive tests.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts::error-sanitization","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5c-consistency.jsonl","original_id":"process::scripts::error-sanitization","category":"process","severity":"S2","type":"process-gap","file":"scripts/archive-doc.js","line":41,"title":"Inconsistent: Error sanitization approaches","description":"Some scripts import sanitizeError utility, others inline error sanitization, and some don't sanitize at all. This creates security risk of exposing sensitive paths or tokens in error messages.","recommendation":"Ensure all scripts use shared sanitizeError() utility from scripts/lib/sanitize-error.js. Add ESLint rule to catch raw error.message usage. Document sanitization requirement in CONTRIBUTING.md.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/ai-review.js::toctou-existsSync-readFileSync","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5b-code-quality.jsonl","original_id":"process::scripts/ai-review.js::toctou-existsSync-readFileSync","category":"process","severity":"S1","type":"process-gap","file":"scripts/ai-review.js","line":139,"title":"Quality: TOCTOU race condition in ai-review.js","description":"Classic TOCTOU (Time-of-Check-Time-of-Use) race condition. File existence is checked with existsSync() then read with readFileSync(). Between these calls, the file could be deleted, moved, or replaced with a symlink, causing crashes or reading wrong files. CODE_PATTERNS.md Rule #3 explicitly requires wrapping ALL file reads in try/catch.","recommendation":"Remove existsSync check and wrap readFileSync in try/catch. Pattern from CODE_PATTERNS.md: try { const content = readFileSync(filePath, 'utf-8'); return { success: true, content }; } catch (error) { if (error.code === 'ENOENT') { return { success: false, error: 'File not found' }; } ... }","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":"scripts/ai-review.js:139"},{"type":"description","detail":"Classic TOCTOU (Time-of-Check-Time-of-Use) race condition. File existence is checked with existsSync() then read with readFileSync(). Between these calls, the file could be deleted, moved, or replaced with a symlink, causing crashes or reading wrong files. CODE_PATTERNS.md Rule #3 explicitly requires wrapping ALL file reads in try/catch."}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-consolidation-status.js::toctou-existsSync-readFileSync","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5b-code-quality.jsonl","original_id":"process::scripts/check-consolidation-status.js::toctou-existsSync-readFileSync","category":"process","severity":"S1","type":"process-gap","file":"scripts/check-consolidation-status.js","line":89,"title":"Quality: TOCTOU race condition in check-consolidation-status.js","description":"Classic TOCTOU race condition. existsSync at line 89 followed by readFileSync at line 96. Violates CODE_PATTERNS.md Critical Pattern #3: 'Wrap ALL file reads in try/catch - existsSync has race conditions'. Between the check and read, file could be deleted causing crash.","recommendation":"Remove existsSync check at line 89. Change error handling to: try { const content = readFileSync(LOG_FILE, 'utf8'); ... } catch (err) { if (err.code === 'ENOENT') { console.error('File not found'); process.exitCode = 2; return; } throw err; }","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":"scripts/check-consolidation-status.js:89"},{"type":"description","detail":"Classic TOCTOU race condition. existsSync at line 89 followed by readFileSync at line 96. Violates CODE_PATTERNS.md Critical Pattern #3: 'Wrap ALL file reads in try/catch - existsSync has race conditions'. Between the check and read, file could be deleted causing crash."}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/debt/resolve-item.js::toctou-existsSync-readFileSync","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5b-code-quality.jsonl","original_id":"process::scripts/debt/resolve-item.js::toctou-existsSync-readFileSync","category":"process","severity":"S1","type":"process-gap","file":"scripts/debt/resolve-item.js","line":53,"title":"Quality: TOCTOU race condition in resolve-item.js","description":"TOCTOU race in loadMasterDebt(). existsSync at line 53 followed by readFileSync at line 56. File could be deleted between check and read. Violates CODE_PATTERNS.md Critical Pattern #3. In a concurrent environment (multiple debt resolution scripts), this can cause crashes.","recommendation":"Replace lines 52-59 with: function loadMasterDebt() { try { const content = fs.readFileSync(MASTER_FILE, 'utf8'); const lines = content.split('\\n').filter(line => line.trim()); return lines.map(line => JSON.parse(line)); } catch (err) { if (err.code === 'ENOENT') return []; throw err; } }","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":"scripts/debt/resolve-item.js:53"},{"type":"description","detail":"TOCTOU race in loadMasterDebt(). existsSync at line 53 followed by readFileSync at line 56. File could be deleted between check and read. Violates CODE_PATTERNS.md Critical Pattern #3. In a concurrent environment (multiple debt resolution scripts), this can cause crashes."}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks/stop-serena-dashboard.js::magic-port-24282","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5b-code-quality.jsonl","original_id":"process::.claude/hooks/stop-serena-dashboard.js::magic-port-24282","category":"process","severity":"S2","type":"process-gap","file":".claude/hooks/stop-serena-dashboard.js","line":30,"title":"Quality: Magic number - hardcoded port without explanation","description":"Port 24282 is hardcoded without any comment explaining why this specific port. Makes it unclear if this is a well-known port, randomly chosen, or has significance. CODE_PATTERNS.md warns against magic numbers/strings without explanation. If port needs to change, developers won't know the constraints.","recommendation":"Add explanatory comment: // Port 24282: Official Serena MCP server port (assigned in .mcp.json). Or better: load from config file to have single source of truth matching .mcp.json configuration.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks/analyze-user-request.js::magic-maxlength-2000","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5b-code-quality.jsonl","original_id":"process::.claude/hooks/analyze-user-request.js::magic-maxlength-2000","category":"process","severity":"S2","type":"process-gap","file":".claude/hooks/analyze-user-request.js","line":37,"title":"Quality: Magic number - MAX_LENGTH without explanation","description":"MAX_LENGTH=2000 hardcoded without explanation of why 2000 characters. Is this to prevent DoS? Buffer overflow? UI limitation? Without context, future maintainers won't know if this can be safely adjusted.","recommendation":"Add comment explaining rationale: // DoS prevention: Limit input to 2000 chars (typical user prompt is <500 chars). Consider making this configurable if different contexts need different limits.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks/large-context-warning.js::magic-line-limit-5000","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5b-code-quality.jsonl","original_id":"process::.claude/hooks/large-context-warning.js::magic-line-limit-5000","category":"process","severity":"S2","type":"process-gap","file":".claude/hooks/large-context-warning.js","line":20,"title":"Quality: Magic number - SINGLE_FILE_LINE_LIMIT without explanation","description":"SINGLE_FILE_LINE_LIMIT=5000 without explanation. Is this based on Claude token limits? Performance testing? Arbitrary choice? Future Claude model upgrades may allow larger contexts, but without documentation, developers won't know if this is safe to change.","recommendation":"Add comment: // Claude 3 context window = ~200K tokens. 5000 lines ≈ 50K tokens average, leaving headroom for conversation. Based on [reference to testing/decision doc if exists]. Consider loading from config for different model tiers.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-consolidation-status.js::magic-archive-threshold-2500","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5b-code-quality.jsonl","original_id":"process::scripts/check-consolidation-status.js::magic-archive-threshold-2500","category":"process","severity":"S2","type":"process-gap","file":"scripts/check-consolidation-status.js","line":26,"title":"Quality: Magic number - ARCHIVE_LINE_THRESHOLD without explanation","description":"ARCHIVE_LINE_THRESHOLD=2500 has no explanation. Why 2500 lines? Performance issue? File size limit? Readability concern? This threshold triggers archival decisions but lacks documentation on how it was determined.","recommendation":"Add comment: // Archive threshold: 2500 lines keeps file manageable for editors (most IDEs struggle >3000 lines). Based on AI_REVIEW_LEARNINGS_LOG.md performance testing [if exists]. Consider making configurable.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/mcp/sonarcloud-server.js::magic-timeout-30000","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5b-code-quality.jsonl","original_id":"process::scripts/mcp/sonarcloud-server.js::magic-timeout-30000","category":"process","severity":"S2","type":"process-gap","file":"scripts/mcp/sonarcloud-server.js","line":68,"title":"Quality: Magic number - REQUEST_TIMEOUT_MS without explanation","description":"REQUEST_TIMEOUT_MS=30000 (30 seconds) hardcoded without explanation. Is this based on SonarCloud API SLA? Network timeout? If SonarCloud response times change or users have slow connections, they won't know if adjusting this is safe.","recommendation":"Add comment: // 30s timeout: SonarCloud API p95 response time ~5s, p99 ~15s (as of 2025-01). 30s provides 2x buffer for slow connections. Reference: [SonarCloud API docs]. Consider making configurable for different network conditions.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks/state-utils.js::hardcoded-state-dir","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5b-code-quality.jsonl","original_id":"process::.claude/hooks/state-utils.js::hardcoded-state-dir","category":"process","severity":"S2","type":"process-gap","file":".claude/hooks/state-utils.js","line":22,"title":"Quality: Hardcoded path should be configurable","description":"STATE_DIR = '.claude/state' is hardcoded. In different project structures or CI environments, state might need to be stored elsewhere (temp dirs, mounted volumes). Makes the utility less reusable across different setups.","recommendation":"Make configurable: const STATE_DIR = process.env.CLAUDE_STATE_DIR || '.claude/state'; Document the environment variable in docs/agent_docs/ or CONTRIBUTING.md. This allows override without code changes.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/debt/intake-audit.js::hardcoded-debt-paths","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5b-code-quality.jsonl","original_id":"process::scripts/debt/intake-audit.js::hardcoded-debt-paths","category":"process","severity":"S2","type":"process-gap","file":"scripts/debt/intake-audit.js","line":53,"title":"Quality: Multiple hardcoded debt paths","description":"DEBT_DIR, MASTER_FILE, LOG_DIR, LOG_FILE all hardcoded to docs/technical-debt. In CI/CD or different repo structures, technical debt data might need different locations. Testing also becomes harder without configurability.","recommendation":"Load from config: const config = loadConfig('debt-paths'); const DEBT_DIR = config.debtDir || path.join(__dirname, '../../docs/technical-debt'); Or use environment variables with fallbacks. Document configuration in docs/agent_docs/.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/debt/resolve-item.js::execsync-string-interpolation","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5b-code-quality.jsonl","original_id":"process::scripts/debt/resolve-item.js::execsync-string-interpolation","category":"process","severity":"S0","type":"process-gap","file":"scripts/debt/resolve-item.js","line":21,"title":"Security: Potential command injection in resolve-item.js execSync","description":"execSync imported from child_process at line 21. While not directly visible in first 100 lines, use of execSync with string concatenation is a critical security issue per CODE_PATTERNS.md. Need to verify later in file that execFileSync is used or execSync uses only array arguments.","recommendation":"If execSync is used with string templates: replace with execFileSync(cmd, [arg1, arg2], options). CODE_PATTERNS.md Security pattern: 'Use execFileSync(cmd, [arg1, arg2]) not execSync(`cmd ${var}`)' eliminates injection vectors even with validated inputs.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":"scripts/debt/resolve-item.js:21"},{"type":"description","detail":"execSync imported from child_process at line 21. While not directly visible in first 100 lines, use of execSync with string concatenation is a critical security issue per CODE_PATTERNS.md. Need to verify later in file that execFileSync is used or execSync uses only array arguments."}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/debt/intake-audit.js::json-parse-validation","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5b-code-quality.jsonl","original_id":"process::scripts/debt/intake-audit.js::json-parse-validation","category":"process","severity":"S1","type":"process-gap","file":"scripts/debt/intake-audit.js","line":119,"title":"Quality: Missing validation on parsed JSON objects","description":"mapDocStandardsToTdms() function processes untrusted JSONL input. While safeCloneObject filters __proto__, the function doesn't validate object shape before accessing properties. Malformed JSONL could cause undefined behavior or crashes when accessing nested properties.","recommendation":"Add input validation: function mapDocStandardsToTdms(item) { if (!item || typeof item !== 'object' || Array.isArray(item)) { return { item: {}, metadata: { format_detected: 'invalid', error: 'Expected object' }}; } ... } Also validate array types before .map(), .length access.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":"scripts/debt/intake-audit.js:119"},{"type":"description","detail":"mapDocStandardsToTdms() function processes untrusted JSONL input. While safeCloneObject filters __proto__, the function doesn't validate object shape before accessing properties. Malformed JSONL could cause undefined behavior or crashes when accessing nested properties."}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-pattern-compliance.js::redos-risk","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5b-code-quality.jsonl","original_id":"process::scripts/check-pattern-compliance.js::redos-risk","category":"process","severity":"S1","type":"process-gap","file":"scripts/check-pattern-compliance.js","line":106,"title":"Quality: Unsafe regex patterns in pattern checker","description":"ANTI_PATTERNS array contains many complex regex with nested quantifiers and unbounded lookaheads (e.g., line 137: /for\\s+\\w+\\s+in\\s+1\\s+2\\s+3\\s*;\\s*do[\\s\\S]{0,120}?&&\\s*break[\\s\\S]{0,80}?done(?![\\s\\S]{0,80}?...). On maliciously crafted input files, these could cause ReDoS (Regular Expression Denial of Service) hanging the checker.","recommendation":"CODE_PATTERNS.md Security: 'Use {1,64} not + for bounded user input' and 'Add heuristic detection (nested quantifiers, length limits)'. Add input size guards before regex matching: if (content.length > 100000) { console.warn('File too large, skipping pattern checks'); return; }. Review each regex for nested quantifiers and add explicit bounds.","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":"scripts/check-pattern-compliance.js:106"},{"type":"description","detail":"ANTI_PATTERNS array contains many complex regex with nested quantifiers and unbounded lookaheads (e.g., line 137: /for\\s+\\w+\\s+in\\s+1\\s+2\\s+3\\s*;\\s*do[\\s\\S]{0,120}?&&\\s*break[\\s\\S]{0,80}?done(?![\\s\\S]{0,80}?...). On maliciously crafted input files, these could cause ReDoS (Regular Expression Denial of Service) hanging the checker."}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks/global/gsd-check-update.js::empty-catch-blocks","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5a-error-handling.jsonl","original_id":"process::.claude/hooks/global/gsd-check-update.js::empty-catch-blocks","category":"process","severity":"S1","type":"process-gap","file":".claude/hooks/global/gsd-check-update.js","line":38,"title":"Error handling: Empty catch blocks swallow errors in gsd-check-update.js","description":"Silent failures in version checking hide network issues and file read errors, preventing users from knowing updates are available","recommendation":"Log errors to stderr or a debug log file. Example: catch (e) { console.error('Failed to check GSD version:', e.message); }","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":".claude/hooks/global/gsd-check-update.js:38"},{"type":"description","detail":"Silent failures in version checking hide network issues and file read errors, preventing users from knowing updates are available"}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::hooks-scripts::empty-catch-pattern","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5a-error-handling.jsonl","original_id":"process::hooks-scripts::empty-catch-pattern","category":"process","severity":"S1","type":"process-gap","file":".claude/hooks/component-size-check.js","line":47,"title":"Error handling: 200+ empty catch blocks across hooks and scripts","description":"Silent failures hide real problems: JSON parse errors, file system issues, permission problems. Debugging becomes impossible when errors are swallowed without any logging","recommendation":"Add minimal error logging: catch (err) { console.error('Operation failed:', err.message); }. For non-critical operations, at least log to debug output","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":".claude/hooks/component-size-check.js:47"},{"type":"description","detail":"Silent failures hide real problems: JSON parse errors, file system issues, permission problems. Debugging becomes impossible when errors are swallowed without any logging"}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::hooks::exit-code-on-security-fail","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5a-error-handling.jsonl","original_id":"process::hooks::exit-code-on-security-fail","category":"process","severity":"S2","type":"process-gap","file":".claude/hooks/typescript-strict-check.js","line":28,"title":"Error handling: Hook validation exits with 0 on security failures","description":"Security checks that detect path traversal or invalid input exit with 0 (success), making it appear operations succeeded when they should have been rejected. This could mask security issues","recommendation":"Distinguish between 'not applicable' (exit 0) and 'validation failed' (exit 1). When detecting security issues like path traversal, exit with non-zero code and log the security violation","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts::unprotected-readfilesync","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5a-error-handling.jsonl","original_id":"process::scripts::unprotected-readfilesync","category":"process","severity":"S1","type":"process-gap","file":"scripts/verify-sonar-phase.js","line":134,"title":"Error handling: readFileSync without try/catch in multiple scripts","description":"Unprotected file reads cause uncaught exceptions that crash scripts. Users see stack traces instead of helpful error messages. ENOENT errors don't explain what file was missing or why","recommendation":"Wrap all readFileSync calls in try/catch with helpful error messages. Example: try { content = fs.readFileSync(file, 'utf8'); } catch (err) { console.error(`Failed to read config file: ${err.message}\\nPlease ensure the file exists and is readable.`); process.exit(1); }","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":"scripts/verify-sonar-phase.js:134"},{"type":"description","detail":"Unprotected file reads cause uncaught exceptions that crash scripts. Users see stack traces instead of helpful error messages. ENOENT errors don't explain what file was missing or why"}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts::execsync-no-timeout","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5a-error-handling.jsonl","original_id":"process::scripts::execsync-no-timeout","category":"process","severity":"S1","type":"process-gap","file":"scripts/validate-audit.js","line":651,"title":"Error handling: execSync without timeout or error handling","description":"execSync calls without timeout can hang indefinitely if child processes freeze. Missing error handling means command failures crash the script with cryptic errors","recommendation":"Always include timeout option and wrap in try/catch. Example: try { const output = execSync(cmd, { timeout: 10000, encoding: 'utf8' }); } catch (err) { if (err.killed) { console.error('Command timed out after 10s'); } else { console.error('Command failed:', err.message); } process.exit(1); }","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":"scripts/validate-audit.js:651"},{"type":"description","detail":"execSync calls without timeout can hang indefinitely if child processes freeze. Missing error handling means command failures crash the script with cryptic errors"}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts::path-exposure-in-errors","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5a-error-handling.jsonl","original_id":"process::scripts::path-exposure-in-errors","category":"process","severity":"S2","type":"process-gap","file":"scripts/validate-audit.js","line":110,"title":"Error handling: Error messages expose full system paths","description":"Error messages that include full absolute paths expose system structure (/home/username/, /Users/name/projects/). In logs or error reports, this leaks potentially sensitive information about deployment structure","recommendation":"Use path.basename() or relative paths in error messages. Example: Instead of 'Audit file not found: /home/user/project/file.jsonl', use 'Audit file not found: file.jsonl (expected in docs/audits/)'","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::state-utils::silent-write-failures","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5a-error-handling.jsonl","original_id":"process::state-utils::silent-write-failures","category":"process","severity":"S1","type":"process-gap","file":".claude/hooks/state-utils.js","line":75,"title":"Error handling: State file operations fail silently","description":"State persistence failures mean hooks lose track of session context, agent invocations, and compaction data. Silent failures leave the system in an inconsistent state without alerting anyone","recommendation":"writeState() should return false on failure but caller should check the return value. Example: if (!writeState(data)) { console.error('⚠️  Failed to save session state - data may be lost after compaction'); }","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":".claude/hooks/state-utils.js:75"},{"type":"description","detail":"State persistence failures mean hooks lose track of session context, agent invocations, and compaction data. Silent failures leave the system in an inconsistent state without alerting anyone"}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::hooks::json-parse-no-context","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5a-error-handling.jsonl","original_id":"process::hooks::json-parse-no-context","category":"process","severity":"S2","type":"process-gap","file":"scripts/verify-skill-usage.js","line":136,"title":"Error handling: JSON.parse failures without validation context","description":"When JSON.parse fails in hooks, empty catch blocks hide what was being parsed and why it failed. Malformed hook arguments or corrupted state files become impossible to debug","recommendation":"Log parse failures with context. Example: catch (err) { console.error('Failed to parse hook arguments:', arg.substring(0, 100), err.message); return null; }","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts::write-no-error-msg","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5a-error-handling.jsonl","original_id":"process::scripts::write-no-error-msg","category":"process","severity":"S2","type":"process-gap","file":"scripts/update-readme-status.js","line":107,"title":"Error handling: Missing error messages in file write operations","description":"writeFileSync failures (disk full, permission denied, read-only filesystem) crash without explaining what failed to write. Users can't tell if their data was saved or lost","recommendation":"Wrap writes in try/catch with descriptive errors. Example: try { fs.writeFileSync(file, data); } catch (err) { console.error(`Failed to write ${path.basename(file)}: ${err.code === 'ENOSPC' ? 'Disk full' : err.message}`); process.exit(1); }","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/settings.json::continue-on-error-usage","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5a-error-handling.jsonl","original_id":"process::.claude/settings.json::continue-on-error-usage","category":"process","severity":"S0","type":"process-gap","file":".claude/settings.json","line":24,"title":"Error handling: continueOnError used appropriately in settings.json","description":"continueOnError is correctly used for non-critical operations: remote branch checks (network may be unavailable), dashboard cleanup (dev-only), and commit tracking (metadata only). These should not block the workflow","recommendation":"No fix needed - usage is appropriate. These hooks enhance the workflow but aren't critical path","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":".claude/settings.json:24"},{"type":"description","detail":"continueOnError is correctly used for non-critical operations: remote branch checks (network may be unavailable), dashboard cleanup (dev-only), and commit tracking (metadata only). These should not block the workflow"}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/verify-skill-usage.js::exit-zero-with-violations","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5a-error-handling.jsonl","original_id":"process::scripts/verify-skill-usage.js::exit-zero-with-violations","category":"process","severity":"S2","type":"process-gap","file":"scripts/verify-skill-usage.js","line":232,"title":"Error handling: Validation scripts exit 0 with violations in non-strict mode","description":"verify-skill-usage.js exits 0 even when violations exist (non-strict mode). This makes CI integration confusing - the script reports issues but signals success. Violations may be ignored","recommendation":"Exit code should reflect presence of violations regardless of mode. Use --quiet to suppress output, not to change exit behavior. Example: if (violations.length > 0) process.exit(1); else process.exit(0);","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks/typescript-strict-check.js::multiple-exit-zero","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5a-error-handling.jsonl","original_id":"process::.claude/hooks/typescript-strict-check.js::multiple-exit-zero","category":"process","severity":"S2","type":"process-gap","file":".claude/hooks/typescript-strict-check.js","line":28,"title":"Error handling: Multiple exit(0) calls suggest unclear control flow","description":"typescript-strict-check.js has 15+ process.exit(0) calls in validation logic. This pattern makes it unclear which exits are 'check passed' vs 'check not applicable' vs 'check skipped due to error'","recommendation":"Refactor to have a single exit point with clear exit code strategy. Use early returns instead of exit(0) in validation functions, then exit once at the end based on accumulated state","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::hooks::error-visibility","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5a-error-handling.jsonl","original_id":"process::hooks::error-visibility","category":"process","severity":"S1","type":"process-gap","file":".claude/hooks/component-size-check.js","line":47,"title":"Error handling: Hook execution errors not propagated to user","description":"When PostToolUse hooks fail silently (empty catch blocks), users don't know validation ran or failed. They may proceed thinking code is validated when checks actually crashed","recommendation":"Hooks should output clear status messages: 'ok' on success, error description on failure. Log to stderr for errors while preserving stdout for hook protocol. Example: catch (err) { console.error('Hook failed:', err.message); console.log('error'); process.exit(1); }","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":".claude/hooks/component-size-check.js:47"},{"type":"description","detail":"When PostToolUse hooks fail silently (empty catch blocks), users don't know validation ran or failed. They may proceed thinking code is validated when checks actually crashed"}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/generate-pending-alerts.js::no-cleanup-on-failure","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5a-error-handling.jsonl","original_id":"process::scripts/generate-pending-alerts.js::no-cleanup-on-failure","category":"process","severity":"S1","type":"process-gap","file":"scripts/generate-pending-alerts.js","line":389,"title":"Error handling: generate-pending-alerts.js throws error on write failure but doesn't clean up partial state","description":"Script throws 'Failed to write alerts file' but doesn't rollback partial writes or clean up temp files. This can leave .alerts.json in inconsistent state, causing downstream tools to fail","recommendation":"Use atomic write pattern: write to temp file, validate, then rename. On failure, clean up temp file and preserve existing alerts file. Example: const tmp = file + '.tmp'; try { fs.writeFileSync(tmp, data); fs.renameSync(tmp, file); } catch (err) { fs.rmSync(tmp, {force:true}); throw err; }","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":"scripts/generate-pending-alerts.js:389"},{"type":"description","detail":"Script throws 'Failed to write alerts file' but doesn't rollback partial writes or clean up temp files. This can leave .alerts.json in inconsistent state, causing downstream tools to fail"}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/debt/sync-sonarcloud.js::verbose-api-errors","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5a-error-handling.jsonl","original_id":"process::scripts/debt/sync-sonarcloud.js::verbose-api-errors","category":"process","severity":"S2","type":"process-gap","file":"scripts/debt/sync-sonarcloud.js","line":290,"title":"Error handling: sync-sonarcloud.js API errors expose implementation details","description":"Error message includes full HTTP response status and potentially sensitive API error details. In logs, this could expose API keys or internal service details","recommendation":"Sanitize error messages before throwing. Example: throw new Error(`SonarCloud API request failed (${response.status}). Check SONARCLOUD_TOKEN environment variable.`); Don't include response body or headers in error messages","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts::execsync-interactive-hang","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-5a-error-handling.jsonl","original_id":"process::scripts::execsync-interactive-hang","category":"process","severity":"S1","type":"process-gap","file":"scripts/validate-audit.js","line":651,"title":"Error handling: execSync in validation scripts can hang on interactive prompts","description":"execSync('npm audit') and execSync('npm run lint') without stdio: 'pipe' can hang if these commands prompt for user input. Hook execution would freeze indefinitely","recommendation":"Already using stdio: ['ignore', 'pipe', 'pipe'] pattern correctly in validate-audit.js. Verify all other execSync calls use similar pattern to prevent stdin interaction","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":"scripts/validate-audit.js:651"},{"type":"description","detail":"execSync('npm audit') and execSync('npm run lint') without stdio: 'pipe' can hang if these commands prompt for user input. Hook execution would freeze indefinitely"}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-pattern-compliance.js::sync-file-reads","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4c-script-performance.jsonl","original_id":"process::scripts/check-pattern-compliance.js::sync-file-reads","category":"process","severity":"S2","type":"process-gap","file":"scripts/check-pattern-compliance.js","line":799,"title":"Perf: check-pattern-compliance.js - Synchronous file reads in loop","description":"Hook script reads 10-20 files synchronously in pre-commit, blocking for ~200-500ms. Async parallel reads could reduce to ~50-100ms","recommendation":"Convert checkFile() to async, use Promise.all() to read files in parallel batches of 10. Change readFileSync to fs.promises.readFile","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-pattern-compliance.js::unoptimized-pattern-matching","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4c-script-performance.jsonl","original_id":"process::scripts/check-pattern-compliance.js::unoptimized-pattern-matching","category":"process","severity":"S2","type":"process-gap","file":"scripts/check-pattern-compliance.js","line":733,"title":"Perf: check-pattern-compliance.js - O(n*m) pattern matching without optimization","description":"For each file, iterates ALL 30+ patterns even if file extension doesn't match. Checking 20 JS files = 600+ regex compilations. Pre-filtering could reduce by 60%","recommendation":"Group patterns by fileTypes, only check relevant patterns. Build Map<extension, patterns[]> at startup. Skip patterns where file extension not in fileTypes","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-pattern-compliance.js::regex-recompilation","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4c-script-performance.jsonl","original_id":"process::scripts/check-pattern-compliance.js::regex-recompilation","category":"process","severity":"S3","type":"process-gap","file":"scripts/check-pattern-compliance.js","line":659,"title":"Perf: check-pattern-compliance.js - Regex recompilation in hot path","description":"Creates new RegExp objects for every file checked (line 659, 662). Checking 20 files with 30 patterns = 1200 regex compilations. Cache compiled regexes","recommendation":"Pre-compile all regexes at module load: const compiledPatterns = ANTI_PATTERNS.map(p => ({...p, regex: new RegExp(...)})); Use compiledPatterns in checkFile","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-docs-light.js::sync-map-file-reads","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4c-script-performance.jsonl","original_id":"process::scripts/check-docs-light.js::sync-map-file-reads","category":"process","severity":"S1","type":"process-gap","file":"scripts/check-docs-light.js","line":825,"title":"Perf: check-docs-light.js - Synchronous file reads in map()","description":"CI docs-lint job reads 50+ markdown files synchronously with readFileSync (line 495), taking 2-3 seconds. Async parallel reads could cut time to <500ms","recommendation":"Convert lintDocument to async function, use Promise.all() with batch size limit (10 concurrent). Replace readFileSync with fs.promises.readFile in readDocumentContent","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":"scripts/check-docs-light.js:825"},{"type":"description","detail":"CI docs-lint job reads 50+ markdown files synchronously with readFileSync (line 495), taking 2-3 seconds. Async parallel reads could cut time to <500ms"}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-docs-light.js::quadratic-anchor-validation","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4c-script-performance.jsonl","original_id":"process::scripts/check-docs-light.js::quadratic-anchor-validation","category":"process","severity":"S2","type":"process-gap","file":"scripts/check-docs-light.js","line":411,"title":"Perf: check-docs-light.js - O(n^2) anchor link validation","description":"validateAnchorLinks has nested loop: for each link (50+), iterates all headings (100+) = 5000 comparisons per doc. Large docs like ROADMAP.md take 500ms just for anchor checks","recommendation":"Build Set of valid anchors ONCE (line 400-409), then O(1) Set.has() lookup per link. Remove lines 426-432 partial match fallback (causes the O(n) inner loop)","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-docs-light.js::repeated-fstat-calls","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4c-script-performance.jsonl","original_id":"process::scripts/check-docs-light.js::repeated-fstat-calls","category":"process","severity":"S2","type":"process-gap","file":"scripts/check-docs-light.js","line":686,"title":"Perf: check-docs-light.js - Repeated realpath/stat calls","description":"resolveFileArgs calls realpathSync 3x per file (lines 686, 707, 714) plus lstatSync. For 50 files = 200 syscalls. Caching realpath(ROOT) saves 100+ calls","recommendation":"Compute rootRealResolved once (done at line 683), cache realpath results in Map<path, realpath>. Skip redundant lstatSync at line 714 (containment already verified)","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/generate-documentation-index.js::sync-doc-processing","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4c-script-performance.jsonl","original_id":"process::scripts/generate-documentation-index.js::sync-doc-processing","category":"process","severity":"S1","type":"process-gap","file":"scripts/generate-documentation-index.js","line":913,"title":"Perf: generate-documentation-index.js - Synchronous file reads in loop","description":"npm run docs:index reads 80+ markdown files sequentially with readFileSync (line 485), taking 3-4 seconds. CI job blocks during this time. Async could reduce to <1 second","recommendation":"Convert processFile to async, use Promise.all with batch limit (15 concurrent): const batches = chunk(activeFiles, 15); for (batch of batches) await Promise.all(batch.map(processFile))","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":"scripts/generate-documentation-index.js:913"},{"type":"description","detail":"npm run docs:index reads 80+ markdown files sequentially with readFileSync (line 485), taking 3-4 seconds. CI job blocks during this time. Async could reduce to <1 second"}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/generate-documentation-index.js::regex-in-loop","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4c-script-performance.jsonl","original_id":"process::scripts/generate-documentation-index.js::regex-in-loop","category":"process","severity":"S3","type":"process-gap","file":"scripts/generate-documentation-index.js","line":376,"title":"Perf: generate-documentation-index.js - Regex compilation in extractLinks loop","description":"extractLinks creates new RegExp on line 376 for EVERY document processed (80+ times). This regex is complex with capturing groups. Move to module level","recommendation":"Move linkRegex to module-level constant: const LINK_REGEX = /\\[([^\\]]{1,500})\\]\\(([^)]{1,500})\\)/g; In extractLinks, clone it: const linkRegex = new RegExp(LINK_REGEX.source, LINK_REGEX.flags)","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/generate-documentation-index.js::quadratic-reference-graph","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4c-script-performance.jsonl","original_id":"process::scripts/generate-documentation-index.js::quadratic-reference-graph","category":"process","severity":"S2","type":"process-gap","file":"scripts/generate-documentation-index.js","line":524,"title":"Perf: generate-documentation-index.js - O(n*m) reference graph building","description":"buildReferenceGraph: for 80 docs with 20 links each = 1600 iterations. Each does Map.get() twice (lines 535-536). With 200+ docs this becomes noticeable (500ms+)","recommendation":"Use Map.get once, assign to variable. Combine lines 534-536 into: const targetNode = graph.get(target); if (targetNode) { node.outbound.push(target); targetNode.inbound.push(doc.path); }","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/aggregate-audit-findings.js::quadratic-dedup","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4c-script-performance.jsonl","original_id":"process::scripts/aggregate-audit-findings.js::quadratic-dedup","category":"process","severity":"S1","type":"process-gap","file":"scripts/aggregate-audit-findings.js","line":1309,"title":"Perf: aggregate-audit-findings.js - O(n^2) deduplication with large buckets","description":"processBucketPairs has O(k^2) nested loop for each bucket. With 250 item bucket cap, worst case is 31,250 comparisons per bucket. Full aggregation takes 10-15 seconds","recommendation":"Add early termination: if bucket size > threshold AND no merges in last N comparisons, skip rest. Or use LSH (Locality Sensitive Hashing) to reduce comparison space. Lower MAX_FILE_BUCKET from 250 to 100","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":"scripts/aggregate-audit-findings.js:1309"},{"type":"description","detail":"processBucketPairs has O(k^2) nested loop for each bucket. With 250 item bucket cap, worst case is 31,250 comparisons per bucket. Full aggregation takes 10-15 seconds"}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/aggregate-audit-findings.js::sync-jsonl-reads","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4c-script-performance.jsonl","original_id":"process::scripts/aggregate-audit-findings.js::sync-jsonl-reads","category":"process","severity":"S2","type":"process-gap","file":"scripts/aggregate-audit-findings.js","line":1201,"title":"Perf: aggregate-audit-findings.js - Synchronous JSONL file reads","description":"Reads 7 JSONL files sequentially in parseSingleSessionAudits and parseCanonFiles (lines 1201, 1226). Each readFileSync blocks. Total time ~300-500ms. Parallel reads could reduce to <100ms","recommendation":"Convert parseJsonlFile to async with fs.promises.readFile. Use Promise.all to read all 7 category files in parallel. Await results before proceeding to phase 2","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/aggregate-audit-findings.js::expensive-levenshtein","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4c-script-performance.jsonl","original_id":"process::scripts/aggregate-audit-findings.js::expensive-levenshtein","category":"process","severity":"S2","type":"process-gap","file":"scripts/aggregate-audit-findings.js","line":1013,"title":"Perf: aggregate-audit-findings.js - Expensive Levenshtein in hot path","description":"levenshteinDistance called in dedup loop with O(m*n) DP algorithm. For 500 findings, potentially 10,000+ calls. Each 500-char comparison = 250,000 operations. Truncate earlier or cache","recommendation":"Reduce MAX_LEVENSHTEIN_LENGTH from 500 to 200 chars (still enough for titles). Add memoization: const cache = new Map(); Check cache before computing. Clear cache between dedup passes","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/aggregate-audit-findings.js::repeated-normalization","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4c-script-performance.jsonl","original_id":"process::scripts/aggregate-audit-findings.js::repeated-normalization","category":"process","severity":"S3","type":"process-gap","file":"scripts/aggregate-audit-findings.js","line":1044,"title":"Perf: aggregate-audit-findings.js - Repeated string normalization","description":"similarityScore does replaceAll(/[^a-z0-9\\s]/g, '') twice (line 1044) for EVERY comparison. Regex replacement is expensive. Called 10,000+ times during dedup","recommendation":"Cache normalized strings: const normalized = new Map(); function getNormalized(str) { if (!normalized.has(str)) normalized.set(str, str.toLowerCase().replaceAll(...)); return normalized.get(str); }","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-content-accuracy.js::sync-reads-loop","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4c-script-performance.jsonl","original_id":"process::scripts/check-content-accuracy.js::sync-reads-loop","category":"process","severity":"S2","type":"process-gap","file":"scripts/check-content-accuracy.js","line":458,"title":"Perf: check-content-accuracy.js - Synchronous file reads in loop","description":"Reads all markdown files sequentially with readFileSync (line 412). For 50+ docs, takes 1-2 seconds. CI content validation could be 3-4x faster with async","recommendation":"Convert checkDocument to async function using fs.promises.readFile. Use Promise.all with batch size 10: const results = []; for (const batch of chunk(files, 10)) results.push(...await Promise.all(batch.map(checkDocument)))","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-content-accuracy.js::regex-in-hot-loops","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4c-script-performance.jsonl","original_id":"process::scripts/check-content-accuracy.js::regex-in-hot-loops","category":"process","severity":"S2","type":"process-gap","file":"scripts/check-content-accuracy.js","line":114,"title":"Perf: check-content-accuracy.js - Regex compilation in hot loops","description":"versionPatterns (line 114), pathPatterns (line 197), npmPatterns (line 286) created fresh for EVERY file. For 50 files = 150+ array allocations with regex literals. Move to module level","recommendation":"Declare patterns as module-level constants outside functions: const VERSION_PATTERNS = [...]; const PATH_PATTERNS = [...]; const NPM_PATTERNS = [...]; Reference these in check functions","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-content-accuracy.js::nested-pattern-loops","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4c-script-performance.jsonl","original_id":"process::scripts/check-content-accuracy.js::nested-pattern-loops","category":"process","severity":"S2","type":"process-gap","file":"scripts/check-content-accuracy.js","line":136,"title":"Perf: check-content-accuracy.js - O(lines * patterns) nested loops","description":"checkVersionAccuracy, checkPathReferences, checkNpmScriptReferences all have nested loops: for each line, iterate all patterns, exec in while loop. Large docs (500+ lines) with 5+ patterns = 2500+ regex execs","recommendation":"Combine all patterns into single alternation regex: /pattern1|pattern2|pattern3/g. Single pass per line with switch on match type. Or use multiline mode to match entire content once","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/ci.yml::build-sequential","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4b-ci-performance.jsonl","original_id":"process::.github/workflows/ci.yml::build-sequential","category":"process","severity":"S2","type":"process-gap","file":".github/workflows/ci.yml","line":136,"title":"CI slow: Build job waits unnecessarily for all lint/test steps","description":"Build could start after type checking completes, saving 2-3 minutes per CI run. Lint/test don't need to block build since both are independent verification steps.","recommendation":"Split into 3 parallel jobs: (1) lint+format+deps checks, (2) typecheck+test, (3) build. Then add a final 'all-checks' job that depends on all three. This reduces critical path from ~8min to ~5min.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/ci.yml::duplicate-npm-ci","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4b-ci-performance.jsonl","original_id":"process::.github/workflows/ci.yml::duplicate-npm-ci","category":"process","severity":"S2","type":"process-gap","file":".github/workflows/ci.yml","line":149,"title":"CI slow: Redundant npm ci in build job","description":"npm ci runs twice (once in lint-typecheck-test, once in build), wasting 30-60s per run. node_modules could be cached as artifact and reused.","recommendation":"Use actions/cache or actions/upload-artifact to cache node_modules after first npm ci, then restore in build job. Or use a shared 'setup' job that both depend on.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/ci.yml::no-nextjs-cache","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4b-ci-performance.jsonl","original_id":"process::.github/workflows/ci.yml::no-nextjs-cache","category":"process","severity":"S2","type":"process-gap","file":".github/workflows/ci.yml","line":152,"title":"CI slow: No Next.js build cache","description":"Next.js builds take 2-4 minutes but .next directory isn't cached between runs. Incremental builds could reduce this to 30-60s for small changes.","recommendation":"Add actions/cache step to cache .next/cache directory using hash of source files as key. Next.js supports incremental builds when cache is present.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/ci.yml::no-path-filters","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4b-ci-performance.jsonl","original_id":"process::.github/workflows/ci.yml::no-path-filters","category":"process","severity":"S2","type":"process-gap","file":".github/workflows/ci.yml","line":3,"title":"CI slow: No path filters on main CI workflow","description":"CI runs full test suite even for docs-only changes (*.md files). Adds 5-8 minutes of unnecessary CI time for documentation PRs.","recommendation":"Add path-ignore filter to skip CI when only docs, markdown, or non-code files change. Keep required checks but mark as skipped for docs PRs.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/deploy-firebase.yml::duplicate-build","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4b-ci-performance.jsonl","original_id":"process::.github/workflows/deploy-firebase.yml::duplicate-build","category":"process","severity":"S2","type":"process-gap","file":".github/workflows/deploy-firebase.yml","line":47,"title":"CI slow: Firebase deploy builds app twice","description":"Both preview-deploy and deploy jobs run 'npm run build' independently (2-4 min each). If CI workflow also builds, that's 3 separate builds of the same code.","recommendation":"Make deploy workflow depend on ci.yml's build job using workflow_run trigger, then download build artifact. Or create a reusable workflow that both can call.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/deploy-firebase.yml::sequential-deploys","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4b-ci-performance.jsonl","original_id":"process::.github/workflows/deploy-firebase.yml::sequential-deploys","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/deploy-firebase.yml","line":141,"title":"CI slow: Firebase deploys run sequentially","description":"Functions, firestore rules, and hosting deploy sequentially (line 141, 144, 147). Each takes 30-90s. Running in parallel could save 1-2 minutes.","recommendation":"Use 3 parallel jobs or firebase deploy with multiple targets in one command (firebase deploy --only functions,firestore:rules,hosting). Verify Firebase CLI supports parallel deploys without conflicts.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/sonarcloud.yml::no-path-filters","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4b-ci-performance.jsonl","original_id":"process::.github/workflows/sonarcloud.yml::no-path-filters","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/sonarcloud.yml","line":7,"title":"CI slow: SonarCloud runs on all changes including docs","description":"SonarCloud analysis runs on every push/PR even for docs-only changes. Takes 1-2 minutes and consumes analysis quota unnecessarily.","recommendation":"Add paths filter to only run when code files change (*.ts, *.tsx, *.js, *.jsx). Skip for docs/markdown-only changes.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/sonarcloud.yml::full-fetch-depth","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4b-ci-performance.jsonl","original_id":"process::.github/workflows/sonarcloud.yml::full-fetch-depth","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/sonarcloud.yml","line":31,"title":"CI slow: Full git history fetched unnecessarily","description":"fetch-depth: 0 downloads entire git history (can be 100MB+ and take 30-60s). Most workflows only need recent commits for diffs.","recommendation":"Change fetch-depth to a reasonable number (e.g., 50) or remove if not needed. Only use fetch-depth: 0 when truly necessary (e.g., for blame analysis).","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/backlog-enforcement.yml::duplicate-npm-ci","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4b-ci-performance.jsonl","original_id":"process::.github/workflows/backlog-enforcement.yml::duplicate-npm-ci","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/backlog-enforcement.yml","line":26,"title":"CI slow: Backlog workflow installs deps twice","description":"backlog-health and security-patterns jobs both run npm ci independently (30-60s each). They could share a setup job or reuse cache.","recommendation":"Create a shared 'setup' job that runs npm ci once and uploads node_modules as artifact. Both jobs depend on setup and download artifact instead of running npm ci.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/review-check.yml::no-path-filters","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4b-ci-performance.jsonl","original_id":"process::.github/workflows/review-check.yml::no-path-filters","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/review-check.yml","line":3,"title":"CI slow: Review check runs on all PRs without path filters","description":"Review trigger check runs on all PRs including docs-only changes. Wastes 30-60s for PRs that don't touch code.","recommendation":"Add paths filter to only run when code files change. For docs-only PRs, this check is not relevant.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/auto-label-review-tier.yml::no-npm-cache","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4b-ci-performance.jsonl","original_id":"process::.github/workflows/auto-label-review-tier.yml::no-npm-cache","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/auto-label-review-tier.yml","line":22,"title":"CI slow: Auto-label workflow has no npm cache","description":"setup-node doesn't have cache: 'npm' configured, so npm packages are re-downloaded on every run (adds 10-20s).","recommendation":"Add cache: 'npm' to setup-node action to enable npm caching. This is a one-line change.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/docs-lint.yml::sequential-processing","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4b-ci-performance.jsonl","original_id":"process::.github/workflows/docs-lint.yml::sequential-processing","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/docs-lint.yml","line":58,"title":"CI slow: Docs lint processes files sequentially","description":"Documentation linter processes files one-by-one in bash loop (line 58-113). For PRs with 10+ markdown files, this can take 2-3 minutes. Parallel processing could reduce to 30-60s.","recommendation":"Refactor to run linter in parallel using xargs -P or rewrite the bash logic into a Node.js script that uses Promise.all to check files concurrently.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.husky/pre-commit::slow-eslint-full-scan","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4a-hook-performance.jsonl","original_id":"process::.husky/pre-commit::slow-eslint-full-scan","category":"process","severity":"S2","type":"process-gap","file":".husky/pre-commit","line":9,"title":"Slow: ESLint full codebase scan in pre-commit","description":"ESLint scans entire codebase (~3-10s) on every commit instead of only staged files. Developers wait unnecessarily even for small changes. Over time this encourages --no-verify bypassing.","recommendation":"Use 'npm run lint -- --cache' for caching, or integrate with lint-staged to check only staged files. lint-staged already runs Prettier (line 23), could also run ESLint on same files.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.husky/pre-commit+pre-push::duplicate-pattern-check","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4a-hook-performance.jsonl","original_id":"process::.husky/pre-commit+pre-push::duplicate-pattern-check","category":"process","severity":"S2","type":"process-gap","file":".husky/pre-commit","line":35,"title":"Duplicate: Pattern compliance runs in both pre-commit and pre-push","description":"'npm run patterns:check' runs twice - once in pre-commit (line 35) and again in pre-push (line 26). Same files checked twice adds 1-3s per push. Pure waste since files don't change between commit and push.","recommendation":"Remove pattern check from pre-commit OR pre-push. Recommend keeping in pre-commit only (fail fast) and removing from pre-push line 21-35. Pattern violations should be caught at commit time.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.husky/pre-push::slow-tsc-no-incremental","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4a-hook-performance.jsonl","original_id":"process::.husky/pre-push::slow-tsc-no-incremental","category":"process","severity":"S2","type":"process-gap","file":".husky/pre-push","line":83,"title":"Slow: TypeScript full project type check on every push","description":"'npx tsc --noEmit' does full project type check (5-15s) on every push with no incremental caching. For large projects this becomes painful. Developers may skip with git push --no-verify.","recommendation":"1) Use 'tsc --noEmit --incremental' with tsbuildinfo caching, OR 2) Use 'tsc --noEmit --pretty' with file filtering for changed files only, OR 3) Move to CI and make optional in pre-push with SKIP_TYPE_CHECK=1 override.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.husky/pre-push::slow-madge-full-scan","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4a-hook-performance.jsonl","original_id":"process::.husky/pre-push::slow-madge-full-scan","category":"process","severity":"S2","type":"process-gap","file":".husky/pre-push","line":12,"title":"Slow: Circular dependency scan on entire codebase every push","description":"'madge --circular' scans lib/, components/, app/ directories (2-5s) on every push regardless of what changed. Circular deps are architectural issues that rarely appear in normal development. Full scan is overkill.","recommendation":"1) Add madge caching or run incrementally on changed files only, OR 2) Move to CI as a scheduled check (daily/weekly), OR 3) Make optional with SKIP_CIRCULAR_CHECK=1 and run only when dependency files change (package.json, imports in changed files).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::package.json::slow-test-build","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4a-hook-performance.jsonl","original_id":"process::package.json::slow-test-build","category":"process","severity":"S2","type":"process-gap","file":"package.json","line":11,"title":"Slow: Test suite rebuilds TypeScript on every test run","description":"'npm test' runs 'test:build' which compiles ALL TypeScript (tsc + tsc-alias) before tests. Pre-commit runs tests (line 59/80) adding 10-30s for full compilation even for small changes. No incremental compilation.","recommendation":"1) Use 'tsc --incremental' in test:build for caching, OR 2) Use tsx/ts-node for on-the-fly compilation without build step, OR 3) Only run test:build when test files or dependencies change (check git diff).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.husky/pre-push::sequential-security-checks","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4a-hook-performance.jsonl","original_id":"process::.husky/pre-push::sequential-security-checks","category":"process","severity":"S3","type":"process-gap","file":".husky/pre-push","line":50,"title":"Inefficient: Sequential security checks in pre-push","description":"Pre-push security checks loop through changed files sequentially (lines 50-65), running 'node scripts/security-check.js --file' once per file. For 10+ changed files, this adds 5-15s. No parallelization means cores sit idle.","recommendation":"1) Modify security-check.js to accept multiple files at once, OR 2) Use xargs -P4 for parallel execution, OR 3) Rewrite loop to spawn checks in parallel and wait for all results. Example: 'echo \"$changed_files\" | xargs -P4 -I{} node scripts/security-check.js --file {}'","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/settings.json::many-posttooluse-hooks","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4a-hook-performance.jsonl","original_id":"process::.claude/settings.json::many-posttooluse-hooks","category":"process","severity":"S2","type":"process-gap","file":".claude/settings.json","line":57,"title":"Performance: 10 Claude hooks run on every Write/Edit operation","description":"Every Write/Edit/MultiEdit triggers 10 separate hooks (check-write-requirements, audit-s0s1-validator, pattern-check, component-size-check, firestore-write-block, test-mocking-validator, app-check-validator, typescript-strict-check, repository-pattern-check, agent-trigger-enforcer). Total: ~5818 lines of hook code. Each hook spawns node process, adds 1-3s latency per file write. Poor DX during active development.","recommendation":"1) Batch-execute hooks in single node process to avoid spawn overhead, OR 2) Make hooks async/parallel where possible, OR 3) Add smart skipping - only run relevant hooks based on file type (e.g., firestore-write-block only for firestore files), OR 4) Move some non-critical checks to pre-commit only.","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks/pattern-check.js::per-file-overhead","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4a-hook-performance.jsonl","original_id":"process::.claude/hooks/pattern-check.js::per-file-overhead","category":"process","severity":"S3","type":"process-gap","file":".claude/hooks/pattern-check.js","line":1,"title":"Inefficient: Pattern check runs on every file write via Claude hook","description":"Pattern-check.js hook (line 73, 123 in settings.json) runs check-pattern-compliance.js on EVERY file write/edit during Claude sessions. For quick doc edits or small changes, running full pattern checker adds 0.5-2s overhead. Pre-commit already runs patterns:check (line 35), making this redundant during development.","recommendation":"1) Make pattern-check.js conditional - skip for .md/.txt/docs files, OR 2) Add debouncing - only check after N writes or M seconds, OR 3) Remove hook and rely solely on pre-commit pattern check (fail fast at commit, not during writing), OR 4) Make hook informational only (warn but don't block).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.husky/pre-commit::multiple-git-scans","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4a-hook-performance.jsonl","original_id":"process::.husky/pre-commit::multiple-git-scans","category":"process","severity":"S3","type":"process-gap","file":".husky/pre-commit","line":47,"title":"Inefficient: Multiple git status/diff scans in pre-commit","description":"Pre-commit runs 'git diff --cached --name-only' separately at lines 47, 94, 138, 159, 194. Each git call adds 50-200ms overhead. For repos with many files, this compounds to 0.5-1s wasted on duplicate filesystem scans.","recommendation":"Run 'git diff --cached --name-only' ONCE at the top of pre-commit hook and store in STAGED_FILES variable. Reuse this variable throughout. Already done partially (line 47, 94 reuse), but lines 138, 159, 194 run fresh git commands. Consolidate all into single scan.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.husky/pre-commit::no-test-timeout","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4a-hook-performance.jsonl","original_id":"process::.husky/pre-commit::no-test-timeout","category":"process","severity":"S3","type":"process-gap","file":".husky/pre-commit","line":59,"title":"Risk: No timeout on npm test in pre-commit","description":"'npm test' runs without timeout in pre-commit (lines 59, 80). If test hangs due to async issue, developer waits indefinitely or force-quits, losing context. No escape hatch besides killing terminal. Degraded DX for rare but frustrating hangs.","recommendation":"Add timeout wrapper: 'timeout 120 npm test' (120s = 2 min). If tests hang beyond reasonable time, hook fails fast with clear timeout message. Document with: 'Tests timed out after 120s. Check for hanging async operations or use SKIP_TESTS=1 for emergency commit.'","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.husky/pre-commit::doc-only-detection-complexity","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4a-hook-performance.jsonl","original_id":"process::.husky/pre-commit::doc-only-detection-complexity","category":"process","severity":"S3","type":"process-gap","file":".husky/pre-commit","line":68,"title":"Optimization: Doc-only commit detection could be smarter","description":"Doc-only commit detection (lines 68-88) uses complex regex grep filtering to skip tests. Logic is hard to maintain and test. False positives (docs with critical info) or false negatives (code masquerading as docs) could occur. Current regex at line 71 is 100+ chars long.","recommendation":"1) Extract doc-only detection to dedicated script 'scripts/is-doc-only-commit.js' with unit tests, OR 2) Use git diff --name-status with explicit allowlist (docs/, *.md, *.png, *.jsonl) instead of complex exclusion regex, OR 3) Make SKIP_TESTS=1 the default for docs and auto-detect risky files (package.json, tsconfig, etc.) to force tests.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/settings.json::slow-session-start","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4a-hook-performance.jsonl","original_id":"process::.claude/settings.json::slow-session-start","category":"process","severity":"S3","type":"process-gap","file":".claude/settings.json","line":8,"title":"Slow: Session start hooks add 2-5s latency to every session","description":"SessionStart hooks run 4 sequential node processes (session-start.js, check-mcp-servers.js, check-remote-session-context.js, stop-serena-dashboard.js) on EVERY Claude session start. Total latency: 2-5s before developer can begin work. Compounds frustration for quick questions/checks. Remote session check can be slow if network latency high.","recommendation":"1) Parallelize independent hooks (session-start, check-mcp-servers, stop-serena can run concurrently), OR 2) Make check-remote-session-context.js async/non-blocking with background notification, OR 3) Add cache TTL - skip checks if last run was <5min ago, OR 4) Optimize scripts - combine into single process to avoid spawn overhead.","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/settings.json::user-prompt-overhead","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-4a-hook-performance.jsonl","original_id":"process::.claude/settings.json::user-prompt-overhead","category":"process","severity":"S3","type":"process-gap","file":".claude/settings.json","line":265,"title":"Optimization: UserPromptSubmit hooks run before every user message","description":"UserPromptSubmit hooks (lines 265-290) run 4 checks (alerts-reminder, analyze-user-request, session-end-reminder, plan-mode-suggestion) before processing EVERY user prompt. Adds 0.5-2s perceived latency. For rapid back-and-forth conversations, this degrades conversational flow.","recommendation":"1) Make hooks async - run in background and surface results after response, OR 2) Add smart throttling - only run every Nth prompt or when certain keywords detected, OR 3) Batch hooks into single process to reduce spawn overhead, OR 4) Cache results - skip redundant checks if recent prompt was similar.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude::missing-skill-registry","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3d-skill-functionality.jsonl","original_id":"process::.claude::missing-skill-registry","category":"process","severity":"S3","type":"process-gap","file":".claude","line":1,"title":"Skill issue: skill-registry.json does not exist","description":"Audit checklist mentions verifying skill-registry.json matches actual skills, but this file doesn't exist. This may be outdated documentation or an incomplete implementation of skill tracking.","recommendation":"Either create .claude/skill-registry.json with current skill metadata, or update audit documentation to remove references to this file if it's no longer used.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/skills/SKILL_INDEX.md::incorrect-count","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3d-skill-functionality.jsonl","original_id":"process::.claude/skills/SKILL_INDEX.md::incorrect-count","category":"process","severity":"S3","type":"process-gap","file":".claude/skills/SKILL_INDEX.md","line":3,"title":"Skill issue: SKILL_INDEX.md has incorrect skill count","description":"SKILL_INDEX.md claims 50 total skills but directory contains 57 skills (ls -1 .claude/skills/ | wc -l). This misleads users about available capabilities.","recommendation":"Update SKILL_INDEX.md line 3 to show correct count: 'Total Skills: 57'. Also review category counts for accuracy.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude::episodic-memory-not-configured","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3d-skill-functionality.jsonl","original_id":"process::.claude::episodic-memory-not-configured","category":"process","severity":"S2","type":"process-gap","file":".claude/skills/audit-process/SKILL.md","line":1,"title":"Skill issue: episodic memory MCP not configured but referenced by 11 skills","description":"11 skills reference mcp__plugin_episodic_memory for context retrieval from past sessions, but no MCP configuration file (mcp.json*) contains episodic memory setup. Skills will fail when trying to use this feature, leading to confusing errors for Claude.","recommendation":"Either: (1) Add episodic-memory MCP server to mcp.json configuration with proper credentials, OR (2) Remove episodic memory search sections from all 11 skills if this feature is not available. Option 2 is faster but loses valuable context-retrieval capability.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::docs/audits::missing-false-positives","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3d-skill-functionality.jsonl","original_id":"process::docs/audits::missing-false-positives","category":"process","severity":"S2","type":"process-gap","file":".claude/skills/audit-process/SKILL.md","line":172,"title":"Skill issue: audit skills reference non-existent FALSE_POSITIVES.jsonl","description":"Multiple audit skills instruct Claude to read docs/audits/FALSE_POSITIVES.jsonl to exclude known false positives, but this file doesn't exist. This will cause file read errors during audits and prevent false positive filtering from working.","recommendation":"Create docs/audits/FALSE_POSITIVES.jsonl as an empty array [] or with initial structure: {\"category\":\"security\",\"pattern\":\"...\",\"reason\":\"...\",\"expires\":\"YYYY-MM-DD\"}. Update audit skill documentation to note the file should be created during first audit if it doesn't exist.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/skills/gh-fix-ci::missing-script","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3d-skill-functionality.jsonl","original_id":"process::.claude/skills/gh-fix-ci::missing-script","category":"process","severity":"S1","type":"process-gap","file":".claude/skills/gh-fix-ci/SKILL.md","line":36,"title":"Skill issue: gh-fix-ci references non-existent inspect_pr_checks.py","description":"gh-fix-ci skill's primary workflow relies on scripts/inspect_pr_checks.py to fetch PR check failures, but this script doesn't exist anywhere in the repository. The skill is completely non-functional without it, and will fail immediately when invoked.","recommendation":"Either: (1) Create .claude/skills/gh-fix-ci/scripts/inspect_pr_checks.py implementing the documented API (--repo, --pr, --json flags), OR (2) Update gh-fix-ci skill to use gh CLI commands directly without the wrapper script. Option 2 is simpler but loses abstraction benefits.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":".claude/skills/gh-fix-ci/SKILL.md:36"},{"type":"description","detail":"gh-fix-ci skill's primary workflow relies on scripts/inspect_pr_checks.py to fetch PR check failures, but this script doesn't exist anywhere in the repository. The skill is completely non-functional without it, and will fail immediately when invoked."}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/skills/systematic-debugging::missing-superpowers-refs","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3d-skill-functionality.jsonl","original_id":"process::.claude/skills/systematic-debugging::missing-superpowers-refs","category":"process","severity":"S2","type":"process-gap","file":".claude/skills/systematic-debugging/SKILL.md","line":229,"title":"Skill issue: systematic-debugging references non-existent superpowers skills","description":"systematic-debugging references 'superpowers:test-driven-development' and 'superpowers:verification-before-completion' as related skills, but no skills with these names exist. This creates broken references and confuses users trying to follow the skill workflow.","recommendation":"Either: (1) Remove the 'superpowers:' prefix and references since these skills don't exist, OR (2) Create these skills if test-driven-development and verification-before-completion are intended features, OR (3) Update references to point to existing equivalent skills if they exist under different names.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/skills/code-reviewer/scripts::placeholder-code","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3d-skill-functionality.jsonl","original_id":"process::.claude/skills/code-reviewer/scripts::placeholder-code","category":"process","severity":"S3","type":"process-gap","file":".claude/skills/code-reviewer/scripts/pr_analyzer.py","line":1,"title":"Skill issue: code-reviewer scripts may be non-functional templates","description":"code-reviewer skill heavily emphasizes using three Python scripts (pr_analyzer.py, code_quality_checker.py, review_report_generator.py), but these scripts appear to be placeholder/template code based on skill description patterns. If they're not functional implementations, the skill guidance is misleading.","recommendation":"Test the three scripts with sample inputs to verify functionality. If they're templates: (1) Add clear 'TEMPLATE - NOT IMPLEMENTED' warnings to skill documentation, (2) Update skill to focus on manual review patterns instead of script automation, OR (3) Implement the scripts properly if automation is the intended workflow.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/skills/audit-process::complex-orchestration","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3d-skill-functionality.jsonl","original_id":"process::.claude/skills/audit-process::complex-orchestration","category":"process","severity":"S2","type":"process-gap","file":".claude/skills/audit-process/SKILL.md","line":1,"title":"Skill issue: audit-process has complex 7-stage orchestration that may be brittle","description":"audit-process orchestrates 22 parallel agents across 7 stages with extensive verification checkpoints and context recovery logic. This complexity increases the risk of agent coordination failures, variable loss during context compaction, and difficult debugging when stages fail. The skill itself acknowledges this with extensive recovery procedures.","recommendation":"Consider simplifying to fewer stages (e.g., 3-4 instead of 7) or providing a 'lite' mode that runs sequentially with simpler orchestration for smaller codebases. Add automated testing for the orchestration logic itself.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/skills::duplicate-pre-audit","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3d-skill-functionality.jsonl","original_id":"process::.claude/skills::duplicate-pre-audit","category":"process","severity":"S3","type":"process-gap","file":".claude/skills/audit-process/SKILL.md","line":100,"title":"Skill issue: multiple audit skills have duplicate functionality in pre-audit steps","description":"All audit skills (process, security, code, comprehensive) have nearly identical Step 0 (episodic memory search), baseline gathering, and false positives loading. This duplication means updates must be applied to 4+ files, increasing maintenance burden and risk of inconsistency.","recommendation":"Extract common pre-audit steps into a shared skill or reference document (.claude/skills/_audit-common/pre-audit-steps.md) that all audit skills import or reference. This creates a single source of truth for audit initialization.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/skills/session-begin::outdated-filename-reference","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3d-skill-functionality.jsonl","original_id":"process::.claude/skills/session-begin::outdated-filename-reference","category":"process","severity":"S3","type":"process-gap","file":".claude/skills/session-begin/SKILL.md","line":301,"title":"Skill issue: session-begin references deprecated TECHNICAL_DEBT_MASTER.md filename","description":"session-begin skill refers to 'TECHNICAL_DEBT_MASTER.md' but the actual file is 'MASTER_DEBT.jsonl' (JSONL format, not Markdown). This will cause file-not-found errors when following the skill checklist.","recommendation":"Update session-begin/SKILL.md line 301 and any other references to use correct filename: 'docs/technical-debt/MASTER_DEBT.jsonl' instead of 'TECHNICAL_DEBT_MASTER.md'.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-review-needed.js::getnextday-silent-failure","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3c-script-functionality.jsonl","original_id":"process::scripts/check-review-needed.js::getnextday-silent-failure","category":"process","severity":"S2","type":"process-gap","file":"scripts/check-review-needed.js","line":170,"title":"Bug: check-review-needed.js - getNextDay() fails silently on invalid dates","description":"getNextDay() returns empty string on invalid date (line 176), but callers at lines 534 and 550 don't validate the result. This passes empty string to git commands as --since=\"\" which may not fail but could produce unexpected results, potentially causing incorrect review trigger calculations.","recommendation":"Add validation in getNextDay() callers to check for empty string return and handle gracefully: const afterDate = getNextDay(sinceDate); if (!afterDate) { return 0; } // or appropriate fallback","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-cross-doc-deps.js::checkdiffpattern-silent-skip","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3c-script-functionality.jsonl","original_id":"process::scripts/check-cross-doc-deps.js::checkdiffpattern-silent-skip","category":"process","severity":"S2","type":"process-gap","file":"scripts/check-cross-doc-deps.js","line":100,"title":"Bug: check-cross-doc-deps.js - checkDiffPattern() silently skips rules on git errors","description":"checkDiffPattern() catches all errors and returns false without warning (lines 110-118). If git diff fails (e.g., binary file, permission issue, corrupted file), the dependency check rule is silently skipped. This could miss required dependent document updates, defeating the purpose of cross-document enforcement.","recommendation":"Log errors when git diff fails in non-verbose mode, or collect failed checks and report them in summary. Consider: if (verbose) logVerbose(`Failed to check diff...`) should be if (verbose || diffCheckFailed) log(`Warning: Failed to check...`)","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-cross-doc-deps.js::empty-rules-inconsistent","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3c-script-functionality.jsonl","original_id":"process::scripts/check-cross-doc-deps.js::empty-rules-inconsistent","category":"process","severity":"S2","type":"process-gap","file":"scripts/check-cross-doc-deps.js","line":69,"title":"Bug: check-cross-doc-deps.js - inconsistent behavior with empty dependency rules","description":"When config loads with empty rules (line 69), the script exits with error code 2 in normal mode (line 75) but continues in dry-run mode (line 73) and reports success. This inconsistency means --dry-run doesn't accurately simulate normal behavior, and empty config might go unnoticed in testing.","recommendation":"Remove the dry-run exemption: if (dependencyRules.length === 0) { log('Error: cross-doc dependency enforcement disabled due to empty rules.', colors.red); process.exit(2); } // No dry-run check","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/security-check.js::getstagedfiles-silent-failure","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3c-script-functionality.jsonl","original_id":"process::scripts/security-check.js::getstagedfiles-silent-failure","category":"process","severity":"S2","type":"process-gap","file":"scripts/security-check.js","line":310,"title":"Bug: security-check.js - getStagedFiles() returns empty array on git failure without error","description":"getStagedFiles() catch block (line 321-323) returns empty array when git fails (not a git repo, git not installed, permission issues) without logging the error. Main function then prints 'No files to check' which is misleading - the issue is git failure, not absence of files. Users may think security check passed when it silently failed.","recommendation":"Log git errors before returning empty array: try { ... } catch (err) { if (!isQuiet) console.error(`Warning: Could not get staged files from git: ${err.message}`); return []; }","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/validate-audit.js::wildcard-no-existence-check","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3c-script-functionality.jsonl","original_id":"process::scripts/validate-audit.js::wildcard-no-existence-check","category":"process","severity":"S3","type":"process-gap","file":"scripts/validate-audit.js","line":370,"title":"Bug: validate-audit.js - wildcard file patterns not validated for existence","description":"validateFilePath() checks wildcard patterns (line 370-383) by validating only the prefix path for containment, but doesn't verify if the pattern matches any actual files. A finding with file='src/*.js' passes validation even if no such files exist. This allows ineffective or typo'd patterns to pass validation, reducing audit quality.","recommendation":"After containment check for wildcards, optionally use glob library to check if pattern matches at least one file: const matches = glob.sync(finding.file, {cwd: repoRoot}); if (matches.length === 0) { issues.push({type: 'WILDCARD_NO_MATCH', ...}) }","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/generate-documentation-index.js::skipped-links-invisible","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3c-script-functionality.jsonl","original_id":"process::scripts/generate-documentation-index.js::skipped-links-invisible","category":"process","severity":"S3","type":"process-gap","file":"scripts/generate-documentation-index.js","line":417,"title":"Enhancement: generate-documentation-index.js - no visibility into skipped links","description":"extractLinks() silently skips links that fail path containment (line 422-424) or URL decoding (line 401-404). In verbose mode, there's no count or warning about how many links were skipped. Users can't tell if their documentation has broken links attempting path traversal or malformed URLs, reducing the index quality.","recommendation":"Add counter for skipped links and log in verbose mode: let skipped = 0; ... if (resolvedPath === null) { skipped++; if (verbose) logVerbose(`Skipped link in ${currentFile}: ${href} (path traversal)`); continue; } ... if (verbose && skipped > 0) log(`Skipped ${skipped} invalid links in ${currentFile}`)","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/check-pattern-compliance.js::silent-file-filtering","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3c-script-functionality.jsonl","original_id":"process::scripts/check-pattern-compliance.js::silent-file-filtering","category":"process","severity":"S3","type":"process-gap","file":"scripts/check-pattern-compliance.js","line":494,"title":"Enhancement: check-pattern-compliance.js - silent filtering of user-provided files","description":"getFilesToCheck() with explicit FILES argument (line 494-508) applies filtering (path validation, existence checks, global excludes) that can reduce the list to empty. If user provides 'node scripts/check-pattern-compliance.js file1.js file2.js' but both are excluded, the script exits with 'No files to check' without explaining why their specified files were ignored. This is confusing user experience.","recommendation":"Track filtering reasons and report them: const filtered = FILES.filter(...).map((f) => ({file: f, reason: null})); // Track reasons during filtering, then: if (filtered.length === 0 && FILES.length > 0) { console.log(`Warning: All ${FILES.length} specified files were excluded`); }","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/aggregate-audit-findings.js::no-progress-feedback","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3c-script-functionality.jsonl","original_id":"process::scripts/aggregate-audit-findings.js::no-progress-feedback","category":"process","severity":"S3","type":"process-gap","file":"scripts/aggregate-audit-findings.js","line":1446,"title":"Bug: aggregate-audit-findings.js - potential long-running operation with no progress indication","description":"aggregate() performs complex multi-pass deduplication (lines 1344-1402), cross-referencing (lines 1518-1544), and markdown generation on potentially thousands of findings. In non-verbose mode, there's no progress indication. If processing takes minutes or hangs, users can't tell if the script is working or frozen, leading to premature cancellation or confusion.","recommendation":"Add progress indicators for long operations: console.log('Phase 3: Deduplicating findings...'); let passCount = 0; while (didMerge && passCount < MAX_PASSES) { passCount++; if (passCount % 2 === 0) process.stdout.write('.'); ... } console.log(` (${passCount} passes)`)","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/deploy-firebase.yml::pull-request-target-risk","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/deploy-firebase.yml::pull-request-target-risk","category":"process","severity":"S0","type":"process-gap","file":".github/workflows/deploy-firebase.yml","line":7,"title":"CI gap: pull_request_target security vulnerability allows untrusted code execution","description":"Using pull_request_target with code checkout from PR head (line 32) allows malicious PRs to execute arbitrary code with repository secrets access. This is a well-documented GitHub Actions security anti-pattern that could lead to credential theft or repository compromise.","recommendation":"Replace pull_request_target with pull_request and use a separate workflow for preview deploys that runs after CI passes. Alternatively, use pull_request_target but only checkout base branch code, then merge PR changes in a sandboxed environment. See GitHub's security hardening guide.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":".github/workflows/deploy-firebase.yml:7"},{"type":"description","detail":"Using pull_request_target with code checkout from PR head (line 32) allows malicious PRs to execute arbitrary code with repository secrets access. This is a well-documented GitHub Actions security anti-pattern that could lead to credential theft or repository compromise."}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/ci.yml::no-coverage-thresholds","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/ci.yml::no-coverage-thresholds","category":"process","severity":"S1","type":"process-gap","file":".github/workflows/ci.yml","line":115,"title":"CI gap: No test coverage thresholds enforced","description":"Tests run with coverage reporting but there are no minimum thresholds configured. Code with 0% test coverage can pass CI, allowing untested code to merge. This defeats the purpose of coverage tracking.","recommendation":"Add c8 configuration with minimum thresholds (e.g., 70% lines, 60% branches). Update ci.yml line 115 to fail if thresholds not met: npm run test:coverage -- --check-coverage --lines 70 --branches 60","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":".github/workflows/ci.yml:115"},{"type":"description","detail":"Tests run with coverage reporting but there are no minimum thresholds configured. Code with 0% test coverage can pass CI, allowing untested code to merge. This defeats the purpose of coverage tracking."}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/ci.yml::continue-on-error-abuse","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/ci.yml::continue-on-error-abuse","category":"process","severity":"S2","type":"process-gap","file":".github/workflows/ci.yml","line":74,"title":"CI gap: continue-on-error bypasses critical validations","description":"Four validation steps use continue-on-error: pattern compliance on main (74), documentation check (79), audit validation (89), and technical debt views (106). These failures never block merges, allowing broken patterns, bad docs, invalid audits, and stale debt tracking to accumulate unnoticed.","recommendation":"Remove continue-on-error from all steps except known unstable checks. Make pattern compliance blocking for changed files. Add separate non-blocking 'advisory' job for experimental checks. Use required status checks in GitHub branch protection.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/ci.yml::missing-secrets-silent","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/ci.yml::missing-secrets-silent","category":"process","severity":"S2","type":"process-gap","file":".github/workflows/ci.yml","line":154,"title":"CI gap: Missing secrets cause silent build success","description":"Build step uses secrets for Firebase config (lines 154-159). If secrets are missing or misconfigured, environment variables are set to empty strings and build succeeds. This hides configuration issues until runtime in production.","recommendation":"Add validation step before build: for secret in NEXT_PUBLIC_FIREBASE_API_KEY ...; do [[ -z $secret ]] && exit 1; done. Or use GitHub's required secrets feature and fail explicitly if not set.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/ci.yml::pattern-check-incomplete","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/ci.yml::pattern-check-incomplete","category":"process","severity":"S2","type":"process-gap","file":".github/workflows/ci.yml","line":58,"title":"CI gap: Pattern compliance only checks changed files in PRs","description":"Line 64 only checks changed files in PRs. If pattern rules are updated, existing violations in unchanged files are never caught. Pattern debt accumulates invisibly until someone touches those files. Also, if someone bypasses the check once, the violation persists forever.","recommendation":"Run full pattern check on a schedule (weekly) and post issues for violations. Or run full check on PRs that modify pattern rules themselves. Consider making pattern check blocking only for new violations but report existing ones.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/ci.yml::no-dependency-caching","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/ci.yml::no-dependency-caching","category":"process","severity":"S2","type":"process-gap","file":".github/workflows/ci.yml","line":136,"title":"CI gap: Build job re-installs dependencies wastefully","description":"Build job (lines 136-149) runs after lint-typecheck-test but re-installs all dependencies and rebuilds from scratch. This wastes 2-5 minutes per CI run and increases risk of dependency resolution differences between jobs.","recommendation":"Cache node_modules as artifact in first job and restore in build job. Or combine jobs into single job with multiple steps. Or use Docker layer caching. Document reason if separate jobs are required.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/auto-label-review-tier.yml::label-race-condition","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/auto-label-review-tier.yml::label-race-condition","category":"process","severity":"S2","type":"process-gap","file":".github/workflows/auto-label-review-tier.yml","line":77,"title":"CI gap: Race condition in tier label assignment","description":"Label removal (lines 77-100) and addition (101-150) are separate steps. If workflow runs twice concurrently on rapid PR updates, labels can get into inconsistent state (e.g., both tier-2 and tier-3 present, or no tier label at all).","recommendation":"Use GitHub API's replaceLabels operation which is atomic. Or add concurrency group keyed on PR number with cancel-in-progress: true. Or use a single API call that removes and adds in one transaction.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/auto-label-review-tier.yml::duplicate-tier-logic","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/auto-label-review-tier.yml::duplicate-tier-logic","category":"process","severity":"S2","type":"process-gap","file":".github/workflows/auto-label-review-tier.yml","line":60,"title":"CI gap: Inline tier assignment logic creates maintenance drift","description":"Lines 60-75 contain inline bash logic that duplicates scripts/assign-review-tier.js. Comment says 'TODO: Uncomment when script is ready' but script exists and is referenced. This technical debt causes maintenance burden and drift between workflow and script logic.","recommendation":"Remove TODO placeholder logic and uncomment line 56 to use the actual script. Or if script needs updates, fix it first then switch. Add test that workflow and script produce same tier for sample file sets.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/sonarcloud.yml::skip-fork-prs","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/sonarcloud.yml::skip-fork-prs","category":"process","severity":"S2","type":"process-gap","file":".github/workflows/sonarcloud.yml","line":22,"title":"CI gap: Fork PRs completely skip SonarCloud analysis","description":"Lines 22-24 skip SonarCloud analysis for all fork PRs because secrets aren't available. External contributions get zero static analysis, allowing security issues, code smells, and bugs to merge without detection. This is especially risky since forks are more likely to introduce novel bugs.","recommendation":"Run SonarCloud on a schedule against main branch to catch issues after merge. Or use pull_request_target carefully to analyze fork code (but see security implications). Or require maintainers to manually trigger analysis before merging fork PRs.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/deploy-firebase.yml::no-deployment-validation","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/deploy-firebase.yml::no-deployment-validation","category":"process","severity":"S2","type":"process-gap","file":".github/workflows/deploy-firebase.yml","line":140,"title":"CI gap: Firebase deployment has no success validation","description":"Lines 140-147 deploy functions, rules, and hosting but don't verify deployment actually succeeded. Firebase CLI can exit 0 even if deployment partially failed. Broken deployments may go unnoticed until users report issues.","recommendation":"Add validation steps after each deploy: query Firebase to confirm functions are deployed and callable, test firestore rules with sample operations, curl hosting URL to verify it returns 200. Fail workflow if validation fails.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/deploy-firebase.yml::no-rollback","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/deploy-firebase.yml::no-rollback","category":"process","severity":"S2","type":"process-gap","file":".github/workflows/deploy-firebase.yml","line":140,"title":"CI gap: Deployment has no rollback mechanism","description":"Deployment steps run sequentially (lines 140-147) but if one fails, there's no rollback. A partial deployment could leave production in inconsistent state (e.g., new functions deployed but old hosting, or new rules but old functions).","recommendation":"Add rollback step that runs on failure: capture previous deployment SHA before deploy, on failure run firebase deploy with previous version. Or use Firebase's rollback API. Or deploy to staging first, validate, then promote.","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/deploy-firebase.yml::credentials-filesystem-risk","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/deploy-firebase.yml::credentials-filesystem-risk","category":"process","severity":"S2","type":"process-gap","file":".github/workflows/deploy-firebase.yml","line":120,"title":"CI gap: Service account credentials written to filesystem","description":"Lines 120-124 write service account JSON to $HOME/gcloud-key.json. If subsequent steps fail or are compromised, credentials could be leaked in logs, artifacts, or through file disclosure. File is only cleaned up in always() block which might not run if workflow is cancelled.","recommendation":"Use Google's official auth action which handles credentials securely without writing to disk. Or use base64 encode/pipe: echo $SECRET | base64 -d | gcloud auth activate-service-account --key-file=-. Ensure cleanup happens even on workflow cancellation.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/deploy-firebase.yml::function-delete-masked","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/deploy-firebase.yml::function-delete-masked","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/deploy-firebase.yml","line":131,"title":"CI gap: Deleting functions uses continue-on-error hiding real failures","description":"Line 138 uses continue-on-error for function deletion. This is intended to handle 'function doesn't exist' but also hides real errors like authentication failures, permission issues, or API outages. These failures should block deployment.","recommendation":"Check if function exists before deleting: firebase functions:list | grep -q functionName && firebase functions:delete functionName. Or capture error message and only ignore specific 404-style errors. Fail on auth/permission/API errors.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/deploy-firebase.yml::env-var-inconsistency","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/deploy-firebase.yml::env-var-inconsistency","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/deploy-firebase.yml","line":51,"title":"CI gap: Preview and production use different env var sources","description":"Preview deploy (line 51) uses vars.* (GitHub environment variables) while production (line 104) uses secrets.*. This inconsistency means preview and production builds could have different configurations, making preview testing unreliable and potentially hiding config issues.","recommendation":"Use same source for both (either both vars or both secrets). Document why they're different if intentional. Add validation that all required env vars are present in both sources. Consider using a config file instead.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/backlog-enforcement.yml::missing-replacement-check","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/backlog-enforcement.yml::missing-replacement-check","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/backlog-enforcement.yml","line":35,"title":"CI gap: Backlog check gracefully skips with no replacement validation","description":"Lines 35-42 gracefully skip if AUDIT_FINDINGS_BACKLOG.md doesn't exist (archived per comment), but there's no check that replacement MASTER_DEBT.jsonl exists and is valid. Backlog tracking could silently break if neither file exists.","recommendation":"Add elif check: if [ -f docs/technical-debt/MASTER_DEBT.jsonl ]; then run new validation; else fail with error. Or integrate with existing TDMS validation in ci.yml. Ensure one source of truth is always validated.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/backlog-enforcement.yml::inefficient-security-loop","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/backlog-enforcement.yml::inefficient-security-loop","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/backlog-enforcement.yml","line":147,"title":"CI gap: Security pattern check runs file-by-file inefficiently","description":"Lines 147-150 run security-check.js in a loop for each changed file. This is inefficient (spawns N processes), doesn't aggregate results, and could hide failures in earlier iterations. Also prevents batch optimizations in the script.","recommendation":"Modify security-check.js to accept multiple files: node scripts/security-check.js --files file1 file2 file3. Or pass all files via stdin. Aggregate results and report summary. Run once instead of N times.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/docs-lint.yml::archives-never-checked","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/docs-lint.yml::archives-never-checked","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/docs-lint.yml","line":78,"title":"CI gap: Documentation linting skips archive files entirely","description":"Lines 78-81 skip archive files completely. While archives are historical, broken links and formatting issues make them harder to reference. If someone needs to consult archived docs, broken content creates confusion and wastes time.","recommendation":"Create separate non-blocking job for archive linting. Report issues but don't block PRs. Or run archive lint on a schedule. Or document that archives are explicitly not maintained and add warning banner to archive docs.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/resolve-debt.yml::closed-pr-skip","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/resolve-debt.yml::closed-pr-skip","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/resolve-debt.yml","line":11,"title":"CI gap: Resolve debt workflow only runs on merged PRs","description":"Line 11 only triggers on merged PRs. If a PR mentions DEBT-123 but is closed without merging, the debt item is never updated to reflect the cancelled work. This causes debt tracking to become stale and inaccurate.","recommendation":"Add separate step for closed-without-merge PRs: update debt items to add comment 'PR #123 closed without merging' and revert status if it was changed. Or don't auto-update debt items at all, require manual resolution.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/resolve-debt.yml::skip-ci-debt","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/resolve-debt.yml::skip-ci-debt","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/resolve-debt.yml","line":88,"title":"CI gap: Debt resolution skips CI with [skip ci]","description":"Line 88 includes [skip ci] in commit message. This means debt resolution commits bypass all CI checks including validation of the debt file structure, pattern compliance, and any other checks. Malformed debt commits could merge without detection.","recommendation":"Remove [skip ci] and let normal CI run. Debt resolution should be validated like any other commit. If CI is too slow, optimize CI rather than skipping it. Or use more specific skip flag that only skips expensive tests.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/resolve-debt.yml::rebase-race","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/resolve-debt.yml::rebase-race","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/resolve-debt.yml","line":92,"title":"CI gap: Debt resolution has race condition on rebase","description":"Line 92 does git pull --rebase to handle case where main moved after checkout. But if another workflow pushes between pull and push, this fails. Multiple merged PRs in quick succession can cause workflow failures and failed debt resolution.","recommendation":"Add retry loop like sync-readme.yml (lines 64-78). Or use GitHub's REST API to create commits instead of git push. Or add concurrency group to serialize debt resolution commits.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/review-check.yml::complex-json-parse","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/review-check.yml::complex-json-parse","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/review-check.yml","line":46,"title":"CI gap: Review trigger check has fragile JSON validation","description":"Lines 46-50 have complex JSON validation using piped node one-liner. If this fails, output is replaced with error JSON but parsing errors are silently swallowed. Malformed JSON could cause workflow to incorrectly mark PRs as needing review.","recommendation":"Simplify validation: use jq or node -p 'JSON.parse(process.argv[1])' $OUTPUT. If validation fails, fail the workflow explicitly rather than substituting error JSON. Log original output for debugging.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/review-check.yml::continue-hides-crashes","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/review-check.yml::continue-hides-crashes","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/review-check.yml","line":33,"title":"CI gap: Review check uses continue-on-error hiding crashes","description":"Line 33 has continue-on-error which means if check-review-needed.js crashes (OOM, unhandled exception, etc), workflow continues and treats it as 'review needed'. This creates false positives and alert fatigue. Real errors should be fixed, not hidden.","recommendation":"Remove continue-on-error. Let script failures fail the workflow. Fix the script to handle errors gracefully and return proper exit codes. Use workflow retry for transient failures.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/validate-plan.yml::dead-workflow","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/validate-plan.yml::dead-workflow","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/validate-plan.yml","line":7,"title":"CI gap: Phase validation workflow is likely dead code","description":"Line 7 only triggers for changes to docs/archive/completed-plans/INTEGRATED_IMPROVEMENT_PLAN.md which is an archived document. This workflow never runs on modern changes. Dead code creates maintenance burden and confusion.","recommendation":"Delete the workflow and document in commit message that phase validation is now handled elsewhere. Or update path to current planning documents. Or disable workflow explicitly with if: false.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/sync-readme.yml::fragile-retry","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/sync-readme.yml::fragile-retry","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/sync-readme.yml","line":64,"title":"CI gap: Sync README has fragile retry logic","description":"Lines 64-78 retry push 3 times with 5-second sleep. This is fragile: assumes conflicts resolve within 5s, doesn't backoff exponentially, and 3 retries may not be enough if multiple workflows queue up. Also mixes pull --rebase with retry which could compound conflicts.","recommendation":"Use exponential backoff: sleep $((i * i * 5)). Increase retries to 5. Use GitHub API to create commits instead of git push to avoid git-level races. Or use concurrency group to serialize commits.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/sync-readme.yml::no-verify-bypass","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/sync-readme.yml::no-verify-bypass","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/sync-readme.yml","line":57,"title":"CI gap: Sync README uses --no-verify bypassing hooks","description":"Line 57 uses --no-verify which bypasses pre-commit hooks. If hooks check for commit message format, trailing whitespace, or other issues, README sync commits could violate standards. This creates inconsistency in commit history.","recommendation":"Remove --no-verify unless there's specific reason (document reason if so). Let hooks run to ensure consistency. If hooks are too slow for automation, optimize hooks rather than skipping them.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/*::inconsistent-pinning","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/*::inconsistent-pinning","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/ci.yml","line":45,"title":"CI gap: Inconsistent GitHub Action version pinning","description":"Some workflows use SHA pinning for security (ci.yml line 45, backlog-enforcement.yml line 18) while others use semantic versions (auto-label-review-tier.yml line 29 uses @v46). Inconsistent pinning creates security gaps and makes supply chain attacks easier.","recommendation":"Adopt consistent pinning strategy: either pin all actions to SHAs with comments showing version, or use Dependabot to keep semantic versions updated. Document strategy in CONTRIBUTING.md.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/ci.yml::no-node-version-check","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/ci.yml::no-node-version-check","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/ci.yml","line":21,"title":"CI gap: No validation of Node.js version consistency","description":"Line 21 hardcodes Node 22 but there's no check that this matches package.json engines field or .nvmrc. Developers could use different Node version locally, causing 'works on my machine' issues. CI should enforce version consistency.","recommendation":"Add .nvmrc or package.json engines field with required Node version. Change workflow to read version from file: node-version-file: '.nvmrc'. Add pre-commit hook to check local Node version matches.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/docs-lint.yml::template-regex-brittle","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/docs-lint.yml::template-regex-brittle","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/docs-lint.yml","line":72,"title":"CI gap: Template file exclusion is brittle regex","description":"Lines 72-75 use regex patterns to skip template files: (TEMPLATE|_TEMPLATE)\\.md$. A file named TEMPLATE-proposal.md or my-TEMPLATE.md wouldn't match and would be incorrectly linted. Brittle pattern matching causes false positives.","recommendation":"Use more specific paths: if [[ $file =~ ^docs/templates/ ]]; then skip. Or maintain list of template files in config. Or add header to templates that linter detects. Make pattern matching more robust.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/docs-lint.yml::markdown-injection-incomplete","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/docs-lint.yml::markdown-injection-incomplete","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/docs-lint.yml","line":91,"title":"CI gap: Markdown injection sanitization incomplete","description":"Line 91 sanitizes ``` to prevent markdown injection but doesn't handle other vectors like [clickjacking](javascript:alert(1)) or HTML tags. Malicious or buggy docs could inject content into PR comments.","recommendation":"Use comprehensive sanitization library or render lint output as code block (which GitHub auto-escapes). Or limit output length and use GitHub's built-in comment rendering which sanitizes HTML.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/backlog-enforcement.yml::git-diff-merge-commits","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/backlog-enforcement.yml::git-diff-merge-commits","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/backlog-enforcement.yml","line":127,"title":"CI gap: Changed files detection could miss merge commits","description":"Line 127 uses git diff origin/$BASE...HEAD which could miss files in merge commits depending on git configuration. Three-dot diff shows changes since common ancestor, but merge commits might introduce changes not in either parent.","recommendation":"Use two-dot diff: git diff origin/$BASE..HEAD. Or use GitHub's changed files API which is authoritative. Or use tj-actions/changed-files action like other workflows for consistency.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/auto-label-review-tier.yml::comment-on-synchronize","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3b-ci-effectiveness.jsonl","original_id":"process::.github/workflows/auto-label-review-tier.yml::comment-on-synchronize","category":"process","severity":"S2","type":"process-gap","file":".github/workflows/auto-label-review-tier.yml","line":186,"title":"CI gap: Tier comment spam on every synchronize event","description":"Line 186 only posts comment on opened/reopened, not synchronize. This is good for avoiding spam, but if tier changes due to new files added, PR author doesn't get notified. They might miss important tier escalation (e.g., tier 2 -> tier 4).","recommendation":"Post comment on synchronize only if tier label changed. Track previous tier in workflow state or by reading PR labels. Notify author when tier increases (escalation) but not when it stays same.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks/audit-s0s1-validator.js::always-warn","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3a-hook-effectiveness.jsonl","original_id":"process::.claude/hooks/audit-s0s1-validator.js::always-warn","category":"process","severity":"S2","type":"process-gap","file":".claude/hooks/audit-s0s1-validator.js","line":21,"title":"Ineffective: audit-s0s1-validator defaults to WARN mode","description":"S0/S1 audit findings require strict validation but hook defaults to non-blocking WARN mode, allowing invalid findings to be written. The hook only blocks if AUDIT_S0S1_MODE=BLOCK is explicitly set, which is not the default.","recommendation":"Change default mode to BLOCK. Move to WARN mode as opt-out (AUDIT_S0S1_MODE=WARN) rather than opt-in blocking. Rationale: S0/S1 findings represent critical/high severity issues that must have proper verification_steps - this should be enforced by default.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks/pattern-check.js::always-succeeds","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3a-hook-effectiveness.jsonl","original_id":"process::.claude/hooks/pattern-check.js::always-succeeds","category":"process","severity":"S2","type":"process-gap","file":".claude/hooks/pattern-check.js","line":221,"title":"Ineffective: pattern-check hook never blocks violations","description":"Pattern compliance hook always exits with 'ok' (line 221) even when violations are detected. Warnings are shown but violations don't prevent writes. This makes the hook informational noise rather than an enforcement mechanism.","recommendation":"Implement severity-based blocking: Block on critical (🔴) pattern violations, warn on non-critical. Add PATTERN_CHECK_MODE env var for gradual rollout (WARN/BLOCK), similar to audit-s0s1-validator but default to BLOCK for critical patterns. Update error message to indicate operation was blocked.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks/pattern-check.js::small-file-bypass","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3a-hook-effectiveness.jsonl","original_id":"process::.claude/hooks/pattern-check.js::small-file-bypass","category":"process","severity":"S3","type":"process-gap","file":".claude/hooks/pattern-check.js","line":138,"title":"Ineffective: Small file bypass in pattern-check","description":"Pattern check skips files under 100 lines (line 138-165). This creates perverse incentive to keep files artificially small to avoid pattern checks. Critical patterns like hardcoded secrets or auth bypasses can exist in small files.","recommendation":"Remove small file bypass or make it configurable. Alternative: Run lightweight pattern checks on all files, reserve expensive checks for large files. Critical security patterns (secrets, auth) should always run regardless of file size. Document rationale if bypass is intentional performance optimization.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.husky/pre-commit::excessive-bypasses","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3a-hook-effectiveness.jsonl","original_id":"process::.husky/pre-commit::excessive-bypasses","category":"process","severity":"S2","type":"process-gap","file":".husky/pre-commit","line":46,"title":"Ineffective: Pre-commit bypass conditions too easy","description":"Pre-commit hook has 6 easy bypass conditions via environment variables: SKIP_TESTS, SKIP_CROSS_DOC_CHECK, SKIP_DOC_HEADER_CHECK, SKIP_AUDIT_VALIDATION, SKIP_DEBT_VALIDATION, SKIP_DOC_INDEX_CHECK. No audit trail or rate limiting. Developers can habitually bypass checks without visibility.","recommendation":"1. Log all bypasses to .claude/hooks/bypass-audit.jsonl with timestamp, user, check type, reason. 2. Require SKIP_REASON environment variable for all bypasses. 3. Add bypass budget: warn if same user bypasses >3 times in 7 days. 4. Make some checks non-bypassable (e.g., SKIP_AUDIT_VALIDATION for S0/S1). 5. Pre-push hook should fail if too many pre-commit bypasses detected.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.husky/pre-push::network-failure-success","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3a-hook-effectiveness.jsonl","original_id":"process::.husky/pre-push::network-failure-success","category":"process","severity":"S3","type":"process-gap","file":".husky/pre-push","line":107,"title":"Ineffective: Network failures treated as success in pre-push","description":"npm audit check (lines 92-118) treats network errors as success - if npm registry is unreachable, check is skipped silently. Attacker with network control could bypass vulnerability detection. Same pattern could exist in other network-dependent checks.","recommendation":"Distinguish between 'no vulnerabilities' and 'cannot verify'. For network failures: 1. Show clear warning that check was skipped. 2. Log to bypass audit trail. 3. Consider making network checks blocking by default (fail closed), with ALLOW_NETWORK_SKIP=1 opt-out. 4. Cache last successful audit result and warn if stale (>7 days).","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks/check-write-requirements.js::post-task-not-enforced","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3a-hook-effectiveness.jsonl","original_id":"process::.claude/hooks/check-write-requirements.js::post-task-not-enforced","category":"process","severity":"S3","type":"process-gap","file":".claude/hooks/check-write-requirements.js","line":72,"title":"Ineffective: check-write-requirements POST-TASK not enforced","description":"Hook outputs 'POST-TASK: MUST run code-reviewer' and 'POST-TASK: SHOULD run test-engineer' but these are suggestions only. No enforcement mechanism. No tracking whether suggested agents actually ran. Messages become background noise that users ignore.","recommendation":"1. Track suggested agents in .claude/state/required-agents.json. 2. Pre-commit hook checks this file and warns/blocks if required agents not invoked. 3. Agent invocation hooks (track-agent-invocation.js) mark agents as completed. 4. MUST requirements block commit, SHOULD requirements warn. 5. Clear with AGENT_REVIEW_COMPLETE=1 override with reason logging.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks/component-size-check.js::always-ok","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3a-hook-effectiveness.jsonl","original_id":"process::.claude/hooks/component-size-check.js::always-ok","category":"process","severity":"S3","type":"process-gap","file":".claude/hooks/component-size-check.js","line":142,"title":"Ineffective: component-size-check always succeeds","description":"Hook warns about oversized components (>300 lines) but always exits with 'ok' (line 142). Warnings are easily ignored. No escalation for egregiously large files (e.g., 1000+ lines). Size limits become suggestions rather than architectural constraints.","recommendation":"Implement tiered enforcement: 1. >300 lines: WARN (current behavior). 2. >500 lines: WARN with stronger message, add to tech debt tracker. 3. >750 lines: BLOCK unless ALLOW_LARGE_COMPONENT=1 with required explanation. 4. Track component sizes over time - warn if file growing rapidly (>50 lines/week). Form components keep higher limits but require Form suffix in filename.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks/agent-trigger-enforcer.js::phase-not-implemented","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3a-hook-effectiveness.jsonl","original_id":"process::.claude/hooks/agent-trigger-enforcer.js::phase-not-implemented","category":"process","severity":"S3","type":"process-gap","file":".claude/hooks/agent-trigger-enforcer.js","line":295,"title":"Ineffective: agent-trigger-enforcer Phase 2/3 not implemented","description":"Hook shows phase transition notifications (lines 219-234) recommending upgrade to Phase 2 WARN or Phase 3 BLOCK modes, but these phases are not implemented. Hook always succeeds regardless of phase setting (line 295). Phase transitions are notification theater without actual behavior change.","recommendation":"Implement phase enforcement logic: Phase 1 (current): Suggest agents. Phase 2: Warn prominently if required agents not invoked, track to pending-reviews.json. Phase 3: Block Write/Edit if required agent not invoked this session, require SKIP_AGENT_CHECK=1 override with reason. Use state.phase to control behavior. Document phase upgrade process and rollback plan.","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks/large-context-warning.js::warning-once","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3a-hook-effectiveness.jsonl","original_id":"process::.claude/hooks/large-context-warning.js::warning-once","category":"process","severity":"S2","type":"process-gap","file":".claude/hooks/large-context-warning.js","line":146,"title":"Ineffective: large-context-warning warningShown flag prevents repeated warnings","description":"Hook warns when >15 files read in session (line 146-153) but sets warningShown flag to prevent repeated warnings. After first warning, can read 50+ more files without additional feedback. Warning effectiveness degrades over long sessions. State resets after 30 minutes, allowing warning suppression.","recommendation":"Change warning strategy: 1. Warn at thresholds: 15, 30, 50, 100 files (escalating urgency). 2. Show file count in status bar if available. 3. After 30 files, suggest /save-context every 5 files. 4. After 50 files, warn that compaction likely soon. 5. Track context pressure score (files + total lines) not just file count. Don't use warningShown flag for suppression.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks/check-remote-session-context.js::informational-only","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3a-hook-effectiveness.jsonl","original_id":"process::.claude/hooks/check-remote-session-context.js::informational-only","category":"process","severity":"S2","type":"process-gap","file":".claude/hooks/check-remote-session-context.js","line":32,"title":"Ineffective: check-remote-session-context always succeeds","description":"Hook detects when remote branches have newer session context (higher session counter) but always exits with 'ok' even when mismatch found. Warning shown (lines 163-176) but no enforcement. Developers can ignore and work on stale context, leading to lost work or duplicate sessions.","recommendation":"Make blocking when session counter difference >5 (likely working on very stale branch): 1. Show warning and suggest merge for small differences (1-2 sessions). 2. Block session start for large differences (>5 sessions) unless ALLOW_STALE_CONTEXT=1. 3. Offer auto-merge or checkout options. 4. Track if user repeatedly ignores warnings (>3 times in 14 days) and escalate to block. 5. continueOnError: true in settings keeps non-blocking for fetch failures.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks/audit-s0s1-validator.js::parse-error-evasion","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3a-hook-effectiveness.jsonl","original_id":"process::.claude/hooks/audit-s0s1-validator.js::parse-error-evasion","category":"process","severity":"S3","type":"process-gap","file":".claude/hooks/audit-s0s1-validator.js","line":84,"title":"Ineffective: audit-s0s1-validator allows parse errors","description":"When JSONL parsing fails (lines 79-86), malformed lines are marked with _parseError but validation continues. If S0/S1 finding is in a malformed line, it escapes validation. Attacker or lazy developer could intentionally malform S0/S1 entries to bypass strict verification requirements.","recommendation":"Fail validation if any parse errors found in audit file: 1. Count parse errors during JSONL parsing. 2. If parseErrorCount > 0, block with message: 'JSONL file has malformed entries - fix syntax before committing'. 3. Show first 3 malformed lines with line numbers. 4. No override - proper JSON is non-negotiable for audit data. 5. Validate that all S0/S1 findings were successfully parsed (cross-check line count of S0/S1 severity strings vs parsed S0/S1 objects).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks/commit-tracker.js::continue-on-error","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3a-hook-effectiveness.jsonl","original_id":"process::.claude/hooks/commit-tracker.js::continue-on-error","category":"process","severity":"S2","type":"process-gap","file":".claude/settings.json","line":251,"title":"Ineffective: commit-tracker continueOnError makes failures silent","description":"commit-tracker.js has continueOnError: true (settings.json line 251) so failures are silent. If state files become corrupted or filesystem has issues, commit tracking silently breaks. Compaction resilience (Session #138) depends on this tracking but failures are invisible.","recommendation":"Keep continueOnError: true (appropriate for non-critical tracking) but add failure detection and alerting: 1. If commit-tracker fails 3+ times in session, show warning. 2. Log failures to .claude/hooks/hook-failures.jsonl with timestamp, hook name, error. 3. Session-start hook checks failure log and warns if recent failures (last 7 days). 4. Health check command to verify state files readable/writable. Document that continueOnError is intentional but monitored.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.husky/pre-push::skip-triggers","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-3a-hook-effectiveness.jsonl","original_id":"process::.husky/pre-push::skip-triggers","category":"process","severity":"S3","type":"process-gap","file":".husky/pre-push","line":123,"title":"Ineffective: Pre-push SKIP_TRIGGERS bypass has no budget","description":"SKIP_TRIGGERS=1 bypasses event-based trigger checks (lines 123-152) including security audits. Override logged to scripts/log-override.js but no enforcement of bypass budget. Developer could use SKIP_TRIGGERS=1 on every push to avoid all trigger-based checks including security scans.","recommendation":"Implement bypass budget for SKIP_TRIGGERS: 1. Track bypass frequency in .claude/state/bypass-budget.json (user, timestamp, reason). 2. Allow 3 bypasses per 7 days without warning. 3. Warn at 4-5 bypasses in 7 days. 4. Block at 6+ bypasses in 7 days unless BYPASS_BUDGET_OVERRIDE=1 (requires escalation approval or explicit reason). 5. Reset budget weekly. 6. Distinguish security trigger bypasses (stricter budget: 1 per 7 days) from other triggers.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/backlog-enforcement.yml::never-executes-backlog-check","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2c-unused.jsonl","original_id":"process::.github/workflows/backlog-enforcement.yml::never-executes-backlog-check","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/backlog-enforcement.yml","line":32,"title":"Never executes: AUDIT_FINDINGS_BACKLOG.md backlog check","description":"Workflow checks for docs/AUDIT_FINDINGS_BACKLOG.md which doesn't exist (archived in TDMS Phase 2). The check always exits early with 0 items, making the entire job pointless. Script check-backlog-health.js also references this non-existent file.","recommendation":"Remove backlog-health job from workflow or update to check docs/technical-debt/MASTER_DEBT.jsonl instead","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::package.json::never-executes-test-coverage-report","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2c-unused.jsonl","original_id":"process::package.json::never-executes-test-coverage-report","category":"process","severity":"S3","type":"process-gap","file":"package.json","line":13,"title":"Never executes: npm script test:coverage:report","description":"Script defined but never called in any workflow, hook, or automation. Only appears in audit documentation. Creates impression of functionality that doesn't execute.","recommendation":"Remove script from package.json or add to CI workflow if coverage reporting is needed","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::package.json::never-executes-learning-category","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2c-unused.jsonl","original_id":"process::package.json::never-executes-learning-category","category":"process","severity":"S3","type":"process-gap","file":"package.json","line":38,"title":"Never executes: npm script learning:category","description":"Script defined but never called in any workflow, hook, documentation, or automation. Likely vestigial from development.","recommendation":"Remove script from package.json","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::package.json::never-executes-learning-since","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2c-unused.jsonl","original_id":"process::package.json::never-executes-learning-since","category":"process","severity":"S3","type":"process-gap","file":"package.json","line":39,"title":"Never executes: npm script learning:since","description":"Script defined but only referenced in archived plan. Not called in any active workflow or automation.","recommendation":"Remove script from package.json","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::package.json::never-executes-config-validate","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2c-unused.jsonl","original_id":"process::package.json::never-executes-config-validate","category":"process","severity":"S3","type":"process-gap","file":"package.json","line":52,"title":"Never executes: npm script config:validate","description":"Inline script to validate JSON config files. Mentioned in DEVELOPMENT.md but never called in CI, pre-commit, or pre-push hooks. Manual-only scripts reduce reliability.","recommendation":"Add to pre-commit hook when scripts/config/*.json files are modified, or remove if configs are stable","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::package.json::never-executes-session-summary","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2c-unused.jsonl","original_id":"process::package.json::never-executes-session-summary","category":"process","severity":"S3","type":"process-gap","file":"package.json","line":41,"title":"Never executes: npm script session:summary","description":"Script passes --summary flag to log-session-activity.js but is only documented, never automated. Manual-only logging reduces effectiveness.","recommendation":"Remove script or add to session-end skill/workflow","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::package.json::never-executes-override-list","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2c-unused.jsonl","original_id":"process::package.json::never-executes-override-list","category":"process","severity":"S3","type":"process-gap","file":"package.json","line":43,"title":"Never executes: npm script override:list","description":"Lists overrides logged by log-override.js but never called in automation. Only manual execution means oversight data is not reviewed systematically.","recommendation":"Remove script or add to weekly/monthly automated review process","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/backlog-enforcement.yml::never-executes-master-branch","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2c-unused.jsonl","original_id":"process::.github/workflows/backlog-enforcement.yml::never-executes-master-branch","category":"process","severity":"S3","type":"process-gap","file":".github/workflows/backlog-enforcement.yml","line":5,"title":"Never executes: GitHub workflow master branch trigger","description":"Workflow configured to trigger on [main, master] but repo only has 'main' branch. The 'master' condition never fires, cluttering the trigger configuration.","recommendation":"Remove 'master' from branches array, keep only 'main'","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/validate-plan.yml::never-executes-validate-plan","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2c-unused.jsonl","original_id":"process::.github/workflows/validate-plan.yml::never-executes-validate-plan","category":"process","severity":"S2","type":"process-gap","file":".github/workflows/validate-plan.yml","line":7,"title":"Never executes: validate-plan workflow for archived file","description":"Workflow triggers only when docs/archive/completed-plans/INTEGRATED_IMPROVEMENT_PLAN.md changes. This file is archived and unlikely to be modified, making the entire workflow dormant.","recommendation":"Archive/disable workflow or expand paths to include active plan documents","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.husky/pre-commit::eslint-duplication","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2b-duplications.jsonl","original_id":"process::.husky/pre-commit::eslint-duplication","category":"process","severity":"S2","type":"process-gap","file":".husky/pre-commit","line":9,"title":"Duplicated: ESLint validation in pre-commit AND CI","description":"Running ESLint in both pre-commit and CI is redundant - pre-commit already blocks commits with errors, so CI check adds no value but doubles execution time","recommendation":"Keep ESLint blocking in pre-commit, make CI check non-blocking or remove it entirely. CI should only catch cases where pre-commit was bypassed","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.husky/pre-commit::pattern-check-duplication","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2b-duplications.jsonl","original_id":"process::.husky/pre-commit::pattern-check-duplication","category":"process","severity":"S2","type":"process-gap","file":".husky/pre-commit","line":35,"title":"Duplicated: Pattern compliance check in pre-commit AND CI","description":"Pattern compliance runs in pre-commit (blocking all files) and CI (PR changed files only). This creates inconsistent behavior and wastes CI resources","recommendation":"Decide single source: either pre-commit blocks all or CI blocks changed files. Remove the other. Current setup means pre-commit catches issues CI might miss","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.husky/pre-commit::debt-validation-duplication","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2b-duplications.jsonl","original_id":"process::.husky/pre-commit::debt-validation-duplication","category":"process","severity":"S2","type":"process-gap","file":".husky/pre-commit","line":248,"title":"Duplicated: Technical debt schema validation in pre-commit AND CI","description":"Tech debt schema validation runs in both pre-commit (blocking when MASTER_DEBT.jsonl staged) and CI. Double validation on same file wastes resources","recommendation":"Keep pre-commit validation (faster feedback). Make CI check non-blocking or remove it","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.husky/pre-commit::canon-validation-duplication","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2b-duplications.jsonl","original_id":"process::.husky/pre-commit::canon-validation-duplication","category":"process","severity":"S2","type":"process-gap","file":".husky/pre-commit","line":97,"title":"Duplicated: CANON schema validation in pre-commit AND CI","description":"CANON validation runs in pre-commit (non-blocking warning) and CI (blocking). Inconsistent - same validation with different severity in two places","recommendation":"Unify validation behavior. Either pre-commit blocks or CI blocks, not both. Current state: pre-commit warns, CI blocks - confusing","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.husky/pre-commit::test-duplication","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2b-duplications.jsonl","original_id":"process::.husky/pre-commit::test-duplication","category":"process","severity":"S1","type":"process-gap","file":".husky/pre-commit","line":59,"title":"Duplicated: Test execution in pre-commit AND CI","description":"Tests run in pre-commit (conditionally blocking) AND CI (always blocking). For config changes, tests run twice. Adds 30-60s to commit+push workflow","recommendation":"Pre-commit: quick smoke tests only for high-risk changes. CI: full test suite. Or skip pre-commit tests entirely, rely on CI","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":".husky/pre-commit:59"},{"type":"description","detail":"Tests run in pre-commit (conditionally blocking) AND CI (always blocking). For config changes, tests run twice. Adds 30-60s to commit+push workflow"}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks::path-validation-duplication","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2b-duplications.jsonl","original_id":"process::.claude/hooks::path-validation-duplication","category":"process","severity":"S1","type":"process-gap","file":".claude/hooks/check-edit-requirements.js","line":18,"title":"Duplicated: Path validation logic across 16+ hooks","description":"16+ hooks duplicate identical path validation (security checks, traversal prevention, normalization). Total ~800 lines. Shared utility exists but unused. Bug fixes must be applied 16+ times","recommendation":"All hooks import and use validateFilePath() from scripts/lib/validate-paths.js. Delete inline duplicates","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":".claude/hooks/check-edit-requirements.js:18"},{"type":"description","detail":"16+ hooks duplicate identical path validation (security checks, traversal prevention, normalization). Total ~800 lines. Shared utility exists but unused. Bug fixes must be applied 16+ times"}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks::file-reading-duplication","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2b-duplications.jsonl","original_id":"process::.claude/hooks::file-reading-duplication","category":"process","severity":"S2","type":"process-gap","file":".claude/hooks/firestore-write-block.js","line":114,"title":"Duplicated: File reading logic across 5 hooks","description":"5 hooks duplicate identical file reading logic: check if content provided, resolve path, readFileSync with error handling. ~50 lines duplicated","recommendation":"Create shared utility readFileForHook(filePath, projectDir) in scripts/lib/validate-paths.js. All hooks use it","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts::error-handling-duplication","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2b-duplications.jsonl","original_id":"process::scripts::error-handling-duplication","category":"process","severity":"S1","type":"process-gap","file":"scripts/check-pattern-compliance.js","line":40,"title":"Duplicated: Error message extraction pattern across 42+ files","description":"Pattern 'err instanceof Error ? err.message : String(err)' appears in 42+ files. Shared sanitizeError() utility exists but unused. Inconsistent error handling","recommendation":"All scripts import and use sanitizeError() from scripts/lib/sanitize-error.js. Replace inline pattern","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":"scripts/check-pattern-compliance.js:40"},{"type":"description","detail":"Pattern 'err instanceof Error ? err.message : String(err)' appears in 42+ files. Shared sanitizeError() utility exists but unused. Inconsistent error handling"}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts::tty-color-duplication","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2b-duplications.jsonl","original_id":"process::scripts::tty-color-duplication","category":"process","severity":"S3","type":"process-gap","file":"scripts/check-doc-headers.js","line":48,"title":"Duplicated: TTY-aware color code across 3+ scripts","description":"TTY color detection and color object creation duplicated across scripts. ~15 lines each. Inconsistent color usage","recommendation":"Create shared getColors() utility in scripts/lib/ that returns color object. All scripts import it","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks::security-validation-duplication","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2b-duplications.jsonl","original_id":"process::.claude/hooks::security-validation-duplication","category":"process","severity":"S2","type":"process-gap","file":".claude/hooks/check-edit-requirements.js","line":40,"title":"Duplicated: Security validations across all hooks","description":"All hooks duplicate identical security validations: startsWith('-') check, multiline rejection, backslash normalization, absolute path blocking, traversal detection. Already covered by validateFilePath() but duplicated inline","recommendation":"Use validateFilePath() from validate-paths.js which includes all security checks. Delete inline duplicates","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts::git-staged-duplication","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2b-duplications.jsonl","original_id":"process::scripts::git-staged-duplication","category":"process","severity":"S3","type":"process-gap","file":"scripts/check-cross-doc-deps.js","line":83,"title":"Duplicated: Git staged files retrieval across scripts","description":"Multiple scripts duplicate git diff --cached --name-only logic with error handling. ~15 lines each","recommendation":"Create shared getStagedFiles() utility in scripts/lib/. All scripts import it","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts::config-loading-duplication","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2b-duplications.jsonl","original_id":"process::scripts::config-loading-duplication","category":"process","severity":"S3","type":"process-gap","file":"scripts/check-pattern-compliance.js","line":34,"title":"Duplicated: Config loading pattern across 17+ files","description":"17+ files duplicate loadConfig/loadConfigWithRegex pattern with try-catch and error message extraction. ~10 lines each. Shared utility exists but usage is inconsistent","recommendation":"Create loadConfigSafe() wrapper that handles try-catch internally. All scripts use one-liner: const config = loadConfigSafe('name')","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks::basedir-resolution-duplication","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2b-duplications.jsonl","original_id":"process::.claude/hooks::basedir-resolution-duplication","category":"process","severity":"S2","type":"process-gap","file":".claude/hooks/check-edit-requirements.js","line":18,"title":"Duplicated: Base directory resolution across hooks","description":"All hooks duplicate baseDir resolution: path.resolve(process.env.CLAUDE_PROJECT_DIR || process.cwd()) plus security validation. ~10 lines each across 16+ hooks","recommendation":"Create getProjectDir() utility in validate-paths.js that returns validated project directory. All hooks use it","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks::json-parsing-duplication","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2b-duplications.jsonl","original_id":"process::.claude/hooks::json-parsing-duplication","category":"process","severity":"S3","type":"process-gap","file":".claude/hooks/check-edit-requirements.js","line":20,"title":"Duplicated: JSON argument parsing across hooks","description":"All hooks duplicate JSON argument parsing: try parse, extract file_path/content, handle errors. ~15 lines each across 16+ hooks","recommendation":"Create parseHookArgs(arg) utility that returns {filePath, content, error}. All hooks use it","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks::extension-check-duplication","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2b-duplications.jsonl","original_id":"process::.claude/hooks::extension-check-duplication","category":"process","severity":"S3","type":"process-gap","file":".claude/hooks/firestore-write-block.js","line":102,"title":"Duplicated: File extension checks across hooks","description":"Multiple hooks check file extensions with regex patterns. While patterns differ, the approach is duplicated","recommendation":"Create utility hasExtension(filePath, extensions) that accepts array of extensions. Standardize extension checking","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks::allowed-paths-duplication","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2b-duplications.jsonl","original_id":"process::.claude/hooks::allowed-paths-duplication","category":"process","severity":"S2","type":"process-gap","file":".claude/hooks/firestore-write-block.js","line":30,"title":"Duplicated: ALLOWED_PATHS pattern matching across hooks","description":"Multiple hooks define ALLOWED_PATHS arrays and test with .some(pattern.test). Pattern is identical but lists differ. Hard to maintain consistency","recommendation":"Centralize path exemption rules in config file. Create isPathExempt(filePath, ruleSet) utility that loads from config","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.claude/hooks::edit-write-requirements-duplication","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2b-duplications.jsonl","original_id":"process::.claude/hooks::edit-write-requirements-duplication","category":"process","severity":"S1","type":"process-gap","file":".claude/hooks/check-edit-requirements.js","line":1,"title":"Duplicated: check-edit-requirements and check-write-requirements logic","description":"These two hooks are 95% identical. Same path validation (lines 18-63), same security checks, same file type detection. Only difference: priority order and specific messages. ~200 lines duplicated","recommendation":"Merge into single check-file-requirements.js that handles both Edit and Write. Pass operation type as parameter","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":".claude/hooks/check-edit-requirements.js:1"},{"type":"description","detail":"These two hooks are 95% identical. Same path validation (lines 18-63), same security checks, same file type detection. Only difference: priority order and specific messages. ~200 lines duplicated"}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::patterns::check-implementation-duplication","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2b-duplications.jsonl","original_id":"process::patterns::check-implementation-duplication","category":"process","severity":"S2","type":"process-gap","file":".claude/hooks/pattern-check.js","line":1,"title":"Duplicated: Pattern check implementation between hook and script","description":"Hook invokes script but also duplicates path validation, file size checks, and output formatting. Hook should be thin wrapper, not duplicate logic","recommendation":"Hook should only validate input and delegate to script. Remove duplicated validation logic from hook","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::validation::audit-schema-duplication","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2b-duplications.jsonl","original_id":"process::validation::audit-schema-duplication","category":"process","severity":"S2","type":"process-gap","file":"scripts/validate-audit.js","line":1,"title":"Duplicated: Validation between validate-audit.js and validate-schema.js","description":"Both validators load schema from config, validate JSONL structure, check required fields. Core validation logic is similar but implemented twice","recommendation":"Extract shared validateJsonlSchema(file, schemaConfig) utility. Both validators use it with different schema configs","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/seed-commit-log.js::orphaned","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2a-orphans.jsonl","original_id":"process::scripts/seed-commit-log.js::orphaned","category":"process","severity":"S2","type":"process-gap","file":"scripts/seed-commit-log.js","line":1,"title":"Orphaned: seed-commit-log.js","description":"Orphaned development/testing script increases maintenance burden without providing value","recommendation":"Remove if no longer needed, or document intended testing workflow","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/sync-claude-settings.js::orphaned","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2a-orphans.jsonl","original_id":"process::scripts/sync-claude-settings.js::orphaned","category":"process","severity":"S2","type":"process-gap","file":"scripts/sync-claude-settings.js","line":1,"title":"Orphaned: sync-claude-settings.js","description":"Orphaned setup/config script with no references in automation or documentation","recommendation":"Remove if obsolete, or document setup workflow that requires it","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/update-legacy-lines.js::orphaned","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2a-orphans.jsonl","original_id":"process::scripts/update-legacy-lines.js::orphaned","category":"process","severity":"S2","type":"process-gap","file":"scripts/update-legacy-lines.js","line":1,"title":"Orphaned: update-legacy-lines.js","description":"Code modernization script with no references - likely completed its purpose","recommendation":"Remove if migration is complete, or schedule remaining work","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/create-canonical-findings.js::orphaned","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2a-orphans.jsonl","original_id":"process::scripts/create-canonical-findings.js::orphaned","category":"process","severity":"S2","type":"process-gap","file":"scripts/create-canonical-findings.js","line":1,"title":"Orphaned: create-canonical-findings.js","description":"Listed as called by 'audit consolidation workflows' but no workflow actually calls it","recommendation":"Remove if obsolete, or integrate into actual workflow if needed","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/generate-detailed-sonar-report.js::orphaned","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2a-orphans.jsonl","original_id":"process::scripts/generate-detailed-sonar-report.js::orphaned","category":"process","severity":"S2","type":"process-gap","file":"scripts/generate-detailed-sonar-report.js","line":1,"title":"Orphaned: generate-detailed-sonar-report.js","description":"SonarCloud workflow exists but doesn't call this script - orphaned reporting tool","recommendation":"Remove if unused, or integrate into sonarcloud.yml if reports are needed","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/generate-placement-report.js::orphaned","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2a-orphans.jsonl","original_id":"process::scripts/generate-placement-report.js::orphaned","category":"process","severity":"S2","type":"process-gap","file":"scripts/generate-placement-report.js","line":1,"title":"Orphaned: generate-placement-report.js","description":"Listed as called by 'documentation workflows' but no workflow uses it","recommendation":"Remove if check-doc-placement.js supersedes it, or integrate if needed","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/migrate-existing-findings.js::orphaned","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2a-orphans.jsonl","original_id":"process::scripts/migrate-existing-findings.js::orphaned","category":"process","severity":"S2","type":"process-gap","file":"scripts/migrate-existing-findings.js","line":1,"title":"Orphaned: migrate-existing-findings.js","description":"One-time migration script no longer needed - technical debt","recommendation":"Remove after confirming migration is complete and stable","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/regenerate-findings-index.js::orphaned","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2a-orphans.jsonl","original_id":"process::scripts/regenerate-findings-index.js::orphaned","category":"process","severity":"S2","type":"process-gap","file":"scripts/regenerate-findings-index.js","line":1,"title":"Orphaned: regenerate-findings-index.js","description":"No references found in any workflow, skill, or npm script","recommendation":"Remove if aggregate-audit-findings.js handles this, or integrate if needed","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/verify-sonar-phase.js::orphaned","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2a-orphans.jsonl","original_id":"process::scripts/verify-sonar-phase.js::orphaned","category":"process","severity":"S2","type":"process-gap","file":"scripts/verify-sonar-phase.js","line":1,"title":"Orphaned: verify-sonar-phase.js","description":"Listed for SonarCloud workflows but sonarcloud.yml doesn't call it","recommendation":"Remove if SonarCloud integration doesn't need phase verification, or integrate if needed","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/auto-label-review-tier.yml::orphaned-script","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2a-orphans.jsonl","original_id":"process::.github/workflows/auto-label-review-tier.yml::orphaned-script","category":"process","severity":"S1","type":"process-gap","file":".github/workflows/auto-label-review-tier.yml","line":56,"title":"Orphaned: assign-review-tier.js disabled in workflow","description":"Script is commented out in auto-label-review-tier.yml with duplicate logic inline - creates confusion and maintenance burden","recommendation":"Either integrate assign-review-tier.js or remove it and keep inline logic","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":".github/workflows/auto-label-review-tier.yml:56"},{"type":"description","detail":"Script is commented out in auto-label-review-tier.yml with duplicate logic inline - creates confusion and maintenance burden"}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/*.ts::orphaned-migrations","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2a-orphans.jsonl","original_id":"process::scripts/*.ts::orphaned-migrations","category":"process","severity":"S2","type":"process-gap","file":"scripts/dedupe-quotes.ts","line":1,"title":"Orphaned: TypeScript migration scripts (14 files)","description":"14 TypeScript database seeding/migration scripts are not called by any automation - likely one-time use completed","recommendation":"Move to scripts/archive/ or scripts/migrations-archive/ to preserve history without clutter","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::package.json::npm-script-learning-category","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2a-orphans.jsonl","original_id":"process::package.json::npm-script-learning-category","category":"process","severity":"S2","type":"process-gap","file":"package.json","line":38,"title":"Orphaned npm script: learning:category","description":"npm script exists but is not documented, called by any workflow, or referenced in skills","recommendation":"Remove if experimental, or document purpose and integrate into learning workflow","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::package.json::npm-script-learning-since","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2a-orphans.jsonl","original_id":"process::package.json::npm-script-learning-since","category":"process","severity":"S2","type":"process-gap","file":"package.json","line":39,"title":"Orphaned npm script: learning:since","description":"npm script exists but is not documented, called by any workflow, or referenced in skills","recommendation":"Remove if experimental, or document purpose and integrate into learning workflow","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::package.json::npm-script-phase-complete-auto","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2a-orphans.jsonl","original_id":"process::package.json::npm-script-phase-complete-auto","category":"process","severity":"S2","type":"process-gap","file":"package.json","line":23,"title":"Orphaned npm script: phase:complete:auto","description":"npm script with --auto flag never called by workflows or skills - unclear purpose","recommendation":"Remove if not needed, or integrate into phase completion workflow","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/backlog-enforcement.yml::obsolete-file-check","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2a-orphans.jsonl","original_id":"process::.github/workflows/backlog-enforcement.yml::obsolete-file-check","category":"process","severity":"S1","type":"process-gap","file":".github/workflows/backlog-enforcement.yml","line":32,"title":"Obsolete: backlog-enforcement.yml checks deleted file","description":"Workflow checks AUDIT_FINDINGS_BACKLOG.md which was archived in TDMS Phase 2 (2026-01-31) - workflow gracefully skips but wastes CI resources","recommendation":"Remove backlog-health job or update to check docs/technical-debt/MASTER_DEBT.jsonl instead","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[{"type":"code_reference","detail":".github/workflows/backlog-enforcement.yml:32"},{"type":"description","detail":"Workflow checks AUDIT_FINDINGS_BACKLOG.md which was archived in TDMS Phase 2 (2026-01-31) - workflow gracefully skips but wastes CI resources"}],"sources":[],"merged_from":[]}
{"source_id":"audit:process::.github/workflows/validate-plan.yml::narrow-trigger","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2a-orphans.jsonl","original_id":"process::.github/workflows/validate-plan.yml::narrow-trigger","category":"process","severity":"S2","type":"process-gap","file":".github/workflows/validate-plan.yml","line":6,"title":"Narrow trigger: validate-plan.yml for specific archived file","description":"Workflow only triggers on PR changes to docs/archive/completed-plans/INTEGRATED_IMPROVEMENT_PLAN.md - extremely specific path unlikely to be modified","recommendation":"Broaden to any completed-plans/*.md or remove if INTEGRATED_IMPROVEMENT_PLAN is fully archived","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:process::scripts/manual-only::documentation-gap","source_file":"docs\\audits\\single-session\\process\\audit-2026-02-09\\stage-2a-orphans.jsonl","original_id":"process::scripts/manual-only::documentation-gap","category":"process","severity":"S3","type":"process-gap","file":"scripts/ai-review.js","line":1,"title":"Manual-only scripts not in automation","description":"ai-review.js and add-false-positive.js are manual command-line tools not in automation - need documentation of when to use them","recommendation":"Add to DEVELOPMENT.md under 'Manual Scripts' section with usage examples","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U0tJTEwubWQg","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-kimik2.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-ai-optimization/SKILL.md","line":0,"title":"SKILL.md file exceeds 500 lines with duplicated boilerplate","description":"The audit-ai-optimization SKILL.md is 632 lines (21.8KB), containing extensive duplicated boilerplate across sections. This wastes ~200 tokens per skill invocation and increases context window pressure. Similar patterns exist across 10+ audit skills.","recommendation":"Extract common sections (CRITICAL RETURN PROTOCOL, Persistence Rules, Stage templates) into a shared base file referenced by all audit skills. Target: reduce to <300 lines per skill.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["File size: 632 lines (470 loc) · 21.8 KB","Duplicated 'CRITICAL: Persistence Rules' section","Duplicated 'CRITICAL RETURN PROTOCOL' section","Stage template patterns repeated verbatim"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U2tpbGxzIHJl","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-kimik2.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/session-begin/","line":0,"title":"Skills read entire large files when only headers/sections needed","description":"Skills appear to load full SKILL.md files (600+ lines) into context when only specific sections are needed for a given task. This wastes hundreds of tokens per skill invocation.","recommendation":"Implement section-based loading with markers (<!-- SECTION:quickref -->), read only required sections based on task parameters.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["SKILL.md files average 400-600 lines","No section markers visible in audit-ai-optimization/SKILL.md","Progressive disclosure tiers mentioned but not enforced"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-MTAgYXVkaXQg","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-kimik2.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-code/SKILL.md","line":0,"title":"10 audit skills share >50% identical structure without shared base","description":"All 9 audit skills follow identical 3-stage parallel agent pattern with duplicated CRITICAL sections, persistence rules, and return protocols. This is maintenance overhead and bloats the skill index.","recommendation":"Create base audit skill template with common sections, use skill parameters to specify audit domain. Consolidate into /audit --domain=code|documentation|performance|security.","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["SKILL_INDEX.md shows 9 separate audit skills","All audit skills have 'Stage 1/2/3' structure","All contain identical 'CRITICAL RETURN PROTOCOL' section"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-RmlsZXN5c3Rl","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-kimik2.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".mcp.json","line":0,"title":"Filesystem MCP server configured but noted as unused","description":"The filesystem MCP server is configured but has an explicit note stating it 'duplicates native Read/Write/Glob tools' and is 'disabled since no skills reference mcp__filesystem__ tools'. This is dead configuration.","recommendation":"Remove the filesystem MCP server entry from .mcp.json since it's explicitly noted as unused and duplicates native capabilities.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["'_note': 'filesystem MCP duplicates native Read/Write/Glob tools — disabled since no skills reference mcp__filesystem__ tools'","Server still configured with command/args despite being 'disabled'"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U3RhdGUgSlNP","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-kimik2.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/state/reviews.jsonl","line":0,"title":"State JSONL files growing without bounds - reviews.jsonl is 18.6KB","description":"reviews.jsonl is 18.6KB with 31 lines and growing with each PR. Without rotation or compaction, these files will exceed 100KB quickly, slowing down hook operations that read them.","recommendation":"Implement log rotation in compaction-handoff.js - archive entries older than 30 days to .claude/state/archive/, keep only last 50 entries in active file.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["reviews.jsonl: 31 lines · 18.6 KB","Last commit shows daily updates to state files","No rotation logic visible in compaction-handoff.js filename"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-SG9va3MgdXNl","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-kimik2.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/state-utils.js","line":0,"title":"Hooks use string manipulation where JSON.parse should be used","description":"Based on commit messages referencing 'fragile parsing patterns' and file names like 'state-utils.js', hooks likely use manual string splitting for JSONL/state file parsing instead of proper JSON.parse, risking corruption on edge cases.","recommendation":"Use JSON.parse() with try/catch for all JSON/JSONL parsing, use readline module for line-by-line JSONL processing instead of split('\\n').","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["Commit: 'Fix 8 fragile parsing patterns: resilient regex across 11 files'","File: state-utils.js likely handles state parsing","File: commit-tracker.js processes JSONL logs"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-QXVkaXQgc2tp","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-kimik2.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-ai-optimization/SKILL.md","line":0,"title":"Audit skill prompts may not consistently reference FALSE_POSITIVES.jsonl","description":"The FALSE_POSITIVES.jsonl file exists with 3 entries but audit skill prompts may not explicitly instruct agents to exclude these patterns, leading to duplicate findings and wasted verification effort.","recommendation":"Add explicit instruction to all audit skill prompts: 'Check docs/technical-debt/FALSE_POSITIVES.jsonl and exclude any findings matching these patterns.'","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["FALSE_POSITIVES.jsonl exists with 3 verified false positive entries","Audit skill is 632 lines but FP reference not visible in preview","Finding DEBT-2598, DEBT-2615, DEBT-0107 are marked FALSE_POSITIVE"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U2hlbGwgc2Ny","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-kimik2.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/hooks/session-start.sh","line":0,"title":"Shell script hooks may be redundant with Node.js versions","description":"Multiple .sh files exist alongside .js versions (session-start.sh + session-start.js). Based on commit messages, the project migrated to Node.js hooks for cross-platform compatibility. Shell versions may be orphaned.","recommendation":"Verify shell scripts are not referenced in .claude/settings.json or hooks.json, then archive to .claude/hooks/archive/ if truly unused.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["session-start.sh exists alongside session-start.js","Commit: 'Cross-platform replacement for session-start.sh'","analyze-user-request.sh + analyze-user-request.js pair exists"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-RGVhZCBTY3Jp","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-jules.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":"scripts/dedupe-quotes.ts","line":0,"title":"Dead Script: dedupe-quotes.ts","description":"Unused migration script increases maintenance burden and confuses developers.","recommendation":"Delete the file.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["Script is not in package.json and not referenced in active codebase (checked via grep)"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-RGVhZCBEb2N1","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-jules.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":"docs/technical-debt/INDEX.md","line":0,"title":"Dead Documentation: technical-debt/INDEX.md","description":"Unreferenced documentation creates confusion and maintenance overhead.","recommendation":"Delete the file.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["File is not referenced by any other file in the project (excluding archive)"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-RnJhZ2lsZSBQ","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-jules.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/post-read-handler.js","line":0,"title":"Fragile Parsing: Git output parsing in post-read-handler.js","description":"Parsing git output by splitting on newline fails for filenames with newlines.","recommendation":"Use -z flag for git diff and split by NUL byte, similar to pre-compaction-save.js.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["gitExec(['diff', '--name-only']).split('\\n') in gatherGitContext"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Rm9ybWF0IFdh","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-jules.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/hooks/session-start.js","line":0,"title":"Format Waste: Verbose session-start output","description":"Verbose output wastes tokens in every session start.","recommendation":"Reduce console.log calls, only show warnings or errors.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["Multiple console.log calls for status updates ('Checking...', 'Skipping...')"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-SG9vayBMYXRl","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-jules.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S1","type":"code-smell","file":".claude/hooks/session-start.js","line":0,"title":"Hook Latency: Unconditional test build","description":"Running 'npm run test:build' on every session start adds significant latency.","recommendation":"Run test build only if source files changed or on demand.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["runCommand('Building test files', 'npm run test:build', 60000) is unconditional"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U3VicHJvY2Vz","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-jules.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/session-start.js","line":0,"title":"Subprocess Overhead: Node spawning in hooks","description":"Spawning new Node processes consumes memory and time.","recommendation":"Require and call script functions directly where possible (e.g. check-pattern-compliance.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["execSync('node scripts/check-pattern-compliance.js', ...)"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U2tpbGwgT3Zl","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-jules.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-code/SKILL.md","line":0,"title":"Skill Overlap: audit-code vs code-reviewer","description":"Two skills perform nearly identical code quality checks, leading to confusion and maintenance drift.","recommendation":"Consolidate into a single 'code-quality' skill with modes (audit vs review) or distinct tasks.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["Both skills check Typescript, React, Firebase, Security patterns with significant content overlap"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-QUkgSW5zdHJ1","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-jules.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-code/SKILL.md","line":0,"title":"AI Instruction Bloat: audit-code SKILL.md","description":"Skill file is 370 lines long, duplicating process documentation.","recommendation":"Move process documentation to a separate doc file and reference it in the skill.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["Contains full 'Pre-Audit Validation', 'Audit Execution', 'Output Requirements' sections"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-TUNQIENvbmZp","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-jules.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".mcp.json","line":0,"title":"MCP Config Efficiency: Unused filesystem server","description":"Unused MCP server adds overhead and potential confusion.","recommendation":"Remove the filesystem server configuration.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["filesystem server is present but marked as disabled/unused in _note"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Q29udGV4dCBP","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-jules.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-code/SKILL.md","line":0,"title":"Context Optimization: Heavy episodic memory search","description":"Mandatory episodic memory search for generic terms ('code audit') loads potentially large/irrelevant context.","recommendation":"Refine search queries or make them conditional.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["memory__search({ query: ['code audit', 'patterns', 'quality'], limit: 5 })"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Q09NTUFORF9S","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-copilot.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S1","type":"code-smell","file":".claude/COMMAND_REFERENCE.md","line":0,"title":"COMMAND_REFERENCE.md is 109KB — loaded on demand but risks massive token cost if read","description":"At 109KB, this single file consumes ~27,000 tokens if read in full. Any skill or session flow that reads this file injects massive context. It duplicates information already present in individual SKILL.md files and HOOKS.md.","recommendation":"Split into focused reference files (commands-ref.md, agents-ref.md, hooks-ref.md) under 10KB each, or create a lightweight index that links to sections on demand.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[".claude/COMMAND_REFERENCE.md has size 108,954 bytes","Content duplicates slash command, agent, skill, hook, and MCP docs that each have their own files"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U2hlbGwgaG9v","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-copilot.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/session-start.sh","line":0,"title":"Shell hooks (.sh) are dead code — replaced by .js equivalents but still present","description":"settings.json references only .js versions (session-start.js, check-mcp-servers.js, post-write-validator.js, pattern-check.js). The .sh scripts are not invoked by any hook, CI workflow, or npm script. They add ~35KB of dead code that confuses audits and inflates the hooks directory.","recommendation":"Delete the 5 .sh files after verifying no other script references them. The .js equivalents are already the active versions.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["settings.json hooks reference: session-start.js, check-mcp-servers.js, post-write-validator.js","check-edit-requirements.sh and check-write-requirements.sh are not referenced in settings.json at all","session-start.sh comments say 'Cross-platform replacement for session-start.sh' in session-start.js"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-c2Vzc2lvbi1z","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-copilot.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S1","type":"code-smell","file":".claude/hooks/session-start.js","line":0,"title":"session-start.js uses execSync with shell:true — subprocess overhead + injection risk","description":"session-start.js runs on every session start and uses execSync with {shell: true} for npm ci, npm run build, and version checks (lines 49, 55, 306-311). This spawns a shell subprocess for each command, adding latency and introducing shell injection risk. The hook itself warns about exec injection patterns in post-write-validator.js.","recommendation":"Replace execSync({shell:true}) with execFileSync('npm', ['ci', ...], {shell:false}) for npm commands. Use execFileSync('node', ['-v']) for version checks.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["Line 18: const { execSync } = require('node:child_process')","Line 306-311: execSync(command, { shell: true, timeout: timeoutMs })","Lines 49, 55: execSync('node -v'), execSync('npm -v')"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-c3RvcC1zZXJl","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-copilot.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/stop-serena-dashboard.js","line":0,"title":"stop-serena-dashboard.js uses 6+ execFileSync calls at session start — port check may be unnecessary","description":"This hook runs on every SessionStart and spawns multiple synchronous child processes (lsof, ps, kill) to stop a Serena dashboard that may not be running. In remote Claude Code environments, Serena is unlikely to be active. The hook is 250+ lines of security-hardened process termination code that executes unconditionally.","recommendation":"Add a fast-path check: if port 24282 is not listening, exit immediately with zero subprocess spawns. Or make this hook conditional on a local-only environment flag.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["settings.json line 28-32: stop-serena-dashboard.js runs on every SessionStart","Hook uses execFileSync for: lsof, ps (multiple calls), kill/SIGTERM","Already has continueOnError: true suggesting it's non-essential"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Y2hlY2stZWRp","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-copilot.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/check-edit-requirements.sh","line":0,"title":"check-edit-requirements.sh and check-write-requirements.sh share ~90% identical code","description":"These two shell scripts have nearly identical input validation, path sanitization, security keyword matching, and file type classification. They differ only in the specific post-task messages. This duplication means bugs must be fixed in two places. However, these are also dead .sh files (see dead shell hooks finding), so this is only relevant if the .sh files are kept.","recommendation":"Since .js replacements exist (post-write-validator.js handles Write/Edit/MultiEdit), simply delete both .sh files. If .sh files need to stay, merge into a single parameterized script.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["check-edit-requirements.sh lines 1-75 are structurally identical to check-write-requirements.sh lines 1-76","Both have identical path traversal rejection, sanitization, and security keyword regex","settings.json uses post-write-validator.js for all Write/Edit/MultiEdit operations"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-cG9zdC13cml0","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-copilot.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/post-write-validator.js","line":0,"title":"post-write-validator.js and pattern-check.js share identical INLINE_PATTERNS arrays","description":"Both hooks contain identical INLINE_PATTERNS arrays (~70 lines each) with the same regex patterns for clickable div, test-mock-firestore, SQL injection, and shell injection detection. The checkInlinePatterns function is also duplicated. Any pattern update must be made in both files or they drift.","recommendation":"Extract INLINE_PATTERNS and checkInlinePatterns into a shared module (e.g., .claude/hooks/lib/inline-patterns.js) and import from both hooks.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["post-write-validator.js lines 480-540: identical patterns to pattern-check.js lines 91-158","checkInlinePatterns function logic is duplicated in both files","Both contain sql-injection-risk, shell-command-injection, test-mock-firestore-directly patterns"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-TXVsdGlwbGUg","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-copilot.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/post-read-handler.js","line":0,"title":"Multiple hooks contain duplicated gitExec helper function","description":"At least 5 hooks define their own gitExec() function with identical logic: execFileSync('git', args, {cwd, encoding, timeout}). This is ~10 lines duplicated 5 times. The state-utils.js shared module pattern already exists but doesn't include git utilities.","recommendation":"Add a gitExec function to .claude/hooks/lib/ (either state-utils.js or a new git-utils.js) and import it from all hooks.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["post-read-handler.js: function gitExec(args) { try { return execFileSync('git', args, {cwd: projectDir ...})","pre-compaction-save.js: function gitExec(args) { try { return execFileSync('git', args, {cwd: projectDir ...})","compaction-handoff.js, commit-tracker.js, check-remote-session-context.js all have equivalent functions"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U2NyaXB0cyBu","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-copilot.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":"scripts/add-false-positive.js","line":0,"title":"Scripts not in package.json: add-false-positive.js, assign-review-tier.js, seed-commit-log.js, sync-claude-settings.js — potentially dead","description":"These scripts exist in scripts/ but have no entry in package.json scripts section. They may be called by skills, hooks, or used manually, but without a package.json entry they're harder to discover and may be truly dead code. enrichment_failures.json (6KB) appears to be output data committed to the repo.","recommendation":"Verify each script's usage: check if any SKILL.md, hook, or CI workflow references them. If unused, delete. If used, add to package.json for discoverability. Move enrichment_failures.json to .gitignore if it's generated output.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["package.json scripts section has 90 entries but none reference add-false-positive.js, assign-review-tier.js, seed-commit-log.js, or sync-claude-settings.js","scripts/enrichment_failures.json is a 6KB data file in the scripts directory","sync-claude-settings.js IS referenced in CROSS_PLATFORM_SETUP.md and HOOKS.md docs"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-aG9vay13YXJu","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-copilot.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/state/hook-warnings-log.jsonl","line":0,"title":"hook-warnings-log.jsonl has repetitive low-value entries — no rotation","description":"hook-warnings-log.jsonl grows unbounded with 15 nearly identical entries visible ('WARNING TRIGGERS (recommended actions):' repeated with only timestamps differing). Over time this file will grow indefinitely, consuming storage and making log analysis harder. The same trigger fires on every push without new information.","recommendation":"Add log rotation: keep only the last 100 entries (or last 7 days). Deduplicate consecutive identical messages (store count instead of repeating).","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[".claude/state/hook-warnings-log.jsonl: 15 entries visible, 14 are identical 'WARNING TRIGGERS' messages","Each entry is ~170 bytes, growing without bounds","No rotation logic found in any hook or script"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-TUNQIHNlcnZl","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-copilot.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/settings.json","line":0,"title":"MCP servers configured but 4 are disabled — disabled list should match actual config","description":"settings.json disables 4 MCP servers (rube, serena, nextjs-devtools, filesystem) but mcp.global-template.json only defines 2 servers (ccusage, playwright). The disabled servers reference names that don't appear in the template, suggesting stale configuration from removed MCP servers.","recommendation":"Remove disabled server names that no longer exist in any MCP config. Document which MCP servers are intentionally disabled and why.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["settings.json line 6: disabledMcpjsonServers: [\"rube\", \"serena\", \"nextjs-devtools\", \"filesystem\"]","mcp.global-template.json only defines: ccusage, playwright","The disabled servers may be in .mcp.json (user-local file not in repo) — confidence adjusted"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U2Vzc2lvblN0","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-codex.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S1","type":"code-smell","file":".claude/hooks/session-start.js","line":0,"title":"SessionStart critical path runs multiple heavyweight synchronous tasks serially","description":"This hook is on every session start and executes dependency installs, builds, pattern checks, consolidation, and metrics checks in sequence. That design can add multi-second to multi-minute startup latency and blocks developer flow before work begins.","recommendation":"Split SessionStart into a fast path (environment sanity + minimal checks) and deferred/background tasks (functions build, test build, consolidation, debt metrics). Add a cache/TTL gate for expensive checks and skip steps unless relevant files changed.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[".claude/hooks/session-start.js:325-379 runs installs/builds in sequence via execSync wrappers.",".claude/hooks/session-start.js:383-423 adds additional synchronous pattern + consolidation commands.",".claude/hooks/session-start.js:456-485 performs extra TDMS read/parse checks on the same startup path.","Command: nl -ba .claude/hooks/session-start.js | sed -n '260,520p'"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-TGVnYWN5IHNo","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-codex.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/analyze-user-request.sh","line":0,"title":"Legacy shell hook scripts appear runtime-unused (possibly unused)","description":"Maintaining duplicate JS+SH hook implementations increases maintenance/token overhead and can confuse future edits. If shell variants are no longer executed by hook config, they become drift-prone documentation code.","recommendation":"Either remove/archive shell variants or mark them explicitly as fallback-only with a single source-of-truth policy. If kept, add automated parity tests between JS and SH behavior.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[".claude/settings.json:13,17,22,28 references only Node hook entrypoints (no .sh hook commands).",".claude/hooks/session-start.js:7 and .claude/hooks/check-mcp-servers.js:7 state they are cross-platform replacements for .sh scripts.","Command: rg -n \".claude/hooks/.*.sh\" .claude/settings.json .github/workflows package.json .husky/* returned no runtime references.","Command: for f in .claude/hooks/*.sh; do rg -n \"$(basename $f)\" .claude .github package.json scripts docs; done"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-UHJlLWNvbW1p","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-codex.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/pre-commit-fixer/SKILL.md","line":0,"title":"Pre-commit subagent Task prompt is under-specified for deterministic outputs","description":"The Task prompt asks for fixes but does not define structured output schema, required artifact paths, or strict return protocol. This can increase retries and ambiguity, wasting tokens and causing inconsistent automation behavior.","recommendation":"Add a strict subagent contract: required output JSON schema, explicit file list constraints, success/failure return block, and path-based artifact/report destinations.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[".claude/skills/pre-commit-fixer/SKILL.md:90-94 defines a free-form Task prompt with no schema or output path contract.",".claude/skills/pre-commit-fixer/SKILL.md:134-150 defines human-readable result format, but not a machine-validated schema for subagent return.","Command: rg -n \"CRITICAL RETURN PROTOCOL|JSONL schema|output file\" .claude/skills/pre-commit-fixer/SKILL.md found no protocol requirement block."],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U2Vzc2lvbi1i","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-codex.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/skills/session-begin/SKILL.md","line":0,"title":"Session-begin checklist duplicates mandatory context reads","description":"Repeated mandatory instructions (e.g., reading ROADMAP Active Sprint in multiple sections) add avoidable context and operator overhead each session. This is small per run but persistent across all sessions.","recommendation":"Deduplicate repeated checklist items into a single canonical step and reference it later by anchor instead of repeating prose.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[".claude/skills/session-begin/SKILL.md:124-126 requires reading ROADMAP Active Sprint.",".claude/skills/session-begin/SKILL.md:176-177 repeats reading ROADMAP Active Sprint.","Command: nl -ba .claude/skills/session-begin/SKILL.md | sed -n '118,182p'"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-UmVtb3RlLWJy","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-codex.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/hooks/check-remote-session-context.js","line":0,"title":"Remote-branch parsing relies on delimiter split that can break on format drift","description":"The parser assumes git branch --format will always contain exactly one | delimiter and directly splits into two fields. Minor output format changes can silently corrupt date parsing and skip useful branch comparisons.","recommendation":"Parse with a safer structured format (e.g., NUL-delimited fields via %x00) or split once with validation and explicit fallback logging.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[".claude/hooks/check-remote-session-context.js:143 uses pipe-delimited git format.",".claude/hooks/check-remote-session-context.js:151-153 uses const [branch, dateStr] = line.split(\"|\") without field-count validation.","Command: nl -ba .claude/hooks/check-remote-session-context.js | sed -n '135,156p'"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-MTMgY29uc29s","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-claude.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/agent-trigger-enforcer.js","line":0,"title":"13 consolidated-out hook JS files remain as dead standalone executables","description":"post-write-validator.js replaced 10 hooks, post-read-handler.js replaced 3 more. Originals remain as ~2000 lines of dead code.","recommendation":"Move to .claude/hooks/archive/ or delete them.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["post-write-validator.js: Replaces 10 separate hooks","post-read-handler.js: Replaces 3 separate hooks"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Q1JJVElDQUwg","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-claude.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-ai-optimization/SKILL.md","line":0,"title":"CRITICAL Persistence Rules boilerplate copy-pasted across 4+ audit SKILL.md files","description":"~50-line Persistence Rules block duplicated across 4+ files. Costs ~150 tokens per skill load.","recommendation":"Create _shared/AUDIT_PERSISTENCE_RULES.md as single canonical source.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["audit-ai-optimization/SKILL.md lines 36-57: identical boilerplate","audit-process/SKILL.md lines 32-52: identical boilerplate"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-ZG9jLW9wdGlt","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-claude.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/doc-optimizer/SKILL.md","line":0,"title":"doc-optimizer and audit-process SKILL.md exceed 1500 lines without modularization","description":"doc-optimizer (1735 lines) and audit-process (1525 lines) loaded in full, adding 3000-5000 tokens.","recommendation":"Extract per-agent prompt templates to reference/ subdirectories.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["wc -l: doc-optimizer 1735, audit-process 1525, audit-documentation 1000, multi-ai-audit 948"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-QWdlbnQgc3Vi","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-claude.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-ai-optimization/SKILL.md","line":0,"title":"Agent sub-prompts omit evidence field from output schema","description":"Audit instructions require evidence array but Task() agent schemas omit this field.","recommendation":"Add evidence field to every agent output schema.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["Agent 1A schema line 170-171: no evidence field","Agent 1B schema line 196-197: same omission"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-VGFzaygpIHN1","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-claude.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-ai-optimization/SKILL.md","line":0,"title":"Task() sub-agents dont check FALSE_POSITIVES.jsonl before reporting","description":"Orchestrator reads FALSE_POSITIVES.jsonl but Task() agents start in fresh contexts without it. Known FPs re-reported every audit.","recommendation":"Add to each agent prompt: read FALSE_POSITIVES.jsonl and exclude matching entries.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["Orchestrator reads FALSE_POSITIVES not propagated to subagents","Agent 1A prompt has zero mention of FALSE_POSITIVES.jsonl"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-ZmlsZXN5c3Rl","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-claude.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".mcp.json","line":0,"title":"filesystem MCP server configured but permanently disabled — dead config","description":"filesystem entry self-annotated as disabled and in disabledMcpjsonServers. Dead config adds cognitive overhead.","recommendation":"Remove filesystem entry from .mcp.json entirely.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[".mcp.json: filesystem with note stating disabled","settings.json: disabledMcpjsonServers includes filesystem"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-aGVhbHRoLXNj","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\raw\\ai-optimization-claude.normalized.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/state/health-score-log.jsonl","line":0,"title":"health-score-log.jsonl and hook-warnings-log.jsonl grow unboundedly — no rotation","description":"reviews.jsonl has rotation. health-score-log and hook-warnings-log have none. rotateJsonl() exists but only applied to reviews.jsonl.","recommendation":"Apply rotateJsonl() to both files in session-start.js.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["session-start.js: rotation NOT applied to other logs","health-score-log.jsonl: 8 entries growing","hook-warnings-log.jsonl: 16 entries growing"],"sources":[],"merged_from":[]}
{"source_id":"audit:CANON-0006","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0006","category":"ai-optimization","severity":"S1","type":"code-smell","file":".claude/hooks/session-start.js","line":0,"title":"session-start.js uses execSync with shell:true — subprocess overhead + injection risk","description":"session-start.js runs on every session start and uses execSync with {shell: true} for npm ci, npm run build, and version checks (lines 49, 55, 306-311). This spawns a shell subprocess for each command, adding latency and introducing shell injection risk. The hook itself warns about exec injection patterns in post-write-validator.js.","recommendation":"Replace execSync({shell:true}) with execFileSync('npm', ['ci', ...], {shell:false}) for npm commands. Use execFileSync('node', ['-v']) for version checks.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["Line 18: const { execSync } = require('node:child_process')","Line 306-311: execSync(command, { shell: true, timeout: timeoutMs })","Lines 49, 55: execSync('node -v'), execSync('npm -v')"],"sources":[{"source":"copilot","file":"ai-optimization-copilot.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/session-start.js::execsync-shell-true"}],"merged_from":[]}
{"source_id":"audit:CANON-0004","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0004","category":"ai-optimization","severity":"S1","type":"code-smell","file":".claude/settings.json","line":0,"title":"SessionStart uses stacked synchronous subprocesses across hook chain","description":"Startup latency compounds because SessionStart invokes multiple hook commands, and at least one of them (session-start.js) itself shells out repeatedly with execSync. This increases startup wait time and failure surface on every session.","recommendation":"Consolidate lightweight checks into one Node process, replace version probes (node -v, npm -v) with process.version and npm_config_user_agent where possible, and move best-effort checks to async/deferred execution.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":[".claude/settings.json:8-33 configures multiple SessionStart commands executed for each session.",".claude/hooks/session-start.js:49-56 shells out for node/npm version checks.",".claude/hooks/session-start.js:303-312 uses execSync(shell:true) for each startup command.","Command: nl -ba .claude/settings.json | sed -n '1,60p'"],"sources":[{"source":"codex","file":"ai-optimization-codex.jsonl","original_fingerprint":"ai-optimization::.claude/settings.json::sessionstart-multi-sync-hooks"}],"merged_from":[]}
{"source_id":"audit:CANON-0025","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0025","category":"ai-optimization","severity":"S2","type":"code-smell","file":"scripts/dedupe-quotes.ts","line":0,"title":"Dead Script: dedupe-quotes.ts","description":"Unused migration script increases maintenance burden and confuses developers.","recommendation":"Delete the file.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["Script is not in package.json and not referenced in active codebase (checked via grep)"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::scripts/dedupe-quotes.ts::dead-script"}],"merged_from":[]}
{"source_id":"audit:CANON-0026","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0026","category":"ai-optimization","severity":"S2","type":"code-smell","file":"scripts/enrich-addresses.ts","line":0,"title":"Dead Script: enrich-addresses.ts","description":"Unused migration script increases maintenance burden and confuses developers.","recommendation":"Delete the file.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["Script is not in package.json and not referenced in active codebase (checked via grep)"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::scripts/enrich-addresses.ts::dead-script"}],"merged_from":["ai-optimization::scripts/enrich-addresses.ts::dead-script","ai-optimization::scripts/migrate-addresses.ts::dead-script"]}
{"source_id":"audit:CANON-0027","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0027","category":"ai-optimization","severity":"S2","type":"code-smell","file":"scripts/import-nashville-links.ts","line":0,"title":"Dead Script: import-nashville-links.ts","description":"Unused migration script increases maintenance burden and confuses developers.","recommendation":"Delete the file.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["Script is not in package.json and not referenced in active codebase (checked via grep)"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::scripts/import-nashville-links.ts::dead-script"}],"merged_from":[]}
{"source_id":"audit:CANON-0028","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0028","category":"ai-optimization","severity":"S2","type":"code-smell","file":"scripts/migrate-library-content.ts","line":0,"title":"Dead Script: migrate-library-content.ts","description":"Unused migration script increases maintenance burden and confuses developers.","recommendation":"Delete the file.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["Script is not in package.json and not referenced in active codebase (checked via grep)"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::scripts/migrate-library-content.ts::dead-script"}],"merged_from":[]}
{"source_id":"audit:CANON-0029","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0029","category":"ai-optimization","severity":"S2","type":"code-smell","file":"scripts/migrate-meetings-dayindex.ts","line":0,"title":"Dead Script: migrate-meetings-dayindex.ts","description":"Unused migration script increases maintenance burden and confuses developers.","recommendation":"Delete the file.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["Script is not in package.json and not referenced in active codebase (checked via grep)"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::scripts/migrate-meetings-dayindex.ts::dead-script"}],"merged_from":[]}
{"source_id":"audit:CANON-0030","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0030","category":"ai-optimization","severity":"S2","type":"code-smell","file":"scripts/migrate-to-journal.ts","line":0,"title":"Dead Script: migrate-to-journal.ts","description":"Unused migration script increases maintenance burden and confuses developers.","recommendation":"Delete the file.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["Script is not in package.json and not referenced in active codebase (checked via grep)"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::scripts/migrate-to-journal.ts::dead-script"}],"merged_from":[]}
{"source_id":"audit:CANON-0031","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0031","category":"ai-optimization","severity":"S2","type":"code-smell","file":"scripts/seed-meetings.ts","line":0,"title":"Dead Script: seed-meetings.ts","description":"Unused migration script increases maintenance burden and confuses developers.","recommendation":"Delete the file.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["Script is not in package.json and not referenced in active codebase (checked via grep)"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::scripts/seed-meetings.ts::dead-script"}],"merged_from":[]}
{"source_id":"audit:CANON-0032","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0032","category":"ai-optimization","severity":"S2","type":"code-smell","file":"scripts/seed-real-data.ts","line":0,"title":"Dead Script: seed-real-data.ts","description":"Unused migration script increases maintenance burden and confuses developers.","recommendation":"Delete the file.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["Script is not in package.json and not referenced in active codebase (checked via grep)"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::scripts/seed-real-data.ts::dead-script"}],"merged_from":[]}
{"source_id":"audit:CANON-0033","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0033","category":"ai-optimization","severity":"S2","type":"code-smell","file":"scripts/seed-sober-living-data.ts","line":0,"title":"Dead Script: seed-sober-living-data.ts","description":"Unused migration script increases maintenance burden and confuses developers.","recommendation":"Delete the file.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["Script is not in package.json and not referenced in active codebase (checked via grep)"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::scripts/seed-sober-living-data.ts::dead-script"}],"merged_from":[]}
{"source_id":"audit:CANON-0034","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0034","category":"ai-optimization","severity":"S2","type":"code-smell","file":"scripts/set-admin-claim.ts","line":0,"title":"Dead Script: set-admin-claim.ts","description":"Unused migration script increases maintenance burden and confuses developers.","recommendation":"Delete the file.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["Script is not in package.json and not referenced in active codebase (checked via grep)"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::scripts/set-admin-claim.ts::dead-script"}],"merged_from":[]}
{"source_id":"audit:CANON-0035","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0035","category":"ai-optimization","severity":"S2","type":"code-smell","file":"scripts/sync-geocache.ts","line":0,"title":"Dead Script: sync-geocache.ts","description":"Unused migration script increases maintenance burden and confuses developers.","recommendation":"Delete the file.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["Script is not in package.json and not referenced in active codebase (checked via grep)"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::scripts/sync-geocache.ts::dead-script"}],"merged_from":[]}
{"source_id":"audit:CANON-0036","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0036","category":"ai-optimization","severity":"S2","type":"code-smell","file":"scripts/test-geocode.ts","line":0,"title":"Dead Script: test-geocode.ts","description":"Unused migration script increases maintenance burden and confuses developers.","recommendation":"Delete the file.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["Script is not in package.json and not referenced in active codebase (checked via grep)"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::scripts/test-geocode.ts::dead-script"}],"merged_from":[]}
{"source_id":"audit:CANON-0037","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0037","category":"ai-optimization","severity":"S2","type":"code-smell","file":"scripts/retry-failures.ts","line":0,"title":"Dead Script: retry-failures.ts","description":"Unused migration script increases maintenance burden and confuses developers.","recommendation":"Delete the file.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["Script is not in package.json and not referenced in active codebase (checked via grep)"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::scripts/retry-failures.ts::dead-script"}],"merged_from":[]}
{"source_id":"audit:CANON-0009","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0009","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/session-start.js","line":0,"title":"session-start.js spawns 2 unnecessary child processes for node/npm version strings","description":"Two execSync() calls for version strings with near-zero diagnostic value. process.version provides node version at zero cost.","recommendation":"Replace execSync('node -v') with process.version. Remove npm -v entirely.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["session-start.js line 49: execSync('node -v')","session-start.js line 55: execSync('npm -v')"],"sources":[{"source":"claude","file":"ai-optimization-claude.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/session-start.js::execsync-version-display-subprocess"}],"merged_from":[]}
{"source_id":"audit:CANON-0010","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0010","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/session-start.sh","line":0,"title":"session-start.sh (365 lines) is dead code — replaced by session-start.js","description":"session-start.js states it is the Cross-platform replacement. settings.json only wires session-start.js. The 365-line shell script is never invoked.","recommendation":"Delete session-start.sh.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["settings.json only lists session-start.js","session-start.js line 7: Cross-platform replacement for session-start.sh"],"sources":[{"source":"claude","file":"ai-optimization-claude.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/session-start.sh::dead-replaced-hook-script"}],"merged_from":[]}
{"source_id":"audit:CANON-0013","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0013","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/stop-serena-dashboard.js","line":0,"title":"stop-serena-dashboard.js runs every SessionStart despite Serena MCP being disabled","description":"Serena is in disabledMcpjsonServers but stop-serena-dashboard.js still runs every session checking port 24282.","recommendation":"Add early-exit reading disabledMcpjsonServers or remove from SessionStart hooks.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["settings.json: disabledMcpjsonServers includes serena","Session transcript: No process listening on port 24282"],"sources":[{"source":"claude","file":"ai-optimization-claude.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/stop-serena-dashboard.js::unnecessary-session-start-hook"}],"merged_from":[]}
{"source_id":"audit:CANON-0019","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0019","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/session-start.sh","line":0,"title":"Shell hooks (.sh) are dead code — replaced by .js equivalents but still present","description":"settings.json references only .js versions (session-start.js, check-mcp-servers.js, post-write-validator.js, pattern-check.js). The .sh scripts are not invoked by any hook, CI workflow, or npm script. They add ~35KB of dead code that confuses audits and inflates the hooks directory.","recommendation":"Delete the 5 .sh files after verifying no other script references them. The .js equivalents are already the active versions.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["settings.json hooks reference: session-start.js, check-mcp-servers.js, post-write-validator.js","check-edit-requirements.sh and check-write-requirements.sh are not referenced in settings.json at all","session-start.sh comments say 'Cross-platform replacement for session-start.sh' in session-start.js"],"sources":[{"source":"copilot","file":"ai-optimization-copilot.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/shell-hooks::dead-shell-hooks"}],"merged_from":[]}
{"source_id":"audit:CANON-0014","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0014","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-ai-optimization/SKILL.md","line":0,"title":"Agent sub-prompts omit evidence field from output schema","description":"Audit instructions require evidence array but Task() agent schemas omit this field.","recommendation":"Add evidence field to every agent output schema.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["Agent 1A schema line 170-171: no evidence field","Agent 1B schema line 196-197: same omission"],"sources":[{"source":"claude","file":"ai-optimization-claude.jsonl","original_fingerprint":"ai-optimization::.claude/skills/audit-ai-optimization/SKILL.md::agent-prompt-missing-evidence-field"}],"merged_from":[]}
{"source_id":"audit:CANON-0001","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0001","category":"ai-optimization","severity":"S1","type":"code-smell","file":".claude/hooks/session-start.js","line":0,"title":"session-start.js outputs 400-600 tokens of verbose status on every session start","description":"SessionStart hook stdout is injected into Claude context on every session. The 30+ line output costs ~400-600 tokens per session before any user work begins.","recommendation":"Condense hook output to 5-8 lines: one status line per major step only, suppress decorative borders, remove footer text.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["session-start.js lines 43-505: 30+ console.log() calls","system-reminder tag confirms full hook stdout injected into context","session-start.js line 383-396: execSync with no hash-cache guard","Hash caching exists for npm install but NOT for pattern check","Lines 43-44: emoji + separator line","Lines 47-60: environment version logging","Lines 219-235: multi-line secrets status","Lines 304-312: per-step status with emoji"],"sources":[{"source":"claude","file":"ai-optimization-claude.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/session-start.js::verbose-hook-output-token-waste"},{"source":"copilot","file":"ai-optimization-copilot.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/session-start.js::verbose-session-output"}],"merged_from":["ai-optimization::.claude/hooks/session-start.js::verbose-hook-output-token-waste","ai-optimization::.claude/hooks/session-start.js::execsync-pattern-check-subprocess","ai-optimization::.claude/hooks/session-start.js::verbose-session-output"]}
{"source_id":"audit:CANON-0003","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0003","category":"ai-optimization","severity":"S1","type":"code-smell","file":".claude/hooks/session-start.js","line":0,"title":"SessionStart critical path runs multiple heavyweight synchronous tasks serially","description":"This hook is on every session start and executes dependency installs, builds, pattern checks, consolidation, and metrics checks in sequence. That design can add multi-second to multi-minute startup latency and blocks developer flow before work begins.","recommendation":"Split SessionStart into a fast path (environment sanity + minimal checks) and deferred/background tasks (functions build, test build, consolidation, debt metrics). Add a cache/TTL gate for expensive checks and skip steps unless relevant files changed.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":[".claude/hooks/session-start.js:325-379 runs installs/builds in sequence via execSync wrappers.",".claude/hooks/session-start.js:383-423 adds additional synchronous pattern + consolidation commands.",".claude/hooks/session-start.js:456-485 performs extra TDMS read/parse checks on the same startup path.","Command: nl -ba .claude/hooks/session-start.js | sed -n '260,520p'"],"sources":[{"source":"codex","file":"ai-optimization-codex.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/session-start.js::serial-heavy-sessionstart"}],"merged_from":[]}
{"source_id":"audit:CANON-0007","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0007","category":"ai-optimization","severity":"S1","type":"code-smell","file":".claude/hooks/session-start.js","line":0,"title":"Hook Latency: Unconditional test build","description":"Running 'npm run test:build' on every session start adds significant latency.","recommendation":"Run test build only if source files changed or on demand.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["runCommand('Building test files', 'npm run test:build', 60000) is unconditional"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/session-start.js::latency-test-build"}],"merged_from":[]}
{"source_id":"audit:CANON-0002","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0002","category":"ai-optimization","severity":"S1","type":"code-smell","file":".claude/settings.json","line":0,"title":"SessionStart runs 4 sequential Node process spawns — 4-8s cold-start latency","description":"settings.json wires 4 sequential SessionStart hooks. Cold-start latency is 4-8 seconds before any user turn.","recommendation":"Merge check-mcp-servers.js and stop-serena-dashboard.js into session-start.js. Run check-remote-session-context.js asynchronously.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["settings.json hooks.SessionStart: 4 separate command entries","check-remote-session-context.js: FETCH_TTL_MS = 5 * 60 * 1000"],"sources":[{"source":"claude","file":"ai-optimization-claude.jsonl","original_fingerprint":"ai-optimization::.claude/settings.json::sequential-session-start-hooks"}],"merged_from":[]}
{"source_id":"audit:CANON-0005","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0005","category":"ai-optimization","severity":"S1","type":"code-smell","file":".claude/COMMAND_REFERENCE.md","line":0,"title":"COMMAND_REFERENCE.md is 109KB — loaded on demand but risks massive token cost if read","description":"At 109KB, this single file consumes ~27,000 tokens if read in full. Any skill or session flow that reads this file injects massive context. It duplicates information already present in individual SKILL.md files and HOOKS.md.","recommendation":"Split into focused reference files (commands-ref.md, agents-ref.md, hooks-ref.md) under 10KB each, or create a lightweight index that links to sections on demand.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":[".claude/COMMAND_REFERENCE.md has size 108,954 bytes","Content duplicates slash command, agent, skill, hook, and MCP docs that each have their own files"],"sources":[{"source":"copilot","file":"ai-optimization-copilot.jsonl","original_fingerprint":"ai-optimization::.claude/COMMAND_REFERENCE.md::oversized-reference-doc"}],"merged_from":[]}
{"source_id":"audit:CANON-0008","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0008","category":"ai-optimization","severity":"S1","type":"code-smell","file":".claude/hooks/session-start.js","line":0,"title":"Session-start hook uses execSync for version checks that could be cached","description":"Hook spawns synchronous child processes for 'node -v' and 'npm -v' on every session start. Each execSync adds 50-200ms latency. Node.js versions rarely change within a session - this is wasteful.","recommendation":"Cache version info in .claude/state/versions.json with 1-hour TTL, or read from package.json engines field directly without spawning processes.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["const nodeVersion = execSync('node -v', {encoding: 'utf8'}).trim();","const npmVersion = execSync('npm -v', {encoding: 'utf8'}).trim();","Lines 60-75: Sequential synchronous process spawning","Sequential pattern: execSync('npm install'), then execSync('npm run build:functions')","Lines 80-120: All operations are synchronous and sequential"],"sources":[{"source":"kimik2","file":"ai-optimization-kimik2.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/session-start.js::execsync-overhead"}],"merged_from":["ai-optimization::.claude/hooks/session-start.js::execsync-overhead","ai-optimization::.claude/hooks/session-start.js::sequential-ops"]}
{"source_id":"audit:CANON-0038","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0038","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/code-reviewer/SKILL.md:140","line":0,"title":"Dead Documentation: Code Review Checklist references","description":"Skill references non-existent documentation (references/ directory), confusing the AI.","recommendation":"Update links to point to docs/agent_docs/CODE_PATTERNS.md or remove them.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["References to references/code_review_checklist.md which does not exist"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::.claude/skills/code-reviewer/SKILL.md::broken-links"}],"merged_from":[]}
{"source_id":"audit:CANON-0039","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0039","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/post-read-handler.js","line":0,"title":"Fragile Parsing: Git output parsing in post-read-handler.js","description":"Parsing git output by splitting on newline fails for filenames with newlines.","recommendation":"Use -z flag for git diff and split by NUL byte, similar to pre-compaction-save.js.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["gitExec(['diff', '--name-only']).split('\\n') in gatherGitContext"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/post-read-handler.js::fragile-git-parsing"}],"merged_from":[]}
{"source_id":"audit:CANON-0042","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0042","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-code/SKILL.md","line":0,"title":"AI Instruction Bloat: audit-code SKILL.md","description":"Skill file is 370 lines long, duplicating process documentation.","recommendation":"Move process documentation to a separate doc file and reference it in the skill.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["Contains full 'Pre-Audit Validation', 'Audit Execution', 'Output Requirements' sections"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::.claude/skills/audit-code/SKILL.md::bloat"}],"merged_from":[]}
{"source_id":"audit:CANON-0021","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0021","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/check-edit-requirements.sh","line":0,"title":"check-edit-requirements.sh and check-write-requirements.sh share ~90% identical code","description":"These two shell scripts have nearly identical input validation, path sanitization, security keyword matching, and file type classification. They differ only in the specific post-task messages. This duplication means bugs must be fixed in two places. However, these are also dead .sh files (see dead shell hooks finding), so this is only relevant if the .sh files are kept.","recommendation":"Since .js replacements exist (post-write-validator.js handles Write/Edit/MultiEdit), simply delete both .sh files. If .sh files need to stay, merge into a single parameterized script.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["check-edit-requirements.sh lines 1-75 are structurally identical to check-write-requirements.sh lines 1-76","Both have identical path traversal rejection, sanitization, and security keyword regex","settings.json uses post-write-validator.js for all Write/Edit/MultiEdit operations"],"sources":[{"source":"copilot","file":"ai-optimization-copilot.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/check-edit-write-requirements::duplicate-shell-hooks"}],"merged_from":[]}
{"source_id":"audit:CANON-0022","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0022","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/post-write-validator.js","line":0,"title":"post-write-validator.js and pattern-check.js share identical INLINE_PATTERNS arrays","description":"Both hooks contain identical INLINE_PATTERNS arrays (~70 lines each) with the same regex patterns for clickable div, test-mock-firestore, SQL injection, and shell injection detection. The checkInlinePatterns function is also duplicated. Any pattern update must be made in both files or they drift.","recommendation":"Extract INLINE_PATTERNS and checkInlinePatterns into a shared module (e.g., .claude/hooks/lib/inline-patterns.js) and import from both hooks.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["post-write-validator.js lines 480-540: identical patterns to pattern-check.js lines 91-158","checkInlinePatterns function logic is duplicated in both files","Both contain sql-injection-risk, shell-command-injection, test-mock-firestore-directly patterns"],"sources":[{"source":"copilot","file":"ai-optimization-copilot.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/post-write-validator-pattern-check::duplicated-inline-patterns"}],"merged_from":[]}
{"source_id":"audit:CANON-0023","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0023","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/post-read-handler.js","line":0,"title":"Multiple hooks contain duplicated gitExec helper function","description":"At least 5 hooks define their own gitExec() function with identical logic: execFileSync('git', args, {cwd, encoding, timeout}). This is ~10 lines duplicated 5 times. The state-utils.js shared module pattern already exists but doesn't include git utilities.","recommendation":"Add a gitExec function to .claude/hooks/lib/ (either state-utils.js or a new git-utils.js) and import it from all hooks.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["post-read-handler.js: function gitExec(args) { try { return execFileSync('git', args, {cwd: projectDir ...})","pre-compaction-save.js: function gitExec(args) { try { return execFileSync('git', args, {cwd: projectDir ...})","compaction-handoff.js, commit-tracker.js, check-remote-session-context.js all have equivalent functions","post-read-handler.js lines 40-55: safeBaseDir/projectDirInput/projectDir/baseForCheck/projectForCheck pattern","commit-tracker.js lines 24-40: identical pattern","compaction-handoff.js lines 35-50: identical pattern","check-remote-session-context.js lines 67-76: same pattern with minor variant"],"sources":[{"source":"copilot","file":"ai-optimization-copilot.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/multiple::duplicated-gitexec-helper"}],"merged_from":["ai-optimization::.claude/hooks/multiple::duplicated-gitexec-helper","ai-optimization::.claude/hooks/multiple::duplicated-projectdir-validation"]}
{"source_id":"audit:CANON-0043","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0043","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-code/SKILL.md","line":0,"title":"Context Optimization: Heavy episodic memory search","description":"Mandatory episodic memory search for generic terms ('code audit') loads potentially large/irrelevant context.","recommendation":"Refine search queries or make them conditional.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["memory__search({ query: ['code audit', 'patterns', 'quality'], limit: 5 })"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::.claude/skills/audit-code/SKILL.md::heavy-context"}],"merged_from":[]}
{"source_id":"audit:CANON-0018","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0018","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/pre-commit-fixer/SKILL.md","line":0,"title":"Pre-commit subagent Task prompt is under-specified for deterministic outputs","description":"The Task prompt asks for fixes but does not define structured output schema, required artifact paths, or strict return protocol. This can increase retries and ambiguity, wasting tokens and causing inconsistent automation behavior.","recommendation":"Add a strict subagent contract: required output JSON schema, explicit file list constraints, success/failure return block, and path-based artifact/report destinations.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":[".claude/skills/pre-commit-fixer/SKILL.md:90-94 defines a free-form Task prompt with no schema or output path contract.",".claude/skills/pre-commit-fixer/SKILL.md:134-150 defines human-readable result format, but not a machine-validated schema for subagent return.","Command: rg -n \"CRITICAL RETURN PROTOCOL|JSONL schema|output file\" .claude/skills/pre-commit-fixer/SKILL.md found no protocol requirement block."],"sources":[{"source":"codex","file":"ai-optimization-codex.jsonl","original_fingerprint":"ai-optimization::.claude/skills/pre-commit-fixer/SKILL.md::task-prompt-missing-structured-contract"}],"merged_from":[]}
{"source_id":"audit:CANON-0012","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0012","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-ai-optimization/SKILL.md","line":0,"title":"CRITICAL Persistence Rules boilerplate copy-pasted across 4+ audit SKILL.md files","description":"~50-line Persistence Rules block duplicated across 4+ files. Costs ~150 tokens per skill load.","recommendation":"Create _shared/AUDIT_PERSISTENCE_RULES.md as single canonical source.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["audit-ai-optimization/SKILL.md lines 36-57: identical boilerplate","audit-process/SKILL.md lines 32-52: identical boilerplate"],"sources":[{"source":"claude","file":"ai-optimization-claude.jsonl","original_fingerprint":"ai-optimization::.claude/skills::duplicated-persistence-rules-boilerplate"}],"merged_from":[]}
{"source_id":"audit:CANON-0024","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0024","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/state/hook-warnings-log.jsonl","line":0,"title":"hook-warnings-log.jsonl has repetitive low-value entries — no rotation","description":"hook-warnings-log.jsonl grows unbounded with 15 nearly identical entries visible ('WARNING TRIGGERS (recommended actions):' repeated with only timestamps differing). Over time this file will grow indefinitely, consuming storage and making log analysis harder. The same trigger fires on every push without new information.","recommendation":"Add log rotation: keep only the last 100 entries (or last 7 days). Deduplicate consecutive identical messages (store count instead of repeating).","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":[".claude/state/hook-warnings-log.jsonl: 15 entries visible, 14 are identical 'WARNING TRIGGERS' messages","Each entry is ~170 bytes, growing without bounds","No rotation logic found in any hook or script"],"sources":[{"source":"copilot","file":"ai-optimization-copilot.jsonl","original_fingerprint":"ai-optimization::.claude/state/hook-warnings-log.jsonl::unbounded-log-growth"}],"merged_from":[]}
{"source_id":"audit:CANON-0016","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0016","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/analyze-user-request.sh","line":0,"title":"Legacy shell hook scripts appear runtime-unused (possibly unused)","description":"Maintaining duplicate JS+SH hook implementations increases maintenance/token overhead and can confuse future edits. If shell variants are no longer executed by hook config, they become drift-prone documentation code.","recommendation":"Either remove/archive shell variants or mark them explicitly as fallback-only with a single source-of-truth policy. If kept, add automated parity tests between JS and SH behavior.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":[".claude/settings.json:13,17,22,28 references only Node hook entrypoints (no .sh hook commands).",".claude/hooks/session-start.js:7 and .claude/hooks/check-mcp-servers.js:7 state they are cross-platform replacements for .sh scripts.","Command: rg -n \".claude/hooks/.*.sh\" .claude/settings.json .github/workflows package.json .husky/* returned no runtime references.","Command: for f in .claude/hooks/*.sh; do rg -n \"$(basename $f)\" .claude .github package.json scripts docs; done"],"sources":[{"source":"codex","file":"ai-optimization-codex.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/.sh::legacy-shell-hooks-possibly-unused"}],"merged_from":[]}
{"source_id":"audit:CANON-0011","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0011","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/agent-trigger-enforcer.js","line":0,"title":"13 consolidated-out hook JS files remain as dead standalone executables","description":"post-write-validator.js replaced 10 hooks, post-read-handler.js replaced 3 more. Originals remain as ~2000 lines of dead code.","recommendation":"Move to .claude/hooks/archive/ or delete them.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["post-write-validator.js: Replaces 10 separate hooks","post-read-handler.js: Replaces 3 separate hooks"],"sources":[{"source":"claude","file":"ai-optimization-claude.jsonl","original_fingerprint":"ai-optimization::.claude/hooks::orphaned-pre-consolidation-hook-files"}],"merged_from":[]}
{"source_id":"audit:CANON-0015","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0015","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-ai-optimization/SKILL.md","line":0,"title":"Task() sub-agents dont check FALSE_POSITIVES.jsonl before reporting","description":"Orchestrator reads FALSE_POSITIVES.jsonl but Task() agents start in fresh contexts without it. Known FPs re-reported every audit.","recommendation":"Add to each agent prompt: read FALSE_POSITIVES.jsonl and exclude matching entries.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["Orchestrator reads FALSE_POSITIVES not propagated to subagents","Agent 1A prompt has zero mention of FALSE_POSITIVES.jsonl"],"sources":[{"source":"claude","file":"ai-optimization-claude.jsonl","original_fingerprint":"ai-optimization::.claude/skills/audit-ai-optimization/SKILL.md::agent-prompts-missing-false-positive-exclusion"}],"merged_from":[]}
{"source_id":"audit:CANON-0020","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0020","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/stop-serena-dashboard.js","line":0,"title":"stop-serena-dashboard.js uses 6+ execFileSync calls at session start — port check may be unnecessary","description":"This hook runs on every SessionStart and spawns multiple synchronous child processes (lsof, ps, kill) to stop a Serena dashboard that may not be running. In remote Claude Code environments, Serena is unlikely to be active. The hook is 250+ lines of security-hardened process termination code that executes unconditionally.","recommendation":"Add a fast-path check: if port 24282 is not listening, exit immediately with zero subprocess spawns. Or make this hook conditional on a local-only environment flag.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["settings.json line 28-32: stop-serena-dashboard.js runs on every SessionStart","Hook uses execFileSync for: lsof, ps (multiple calls), kill/SIGTERM","Already has continueOnError: true suggesting it's non-essential"],"sources":[{"source":"copilot","file":"ai-optimization-copilot.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/stop-serena-dashboard.js::unnecessary-session-start-overhead"}],"merged_from":[]}
{"source_id":"audit:CANON-0049","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0049","category":"ai-optimization","severity":"S2","type":"code-smell","file":"scripts/add-false-positive.js","line":0,"title":"Scripts not in package.json: add-false-positive.js, assign-review-tier.js, seed-commit-log.js, sync-claude-settings.js — potentially dead","description":"These scripts exist in scripts/ but have no entry in package.json scripts section. They may be called by skills, hooks, or used manually, but without a package.json entry they're harder to discover and may be truly dead code. enrichment_failures.json (6KB) appears to be output data committed to the repo.","recommendation":"Verify each script's usage: check if any SKILL.md, hook, or CI workflow references them. If unused, delete. If used, add to package.json for discoverability. Move enrichment_failures.json to .gitignore if it's generated output.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["package.json scripts section has 90 entries but none reference add-false-positive.js, assign-review-tier.js, seed-commit-log.js, or sync-claude-settings.js","scripts/enrichment_failures.json is a 6KB data file in the scripts directory","sync-claude-settings.js IS referenced in CROSS_PLATFORM_SETUP.md and HOOKS.md docs"],"sources":[{"source":"copilot","file":"ai-optimization-copilot.jsonl","original_fingerprint":"ai-optimization::scripts::unreferenced-scripts"}],"merged_from":[]}
{"source_id":"audit:CANON-0051","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0051","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/state-utils.js","line":0,"title":"Hooks use string manipulation where JSON.parse should be used","description":"Based on commit messages referencing 'fragile parsing patterns' and file names like 'state-utils.js', hooks likely use manual string splitting for JSONL/state file parsing instead of proper JSON.parse, risking corruption on edge cases.","recommendation":"Use JSON.parse() with try/catch for all JSON/JSONL parsing, use readline module for line-by-line JSONL processing instead of split('\\n').","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["Commit: 'Fix 8 fragile parsing patterns: resilient regex across 11 files'","File: state-utils.js likely handles state parsing","File: commit-tracker.js processes JSONL logs"],"sources":[{"source":"kimik2","file":"ai-optimization-kimik2.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/*.js::fragile-parsing"}],"merged_from":[]}
{"source_id":"audit:CANON-0052","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0052","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-ai-optimization/SKILL.md","line":0,"title":"Audit skill prompts may not consistently reference FALSE_POSITIVES.jsonl","description":"The FALSE_POSITIVES.jsonl file exists with 3 entries but audit skill prompts may not explicitly instruct agents to exclude these patterns, leading to duplicate findings and wasted verification effort.","recommendation":"Add explicit instruction to all audit skill prompts: 'Check docs/technical-debt/FALSE_POSITIVES.jsonl and exclude any findings matching these patterns.'","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["FALSE_POSITIVES.jsonl exists with 3 verified false positive entries","Audit skill is 632 lines but FP reference not visible in preview","Finding DEBT-2598, DEBT-2615, DEBT-0107 are marked FALSE_POSITIVE"],"sources":[{"source":"kimik2","file":"ai-optimization-kimik2.jsonl","original_fingerprint":"ai-optimization::.claude/skills/audit-ai-optimization/SKILL.md::missing-fp-exclusion"}],"merged_from":[]}
{"source_id":"audit:CANON-0053","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0053","category":"ai-optimization","severity":"S3","type":"code-smell","file":".mcp.json","line":0,"title":"filesystem MCP server configured but permanently disabled — dead config","description":"filesystem entry self-annotated as disabled and in disabledMcpjsonServers. Dead config adds cognitive overhead.","recommendation":"Remove filesystem entry from .mcp.json entirely.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":[".mcp.json: filesystem with note stating disabled","settings.json: disabledMcpjsonServers includes filesystem","'_note': 'filesystem MCP duplicates native Read/Write/Glob tools — disabled since no skills reference mcp__filesystem__ tools'","Server still configured with command/args despite being 'disabled'"],"sources":[{"source":"claude","file":"ai-optimization-claude.jsonl","original_fingerprint":"ai-optimization::.mcp.json::dead-filesystem-mcp-server-config"},{"source":"kimik2","file":"ai-optimization-kimik2.jsonl","original_fingerprint":"ai-optimization::.mcp.json::unused-mcp-server"}],"merged_from":["ai-optimization::.mcp.json::dead-filesystem-mcp-server-config","ai-optimization::.mcp.json::unused-mcp-server"]}
{"source_id":"audit:CANON-0041","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0041","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-code/SKILL.md","line":0,"title":"Skill Overlap: audit-code vs code-reviewer","description":"Two skills perform nearly identical code quality checks, leading to confusion and maintenance drift.","recommendation":"Consolidate into a single 'code-quality' skill with modes (audit vs review) or distinct tasks.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["Both skills check Typescript, React, Firebase, Security patterns with significant content overlap"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::.claude/skills/audit-code/SKILL.md::overlap"}],"merged_from":[]}
{"source_id":"audit:CANON-0061","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0061","category":"ai-optimization","severity":"S3","type":"code-smell","file":"docs/technical-debt/INDEX.md","line":0,"title":"Dead Documentation: technical-debt/INDEX.md","description":"Unreferenced documentation creates confusion and maintenance overhead.","recommendation":"Delete the file.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["File is not referenced by any other file in the project (excluding archive)"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::docs/technical-debt/INDEX.md::dead-doc"}],"merged_from":[]}
{"source_id":"audit:CANON-0063","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0063","category":"ai-optimization","severity":"S3","type":"code-smell","file":".mcp.json","line":0,"title":"MCP Config Efficiency: Unused filesystem server","description":"Unused MCP server adds overhead and potential confusion.","recommendation":"Remove the filesystem server configuration.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["filesystem server is present but marked as disabled/unused in _note"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::.mcp.json::unused-server"}],"merged_from":[]}
{"source_id":"audit:CANON-0054","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0054","category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/hooks/session-start.js","line":0,"title":"Format Waste: Verbose session-start output","description":"Verbose output wastes tokens in every session start.","recommendation":"Reduce console.log calls, only show warnings or errors.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["Multiple console.log calls for status updates ('Checking...', 'Skipping...')","console.log('━'.repeat(66)) - decorative separator","console.log('🚀 SessionStart Hook for sonash-v0') - emoji output","console.log('📋 Environment:') - verbose section headers"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/session-start.js::verbose-output"},{"source":"kimik2","file":"ai-optimization-kimik2.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/session-start.js::verbose-output"}],"merged_from":["ai-optimization::.claude/hooks/session-start.js::verbose-output","ai-optimization::.claude/hooks/session-start.js::verbose-output"]}
{"source_id":"audit:CANON-0040","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0040","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/session-start.js","line":0,"title":"Subprocess Overhead: Node spawning in hooks","description":"Spawning new Node processes consumes memory and time.","recommendation":"Require and call script functions directly where possible (e.g. check-pattern-compliance.js).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["execSync('node scripts/check-pattern-compliance.js', ...)"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/session-start.js::subprocess-overhead"}],"merged_from":[]}
{"source_id":"audit:CANON-0062","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0062","category":"ai-optimization","severity":"S3","type":"code-smell","file":"docs/technical-debt/logs/verification-log.jsonl","line":0,"title":"Dead Documentation: technical-debt/logs artifacts","description":"Old log artifacts consume space and are not referenced.","recommendation":"Delete or archive the directory.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["Files in docs/technical-debt/logs/ are not referenced by active scripts"],"sources":[{"source":"jules","file":"ai-optimization-jules.jsonl","original_fingerprint":"ai-optimization::docs/technical-debt/logs::dead-doc"}],"merged_from":[]}
{"source_id":"audit:CANON-0044","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0044","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-ai-optimization/SKILL.md","line":0,"title":"SKILL.md file exceeds 500 lines with duplicated boilerplate","description":"The audit-ai-optimization SKILL.md is 632 lines (21.8KB), containing extensive duplicated boilerplate across sections. This wastes ~200 tokens per skill invocation and increases context window pressure. Similar patterns exist across 10+ audit skills.","recommendation":"Extract common sections (CRITICAL RETURN PROTOCOL, Persistence Rules, Stage templates) into a shared base file referenced by all audit skills. Target: reduce to <300 lines per skill.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["File size: 632 lines (470 loc) · 21.8 KB","Duplicated 'CRITICAL: Persistence Rules' section","Duplicated 'CRITICAL RETURN PROTOCOL' section","Stage template patterns repeated verbatim"],"sources":[{"source":"kimik2","file":"ai-optimization-kimik2.jsonl","original_fingerprint":"ai-optimization::.claude/skills/audit-ai-optimization/SKILL.md::skill-bloat"}],"merged_from":[]}
{"source_id":"audit:CANON-0055","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0055","category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/settings.json","line":0,"title":"settings.json disabledMcpjsonServers has 3 stale entries not in .mcp.json","description":"disabledMcpjsonServers includes rube, serena, nextjs-devtools — none in .mcp.json. Stale entries with no documentation.","recommendation":"Remove stale entries or add comments explaining they target global configs.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["settings.json: rube, serena, nextjs-devtools, filesystem",".mcp.json only has: filesystem, playwright, memory, sonarcloud"],"sources":[{"source":"claude","file":"ai-optimization-claude.jsonl","original_fingerprint":"ai-optimization::.claude/settings.json::stale-disabled-mcp-server-entries"}],"merged_from":[]}
{"source_id":"audit:CANON-0058","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0058","category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/skills/session-begin/SKILL.md","line":0,"title":"Session-begin checklist duplicates mandatory context reads","description":"Repeated mandatory instructions (e.g., reading ROADMAP Active Sprint in multiple sections) add avoidable context and operator overhead each session. This is small per run but persistent across all sessions.","recommendation":"Deduplicate repeated checklist items into a single canonical step and reference it later by anchor instead of repeating prose.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":[".claude/skills/session-begin/SKILL.md:124-126 requires reading ROADMAP Active Sprint.",".claude/skills/session-begin/SKILL.md:176-177 repeats reading ROADMAP Active Sprint.","Command: nl -ba .claude/skills/session-begin/SKILL.md | sed -n '118,182p'"],"sources":[{"source":"codex","file":"ai-optimization-codex.jsonl","original_fingerprint":"ai-optimization::.claude/skills/session-begin/SKILL.md::duplicate-context-load-steps"}],"merged_from":[]}
{"source_id":"audit:CANON-0017","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0017","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-code/SKILL.md","line":0,"title":"Audit skill templates have high duplication and could be parameterized","description":"Large duplicated prompt scaffolding increases context token load and maintenance cost; fixes must be replicated across multiple long SKILL.md files, increasing drift risk.","recommendation":"Extract shared sections (execution-mode table, pre-audit validation framework, checkpoint schema, output protocol) into a referenced base template and keep only domain-specific deltas per skill.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":[".claude/skills/audit-code/SKILL.md:12-20 and .claude/skills/audit-security/SKILL.md:12-20 contain near-identical execution-mode matrices.",".claude/skills/audit-code/SKILL.md:114-203 and .claude/skills/audit-security/SKILL.md:147-247 mirror pre-audit validation structure and flow.","Command: Python difflib SequenceMatcher reported 0.63 similarity for audit-code vs audit-security."],"sources":[{"source":"codex","file":"ai-optimization-codex.jsonl","original_fingerprint":"ai-optimization::.claude/skills/audit-/SKILL.md::audit-skill-overlap"}],"merged_from":[]}
{"source_id":"audit:CANON-0045","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0045","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/session-start.js","line":0,"title":"Session-start hook is 505 lines with inline prompts >10 lines","description":"Session-start.js is 505 lines (16.7KB) and runs on EVERY session start. Large hooks on the critical path add latency and consume tokens before any user work begins. Contains verbose console output and inline formatting.","recommendation":"Move non-critical checks to PostToolUse hooks, extract verbose output to a separate debug module, use progressive disclosure (only show details on --verbose flag).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["505 lines (453 loc) · 16.7 KB","console.log('🚀 SessionStart Hook for sonash-v0') - verbose emoji output","Sequential execSync calls for version checks"],"sources":[{"source":"kimik2","file":"ai-optimization-kimik2.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/session-start.js::hook-bloat"}],"merged_from":[]}
{"source_id":"audit:CANON-0047","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0047","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/state/reviews.jsonl","line":0,"title":"State JSONL files growing without bounds - reviews.jsonl is 18.6KB","description":"reviews.jsonl is 18.6KB with 31 lines and growing with each PR. Without rotation or compaction, these files will exceed 100KB quickly, slowing down hook operations that read them.","recommendation":"Implement log rotation in compaction-handoff.js - archive entries older than 30 days to .claude/state/archive/, keep only last 50 entries in active file.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["reviews.jsonl: 31 lines · 18.6 KB","Last commit shows daily updates to state files","No rotation logic visible in compaction-handoff.js filename"],"sources":[{"source":"kimik2","file":"ai-optimization-kimik2.jsonl","original_fingerprint":"ai-optimization::.claude/state/reviews.jsonl::unbounded-growth"}],"merged_from":[]}
{"source_id":"audit:CANON-0056","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0056","category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/hooks/session-start.js","line":0,"title":"session-start.js reads full reviews.jsonl for a single count check","description":"Reads entire reviews.jsonl (19KB), splits, counts entries for rotation threshold. A sidecar count file would suffice.","recommendation":"Track count in reviews-meta.json sidecar file.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["session-start.js lines 427-452: reads full file for count only","reviews.jsonl: 19KB with 31 entries"],"sources":[{"source":"claude","file":"ai-optimization-claude.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/session-start.js::reviews-jsonl-full-read-rotation-check"}],"merged_from":[]}
{"source_id":"audit:CANON-0059","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0059","category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/settings.json","line":0,"title":"MCP servers configured but 4 are disabled — disabled list should match actual config","description":"settings.json disables 4 MCP servers (rube, serena, nextjs-devtools, filesystem) but mcp.global-template.json only defines 2 servers (ccusage, playwright). The disabled servers reference names that don't appear in the template, suggesting stale configuration from removed MCP servers.","recommendation":"Remove disabled server names that no longer exist in any MCP config. Document which MCP servers are intentionally disabled and why.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["settings.json line 6: disabledMcpjsonServers: [\"rube\", \"serena\", \"nextjs-devtools\", \"filesystem\"]","mcp.global-template.json only defines: ccusage, playwright","The disabled servers may be in .mcp.json (user-local file not in repo) — confidence adjusted"],"sources":[{"source":"copilot","file":"ai-optimization-copilot.jsonl","original_fingerprint":"ai-optimization::.claude/settings.json::disabled-mcp-servers"}],"merged_from":[]}
{"source_id":"audit:CANON-0050","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0050","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/session-begin/","line":0,"title":"Skills read entire large files when only headers/sections needed","description":"Skills appear to load full SKILL.md files (600+ lines) into context when only specific sections are needed for a given task. This wastes hundreds of tokens per skill invocation.","recommendation":"Implement section-based loading with markers (<!-- SECTION:quickref -->), read only required sections based on task parameters.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["SKILL.md files average 400-600 lines","No section markers visible in audit-ai-optimization/SKILL.md","Progressive disclosure tiers mentioned but not enforced"],"sources":[{"source":"kimik2","file":"ai-optimization-kimik2.jsonl","original_fingerprint":"ai-optimization::.claude/skills/*/SKILL.md::full-file-read"}],"merged_from":[]}
{"source_id":"audit:CANON-0048","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0048","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/doc-optimizer/SKILL.md","line":0,"title":"doc-optimizer and audit-process SKILL.md exceed 1500 lines without modularization","description":"doc-optimizer (1735 lines) and audit-process (1525 lines) loaded in full, adding 3000-5000 tokens.","recommendation":"Extract per-agent prompt templates to reference/ subdirectories.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["wc -l: doc-optimizer 1735, audit-process 1525, audit-documentation 1000, multi-ai-audit 948"],"sources":[{"source":"claude","file":"ai-optimization-claude.jsonl","original_fingerprint":"ai-optimization::.claude/skills::oversized-skill-md-files"}],"merged_from":[]}
{"source_id":"audit:CANON-0046","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0046","category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-code/SKILL.md","line":0,"title":"10 audit skills share >50% identical structure without shared base","description":"All 9 audit skills follow identical 3-stage parallel agent pattern with duplicated CRITICAL sections, persistence rules, and return protocols. This is maintenance overhead and bloats the skill index.","recommendation":"Create base audit skill template with common sections, use skill parameters to specify audit domain. Consolidate into /audit --domain=code|documentation|performance|security.","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["SKILL_INDEX.md shows 9 separate audit skills","All audit skills have 'Stage 1/2/3' structure","All contain identical 'CRITICAL RETURN PROTOCOL' section"],"sources":[{"source":"kimik2","file":"ai-optimization-kimik2.jsonl","original_fingerprint":"ai-optimization::.claude/skills/audit-*/SKILL.md::skill-overlap"}],"merged_from":[]}
{"source_id":"audit:CANON-0060","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0060","category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/hooks/post-read-handler.js","line":0,"title":"Multiple hooks duplicate loadJson/saveJson atomic write pattern","description":"At least 3 hooks implement their own loadJson/saveJson functions with atomic write (temp file + rename) and symlink guard integration. The state-utils.js module already provides readState/writeState but some hooks don't use it, duplicating the atomic write pattern with slight variations.","recommendation":"Standardize on state-utils.js for all JSON state I/O. Extend it if needed for non-state-directory paths.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["post-read-handler.js lines 86-155: loadJson + saveJson with backup-swap","compaction-handoff.js lines 66-84: loadJson + saveJson","state-utils.js already exports readState/writeState with atomic writes"],"sources":[{"source":"copilot","file":"ai-optimization-copilot.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/multiple::duplicated-json-io"}],"merged_from":[]}
{"source_id":"audit:CANON-0057","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0057","category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/state/health-score-log.jsonl","line":0,"title":"health-score-log.jsonl and hook-warnings-log.jsonl grow unboundedly — no rotation","description":"reviews.jsonl has rotation. health-score-log and hook-warnings-log have none. rotateJsonl() exists but only applied to reviews.jsonl.","recommendation":"Apply rotateJsonl() to both files in session-start.js.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["session-start.js: rotation NOT applied to other logs","health-score-log.jsonl: 8 entries growing","hook-warnings-log.jsonl: 16 entries growing"],"sources":[{"source":"claude","file":"ai-optimization-claude.jsonl","original_fingerprint":"ai-optimization::.claude/state::unbounded-jsonl-logs-no-rotation"}],"merged_from":[]}
{"source_id":"audit:CANON-0064","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0064","category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/hooks/check-remote-session-context.js","line":0,"title":"Remote-branch parsing relies on delimiter split that can break on format drift","description":"The parser assumes git branch --format will always contain exactly one | delimiter and directly splits into two fields. Minor output format changes can silently corrupt date parsing and skip useful branch comparisons.","recommendation":"Parse with a safer structured format (e.g., NUL-delimited fields via %x00) or split once with validation and explicit fallback logging.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":[".claude/hooks/check-remote-session-context.js:143 uses pipe-delimited git format.",".claude/hooks/check-remote-session-context.js:151-153 uses const [branch, dateStr] = line.split(\"|\") without field-count validation.","Command: nl -ba .claude/hooks/check-remote-session-context.js | sed -n '135,156p'"],"sources":[{"source":"codex","file":"ai-optimization-codex.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/check-remote-session-context.js::fragile-branch-line-split"}],"merged_from":[]}
{"source_id":"audit:CANON-0065","source_file":"docs\\audits\\multi-ai\\maa-2026-02-17-182d43\\final\\UNIFIED-FINDINGS.jsonl","original_id":"CANON-0065","category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/hooks/session-start.sh","line":0,"title":"Shell script hooks may be redundant with Node.js versions","description":"Multiple .sh files exist alongside .js versions (session-start.sh + session-start.js). Based on commit messages, the project migrated to Node.js hooks for cross-platform compatibility. Shell versions may be orphaned.","recommendation":"Verify shell scripts are not referenced in .claude/settings.json or hooks.json, then archive to .claude/hooks/archive/ if truly unused.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":true,"resolution":null,"evidence":["session-start.sh exists alongside session-start.js","Commit: 'Cross-platform replacement for session-start.sh'","analyze-user-request.sh + analyze-user-request.js pair exists"],"sources":[{"source":"kimik2","file":"ai-optimization-kimik2.jsonl","original_fingerprint":"ai-optimization::.claude/hooks/*.sh::redundant-shell-scripts"}],"merged_from":[]}
{"source_id":"audit:hash-RmlyZWJhc2Ug","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-workflow.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"firebase.json:1","line":0,"title":"Firebase deployment lacks rollback on partial failure","description":"Inconsistent deployment state can cause runtime errors when frontend expects API endpoints that haven't deployed","recommendation":"","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"firebase.json configures both hosting and functions targets deployed together","sources":[],"merged_from":[]}
{"source_id":"audit:hash-Q0kgcnVucyBm","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-workflow.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":".github/workflows/ci.yml:1","line":0,"title":"CI runs full build twice - once for lint, once for test","description":"Reduces CI pipeline duration by eliminating redundant compilation, faster PR feedback","recommendation":"","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"CI workflow has separate build steps for lint and test stages","sources":[],"merged_from":[]}
{"source_id":"audit:hash-U29uYXJDbG91","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-workflow.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":".github/workflows/ci.yml:1","line":0,"title":"SonarCloud not enforced in CI gates","description":"Without enforcement, SonarCloud findings accumulate without accountability, reducing the tool's value","recommendation":"","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"SonarCloud integration exists but not configured as blocking CI check","sources":[],"merged_from":[]}
{"source_id":"audit:hash-U2VudHJ5IGRp","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-workflow.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"lib/sentry.ts:1","line":0,"title":"Sentry disabled in dev mode by default","description":"Some errors only reproduce in specific conditions; having dev errors in Sentry helps identify patterns before they reach production","recommendation":"","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Sentry initialization checks for production environment before enabling","sources":[],"merged_from":[]}
{"source_id":"audit:hash-SG9vayBwZXJm","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-workflow.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":".claude/hooks/:multiple","line":0,"title":"Hook performance not tracked - no metrics on execution time","description":"Without metrics, slow hooks accumulate unnoticed, gradually degrading developer experience","recommendation":"","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"20+ hooks in .claude/hooks/ with no execution time tracking","sources":[],"merged_from":[]}
{"source_id":"audit:hash-UHJlLXB1c2gg","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-workflow.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":".husky/pre-push:1","line":0,"title":"Pre-push duplicates pre-commit pattern checks","description":"Saves time per push and prevents graduated enforcement self-escalation (warned in pre-commit, blocked in pre-push)","recommendation":"","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Both .husky/pre-commit and .husky/pre-push run npm run patterns:check","sources":[],"merged_from":[]}
{"source_id":"audit:hash-dW5kZWZpbmVk","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-workflow.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"","line":0,"title":"Untitled finding","description":"Compaction-resilient state persistence with 4-layer approach (commit-tracker, compaction-handoff, pre-compaction-save, compact-restore)","recommendation":"","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":["4 independent layers ensure no state loss across compaction","commit-log.jsonl as single source of truth","Successfully recovered from crashes in production use"],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-TWlzc2luZyBB","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-ux.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"components/navigation/:multiple","line":0,"title":"Missing ARIA labels on critical navigation tabs","description":"Navigation is the primary interaction pattern; missing ARIA labels make the app unusable for screen reader users","recommendation":"","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Tab components found without aria-label attributes in navigation components","sources":[],"merged_from":[]}
{"source_id":"audit:hash-U21hbGwgdG91","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-ux.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"components/navigation/:multiple","line":0,"title":"Small touch targets on mobile - tabs only 8-10px padding","description":"WCAG 2.5.8 requires minimum 44x44px touch targets; small targets cause frustration and errors on mobile","recommendation":"","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Tab components with p-2 (8px) padding observed","sources":[],"merged_from":[]}
{"source_id":"audit:hash-Tm8gZm9jdXMg","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-ux.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"components/:multiple","line":0,"title":"No focus trap management in modals and dialogs","description":"Focus escaping modals is a WCAG 2.4.3 violation and confusing for keyboard and screen reader users","recommendation":"","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Modal components without focus trap implementation or aria-modal attribute","sources":[],"merged_from":[]}
{"source_id":"audit:hash-TWlzc2luZyBl","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-ux.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"components/:multiple","line":0,"title":"Missing error state illustrations - plain text errors only","description":"Visual error states are more noticeable and help users understand what went wrong faster","recommendation":"","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Error handling in components uses plain text without icons or illustrations","sources":[],"merged_from":[]}
{"source_id":"audit:hash-TWlzc2luZyBs","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-ux.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"app/:multiple","line":0,"title":"Missing loading skeletons on data-heavy pages","description":"Consistent loading patterns reduce perceived wait time and create a more polished experience","recommendation":"","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Mix of skeleton, spinner, and text loading states across app pages","sources":[],"merged_from":[]}
{"source_id":"audit:hash-Tm8gb3B0aW1p","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-ux.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"components/journal/:multiple","line":0,"title":"No optimistic updates for form submissions","description":"Optimistic updates make the app feel instant and responsive, improving perceived performance","recommendation":"","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Form components use loading state and await server response before UI update","sources":[],"merged_from":[]}
{"source_id":"audit:hash-TWlzc2luZyBr","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-ux.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"app/:multiple","line":0,"title":"Missing keyboard shortcuts for power users","description":"Power users who journal daily benefit significantly from keyboard shortcuts for repetitive actions","recommendation":"","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"No keyboard event handlers or shortcut system found in app code","sources":[],"merged_from":[]}
{"source_id":"audit:hash-Rm9ybSB2YWxp","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-ux.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"components/journal/:multiple","line":0,"title":"Form validation shows errors only on submit, not inline","description":"Inline validation prevents form submission failures and helps users correct mistakes in real-time","recommendation":"","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Form components use Zod validation on submit but don't show field-level errors during input","sources":[],"merged_from":[]}
{"source_id":"audit:hash-Tm8gdmlzdWFs","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-testing.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"package.json:1","line":0,"title":"No visual regression testing despite Playwright being installed","description":"Catches unintended CSS/layout regressions that functional tests miss; especially important with Tailwind utility classes that can have subtle side effects","recommendation":"","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Playwright in dependencies; 28 .protocol.json files exist but no screenshot comparison tests","sources":[],"merged_from":[]}
{"source_id":"audit:hash-Q292ZXJhZ2Ug","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-testing.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"package.json:10-12","line":0,"title":"Coverage thresholds not enforced despite c8 being available","description":"Without thresholds, coverage can silently decrease as new code is added without tests","recommendation":"","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"npm run test:coverage exists but no --check-coverage flags or .c8rc configuration found","sources":[],"merged_from":[]}
{"source_id":"audit:hash-TGltaXRlZCBz","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-testing.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"tests/:multiple","line":0,"title":"Limited script testing - 5 test files for 60+ npm scripts","description":"Script bugs cause cascading failures in the entire development pipeline; the pattern checker and security checker are critical infrastructure","recommendation":"","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"85 files in scripts/, 60+ npm scripts, only ~5 test files covering script behavior","sources":[],"merged_from":[]}
{"source_id":"audit:hash-Tm8gcGVyZm9y","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-testing.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"components/:multiple","line":0,"title":"No performance benchmarks for pagination and data loading","description":"Performance regressions are hard to detect in code review; automated benchmarks catch them before users notice","recommendation":"","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Pagination and data loading mentioned in ROADMAP as P0 concerns but no automated performance tests exist","sources":[],"merged_from":[]}
{"source_id":"audit:hash-RXJyb3IgYm91","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-testing.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"components/:multiple","line":0,"title":"Error boundary and Sentry integration not tested","description":"If error boundaries fail silently, users see white screens instead of graceful fallbacks; if Sentry breaks, errors go unreported","recommendation":"","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Sentry integration in lib/sentry.ts, error boundaries in components, no test coverage for either","sources":[],"merged_from":[]}
{"source_id":"audit:hash-Rmxha3kgdGlt","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-testing.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"tests/rate-limiter.test.ts:1","line":0,"title":"Flaky timing in rate limiter tests using real setTimeout","description":"Real timer tests are inherently flaky under CI load and slow down the test suite unnecessarily","recommendation":"","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Rate limiter test has explicit setTimeout waits: 30ms, 72ms, 110ms observed in test output","sources":[],"merged_from":[]}
{"source_id":"audit:hash-bXN3IGluc3Rh","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-testing.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"package.json:1","line":0,"title":"msw installed but unused for API mocking","description":"msw provides more realistic API mocking that catches serialization and request format issues","recommendation":"","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"msw in package.json dependencies but no msw handlers or setup files found in tests/","sources":[],"merged_from":[]}
{"source_id":"audit:hash-RW5hYmxlIE5l","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-infrastructure.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"next.config.mjs:12-19","line":0,"title":"Enable Next.js experimental optimizations and bundle analysis","description":"Large map/chart libraries (leaflet, recharts) are imported but not tree-shaken optimally","recommendation":"","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"app/layout.tsx imports multiple heavy libraries, no dynamic imports detected, meeting-map.tsx imports entire leaflet","sources":[],"merged_from":[]}
{"source_id":"audit:hash-QWRkIENvbnRl","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-infrastructure.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"firebase.json:6-57","line":0,"title":"Add Content-Security-Policy header to Firebase hosting configuration","description":"CSP provides additional layer against XSS attacks; industry best practice for modern web apps","recommendation":"","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"firebase.json has X-Frame-Options, HSTS, X-Content-Type-Options but no CSP","sources":[],"merged_from":[]}
{"source_id":"audit:hash-QWRkIGVuZ2lu","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-infrastructure.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"package.json:1-165","line":0,"title":"Add engines field to root package.json for CI/CD consistency","description":"Ensures consistent Node version across development, CI, and production","recommendation":"","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"functions/package.json:14 specifies node 20, root has no engines field","sources":[],"merged_from":[]}
{"source_id":"audit:hash-RmlyZXN0b3Jl","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-infrastructure.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"firebase.json:72-74","line":0,"title":"Firestore security rules file not found in repository","description":"Security rules are critical infrastructure and should be version controlled for audit trail","recommendation":"","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"firebase.json:73 references firestore.rules, no .rules files found in glob search","sources":[],"merged_from":[]}
{"source_id":"audit:hash-Q29uZmlndXJl","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-infrastructure.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"next.config.mjs:12","line":0,"title":"Configure Next.js build cache and dependency caching for faster CI builds","description":"Faster feedback loops for PRs; reduced CI minutes consumption","recommendation":"","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"tsconfig.json:15 has incremental: true, no CI cache actions found","sources":[],"merged_from":[]}
{"source_id":"audit:hash-TGF6eSBsb2Fk","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-infrastructure.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"components/maps/meeting-map.tsx:1-80","line":0,"title":"Lazy load Leaflet and Recharts with dynamic imports and Suspense","description":"Not all users visit map/chart pages; faster time-to-interactive for initial load","recommendation":"","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"meeting-map.tsx imports full leaflet synchronously, no dynamic imports for recharts","sources":[],"merged_from":[]}
{"source_id":"audit:hash-VXBncmFkZSBG","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-infrastructure.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"firebase.json:68","line":0,"title":"Upgrade Firebase Functions to Node.js 24 runtime","description":"Longer LTS support window; aligns with bleeding-edge philosophy of the project","recommendation":"","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"firebase.json:68 shows nodejs24 available, functions uses node 20","sources":[],"merged_from":[]}
{"source_id":"audit:hash-QWRkIGNvbXBv","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-infrastructure.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"firestore.indexes.json:18-80","line":0,"title":"Add composite index for userId + timestamp on security_logs collection","description":"Admin panel likely needs per-user security logs; composite index prevents full collection scans","recommendation":"","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"firestore.indexes.json has security_logs indexes but only severity/type/functionName composites","sources":[],"merged_from":[]}
{"source_id":"audit:hash-U3RhbGUgZG9j","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-docs.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"tech-debt","file":"docs/:multiple","line":0,"title":"Stale documentation markers - 96 TODO/TBD occurrences across 34 files","description":"Stale TODOs reduce documentation credibility and create confusion about what is actually planned vs abandoned","recommendation":"","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"96 TODO/TBD occurrences found across 34 files via grep","sources":[],"merged_from":[]}
{"source_id":"audit:hash-U2VjdXJpdHkg","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-docs.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"tech-debt","file":"docs/SECURITY.md:1","line":0,"title":"Security guidance consolidation - multiple overlapping security docs","description":"Duplicated security guidance risks contradictions when one doc is updated but others are not, and increases maintenance burden","recommendation":"","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"4 separate security-focused documents with overlapping content on path traversal, error sanitization, and input validation","sources":[],"merged_from":[]}
{"source_id":"audit:hash-RG9jdW1lbnRh","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-docs.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"tech-debt","file":"docs/:multiple","line":0,"title":"Documentation effectiveness metrics - no tracking of which docs are useful","description":"Data-driven documentation pruning would reduce maintenance burden and focus effort on docs that actually improve outcomes","recommendation":"","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"300+ markdown files in the project, unclear which are actively referenced vs historical","sources":[],"merged_from":[]}
{"source_id":"audit:hash-Q3Jvc3MtcmVm","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-docs.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"tech-debt","file":"CLAUDE.md:1","line":0,"title":"Cross-reference navigation overhead in documentation","description":"Reducing indirection means AI agents and humans can understand guidance without chasing references across files","recommendation":"","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Multiple 'See: docs/agent_docs/...' references in CLAUDE.md and AI_WORKFLOW.md","sources":[],"merged_from":[]}
{"source_id":"audit:hash-Q0kgbm9uLWJs","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-devx.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":".github/workflows/ci.yml:1","line":0,"title":"CI non-blocking checks should block - 5 checks use continue-on-error","description":"Non-blocking checks that always pass provide false confidence. If they fail silently, issues accumulate undetected","recommendation":"","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"5 checks with continue-on-error: true in ci.yml","sources":[],"merged_from":[]}
{"source_id":"audit:hash-U2NyaXB0IGNv","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-devx.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"scripts/:multiple","line":0,"title":"Script consolidation - 30+ check/validate/sync scripts with inconsistent CLI patterns","description":"Consistent CLI patterns reduce cognitive load and make scripts easier to discover, document, and maintain","recommendation":"","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"82 npm scripts in package.json, 85 files in scripts/ directory","sources":[],"merged_from":[]}
{"source_id":"audit:hash-R2VuZXJpYyBi","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-content.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"components/journal/journal-entry-form.tsx:1","line":0,"title":"Generic button labels - Submit used instead of action-specific text","description":"Action-specific button labels reduce cognitive load and confirm what will happen when clicked","recommendation":"","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Generic Submit/Save buttons found in form components","sources":[],"merged_from":[]}
{"source_id":"audit:hash-RXJyb3IgbWVz","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-content.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"components/:multiple","line":0,"title":"Error messages don't guide user to fix the problem","description":"Actionable error messages reduce support burden and user frustration, especially for daily-use apps","recommendation":"","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Error handling shows generic messages like Something went wrong or An error occurred","sources":[],"merged_from":[]}
{"source_id":"audit:hash-SW5jb25zaXN0","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-content.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"components/meetings/:multiple","line":0,"title":"Inconsistent terminology - meeting vs session vs appointment","description":"Inconsistent terminology confuses users and makes the app feel less professional","recommendation":"","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Multiple terms for same concept found across meeting-related components","sources":[],"merged_from":[]}
{"source_id":"audit:hash-Q29uZmlybWF0","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-content.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"components/:multiple","line":0,"title":"Confirmation dialogs lack specific consequences","description":"Users need to understand consequences before destructive actions, especially for personal recovery data","recommendation":"","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Confirmation dialogs found with generic Are you sure? messaging","sources":[],"merged_from":[]}
{"source_id":"audit:hash-TG9hZGluZyB0","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-content.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"app/:multiple","line":0,"title":"Loading text inconsistency - Loading... vs Fetching vs spinner only","description":"Consistent loading patterns create a more cohesive, polished user experience","recommendation":"","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Multiple loading text variants found across app and component directories","sources":[],"merged_from":[]}
{"source_id":"audit:hash-RGF0ZSBmb3Jt","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-content.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"components/:multiple","line":0,"title":"Date formats inconsistent across the app","description":"Inconsistent date formats reduce readability and make the app feel unpolished","recommendation":"","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Multiple date formatting approaches found across components and lib files","sources":[],"merged_from":[]}
{"source_id":"audit:hash-U3VjY2VzcyBm","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-content.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"components/:multiple","line":0,"title":"Success feedback messages too brief","description":"Contextual success messages confirm the user's action and build confidence that the right thing was saved","recommendation":"","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Toast notifications with minimal text observed in form submission handlers","sources":[],"merged_from":[]}
{"source_id":"audit:hash-Q29uc29saWRh","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-architecture.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"components/mood-selector.tsx:1","line":0,"title":"Consolidate duplicate mood selector components - 3 implementations with diverging mood options","description":"Duplicate components diverge over time, creating inconsistent user experience and tripling the maintenance burden for mood-related features","recommendation":"","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"3 mood selector implementations found with different emoji sets across components/","sources":[],"merged_from":[]}
{"source_id":"audit:hash-RXh0cmFjdCBt","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-architecture.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"components/meetings/meeting-form.tsx:1","line":0,"title":"Extract meeting time parsing logic - ~80 lines duplicated between 2 files","description":"Duplicated parsing logic is a bug magnet - fixes applied to one copy but not the other create subtle inconsistencies","recommendation":"","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"~80 lines of time parsing duplicated between 2 meeting component files","sources":[],"merged_from":[]}
{"source_id":"audit:hash-TWlncmF0ZSB1","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-architecture.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"hooks/useAuth.ts:1","line":0,"title":"Migrate useAuth consumers to focused hooks - 16 components still using deprecated hook","description":"Focused hooks prevent unnecessary re-renders when only user or only todayLog changes, improving perceived performance especially on mobile","recommendation":"","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"16 components import useAuth vs 2 using focused hooks. Auth context is split into AuthProvider (stable) and TodayLogProvider (volatile)","sources":[],"merged_from":[]}
{"source_id":"audit:hash-RXh0cmFjdCBj","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-architecture.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"components/journal/journal-entry-form.tsx:1","line":0,"title":"Extract common form state logic - ~150 lines of duplicate submission handling","description":"Reduces boilerplate in form components and ensures consistent error handling and user feedback patterns","recommendation":"","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"~150 lines of similar submission handling found across 3+ form components","sources":[],"merged_from":[]}
{"source_id":"audit:hash-Q3JlYXRlIGJh","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-architecture.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"components/features/index.ts:1","line":0,"title":"Create barrel exports for component directories - only 1 exists","description":"Cleaner imports improve code readability and make refactoring easier since internal file moves don't break external imports","recommendation":"","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Only 1 barrel export found. 38 default exports vs 69 named exports showing no consistent convention","sources":[],"merged_from":[]}
{"source_id":"audit:hash-Q29sbG9jYXRl","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-architecture.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"components/quotes/:1","line":0,"title":"Collocate related quote components - 3 variants scattered across 2 directories","description":"Scattered related components make it harder to understand the full quote feature surface area and increase risk of unintentional divergence","recommendation":"","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"3 quote variants found across 2 directories","sources":[],"merged_from":[]}
{"source_id":"audit:hash-U3RhbmRhcmRp","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-architecture.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"components/:multiple","line":0,"title":"Standardize export style - 38 default vs 69 named exports with no convention","description":"Consistent exports improve IDE support (auto-imports work better with named exports) and prevent the common default-export renaming issue","recommendation":"","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"38 default exports vs 69 named exports found across components/","sources":[],"merged_from":[]}
{"source_id":"audit:hash-dXNlRGFpbHlR","source_file":"docs\\audits\\single-session\\enhancements\\audit-2026-02-11\\stage-1-architecture.jsonl","original_id":null,"category":"code-quality","severity":"S2","type":"code-smell","file":"hooks/useDailyQuote.ts:1","line":0,"title":"useDailyQuote hook has smart module-level caching preventing duplicate fetches","description":"Prevents unnecessary API calls and ensures consistent data across components","recommendation":"","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Module-level cache variable in useDailyQuote.ts shared across 3 consumers","sources":[],"merged_from":[]}
{"source_id":"audit:hash-Q3Jvc3MtY3V0","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-3b-cross-cutting.jsonl","original_id":null,"category":"ai-optimization","severity":"S1","type":"code-smell","file":".claude/settings.json","line":0,"title":"Cross-cutting: Hook process spawn explosion — 10+ Node.js processes per tool use across all hook domains","description":"The single most impactful architectural issue: every Write spawns 10 processes, every Edit spawns 9, every Read spawns 3, every UserPromptSubmit spawns 4. This is 26+ process spawns per edit-read-prompt cycle. At ~40ms cold-start each, that is over 1 second of pure process overhead per interaction cycle. Connects findings: 2a::posttooluse-write::10-sequential-hooks, 2a::posttooluse-edit::9-sequential-hooks, 2a::posttooluse-read::redundant-state-tracking, 2a::userpromptsubmit::4-hooks-every-message, 2a::posttooluse::duplicate-file-reads, 2d::write-hook-overload, 2d::read-hook-overhead.","recommendation":"Consolidate into 3 unified hook entry points: (1) post-tool-use-write-edit.js for all Write/Edit/MultiEdit checks, (2) context-monitor.js for all Read tracking, (3) user-prompt-handler.js for all UserPromptSubmit logic. Each reads target file once, runs all checks in-process, shares state. Reduces 26 spawns to 3 per cycle.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Tm8gYXV0b21h","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-3a-automation-gaps.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/SKILL_INDEX.md","line":0,"title":"No automated SKILL_INDEX.md sync — 9 orphaned skills discovered manually","description":"Stage 2b found 9 skills missing from SKILL_INDEX.md and 2 duplicate listings. There is no pre-commit hook or CI check that validates SKILL_INDEX.md matches the filesystem. New skills can be added without updating the index indefinitely.","recommendation":"Create scripts/check-skill-index.js that scans .claude/skills/*/SKILL.md directories and validates every directory has a SKILL_INDEX.md entry with no duplicates. Add to pre-commit hook chain after doc-index check.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Tm8gcHJlLWNv","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-3a-automation-gaps.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/skills/audit-process/SKILL.md","line":0,"title":"No pre-commit check for FALSE_POSITIVES.jsonl integration in audit skills","description":"Stage 2b found audit-process and audit-enhancements do not reference FALSE_POSITIVES.jsonl, meaning they re-report known false positives. No CI or hook check validates that all audit skills integrate with the false-positives exclusion list.","recommendation":"Add a check to scripts/check-skill-index.js (or new script) that greps each audit-*/SKILL.md for FALSE_POSITIVES.jsonl reference. Fail if any audit skill lacks it. Add to pre-commit chain.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U2Vzc2lvbi1l","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-3a-automation-gaps.jsonl","original_id":null,"category":"ai-optimization","severity":"S1","type":"code-smell","file":".claude/hooks/.session-state.json","line":0,"title":"Session-end cleanup is practically dead code — needs migration to session-start","description":"Stage 2e found 166 session begins vs 16 session ends (10:1 ratio). All state cleanup logic in session-end step 6 is effectively dead code since it runs in <10% of sessions. Temp files, ephemeral state, stale tasks, and JSONL rotation all depend on session-end which almost never runs.","recommendation":"Move all critical cleanup operations from session-end step 6 to session-start.js: (1) remove stale temp files, (2) prune old task states, (3) clean ephemeral agent tracking files, (4) check JSONL sizes and rotate if needed. Session-end becomes optional nice-to-have, not a critical cleanup dependency.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Y29tbWl0LWxv","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2e-memory-state.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/state/commit-log.jsonl","line":0,"title":"commit-log.jsonl has no rotation/size-cap logic (39KB, append-only)","description":"commit-log.jsonl is append-only with no rotation, archival, or size-cap logic. At 39KB after ~10 days of use, it will grow unbounded over months. STATE_SCHEMA.md explicitly notes 'Append-only. No automatic cleanup.' The handoff.json pre-compaction save embeds the FULL commitLog array (currently 15+ entries with filesList arrays), amplifying the bloat.","recommendation":"Add rotation logic to commit-tracker.js: when line count exceeds 500, archive older entries to commit-log.archive.jsonl and truncate to most recent 200. Alternatively, add a prune step to session-end that keeps only the last 30 days of entries.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-aGFuZG9mZi5q","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2e-memory-state.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/state/handoff.json","line":0,"title":"handoff.json embeds full commitLog array (25KB, unbounded growth)","description":"handoff.json is 25KB, with the commitLog array consuming most of that space. Each commit entry includes a filesList array of up to 30 paths. pre-compaction-save.js copies the entire commit-log.jsonl into handoff.json on every compaction. This duplicates data and makes handoff.json grow proportionally to total commit history.","recommendation":"In pre-compaction-save.js, limit commitLog to the last 15 entries (most recent session's commits). The full history remains in commit-log.jsonl for gap detection. compact-restore.js only needs recent context, not full history.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-cmV2aWV3cy5q","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2e-memory-state.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/state/reviews.jsonl","line":0,"title":"reviews.jsonl has no rotation (19KB, 30+ entries, threshold is 50)","description":"STATE_SCHEMA.md recommends 'Archive recommended at >50 entries' but no code implements this archival. Currently at ~30 entries (19KB). Each entry contains patterns and learnings arrays. At current review velocity (~10/session), the 50-entry threshold will be hit within 2 sessions.","recommendation":"Add rotation logic to the consolidation script or session-end: when reviews.jsonl exceeds 50 lines, archive entries older than consolidation.lastConsolidatedReview to reviews.archive.jsonl.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-d2FybmVkLWZp","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2e-memory-state.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/state/warned-files.json","line":0,"title":"warned-files.json grows unbounded (4KB, 48 entries, no expiry)","description":"warned-files.json tracks file::pattern combos that have been warned. Entries accumulate indefinitely with no expiry or cleanup. Currently 48 entries at 4KB. As more files are scanned and patterns added, this will grow linearly. Old entries for deleted files or resolved patterns waste space and could cause false graduation to blocking.","recommendation":"Add expiry logic to check-pattern-compliance.js: remove entries older than 30 days or where the referenced file no longer exists. Run cleanup at the start of each pattern check.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-dGFzay1hdWRp","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2e-memory-state.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/state/task-audit-template-overhaul.state.json","line":0,"title":"task-audit-template-overhaul.state.json is stale (7 days, all steps pending)","description":"This task state file was last updated 2026-02-07, all 6 steps show 'pending' status, yet the audit template overhaul was completed (commit 360f714 on 2026-02-07). The session-end cleanup only removes task state files if no tasks are in_progress, but this file has status 'planned' (not 'in_progress'), so it persists. The handoff.json also embeds this stale state in taskStates, wasting space.","recommendation":"Delete the stale file manually now. Fix session-end cleanup logic to also remove task files with status 'planned' that are older than 7 days, or where all steps are 'pending' and lastUpdated is >3 days old.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-b3ZlcnJpZGUt","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2e-memory-state.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/override-log.jsonl","line":0,"title":"override-log.jsonl has no rotation or size cap","description":"override-log.jsonl is append-only with no rotation logic. Currently small (5 entries) but will grow unbounded over time. Unlike commit-log.jsonl which at least has documentation noting the gap, override-log.jsonl has no size management mentioned anywhere.","recommendation":"Add rotation in log-override.js: when entries exceed 100, archive older entries. Alternatively, add to session-end cleanup to prune entries older than 90 days.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-YWdlbnQtaW52","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2e-memory-state.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/state/agent-invocations.jsonl","line":0,"title":"agent-invocations.jsonl has no rotation or size cap","description":"agent-invocations.jsonl is append-only with no cleanup logic. Currently tiny (1 entry, 123 bytes) but designed to log every agent invocation. With increased agent usage, this will accumulate rapidly. No rotation, archival, or session-based cleanup exists.","recommendation":"Add size-cap logic to track-agent-invocation.js: if file exceeds 200 lines, truncate to most recent 100. Or add to session-end cleanup.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-dmVsb2NpdHkt","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2e-memory-state.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/state/velocity-log.jsonl","line":0,"title":"velocity-log.jsonl has malformed sprint field data","description":"All 5 entries in velocity-log.jsonl have a malformed sprint field containing what appears to be a full markdown table row instead of a sprint name (e.g., 'M1 - Foundation** | Complete | 100% | Foundation | P0 | - |'). The regex parsing in track-session.js is capturing too much from ROADMAP.md. This corrupts velocity analytics and trend calculations.","recommendation":"Fix the sprint extraction regex in track-session.js to capture only the sprint name (e.g., 'M1 - Foundation'). Retroactively fix existing entries or delete and re-seed the file.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-LmNsYXVkZS90","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2e-memory-state.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/tmp-alerts.json","line":0,"title":".claude/tmp-alerts.json persists across sessions (temp file not cleaned up)","description":"tmp-alerts.json is an untracked temporary file that persists across sessions. It appears in git status as untracked. session-end cleanup does not remove it. Temp files should be cleaned up after use or on session start.","recommendation":"Add cleanup of .claude/tmp-*.json to session-end step 6 or session-start.js. The alerts script should use a proper temp directory or clean up after itself.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-c2Vzc2lvbi1l","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2e-memory-state.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/skills/session-end/SKILL.md","line":0,"title":"session-end does not clean .session-agents.json or .agent-trigger-state.json","description":"session-end step 4 reads .session-agents.json and .agent-trigger-state.json for compliance review but never deletes them. Step 6 only removes pending-reviews.json and conditionally handoff.json. These ephemeral state files should be cleaned up at session end to prevent stale data from affecting the next session's agent tracking.","recommendation":"Add rm -f commands in session-end step 6 for .claude/hooks/.session-agents.json and .claude/hooks/.agent-trigger-state.json after the compliance review is complete.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-TUVNT1JZLm1k","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2e-memory-state.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":"C:\\Users\\jason\\.claude\\projects\\C--Users-jason-Workspace-dev-projects-sonash-v0\\memory\\MEMORY.md","line":0,"title":"MEMORY.md is within size limits but contains completed/stale entries","description":"MEMORY.md contains entries marked as 'COMPLETE' (Multi-AI Audit Skill Evaluation) that no longer need to occupy memory space. The 'eval wrappers removed' note is historical context that could be archived. At ~55 lines the file is well within the 200-line limit, but proactive cleanup prevents accumulation. The currentDate entry (2026-02-14) also needs manual updating.","recommendation":"Remove the completed Multi-AI Audit Skill Evaluation section. The currentDate field should be set automatically rather than manually maintained.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-LnNlc3Npb24t","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2e-memory-state.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/.session-state.json","line":0,"title":".session-state.json shows 166 begins vs 16 ends (10:1 ratio)","description":"The session state shows 166 session begins but only 16 session ends, a 10:1 ratio. This means ~90% of sessions end without running session-end, which means state cleanup (step 6) almost never runs. All the cleanup issues identified in this audit are compounded by the fact that session-end is rarely executed. State files accumulate because the cleanup mechanism is practically never triggered.","recommendation":"Add lightweight automatic cleanup to session-start.js that runs the critical cleanup steps (remove stale temp files, prune old task states, check JSONL sizes). This ensures cleanup happens even when session-end is skipped. Consider adding a session-start alert when begin/end ratio exceeds 5:1.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-c2Vzc2lvbi1i","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2d-context-optimization.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/session-begin/SKILL.md","line":0,"title":"session-begin SKILL.md reads ROADMAP.md (3164 lines) in full at every session start","description":"ROADMAP.md is 3164 lines. Reading it fully at session start consumes ~4K tokens of context window. Session-begin only needs the Active Sprint section (typically <100 lines). This happens every session, so cumulative token waste is significant.","recommendation":"Change session-begin Step 1 and Step 3 to read only the Active Sprint section of ROADMAP.md using offset/limit parameters (e.g., Read with limit:100 from the Active Sprint header). Add a grep-first pattern to find the section offset dynamically.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Y29tcGFjdC1y","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2d-context-optimization.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/hooks/compact-restore.js","line":0,"title":"compact-restore.js injects full recovery context (~30 lines) even when handoff is stale","description":"compact-restore.js always outputs the full recovery block to stdout (lines 122-155, ~30 lines) regardless of how old the handoff data is. If handoff.json is hours or days old (from a previous session), it injects irrelevant recovery context. There is no staleness check beyond displaying the age.","recommendation":"Add a staleness threshold (e.g., 60 minutes). If handoff.json is older than threshold, output a 1-line summary to stdout ('Stale handoff found (Xh ago) - run /session-begin for fresh context') instead of the full recovery block. Keep full output only for recent compactions.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-cHItcmV2aWV3","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2d-context-optimization.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/pr-review/SKILL.md","line":0,"title":"pr-review SKILL.md is 840 lines loaded entirely when skill is invoked","description":"At 840 lines, pr-review is one of the largest skill files. It includes detailed examples, anti-patterns, agent selection matrices, and error handling that consume ~10K tokens. Much of this (Steps 6.5 TDMS integration, Step 7.5 health check, future enhancements) is rarely needed in a single invocation.","recommendation":"Split pr-review SKILL.md into a core protocol (~300 lines covering Steps 0-5) and a reference section in a separate file (pr-review/REFERENCE.md) covering Steps 6-9, TDMS integration, and examples. The core file instructs to read REFERENCE.md only when reaching those steps.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-YXVkaXQtY29t","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2d-context-optimization.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-comprehensive/SKILL.md","line":0,"title":"audit-comprehensive SKILL.md is 854 lines loaded entirely for every comprehensive audit","description":"At 854 lines, audit-comprehensive is the largest skill file. It includes detailed stage instructions, recovery matrices, triage formulas, and version history. The recovery section (lines 716-752) and triage section (lines 559-654) are only needed in specific circumstances, not on every invocation.","recommendation":"Extract the Recovery section and Triage & Roadmap Integration section into separate reference files. The main SKILL.md should reference them with 'If context compacts, read audit-comprehensive/RECOVERY.md' and 'After TDMS intake, read audit-comprehensive/TRIAGE.md'.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-MTAgUG9zdFRv","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2d-context-optimization.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/settings.json","line":0,"title":"10 PostToolUse hooks fire on every Write operation creating cumulative latency","description":"Every Write tool invocation triggers 10 PostToolUse hooks sequentially: check-requirements, audit-s0s1-validator, pattern-check, component-size-check, firestore-write-block, test-mocking-validator, app-check-validator, typescript-strict-check, repository-pattern-check, agent-trigger-enforcer. Most of these produce 'ok' (no context injection) but each adds ~50-100ms latency. For sessions with 50+ writes, this adds 25-50 seconds of cumulative delay.","recommendation":"Consolidate domain-specific validators (firestore-write-block, test-mocking-validator, app-check-validator, typescript-strict-check, repository-pattern-check) into a single check-code-patterns.js hook that does file-path-based routing internally. This reduces 10 process spawns to 4-5 per Write. Each duplicate hook also has its own path parsing and security validation boilerplate.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-RWRpdCBhbmQg","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2d-context-optimization.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/settings.json","line":0,"title":"Edit and MultiEdit hook lists are identical 9-hook copies of Write hooks","description":"The Edit and MultiEdit PostToolUse hook arrays (settings.json lines 114-210) are near-exact copies of the Write hooks (minus audit-s0s1-validator). This triplicates configuration maintenance. When a hook is added or removed, all three sections must be updated. The settings.json file is 293 lines, with ~180 lines being duplicated hook definitions.","recommendation":"Use a single matcher pattern like '^(?i)(write|edit|multiedit)$' for the shared hooks, and keep Write-only hooks (audit-s0s1-validator) in a separate Write-specific entry. This reduces settings.json by ~120 lines and eliminates sync drift risk.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-YWxlcnRzLXJl","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2d-context-optimization.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/alerts-reminder.js","line":0,"title":"alerts-reminder.js injects context-consuming messages on every UserPromptSubmit","description":"alerts-reminder.js runs on every UserPromptSubmit and outputs to stdout (console.log) which injects into Claude's context. When alerts exist and context threshold is exceeded, it injects 3-4 lines per user message. Over a session with 30+ user messages, this adds ~100 lines of repeated 'ALERTS: N pending' and 'CONTEXT: N files read' text to the conversation context.","recommendation":"Add a cooldown mechanism: only inject context-consuming alert text once per 10 minutes (or once per session). Use a state file to track last injection time. Subsequent prompts within the cooldown should output to stderr (user-visible) instead of stdout (context-consuming).","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-YW5hbHl6ZS11","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2d-context-optimization.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/hooks/analyze-user-request.js","line":0,"title":"analyze-user-request.js high-confidence matches inject directive into context on every match","description":"When analyze-user-request.js matches a high-confidence pattern (e.g., any mention of 'bug', 'broken', 'css', 'tailwind'), it injects a PRE-TASK directive to stdout. This happens on every matching UserPromptSubmit. In a debugging session, every message mentioning 'bug' reinjects 'PRE-TASK: MUST use systematic-debugging skill FIRST' consuming context tokens. The agent-trigger-enforcer already tracks this per-session.","recommendation":"Add session-level deduplication: track which directives have been emitted this session (via state file). Only inject to stdout on first occurrence per directive type. Subsequent matches should go to stderr or be suppressed entirely.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-MyBob29rcyBv","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2d-context-optimization.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/settings.json","line":0,"title":"3 hooks on every Read operation add latency without context benefit for most reads","description":"Every Read tool invocation triggers 3 PostToolUse hooks: large-context-warning.js, auto-save-context.js, and compaction-handoff.js. Each spawns a Node.js process, reads state files, and checks thresholds. For the first 15-20 reads in a session (before any threshold is hit), all 3 hooks do nothing but return 'ok'. In a typical session with 30+ reads, the first 15 reads each spawn 3 unnecessary processes.","recommendation":"Consolidate the 3 Read hooks into a single context-monitor.js hook that handles all tracking, warnings, auto-save, and handoff preparation in one process spawn. This reduces per-Read overhead from 3 process spawns to 1, and shares state file reads.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Y29kZS1yZXZp","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2d-context-optimization.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/skills/code-reviewer/SKILL.md","line":0,"title":"code-reviewer SKILL.md contains generic boilerplate not specific to this project","description":"code-reviewer SKILL.md is 313 lines, of which ~150 lines (sections: Tech Stack, Development Workflow, Common Commands, Troubleshooting) are generic boilerplate mentioning Python, Docker, Kubernetes, PostgreSQL, Flutter, etc. that are not part of this project's stack. This wastes ~2K tokens of context with irrelevant information every time the code-reviewer skill is invoked.","recommendation":"Remove generic boilerplate sections (Tech Stack generic list, Development Workflow generic setup, Common Commands generic docker/k8s, Troubleshooting generic). Keep only the SoNash-specific Script Checklist (lines 188-204) and the project-relevant review guidance. Target: under 200 lines.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-TUNQIGdpdCBz","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2c-mcp-config.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".mcp.json","line":0,"title":"MCP git server configured but unused and redundant with native Bash git","description":"The git MCP server is configured in .mcp.json but (a) not listed in enabledMcpjsonServers, (b) has zero references in any skill or hook, and (c) duplicates native git CLI via Bash. It adds startup overhead if ever enabled and creates confusion about which git interface to use.","recommendation":"Remove the 'git' entry from .mcp.json mcpServers since all git operations use Bash(git ...) natively.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-TUNQIG1lbW9y","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2c-mcp-config.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".mcp.json","line":0,"title":"MCP memory server configured but not enabled — 3 skills have dead mcp__memory__ code paths","description":"The memory server is in .mcp.json but missing from enabledMcpjsonServers in settings.local.json. Three skills (save-context, audit-enhancements, pr-retro) reference mcp__memory__ tools that will silently fail. Either enable it or remove dead references.","recommendation":"Decision needed: (1) Add 'memory' to enabledMcpjsonServers if memory persistence is wanted, OR (2) Remove mcp__memory__ references from the 3 skills and delete the memory entry from .mcp.json.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-TUNQIGZpbGVz","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2c-mcp-config.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".mcp.json","line":0,"title":"MCP filesystem server duplicates native Claude Code Read/Write/Glob/Grep tools","description":"The filesystem MCP server provides list_directory, read_file, directory_tree etc. but Claude Code has native Read, Write, Edit, Glob, Grep tools that are faster (no MCP serialization overhead) and more capable. The server consumes a process slot, adds startup latency, and 7 filesystem MCP tools are pre-approved in settings.local.json permissions despite zero skill references.","recommendation":"Remove 'filesystem' from .mcp.json and enabledMcpjsonServers. Remove the 7 mcp__filesystem__* permission entries from settings.local.json. Use native Read/Write/Glob/Grep instead.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-TUNQIGdpdGh1","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2c-mcp-config.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/settings.local.json","line":0,"title":"MCP github server enabled but not configured in .mcp.json — likely plugin-only, redundant with gh CLI","description":"'github' is listed in enabledMcpjsonServers but has no entry in .mcp.json. It may work via the Claude plugin system, but zero skills reference mcp__github__ tools. All GitHub operations use gh CLI via Bash (gh pr view, gh run list, etc.). The enabled entry is either stale or redundant.","recommendation":"Remove 'github' from enabledMcpjsonServers since no skills use mcp__github__ tools and gh CLI covers all GitHub operations.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-NyBtY3BfX2Zp","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2c-mcp-config.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/settings.local.json","line":0,"title":"7 mcp__filesystem__ permissions approved in settings.local.json for unused server","description":"settings.local.json has 7 pre-approved mcp__filesystem__* permissions (list_directory, directory_tree, read_text_file, read_multiple_files, get_file_info, list_allowed_directories, list_directory_with_sizes inferred). These bloat the permissions list and could be confusing since native tools should be preferred.","recommendation":"Remove all mcp__filesystem__* entries from settings.local.json permissions.allow array.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-MyBtY3BfX3Nl","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2c-mcp-config.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/settings.local.json","line":0,"title":"3 mcp__serena__ permissions approved but serena is in disabledMcpjsonServers","description":"settings.local.json has 3 approved mcp__serena__ permissions (list_dir, get_current_config, activate_project) but serena is explicitly disabled in settings.json disabledMcpjsonServers. These permissions are dead entries that add clutter.","recommendation":"Remove all mcp__serena__* entries from settings.local.json permissions.allow array.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-TUNQIGdsb2Jh","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2c-mcp-config.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/mcp.global-template.json","line":0,"title":"MCP global template (.claude/mcp.global-template.json) includes puppeteer which conflicts with playwright","description":"The global MCP template suggests puppeteer for browser automation, but the project uses playwright MCP server for all browser testing (test-suite skill, 15+ tool references). If a user follows the template and installs both, they get two competing browser automation servers consuming resources.","recommendation":"Update mcp.global-template.json to suggest playwright instead of puppeteer, matching the actual project configuration.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-TUNQIGZpcmVi","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2c-mcp-config.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/settings.local.json","line":0,"title":"MCP firebase server enabled but not configured — may rely on plugin auto-discovery","description":"'firebase' is in enabledMcpjsonServers but has no entry in .mcp.json. Three mcp__firebase__ permissions exist in settings.local.json. If this relies on plugin auto-discovery it works but is fragile. If it is stale configuration from a removed server, it adds confusion.","recommendation":"Either add firebase server configuration to .mcp.json for explicit setup, or verify it works via plugin and document that dependency.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U2tpbGwgb3Zl","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2b-skill-architecture.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/sonarcloud-sprint/SKILL.md","line":0,"title":"Skill overlap: sonarcloud-sprint is superseded by sonarcloud","description":"sonarcloud skill explicitly states it consolidates sonarcloud-sprint, yet both still exist as separate skills. Users may invoke the older skill and miss newer capabilities (sync, resolve, status modes). Wastes context loading the wrong one.","recommendation":"Delete .claude/skills/sonarcloud-sprint/ directory and update SKILL_INDEX.md to list /sonarcloud with all modes","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-T3JwaGFuZWQg","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2b-skill-architecture.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/find-skills/SKILL.md","line":0,"title":"Orphaned skill: find-skills not in SKILL_INDEX.md","description":"find-skills exists in filesystem but is not listed in SKILL_INDEX.md. Users consulting the index will not discover it. The skill helps users find installable skills — ironic that it itself is unfindable.","recommendation":"Add find-skills to the Infrastructure & Setup category in SKILL_INDEX.md","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U0tJTExfSU5E","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2b-skill-architecture.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/skills/SKILL_INDEX.md","line":0,"title":"SKILL_INDEX.md claims 55 total skills but count is inaccurate","description":"Header claims 55 skills but filesystem has 56 directories, index has duplicate listings (code-reviewer, senior-fullstack), and 9 skills are missing from the index. Misleading metadata.","recommendation":"Recalculate: count unique skill directories, remove duplicates, add missing skills, update header count","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-QWdlbnQgcHJv","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2b-skill-architecture.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-process/SKILL.md","line":0,"title":"Agent prompts in audit-process lack CRITICAL RETURN PROTOCOL","description":"audit-process has 12+ Task() agent prompts that say 'Do NOT return findings as text' but lack the CRITICAL RETURN PROTOCOL ('Return ONLY: COMPLETE...'). Agents may return verbose summaries, bloating orchestrator context and risking overflow (Session #140 lesson).","recommendation":"Add 'Return ONLY: COMPLETE: [id] wrote N findings to [path]' to every Task() prompt in audit-process, matching the pattern used in doc-optimizer and audit-ai-optimization","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-RkFMU0VfUE9T","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2b-skill-architecture.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/skills/audit-process/SKILL.md","line":0,"title":"FALSE_POSITIVES.jsonl not referenced in audit-process or audit-enhancements","description":"audit-code, audit-security, audit-performance, audit-documentation, audit-refactoring, and audit-comprehensive all reference FALSE_POSITIVES.jsonl for exclusion. audit-process and audit-enhancements do not, meaning they will re-report known false positives every run.","recommendation":"Add FALSE_POSITIVES.jsonl loading step to Pre-Audit Setup in both audit-process and audit-enhancements","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-cHJlLWNvbW1p","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2b-skill-architecture.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/skills/pre-commit-fixer/SKILL.md","line":0,"title":"pre-commit-fixer agent prompts are generic category dispatches, not structured","description":"pre-commit-fixer spawns subagents for ESLint and pattern compliance fixes but references agent types generically ('debugger', 'code-reviewer', 'general-purpose') without structured prompts. Agents receive error output but no explicit fix-and-verify workflow.","recommendation":"Add structured prompt templates for each Category B fix type: include the error output, affected files, expected fix pattern, and verification command","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Y29tcGFjdGlv","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2a-hook-efficiency.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/compaction-handoff.js","line":0,"title":"compaction-handoff.js uses execSync (shell) instead of execFileSync for git commands","description":"compaction-handoff.js gitExec() uses execSync (which spawns a shell) instead of execFileSync (which calls git directly). Shell spawn adds ~20-50ms overhead per call. The function is called 5 times for git operations: rev-parse, log --oneline -1, diff --name-only, ls-files, diff --cached, log --oneline -10. This is both a performance issue and a security issue (shell injection risk via crafted branch names).","recommendation":"Change execSync to execFileSync with array arguments, matching the pattern already used in commit-tracker.js and pre-compaction-save.js. This is a simple find-and-replace: execSync('git rev-parse --abbrev-ref HEAD') becomes execFileSync('git', ['rev-parse', '--abbrev-ref', 'HEAD']).","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-YWdlbnQtdHJp","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2a-hook-efficiency.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/hooks/agent-trigger-enforcer.js","line":0,"title":"agent-trigger-enforcer.js loads external config via require() on every invocation","description":"agent-trigger-enforcer.js calls loadConfigWithRegex('agent-triggers') which reads and parses a JSON file from disk, then recursively converts regex descriptor objects to RegExp instances. This happens on every Write, Edit, and MultiEdit operation. While Node.js caches require(), the loadConfig function always re-reads from disk since it uses fs.readFileSync directly rather than require().","recommendation":"Cache the parsed config in-memory by using require() for the JSON file instead of fs.readFileSync, or add a module-level cache with a file mtime check. Better yet, if hooks are consolidated into a single process, this config only needs to be loaded once.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-bGFyZ2UtY29u","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2a-hook-efficiency.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/hooks/large-context-warning.js","line":0,"title":"large-context-warning.js reads entire file just to count lines","description":"large-context-warning.js reads the entire file content with fs.readFileSync then splits by newline to count lines. For large files (the exact ones this hook is designed to warn about), this can be slow and memory-intensive. A 5000-line file could be several hundred KB.","recommendation":"Use fs.statSync to get file size and estimate line count (average ~40-80 bytes per line for code files), or read only the first N bytes to count newlines. Alternatively, use a streaming approach with fs.createReadStream to count newlines without loading the entire file into memory.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-VXNlclByb21w","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2a-hook-efficiency.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/alerts-reminder.js","line":0,"title":"UserPromptSubmit: 4 hooks run on every user message including heavy regex matching","description":"Every user message triggers 4 separate Node.js process spawns. analyze-user-request.js constructs multiple RegExp objects dynamically per invocation for word boundary matching. plan-mode-suggestion.js tests 20+ regex patterns against the user message. alerts-reminder.js reads 4 separate JSON files from disk. Total overhead is ~200-400ms per user message.","recommendation":"Consolidate into a single user-prompt-handler.js. Read all necessary state files once. Run all pattern matching in a single pass. The four hooks have zero dependencies on each other and could trivially be combined into sequential function calls in one process.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-cHJlLWNvbXBh","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2a-hook-efficiency.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/hooks/pre-compaction-save.js","line":0,"title":"pre-compaction-save.js calls 7 git subprocess operations sequentially","description":"pre-compaction-save.js gatherGitContext() calls execFileSync 7 times sequentially for: rev-parse, log -1, log -15, diff --name-only, diff --cached, ls-files, and another rev-parse. Each spawns a separate git process. While PreCompact is less frequent than PostToolUse, it adds unnecessary latency during compaction.","recommendation":"Combine git commands where possible. Use git status --porcelain=v2 to get staged, unstaged, and untracked files in a single call. Combine the two log commands into one (git log --oneline -15 subsumes git log --oneline -1). This reduces 7 calls to approximately 3.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-Y29tbWl0LXRy","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2a-hook-efficiency.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/hooks/commit-tracker.js","line":0,"title":"commit-tracker.js spawns 4 git subprocesses on commit detection","description":"When a commit is detected, commit-tracker.js calls gitExec 4 times: rev-parse HEAD, git log --format, rev-parse --abbrev-ref HEAD, and diff-tree. It also reads SESSION_CONTEXT.md to extract the session counter. While the fast-path regex bail-out is good (~1ms for non-commit commands), the commit detection path spawns 4 git processes sequentially.","recommendation":"Combine rev-parse HEAD and rev-parse --abbrev-ref HEAD into a single call using git log --format='%H%x1f%h%x1f%s%x1f%an%x1f%ad%x1f%D' which includes the ref names. This reduces from 4 to 2 git calls.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-cGF0dGVybi1j","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-2a-hook-efficiency.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/hooks/pattern-check.js","line":0,"title":"pattern-check.js calls fs.realpathSync twice (file and project dir)","description":"pattern-check.js calls fs.realpathSync on both the target file path and the project directory on every invocation. realpathSync resolves symlinks by making multiple OS calls. The project directory never changes within a session, so resolving it every time is wasteful. Combined with the statSync call, this is 3 synchronous filesystem metadata operations per hook invocation.","recommendation":"Cache the resolved project directory path. It could be computed once at module load time since it will not change. This saves one realpathSync call per invocation.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-TXVsdGktbGlu","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-1b-parsing-format.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/auto-save-context.js","line":0,"title":"Multi-line regex with greedy \\[\\s\\S\\]*? quantifier in auto-save-context.js","description":"Line 126 uses [\\s\\S]*? for multi-line markdown section matching — potential ReDoS on crafted input; should use line-by-line parsing per two-strikes rule","recommendation":"Replace regex with line-split parsing: split on \\n, find section start, scan until next ## or ---","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-SlNPTkwgbGlu","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-1b-parsing-format.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/hooks/session-start.js","line":0,"title":"JSONL line counting pattern repeated 5x without abstraction","description":".trim().split('\\n').filter(Boolean).length pattern repeated 5 times across hooks/scripts; a shared helper would reduce duplication and ensure consistent behavior","recommendation":"Extract to scripts/lib/count-jsonl-lines.js helper and import in all 5 locations","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U3RyaW5nIGNv","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-1b-parsing-format.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":"scripts/archive-doc.js","line":0,"title":"String concatenation for file paths instead of path.join","description":"Using filePath + '.tmp' and filePath + '.bak' instead of path operations; while unlikely to break on consistent OS, violates cross-platform safety patterns","recommendation":"Replace with path-based operations or template literals with documented intent","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-RnJhZ2lsZSBt","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-1b-parsing-format.jsonl","original_id":null,"category":"ai-optimization","severity":"S2","type":"code-smell","file":".claude/hooks/commit-tracker.js","line":0,"title":"Fragile markdown field parsing regex repeated across 3+ scripts","description":"Patterns like /Current Session Count(er)?.*:(\\d+)/i appear in 3+ scripts with slight variations; fragile to markdown formatting changes and duplicated maintenance burden","recommendation":"Extract to scripts/lib/parse-markdown-field.js with parseMarkdownField(content, fieldName) helper","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-SG9va3Mgb3V0","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-1b-parsing-format.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/hooks/auto-save-context.js","line":0,"title":"Hooks output decorative error messages instead of machine-readable format","description":"Hook console.error blocks use 5-12 line decorative formatting with borders and emoji for errors that are only machine-consumed; wastes tokens in conversation context","recommendation":"Use structured JSON stderr output for hook errors; reserve decorative output for user-facing messages only","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-VW51c2VkIGZp","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-1b-parsing-format.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":".claude/state/commit-log.jsonl","line":0,"title":"Unused fields in commit-log.jsonl state file","description":"authorDate and author fields in commit-log.jsonl entries are often null or unused by any consumer script; removing could reduce file size by 15-20%","recommendation":"Remove unused fields from commit-tracker.js output; verify no script reads these fields","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-VEVDSE5JQ0FM","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-1a-dead-assets.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":"docs/plans/TECHNICAL_DEBT_MANAGEMENT_SYSTEM_PLAN.md","line":0,"title":"TECHNICAL_DEBT_MANAGEMENT_SYSTEM_PLAN.md marked COMPLETE but still in active plans/","description":"Completed plan marked as '✅ COMPLETE - All 18 Phases Implemented' remains in active docs/plans/ directory instead of docs/archive/completed-plans/, adding clutter to active planning docs","recommendation":"Move to docs/archive/completed-plans/ and update any cross-references","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:hash-U0VTU0lPTl9I","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-14\\stage-1a-dead-assets.jsonl","original_id":null,"category":"ai-optimization","severity":"S3","type":"code-smell","file":"docs/SESSION_HISTORY.md","line":0,"title":"SESSION_HISTORY.md and SESSION_DECISIONS.md not in DOCUMENTATION_INDEX.md","description":"Two active documentation files exist in docs/ but are not tracked in the documentation index, making them invisible to automated doc tooling and cross-reference checks","recommendation":"Run npm run docs:index to regenerate DOCUMENTATION_INDEX.md, or add entries manually","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":[],"sources":[],"merged_from":[]}
{"source_id":"audit:OPT-F001","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-F001","category":"code-quality","severity":"S1","type":"code-smell","file":"/home/user/sonash-v0/ROADMAP.md","line":0,"title":"ROADMAP.md milestone tracking tables","description":"ROADMAP.md contains 270 lines of markdown tables tracking milestones, status, progress %, phases, and priorities. Large structure with frequent updates during sprint work.","recommendation":"Extract milestone data to milestones.jsonl with schema: {id, name, status, progress, phase, priority, items, relatedDocs}. Keep ROADMAP.md as narrative + embedded reference. Add npm script to sync ROADMAP.md from milestones.jsonl.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Sprint-focused: SESSION_CONTEXT.md reads ROADMAP.md to extract current priorities; scripts/velocity/track-session.js uses readFileSync on markdown; updated almost every session (Session #156 is latest); 270 table rows parsing fragile to formatting changes","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-F002","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-F002","category":"code-quality","severity":"S1","type":"code-smell","file":"/home/user/sonash-v0/docs/AUDIT_TRACKER.md","line":0,"title":"AUDIT_TRACKER.md audit log tables","description":"AUDIT_TRACKER.md contains 96 table rows tracking audit completion dates, commits covered, findings, and threshold reset status across 7 audit categories. Updated after each audit cycle (Session #143 shows 258 findings).","recommendation":"Extract to audits.jsonl with schema: {auditType, date, session, commitsCount, filesCount, findingsRaw, findingsUnique, findingsBySeverity, resetThreshold, relatedFile}. Create views by category and date for faster querying.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Directly queried by audit workflow; Expansion Evaluation Tracker cross-references audit status; Manual table maintenance error-prone (Session #116 showed date misalignment that had to be fixed); thresholds reset frequently","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-F003","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-F003","category":"code-quality","severity":"S1","type":"code-smell","file":"/home/user/sonash-v0/docs/EXPANSION_EVALUATION_TRACKER.md","line":0,"title":"EXPANSION_EVALUATION_TRACKER.md decision log with 280 ideas","description":"Tracks evaluation of ~280 expansion ideas across 21 modules (F1-F12, T1-T9) with decision logs, placement metadata, milestone assignments, insertion points, and relationships. Complex multi-session tracking document.","recommendation":"Extract decisions to decisions.jsonl with schema: {moduleId, ideaNum, title, decision, rationale, milestone, insertAfter, relationship, stagedDate, decidedInSession, tags}. Keep EXPANSION_EVALUATION_TRACKER.md as UI summary with aggregates. AI processes decisions.jsonl directly.","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"AI-intensive: /expansion-evaluation skill reads/writes this document; 280 items across 21 modules creates parsing overhead; Session #152 shows merging of IMS into TDMS — cross-document sync required; placement metadata mandatory for all items but stored inline as prose","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-F004","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-F004","category":"code-quality","severity":"S1","type":"code-smell","file":"/home/user/sonash-v0/docs/AUDIT_TRACKER.md","line":0,"title":"AUDIT_TRACKER.md threshold matrix and version history","description":"Contains 2 tables tracking threshold configuration (46 rows) and version history (12 rows). Thresholds reset after each audit; version history appended frequently.","recommendation":"Extract to thresholds.jsonl and versions.jsonl. Thresholds schema: {category, lastAudit, commitsSince, filesSince, triggerAt, resetScript}. Allows automation of threshold checks via npm scripts. Version history is append-only log.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"scripts/reset-audit-triggers.js manipulates thresholds but reads from markdown; Manual table updates (Session #143 added new category; Session #152 merged IMS); Version history now 260+ lines","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-F005","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-F005","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/docs/DOCUMENT_DEPENDENCIES.md","line":0,"title":"DOCUMENT_DEPENDENCIES.md sync status tracking","description":"Tracks 43 rows of template-instance relationships, sync status, and last-synced dates. Manual sync protocol requires regex parsing to detect drift (placeholder detection patterns).","recommendation":"Extract to doc-sync-status.jsonl with schema: {templatePath, instancePath, lastSynced, syncStatus, driftDetected, issuesFound}. Enhance scripts/check-document-sync.js to read/write this file. Enables automated validation with clear history.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"scripts/check-document-sync.js (Session #35) validates sync status using regex patterns; >90 day staleness checks require parsing markdown dates; Session #140 removed 6 archived instances — requires manual table cleanup; Session #144 shows drift detection complexity","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-F006","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-F006","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/SESSION_CONTEXT.md","line":0,"title":"SESSION_CONTEXT.md quick status table","description":"Contains 8-row status tracking table (lines 118-128) for track status (Operational Visibility, Track A/B/C, GRAND PLAN, milestones). Updated frequently at session start/end.","recommendation":"Extract to session-status.jsonl with schema: {item, status, progress, percent, lastUpdated, session}. Keep SESSION_CONTEXT.md <300 lines (current instruction). Allow automated session startup to read/write status atomically.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"SESSION_CONTEXT.md reads during every session (Session #156 latest); scripts/velocity/track-session.js explicitly reads this file via readFileSync; frequent updates (Session-to-session); 8 rows × 156 sessions = massive token overhead","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-F007","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-F007","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/docs/DOCUMENT_DEPENDENCIES.md","line":0,"title":"DOCUMENT_DEPENDENCIES.md cross-document update triggers matrix","description":"48-row trigger matrix (lines 309-342) mapping document changes to dependent documents. Used to coordinate cross-document sync but stored as markdown table.","recommendation":"Extract to doc-triggers.jsonl with schema: {sourceDoc, triggerCondition, targetDocs[], reason, enforced, blockingLevel}. Integrate into pre-commit hook to auto-warn on dependent document changes (currently 'Manual' enforcement in 35/48 rows).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Session #152 shows IMS merged into TDMS requiring widespread trigger updates; only 2/48 triggers are ✅ BLOCK enforced; 35 are Manual enforcement = high error rate; Pre-commit hook currently doesn't use this matrix","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-F008","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-F008","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/ROADMAP.md","line":0,"title":"ROADMAP.md detailed milestone specifications embedded","description":"ROADMAP.md contains narrative milestone details mixed with data (status, progress %, priority, items count). Detailed specifications for M1.5-M10 hardcoded inline with dependency references.","recommendation":"Create milestones-detail.jsonl with schema: {milestoneId, phase, priority, description, itemCount, dependencies[], risks[], successCriteria[], dependencies}. ROADMAP.md becomes curated narrative referencing milestones.jsonl data via embedded tables regenerated from data.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Session #151 shows ROADMAP_FUTURE.md manually split from ROADMAP.md; ROADMAP.md is 3164 lines, heavily cross-referenced; Expansion Evaluation Tracker references placement in ROADMAP but can't parse it reliably; dependencies[].blockedBy structure suggests structured data buried in prose","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-F009","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-F009","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/docs/PR_WORKFLOW_CHECKLIST.md","line":0,"title":"PR_WORKFLOW_CHECKLIST.md version history table","description":"Version history table (lines 443-447) tracking 3 versions with dates and changes. Append-only log stored as markdown.","recommendation":"Extract to doc-versions.jsonl (append-only) with schema: {doc, version, date, changes, author}. All documentation version history consolidates to single source. Enables automated change tracking per document.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Every document has version history table (PR_WORKFLOW_CHECKLIST.md, DOCUMENT_DEPENDENCIES.md, SESSION_CONTEXT.md, PLAN_MAP.md show pattern); Manual maintenance; Lines 240-260+ in many docs; Could be centralized","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-F010","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-F010","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/docs/EXPANSION_EVALUATION_TRACKER.md","line":0,"title":"EXPANSION_EVALUATION_TRACKER.md command reference table","description":"Command reference table (lines 81-99) documenting 11 commands with descriptions. Static reference data embedded as markdown.","recommendation":"Extract to .claude/skills/expansion-evaluation/commands.jsonl with schema: {command, subcommands[], parameters, description, example}. Centralize skill command documentation to single source; .claude/COMMAND_REFERENCE.md references it.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Duplicated in COMMAND_REFERENCE.md (Session #140 update adds expansion-evaluation skill); Single source of truth in skills/ directory reduces cross-sync burden; Complex sub-command taxonomy (accept/defer/reject/merge/discuss)","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-F011","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-F011","category":"code-quality","severity":"S3","type":"code-smell","file":"/home/user/sonash-v0/SESSION_CONTEXT.md","line":0,"title":"SESSION_CONTEXT.md recent session summaries","description":"3 session summaries (lines 82-112) capturing major work completed. Append-only archive with manual rotation to SESSION_HISTORY.md every session.","recommendation":"Extract to session-summaries.jsonl with schema: {sessionNum, date, title, workItems[], impact, nextSteps}. SESSION_CONTEXT.md reads latest 3 automatically. /session-end skill handles archive rotation. Centralize all session history.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Manual rotation (Session #149 shows archival from SESSION_CONTEXT to SESSION_HISTORY); 3-session limit = rotating window; /session-end explicitly handles this archival step; Could be automated","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-F012","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-F012","category":"code-quality","severity":"S3","type":"code-smell","file":"/home/user/sonash-v0/docs/PLAN_MAP.md","line":0,"title":"PLAN_MAP.md version history table","description":"Version history table (lines 228-242) tracking 14 versions. Append-only log with dates, descriptions, authors.","recommendation":"Extract to doc-versions.jsonl (see OPT-F009 for consolidation). PLAN_MAP.md can remove version history table entirely.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"All 30+ markdown files have version history tables; Centralized version tracking reduces duplication; Could be auto-generated from git history","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-F013","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-F013","category":"code-quality","severity":"S3","type":"code-smell","file":"/home/user/sonash-v0/docs/AI_REVIEW_LEARNINGS_LOG.md","line":0,"title":"AI_REVIEW_LEARNINGS_LOG.md large append-only learning journal (317KB)","description":"Large document (1587 lines, 317KB) containing review-level learning entries. Used by /pr-review skill but stored as markdown prose without structured extraction.","recommendation":"Parallel reviews.jsonl with schema: {reviewNum, prNum, date, category, finding, rationale, pattern, linkedDocs[], status}. Keep AI_REVIEW_LEARNINGS_LOG.md as human-readable summary; skill reads from structured reviews.jsonl for automation.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Scripts/add-false-positive.js references AI_REVIEW_LEARNINGS_LOG.md#review-NNN format in comments; Session #142 shows learnings being added; /pr-review skill processes learnings; 317KB markdown = massive token cost when read into context; Narrative prose harder to aggregate/cross-reference than structured data","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-F014","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-F014","category":"code-quality","severity":"S3","type":"code-smell","file":"/home/user/sonash-v0/ROADMAP_LOG.md","line":0,"title":"ROADMAP_LOG.md completed items history (31KB, 1,129 lines)","description":"Archive of completed milestones and features in markdown. Append-only log with dates, completion summaries, version history.","recommendation":"Create roadmap-history.jsonl (append-only) with schema: {completedItem, completedDate, milestone, summary, session, commits, impact}. ROADMAP_LOG.md becomes human-readable narrative referencing jsonl data. Allows automated timeline generation.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"1129 lines of append-only history; Used as reference for context but rarely updated (append-only); Could be auto-generated from milestone completion dates + commit history","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-S001","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-S001","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/scripts/ai-review.js","line":0,"title":"ai-review.js - Unused AI review prompt applicator","description":"Script applies specialized AI review prompts to different artifact types. Despite having security features (sensitive file detection), it is never invoked from package.json, workflows, hooks, skills, or documentation. Only historical archive references exist in REVIEWS_42-60.md.","recommendation":"Either add npm script entry or remove. If planned for future AI-driven reviews, add to DEVELOPMENT.md with clear invocation pattern.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Not found in package.json, .claude/settings.json, .github/workflows/*.yml, .husky/*, or skill references. Only archive mentions of past security reviews.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-S002","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-S002","category":"code-quality","severity":"S3","type":"code-smell","file":"/home/user/sonash-v0/scripts/check-review-triggers.sh","line":0,"title":"check-review-triggers.sh - Dead shell script for multi-AI triggers","description":"Bash script checks git commit/file counts to determine if code review triggers are active. Appears to duplicate functionality of check-triggers.js (which IS referenced in package.json). Script prints colored output to console but has no output targets.","recommendation":"Remove in favor of the active check-triggers.js npm script. Consolidate shell logic into Node.js for consistency.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"check-triggers.js is referenced in package.json as 'npm run triggers:check'. This .sh file is never called from any configuration or workflow.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-S003","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-S003","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/scripts/create-canonical-findings.js","line":0,"title":"create-canonical-findings.js - Unused canonical findings generator","description":"Script converts net-new findings from docs/aggregation/net-new-findings.jsonl into canonical format with ROADMAP placement mapping. References deprecated ROADMAP_INTEGRATION logic. 340 lines with clear purpose but never executed.","recommendation":"Add to package.json scripts if part of audit pipeline (e.g., 'npm run canon:create'), or consolidate into aggregate-audit-findings.js workflow. Currently blocks on file that depends on aggregate-audit-findings.js output.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Referenced in no npm scripts, workflows, or hooks. audit/validate-audit-integration.js mentions 'aggregate-audit-findings.js' but not create-canonical-findings.js.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-S004","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-S004","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/scripts/generate-pending-alerts.js","line":0,"title":"generate-pending-alerts.js - Unused session-start alert generator","description":"Script scans AI_REVIEW_LEARNINGS_LOG.md and AUDIT_FINDINGS_BACKLOG.md for DEFERRED/S1+ items to write pending-alerts.json for Claude session start. Functional but never called. Depends on legacy backlog files (now archived to MASTER_DEBT.jsonl).","recommendation":"Either add to session-start hook or remove. If needed for alerts, update file paths to use MASTER_DEBT.jsonl instead of archived AUDIT_FINDINGS_BACKLOG.md.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Not referenced in package.json, workflows, or .claude/settings.json hooks. Mentioned in skill markdown but not as actual command invocation.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-S005","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-S005","category":"code-quality","severity":"S3","type":"code-smell","file":"/home/user/sonash-v0/scripts/generate-placement-report.js","line":0,"title":"generate-placement-report.js - Unused roadmap placement suggester","description":"Reads net-new findings from docs/aggregation/net-new-findings.jsonl and generates roadmap placement suggestions in NET_NEW_ROADMAP_PLACEMENT.md. Depends on external file that may or may not exist. Complements create-canonical-findings.js.","recommendation":"Remove or consolidate into create-canonical-findings.js. If placement suggestions are valuable, add explicit npm script and document workflow.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"No references in any configuration, npm scripts, workflows, hooks, or documentation. Depends on aggregation pipeline output but has no consumer.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-S006","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-S006","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/scripts/migrate-existing-findings.js","line":0,"title":"migrate-existing-findings.js - Unused legacy findings migration tool","description":"One-time migration script to move ROADMAP findings to canonical location (docs/audits/canonical/MASTER_FINDINGS.jsonl). References obsolete file structures (REFACTOR_BACKLOG.md). Clear one-off purpose but permanently left in codebase.","recommendation":"Move to docs/archive/scripts/ or remove entirely. One-time migration utilities should be archived after successful migration to prevent accidental re-runs.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Never called from npm scripts, workflows, or hooks. Clear 'Session #116' marker indicates one-time use.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-S007","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-S007","category":"code-quality","severity":"S3","type":"code-smell","file":"/home/user/sonash-v0/scripts/redeploy-admin-dashboard.sh","line":0,"title":"redeploy-admin-dashboard.sh - Firebase deployment helper for admin functions","description":"Shell script for deleting and redeploying admin dashboard Cloud Functions (adminHealthCheck, adminGetDashboardStats) to ensure clean App Check configuration. Hardcoded to 'sonash-app' Firebase project. 20 lines.","recommendation":"Either parameterize Firebase project and add to npm scripts, or document as manual troubleshooting tool with clear prerequisites.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Not in package.json, workflows, .husky/, or any configuration. Appears to be manual maintenance script left behind after deployment debugging.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-S008","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-S008","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/scripts/regenerate-findings-index.js","line":0,"title":"regenerate-findings-index.js - Unused canonical findings index rebuilder","description":"Reads MASTER_FINDINGS.jsonl and regenerates MASTER_FINDINGS_INDEX.md with severity/category grouping. ~80 lines with clear, single-purpose functionality. Related to Session #116 canonicalization but never invoked in workflows.","recommendation":"Add to npm scripts (e.g., 'npm run canon:index') or consolidate into debt management workflow. If MASTER_FINDINGS.jsonl is auto-updated, add regenerate-findings-index to post-intake hooks.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"No references in package.json npm scripts, workflows, or hooks. Appears to be utility for canonical audit system that was never wired into automation.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-S009","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-S009","category":"code-quality","severity":"S3","type":"code-smell","file":"/home/user/sonash-v0/scripts/seed-commit-log.js","line":0,"title":"seed-commit-log.js - One-time commit log backfill utility","description":"One-time script to initialize .claude/state/commit-log.jsonl with recent git commits for commit tracking system. Self-documenting with clear 'only run once' semantics. Part of Session #138 state persistence setup.","recommendation":"Document as one-time setup script in DEVELOPMENT.md or move to docs/setup/. No need to run again unless --force is used. Safe to leave but consider archiving.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Not in npm scripts, workflows, or hooks. Self-identifies as 'one-time backfill utility' with guard against double-execution.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-S010","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-S010","category":"code-quality","severity":"S1","type":"code-smell","file":"/home/user/sonash-v0/scripts/sync-claude-settings.js","line":0,"title":"sync-claude-settings.js - Unused Claude Code settings synchronization utility","description":"Syncs Claude Code settings between local ~/.claude/ and repository .claude/ for cross-platform portability. 508 lines with --export, --import, --diff flags. REFERENCED IN DOCUMENTATION but never called from automation. Listed in DEVELOPMENT.md table but not in package.json scripts. Users expected to run manually.","recommendation":"Add npm script entry 'npm run settings:sync' with sensible default (--diff or --import). Or remove from codebase if manual invocation via 'node scripts/...' is sufficient. Currently confusing: documented but not in package.json scripts.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Referenced 3 times in DEVELOPMENT.md (lines mentioning '--import', '--export', '--diff') but NOT in package.json npm scripts section or any workflow/hook. Creates user confusion about how to invoke.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-S011","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-S011","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/scripts/update-legacy-lines.js","line":0,"title":"update-legacy-lines.js - Unused legacy findings line number updater","description":"One-time script to backfill line numbers for legacy findings (DEDUP-XXXX, EFF-XXX, PERF-XXX, M-series IDs). Hardcoded mapping of 50+ finding IDs to file locations. Session #116 artifact, 100+ lines.","recommendation":"Move to docs/archive/scripts/ or remove. One-time canonicalization utility with no ongoing use. If legacy findings are still updated, consolidate logic into update script.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Not in any npm scripts, workflows, hooks. Hardcoded data suggests one-time execution completed in Session #116.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-H001","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-H001","category":"code-quality","severity":"S1","type":"code-smell","file":".claude/settings.json","line":0,"title":"Write/Edit/MultiEdit share 8 redundant hooks (~530ms overhead)","description":"Write, Edit, and MultiEdit tools execute nearly identical hook chains with 8 shared hooks (pattern-check, component-size-check, firestore-write-block, test-mocking-validator, app-check-validator, typescript-strict-check, repository-pattern-check, agent-trigger-enforcer). Only difference: Write uses check-write-requirements (test-first) vs Edit/MultiEdit use check-edit-requirements (security-first). This causes ~530ms latency on every file write operation.","recommendation":"Consolidate to single validation pipeline with tool-aware conditional logic. Create unified hook that checks file type once, then runs all applicable validators in sequence. Reuse file content across validators instead of re-reading.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Analyzed hook array definitions in settings.json. Each of Write/Edit/MultiEdit has identical command chains except first hook. Total cumulative time: pattern-check(100ms) + typescript-strict(100ms) + agent-trigger(100ms) + repository-pattern(80ms) + app-check(60ms) + firestore-block(50ms) + test-mocking(30ms) + component-size(10ms) = ~530ms per operation","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-H002","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-H002","category":"code-quality","severity":"S0","type":"code-smell","file":".claude/hooks/pattern-check.js","line":0,"title":"pattern-check.js spawns subprocess every Write/Edit/MultiEdit (~100ms latency)","description":"pattern-check.js runs spawnSync to execute scripts/check-pattern-compliance.js on EVERY Write/Edit/MultiEdit operation, adding 100ms latency. File has pre-filters (only runs on .js/.ts/.sh files >100 lines) but subprocess spawn is expensive. Non-blocking warning only.","recommendation":"Cache pattern checker state or use native regex validation for common patterns. Add session-level cache of recently-checked files. Skip re-validation on already-validated files this session. Consider moving to async hook if possible.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"pattern-check.js lines 181-186 show spawnSync call. Combined with agent-trigger-enforcer (100ms) and typescript-strict-check (100ms), every Write/Edit now incurs 300ms just from these three hooks","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-H003","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-H003","category":"code-quality","severity":"S1","type":"code-smell","file":".claude/hooks/check-write-requirements.js, .claude/hooks/check-edit-requirements.js","line":0,"title":"check-write-requirements vs check-edit-requirements duplication","description":"Two nearly identical hooks with different priority orders. check-write-requirements (Write only) checks tests first, then security. check-edit-requirements (Edit/MultiEdit) checks security first. Both perform identical path validation and file classification but in different order. Adds 10ms overhead per tool call.","recommendation":"Merge into single check-requirements.js hook that accepts tool parameter and applies correct priority. Use conditional branches for tool-specific behavior rather than duplicate files.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Both files implement identical security validation (lines 40-68 in both), identical file parsing (lines 20-32 in both), but differ only in priority order (security-first vs test-first)","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-H004","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-H004","category":"code-quality","severity":"S2","type":"code-smell","file":".claude/hooks/agent-trigger-enforcer.js","line":0,"title":"agent-trigger-enforcer.js runs on every code file edit with double-write overhead","description":"Runs on every Write/Edit/MultiEdit (100ms latency) to track file modifications and suggest agents. Loads config from disk every invocation. Uses double-write pattern: writes .claude/hooks/.agent-trigger-state.json AND potentially .claude/state/pending-reviews.json. Only matters for code files matching AGENT_TRIGGERS patterns, but runs unconditionally then does pattern matching.","recommendation":"Add early check for applicable agent patterns BEFORE reading state file. Cache AGENT_TRIGGERS config at hook initialization. Batch state writes: consolidate review queue write into single atomic operation instead of separate writeJson call.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Loads config at lines 34-43, reads state at line 189, writes at line 214, then reads/writes review queue at lines 258-321. For non-code files, could skip entire state read/write cycle.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-H005","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-H005","category":"code-quality","severity":"S2","type":"code-smell","file":".claude/hooks/large-context-warning.js, .claude/hooks/auto-save-context.js, .claude/hooks/compaction-handoff.js","line":0,"title":"Three Read hooks contend for .context-tracking-state.json state file","description":"large-context-warning.js, auto-save-context.js, and compaction-handoff.js all read/write .claude/hooks/.context-tracking-state.json on every Read operation. Multiple hooks doing atomic writes (temp file + rename) creates contention and potential race conditions. State resets if >30 minutes old (large-context-warning line 98).","recommendation":"Consolidate context tracking into single hook that: 1) reads state once, 2) updates all needed metrics, 3) writes once. Or create state-utils-based shared handler. Have large-context-warning handle reset logic for all three hooks.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"large-context-warning: lines 92-131 (read/write cycle), auto-save-context: lines 107-113 (read filesRead), compaction-handoff: lines 242-248 (read filesRead). All three do their own atomic write operations","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-H006","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-H006","category":"code-quality","severity":"S2","type":"code-smell","file":".claude/state/, .claude/hooks/","line":0,"title":"State file sprawl across .claude/hooks/ and .claude/state/","description":"10 separate state files created by hooks: 6 in .claude/hooks/ (.session-state, .context-tracking-state, .auto-save-state, .handoff-state, .commit-tracker-state, .agent-trigger-state) and 4 in .claude/state/ (handoff.json, pending-reviews.json, commit-log.jsonl, agent-invocations.jsonl). Some files only read/written by single hook (redundant). No schema documentation.","recommendation":"Consolidate single-use state files. Establish clear naming convention: .claude/state/ for session-surviving data (compaction-safe), .claude/hooks/ for ephemeral session state. Create state-schema.md documenting all state files, their consumers, and retention policy.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"agent-trigger-enforcer uses 2 state files, compaction-handoff reads 4 files, commit-tracker uses 2. Many files created but single-purposed (e.g., .auto-save-state.json only used by auto-save-context.js)","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-H007","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-H007","category":"code-quality","severity":"S2","type":"code-smell","file":".claude/hooks/component-size-check.js, firestore-write-block.js, test-mocking-validator.js, app-check-validator.js, typescript-strict-check.js, repository-pattern-check.js","line":0,"title":"validation hooks could share file read to reduce I/O","description":"Multiple validation hooks on Write/Edit/MultiEdit independently read file content: component-size-check, firestore-write-block, test-mocking-validator, app-check-validator, typescript-strict-check, repository-pattern-check all do fs.readFileSync on same file. Pattern-check also reads file. No caching between hooks.","recommendation":"Implement hook file cache: pass file content through hook environment or temp file. Or create composite validator hook that reads file once and runs all applicable validators. At minimum, share path validation results.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"6 hooks × fs.readFileSync per Write/Edit = significant I/O overhead. Each does similar path containment checks, file existence checks, and security validation before actual logic.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-H008","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-H008","category":"code-quality","severity":"S1","type":"code-smell","file":".claude/hooks/audit-s0s1-validator.js","line":0,"title":"audit-s0s1-validator.js only triggers on audit files but runs full validation on Write","description":"audit-s0s1-validator.js (lines 216-218) only processes docs/audits/*.jsonl files but is registered on PostToolUse Write hook, meaning it runs on every file write operation. Does JSON parsing of file argument and path matching checks (~10-15ms wasted) on ~99% of writes that don't match audit file pattern.","recommendation":"Create separate matcher condition in settings.json for audit files (similar to how Read, Bash, Task have matchers). Only register this hook when file path matches audit pattern. Or use very fast path-only check at top of hook before any other processing.","effort":"E3","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Hook does quick exit at line 218 for non-audit files, but all overhead (path normalization, argument parsing, linting checks) still happens. Runs on ~99% of writes unnecessarily.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-H009","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-H009","category":"code-quality","severity":"S1","type":"code-smell","file":".claude/hooks/large-context-warning.js, .claude/hooks/auto-save-context.js, .claude/hooks/compaction-handoff.js","line":0,"title":"Read hooks have no execution order guarantee - context tracking race condition potential","description":"large-context-warning, auto-save-context, and compaction-handoff run in arbitrary order on every Read. They all touch .context-tracking-state.json. If one fails/timeout, state could be corrupt or get reset by another hook. Large-context-warning resets state if >30min old (line 98), which could wipe data another hook just wrote.","recommendation":"Establish clear execution order (orchestrate in single hook or specify in settings). Have one hook be state authority that handles reset logic. Others read-only or use state-utils shared module. Document dependency order.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"large-context-warning lines 96-103 show potential reset. If large-context-warning runs after auto-save-context in some scenarios, it could reset context that was just saved. Atomic writes don't prevent logical race conditions.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-H010","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-H010","category":"code-quality","severity":"S3","type":"code-smell","file":".claude/hooks/commit-tracker.js","line":0,"title":"Bash hook (commit-tracker) does fast-path regex on every command but mostly bails (~1ms overhead)","description":"commit-tracker.js runs on every Bash command but uses COMMIT_COMMAND_REGEX (line 50) to bail out fast for non-commit commands. Estimated ~1ms overhead per Bash call for non-commit operations (regex + argument parsing). Non-critical since bail-out is very fast.","recommendation":"Move regex check to settings matcher instead of hook code. Create specific 'git commit' matcher rather than catching all Bash and bailing out. Would eliminate overhead entirely.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"commit-tracker.js line 157: 'if (!COMMIT_COMMAND_REGEX.test(command))' - regex test happens on every bash call even though mostly bails. Matcher in settings could avoid hook invocation entirely.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-H011","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-H011","category":"code-quality","severity":"S3","type":"code-smell","file":".claude/hooks/check-write-requirements.js, .claude/hooks/check-edit-requirements.js","line":0,"title":"check-write-requirements and check-edit-requirements could be unified with tool parameter","description":"Both hooks (106 lines each) contain ~95% identical code. Only difference is keyword priority order (test-first vs security-first). Could merge into single hook that accepts tool name parameter and applies correct priority matrix.","recommendation":"Create single unified hook: check-file-requirements.js. Accept tool parameter. Build priority array based on tool. Use loop through priority array instead of separate if-blocks for each type. Saves 1 file and reduces maintenance burden.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Lines 70-103 in both files show priority order is only real difference. Everything else (argument parsing, path validation, filename extraction) is identical.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-H012","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-H012","category":"code-quality","severity":"S2","type":"code-smell","file":".claude/hooks/session-start.js","line":0,"title":"session-start.js does heavy work at SessionStart (builds, installs, checks) - could be async","description":"session-start.js (561 lines) runs synchronously at SessionStart and does heavy I/O: npm install, npm ci, build commands (up to 120s timeout each), pattern checks, consolidation checks, TDMS metrics. Blocks session start if any step hangs. SessionStart is synchronous hook context.","recommendation":"Split session-start into critical-path (check secrets, load alerts) and background tasks (npm install, build, pattern check). Document which steps are blocking vs can be skipped if time-constrained. Consider if builds should happen at all during hook vs on-demand.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"session-start.js total execution: npm ci (potentially 30-60s) + functions npm ci (30-60s) + build (60s) + pattern check (5-10s) + consolidation (5-10s) + TDMS check (5s) = potential 150+ seconds blocking session start","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-H013","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-H013","category":"code-quality","severity":"S2","type":"code-smell","file":".claude/hooks/auto-save-context.js","line":0,"title":"Auto-save-context hook reads 4 files per Read operation to find recent decisions","description":"auto-save-context.js reads SESSION_DECISIONS.md and processes it with regex on every Read operation to extract recent decisions (line 119-138). File could be large. Regex does full content scan. Only saves if thresholds exceeded (~15min interval), but reads every time.","recommendation":"Cache recent decisions with timestamp. Only re-read SESSION_DECISIONS.md if modification time changed. Store cache in .auto-save-state.json. Reduces I/O from every Read to periodic (file-change-based).","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"getRecentDecisions() is called line 253 on every Read hook invocation, but auto-save only happens per SAVE_INTERVAL_MINUTES (line 24 = 15min). Doing full file read/parse on every invocation is wasteful.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-H014","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-H014","category":"code-quality","severity":"S3","type":"code-smell","file":".claude/hooks/typescript-strict-check.js","line":0,"title":"TypeScript strict check runs on every Write/Edit/MultiEdit but skips for small files","description":"typescript-strict-check.js (100ms cost) runs on every Write/Edit/MultiEdit but skips test files (.test.ts), .d.ts files, and scripts/ directory. Still does full file read even for pre-filtered file types.","recommendation":"Move file read behind secondary filter check. Check file extension AND skip patterns before fs.readFileSync. Add cache for recently-checked files so repeated edits don't re-scan.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Hook reads file for every .ts/.tsx file (line 108 fs.readFileSync) even though some will be skipped. Could add extension-based cache key to avoid re-reading same file multiple times in one session.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-H015","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-H015","category":"code-quality","severity":"S2","type":"code-smell","file":".claude/hooks/session-start.js","line":0,"title":"SessionStart hook chain is sequential with no parallelization","description":"session-start.js runs npm install, npm ci, builds, and checks sequentially (lines 312-410). Each command waits for previous. Node installations could run in parallel. Build after install requires wait, but pattern check and consolidation check could run in parallel.","recommendation":"Use Promise.all() for parallelizable steps: npm install root + functions can run in parallel. Pattern check + consolidation check can run parallel. Build must wait for install. Requires async/await refactor but could cut session startup time by 40-50%.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Current sequential: npm (30-60s) + functions npm (30-60s) + build (60s) = 150s+ total. Parallel: Math.max(npm, functions npm) + build = ~100-120s potential savings.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-K001","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-K001","category":"code-quality","severity":"S1","type":"code-smell","file":".claude/skills/audit-*/SKILL.md","line":0,"title":"Multiple audit skills with overlapping domain coverage","description":"audit-code, audit-security, audit-performance, audit-refactoring, audit-documentation, audit-process, and audit-engineering-productivity are individual audits that are also orchestrated together via audit-comprehensive. audit-enhancements is an enhancement-specific audit that partially overlaps functionality.","recommendation":"Clarify the relationship: are individual audits meant to be standalone or only called from comprehensive? Consider consolidating orchestration logic or creating a more explicit hierarchy to prevent confusion about when to use which.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"audit-comprehensive explicitly calls audit-code, audit-security, audit-performance, audit-refactoring, audit-documentation, audit-process. Each individual audit also stands alone with full execution instructions. audit-enhancements does similar discovery but for enhancements vs fixes.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-K002","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-K002","category":"code-quality","severity":"S2","type":"code-smell","file":".claude/skills/docs-sync/SKILL.md, docs-update/SKILL.md, doc-optimizer/SKILL.md","line":0,"title":"Skill overlap: docs-sync vs docs-update vs doc-optimizer","description":"Three skills appear to address documentation updates/synchronization. Without reading full content (files are empty/minimal in search), unclear if there's genuine overlap or specialization.","recommendation":"Verify the specialization of each: if docs-sync is for keeping docs in sync, docs-update is for content changes, and doc-optimizer is for quality, that's clear. If not, consolidate.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Names suggest overlapping responsibility: sync, update, optimize all deal with documentation. Audit-documentation skill also modifies docs.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-K003","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-K003","category":"code-quality","severity":"S1","type":"code-smell","file":".claude/skills/senior-*/SKILL.md","line":0,"title":"Senior specialist skills vs audit-comprehensive coverage","description":"6 senior-* skills (architect, backend, devops, frontend, fullstack, qa) may duplicate functionality already covered by audit-comprehensive and its 7 domain audits.","recommendation":"Clarify: Are senior-* skills meant for code review/consultation vs automated audits? If they're for architectural review, they should have distinct scope from audits. If they're redundant, consider consolidating review logic into audits.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Audit skills find issues; senior-* skills presumably review code. Possible that senior-* are deprecated or should be renamed to 'review-*' instead.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-K004","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-K004","category":"code-quality","severity":"S2","type":"code-smell","file":".claude/skills/[multiple]/SKILL.md","line":0,"title":"Empty or minimal SKILL.md descriptions","description":"Many skills have description fields with empty or placeholder values: developer-growth-analysis, excel-analysis, find-skills, frontend-design, etc.","recommendation":"Complete all description fields. Even a one-sentence summary helps users understand when to use each skill. This is a quick fix with high clarity benefit.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Grep output shows 'description:' with nothing after it for many skills. Users cannot understand purpose from skill index.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-K005","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-K005","category":"code-quality","severity":"S2","type":"code-smell","file":".claude/skills/add-deferred-debt/SKILL.md, add-manual-debt/SKILL.md, verify-technical-debt/SKILL.md, sync-sonarcloud-debt/SKILL.md","line":0,"title":"Skill overlap: debt tracking skills (add-deferred-debt, add-manual-debt, verify-technical-debt, sync-sonarcloud-debt)","description":"Four skills handle technical debt in different ways. add-deferred-debt and add-manual-debt both add debt but from different sources. verify-technical-debt verifies. sync-sonarcloud-debt imports from SonarCloud.","recommendation":"These may be appropriately specialized by source (deferred from PR, manual discovery, SonarCloud import, verification workflow). Verify each has distinct trigger criteria. If overlapping, consolidate intake logic.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"All route to MASTER_DEBT.jsonl via intake-audit.js. Overlap is in the 'add' step; deferred vs manual is a valid distinction by source.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-K006","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-K006","category":"code-quality","severity":"S2","type":"code-smell","file":".claude/skills/pr-review/SKILL.md, pr-retro/SKILL.md, code-reviewer/SKILL.md, requesting-code-review/SKILL.md","line":0,"title":"Skill overlap: PR and review skills (pr-review, pr-retro, code-reviewer, requesting-code-review)","description":"Four skills handle pull requests and code review. pr-review is a comprehensive review skill. pr-retro does retrospective analysis. code-reviewer is a general code review tool. requesting-code-review initiates code review.","recommendation":"Clarify workflow: Does requesting-code-review trigger pr-review? Is pr-retro a post-PR analysis? Is code-reviewer the general tool used by pr-review? Map the relationships clearly.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"All four deal with pull requests, code quality, and review processes. Names suggest a workflow but hierarchy is unclear.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-K007","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-K007","category":"code-quality","severity":"S1","type":"code-smell","file":".claude/skills/audit-validation-wrapper/SKILL.md","line":0,"title":"Unclear relationship: audit-validation-wrapper vs audit-comprehensive","description":"audit-validation-wrapper 'wraps' audit-comprehensive but also serves as a standalone alternative. Uncertain if it should always run with comprehensive or be independent.","recommendation":"Clarify: Is audit-validation-wrapper the authoritative entry point (call audit-comprehensive from it) or should they be independent? Current doc creates ambiguity about which to invoke.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"SKILL.md shows both 'Manual Integration' and 'Automated Wrapper (Recommended)' workflows, suggesting uncertainty about the primary flow.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-K008","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-K008","category":"code-quality","severity":"S3","type":"code-smell","file":".claude/skills/using-superpowers/SKILL.md, task-next/SKILL.md, validate-claude-folder/SKILL.md","line":0,"title":"Placeholder skills with minimal utility (using-superpowers, task-next, validate-claude-folder)","description":"Several skills appear to be utilities or helpers with limited scope. using-superpowers presumably activates advanced features. task-next shows next task. validate-claude-folder validates .claude folder.","recommendation":"These are fine as utilities, but ensure they're documented clearly. Consider a separate 'utilities' section in skill index to avoid confusion with major skills.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"These skills are helper functions, not major workflows. They're useful but shouldn't be at the same priority level as audit-comprehensive.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-K009","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-K009","category":"code-quality","severity":"S2","type":"code-smell","file":".claude/skills/skill-creator/SKILL.md, find-skills/SKILL.md","line":0,"title":"Potential deprecation: skill-creator, skill-related skills in favor of ai-native workflow","description":"skill-creator and find-skills manage skills as artifacts. But skills may be better managed through evolving the codebase or agent instructions rather than as files.","recommendation":"Evaluate whether skill-creator and find-skills can be automated or replaced by better skill discovery mechanisms. If skill management is becoming a bottleneck, consider refactoring.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"skill-creator and find-skills exist to manage skills manually. If this is frequently needed, it suggests the skill system itself needs improvement.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-K010","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-K010","category":"code-quality","severity":"S3","type":"code-smell","file":".claude/skills/session-begin/SKILL.md, session-end/SKILL.md, checkpoint/SKILL.md","line":0,"title":"Session lifecycle skills (session-begin, session-end, checkpoint) could be consolidated","description":"Three skills handle session management: session-begin starts sessions, session-end ends sessions, checkpoint saves state. These are tightly coupled.","recommendation":"Consider consolidating into a single 'session-management' skill with subcommands for begin/end/checkpoint. This reduces skill index clutter.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"These three skills are procedurally coupled (always used in session-begin → work → checkpoint → session-end order). One unified skill would reduce invocation overhead.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-K011","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-K011","category":"code-quality","severity":"S1","type":"code-smell","file":".claude/skills/audit-*/SKILL.md","line":0,"title":"Audit skill explosion: 9 audit-related skills with inconsistent parameterization","description":"audit-code, audit-security, audit-performance, audit-refactoring, audit-documentation, audit-process, audit-engineering-productivity, audit-comprehensive, audit-enhancements + audit-validation-wrapper and audit-aggregator = 11 audit-related skills","recommendation":"Evaluate consolidation: Could these be one 'audit' skill with domain parameters (e.g., /audit --domain code,security,performance)? Or are the individual skills appropriately specialized for standalone use? Current approach creates high cognitive load.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"57 total skills, 11 are audits (19% of skill portfolio). This is a significant portion devoted to one pattern. Consolidation could free up skill slots for new functionality.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-K012","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-K012","category":"code-quality","severity":"S2","type":"code-smell","file":".claude/skills/audit-enhancements/SKILL.md, audit-process/SKILL.md","line":0,"title":"Skill naming inconsistency: enhancement vs audit-enhancements, process vs audit-process","description":"Most audits are prefixed 'audit-' (audit-code, audit-security) but audit-enhancements uses 'enhancement' alone. audit-process is standalone but part of audit-comprehensive.","recommendation":"Standardize: Either all audit skills are audit-* (audit-enhancements, audit-process are correct) or domain names are standalone (code, security, enhancements are correct). Pick one pattern.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"audit-code, audit-security, audit-performance, audit-refactoring, audit-documentation, audit-process, audit-engineering-productivity use 'audit-' prefix. audit-enhancements doesn't. Inconsistent.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-K013","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-K013","category":"code-quality","severity":"S2","type":"code-smell","file":".claude/skills/content-research-writer/SKILL.md, market-research-reports/SKILL.md, ux-researcher-designer/SKILL.md","line":0,"title":"Marketing-focused skills in technical codebase (content-research-writer, market-research-reports, ux-researcher-designer)","description":"Three skills are marketing/content/design focused and may be out of scope for a technical codebase audit toolkit.","recommendation":"Verify these belong in the codebase. If the project is web-based with UX concerns, keep them. If purely backend/technical, consider moving to separate skill repository or marking as optional.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"content-research-writer helps with articles/newsletters. market-research-reports does market research. ux-researcher-designer does UX research. These are orthogonal to code audits, debt tracking, and technical skills.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-K014","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-K014","category":"code-quality","severity":"S2","type":"code-smell","file":".claude/skills/*/SKILL.md","line":0,"title":"Undefined skill descriptions create discovery problem (50% of skills missing meaningful descriptions)","description":"At least 25+ skills have empty description fields, preventing skill discovery via /find-skills or skill index searches.","recommendation":"Populate all descriptions with 1-2 sentence summaries. This is foundational metadata for a 57-skill portfolio.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Grep output shows 'description:' with no value for ~50% of skills. Users cannot discover these skills via automated tools.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-K015","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-K015","category":"code-quality","severity":"S1","type":"code-smell","file":".claude/skills/artifacts-builder/SKILL.md, markitdown/SKILL.md, mcp-builder/SKILL.md, expansion-evaluation/SKILL.md, systematic-debugging/SKILL.md","line":0,"title":"Deprecated or unclear purpose: artifacts-builder, markitdown, mcp-builder, expansion-evaluation, systematic-debugging","description":"Five skills have unclear or potentially deprecated purposes: artifacts-builder (build HTML artifacts), markitdown (convert markdown), mcp-builder (build MCP servers), expansion-evaluation (evaluate expansions), systematic-debugging (debug systematically).","recommendation":"Audit usage: Are these actually used? If artifacts-builder is for creating Claude artifacts, verify it's still needed post-api-changes. If MCP-builder is for custom MCP servers, verify it's maintained. Mark deprecated if not actively used.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"markitdown description mentions 'convert to markdown' but unclear from what. expansion-evaluation is unexplained. systematic-debugging has no description. These need clarity or deprecation notices.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-A001","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-A001","category":"code-quality","severity":"S1","type":"code-smell","file":"docs/**/*.md, SESSION_CONTEXT.md, AUDIT_TRACKER.md, PLAN_MAP.md (and 54 others)","line":0,"title":"57 documents with duplicate/inconsistent AI Instructions sections","description":"Audit found 57 markdown files containing 'AI Instructions' sections. Many are duplicated across docs with similar guidance (e.g., APPCHECK_SETUP.md, RECAPTCHA_REMOVAL_GUIDE.md both have App Check-specific instructions that could be consolidated). Each section ranges from ~100-800 chars (25-200 tokens). Total estimated token waste: ~4,500+ tokens per session load.","recommendation":"Consolidate AI Instructions into 3-4 canonical sections in claude.md: (1) Universal Meta-Instructions (placement, format, scope), (2) Per-Document-Type Instructions (planning docs vs process docs vs setup guides), (3) Safety/Compliance Checks. Reference from docs using 'See claude.md Section X.Y' instead of duplicating.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"grep found 57 files with '^## AI Instructions' pattern. Sample: APPCHECK_SETUP.md (line 318/343=92% down), DOCUMENTATION_STANDARDS.md (line 57/864=6% up), INCIDENT_RESPONSE.md (line 283/300=94% down). DOCUMENTATION_STANDARDS.md itself mandates 'AI Instructions MUST be near top' but 30% of docs violate this.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-A002","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-A002","category":"code-quality","severity":"S1","type":"code-smell","file":"docs/DOCUMENTATION_STANDARDS.md, docs/APPCHECK_SETUP.md, docs/INCIDENT_RESPONSE.md, docs/SONARCLOUD_CLEANUP_RUNBOOK.md (and others)","line":0,"title":"AI Instructions placement violates own DOCUMENTATION_STANDARDS","description":"DOCUMENTATION_STANDARDS.md (line 57-67) explicitly states: 'AI Instructions section MUST be near the top (after title and metadata)' with rationale that 'LLMs read top-to-bottom; instructions at bottom are often missed'. However, at least 8 sampled docs place AI Instructions at 90%+ through the document (APPCHECK_SETUP.md at line 318/343, INCIDENT_RESPONSE.md at line 283/300), making instructions invisible to most LLM attention spans.","recommendation":"(1) Add check to pre-commit hook: validate AI Instructions at line <50 for docs >100 lines. (2) Audit all 57 docs for placement violation. (3) Move misplaced instructions to line 20-30 (post-metadata).","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"DOCUMENTATION_STANDARDS.md lines 63-66 state placement rule. Grep shows APPCHECK_SETUP.md, INCIDENT_RESPONSE.md, SONARCLOUD_CLEANUP_RUNBOOK.md all >90% through their files. Compare: MCP_SETUP.md correctly places at line 16/178 (9%), DOCUMENTATION_STANDARDS.md at line 57/864 (6%).","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-A003","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-A003","category":"code-quality","severity":"S2","type":"code-smell","file":"docs/APPCHECK_SETUP.md, docs/RECAPTCHA_REMOVAL_GUIDE.md, claude.md","line":0,"title":"Redundant App Check instructions across 3 documents","description":"App Check setup guidance appears in 3 separate files: (1) APPCHECK_SETUP.md (tier 3 setup guide), (2) RECAPTCHA_REMOVAL_GUIDE.md (tier 3 procedure), (3) claude.md Section 2 (security rule about App Check Required). Each has overlapping instructions: check env var → verify config → test deployment. Estimated 3-5 tokens wasted per session per doc.","recommendation":"Keep only one authoritative guide (APPCHECK_SETUP.md). Remove App Check instructions from RECAPTCHA_REMOVAL_GUIDE.md and cross-reference. Simplify claude.md Section 2 security rule to: 'App Check Required - see APPCHECK_SETUP.md for troubleshooting' (reduce from current advisory to single pointer).","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Sampled 3 App Check docs: all have setup guidance. Cross-references not present. DOCUMENTATION_STANDARDS.md at line 200-207 defines 'sync triggers' but no sync trigger exists for App Check instructions.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-A004","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-A004","category":"code-quality","severity":"S2","type":"code-smell","file":"docs/SESSION_HISTORY.md (lines 25-50), docs/AI_REVIEW_LEARNINGS_LOG.md (lines with 'IMS→TDMS'), docs/AUDIT_TRACKER.md (version 2.6-2.7)","line":0,"title":"Outdated IMS references in SESSION_HISTORY.md and AI_REVIEW_LEARNINGS_LOG.md","description":"Session #152 (2026-02-12) merged IMS (Improvement Management System) into TDMS (Technical Debt Management System). Multiple documents contain historical references to 'IMS', 'docs/improvements/', and 'MASTER_IMPROVEMENTS.jsonl' that are now obsolete. While SESSION_HISTORY.md correctly documents the merge in version history, the operational guidance hasn't been updated. Risk: AI agents reading outdated session logs may attempt to reference deleted systems.","recommendation":"(1) Update SESSION_HISTORY.md entries for Sessions #150-152 to add post-merge callout: [IMS DEPRECATED - see Session #152 for merger details]. (2) Update AI Instructions in AUDIT_TRACKER.md to reference TDMS exclusively. (3) Add one-time cross-reference in SESSION_DECISIONS.md: 'IMS merged to TDMS in Session #152 - historical refs may be outdated'.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"docs/improvements/ does not exist (verified). AUDIT_TRACKER.md version history shows merge (2.6→2.7). PLAN_MAP.md v2.1 explicitly documents removal. Historical session logs still reference old system.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-A006","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-A006","category":"code-quality","severity":"S3","type":"code-smell","file":"docs/*.md (all 57 files)","line":0,"title":"Inconsistent AI Instructions format across document tiers","description":"Different document tiers use different AI Instructions formats: (1) Tier 2 docs (setup guides) use numbered lists with actions (e.g., APPCHECK_SETUP.md), (2) Tier 4 docs (references) use bullet lists with guidelines (e.g., REVIEW_POLICY_QUICK_REF.md), (3) Some use 'When X do Y' format, others use 'Rules are', others use 'Do not'. DOCUMENTATION_STANDARDS.md doesn't prescribe a format for AI Instructions subsections. This inconsistency costs ~50-100 tokens per doc as LLMs must re-parse format variations.","recommendation":"Add Section 5 to DOCUMENTATION_STANDARDS.md: 'AI Instructions Format Spec'. Prescribe: (1) Use bulleted list (not numbered) for generality, (2) Start each bullet with imperative verb: 'Check/Validate/Review/When/Always/Never', (3) Keep <15 words per bullet, (4) Max 5-8 bullets per section, (5) Example: '- Check file status before modifying\n- Validate with npm run docs:check\n- Reference ROADMAP.md for sync triggers'.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Sampled 5 files show 5 different formats. No DOCUMENTATION_STANDARDS.md section covers format. Format variations add parsing overhead without benefit.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-A007","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-A007","category":"code-quality","severity":"S3","type":"code-smell","file":"docs/TESTING_PLAN.md, docs/SONARCLOUD_CLEANUP_RUNBOOK.md, docs/RECAPTCHA_REMOVAL_GUIDE.md","line":0,"title":"Disconnected AI Instructions from actual automation - TESTING_PLAN.md example","description":"TESTING_PLAN.md AI Instructions (line ~1050) say 'First run npm test to check automated test status'. But there is no automatic test runner integrated into the documented workflow. The instruction assumes synchronous CLI execution, while modern SoNash uses async /test-suite skill. The instruction is not obsolete but outdated (pre-skill era). Similar issue in 3-5 other docs.","recommendation":"(1) Update TESTING_PLAN.md AI Instructions: 'Use /test-suite skill (recommended) or npm test for local verification'. (2) Add 'Preferred Automation' subsection to claude.md Section 7 that lists 10 core skills with their trigger contexts. (3) Mark AI Instructions with version (['Updated Session #X'] to help AI understand freshness.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"TESTING_PLAN.md created ~Session #110, /test-suite skill created Session #141. Session #141 notes say 'comprehensive testing suite'. But TESTING_PLAN.md AI Instructions never updated to recommend new skill. Compare: TESTING_USER_MANUAL.md (Session #141) correctly references /test-suite.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-A008","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-A008","category":"code-quality","severity":"S3","type":"code-smell","file":"SESSION_CONTEXT.md, AI_WORKFLOW.md, ROADMAP.md","line":0,"title":"AI Instructions in SESSION_CONTEXT.md creates circular reference risk","description":"SESSION_CONTEXT.md AI Instructions (line 7-43) prescribe 6 steps for session start and 5 rules for updating, concluding with 'Check Navigation' section that links to ROADMAP.md, AI_WORKFLOW.md, etc. These links then loop back and reference SESSION_CONTEXT.md. While not contradictory, this creates a 3-hop dependency (SESSION_CONTEXT → AI_WORKFLOW → ROADMAP → SESSION_CONTEXT) that costs tokens every session load and makes updates harder.","recommendation":"(1) Establish clear hierarchy: ROADMAP.md is canonical, SESSION_CONTEXT.md is current-state read-only snapshot, AI_WORKFLOW.md is navigation. (2) Simplify SESSION_CONTEXT.md AI Instructions to 3 points: 'Read first → check Next Session Goals → see ROADMAP for priorities'. Remove internal navigation links. (3) Move navigation links to ai-navigation section in claude.md.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"SESSION_CONTEXT.md lines 45-51 (Navigation section) create 3-hop links. Actual reading order is SESSION_CONTEXT → ROADMAP (for goals) → ROADMAP_LOG (for history) → back to SESSION_CONTEXT (for current session). Circular dependency confirmed.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-A009","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-A009","category":"code-quality","severity":"S0","type":"code-smell","file":"All 57 files with AI Instructions sections","line":0,"title":"CRITICAL: 57 separate AI Instructions sections = ~4,500+ unnecessary tokens per session","description":"COMPREHENSIVE FINDING: The project maintains 57 separate 'AI Instructions' sections across documentation. At ~80 tokens per section average (320-1,200 chars / 4 chars per token), this represents ~4,500+ tokens loaded per session. However, claudee.md (118 lines, ~30 tokens) is the only file that MUST be loaded every session for AI context. The other 56 sections are redundantly included in documentation that's selectively read. Token waste estimate: 90% of AI Instructions are never referenced in a given session (only 1-2 docs are read per session on average). This violates the project's own principle (claude.md line 10-13: 'Kept minimal (~120 lines) to reduce token waste').","recommendation":"IMMEDIATE: Audit all 57 docs by tier. Keep AI Instructions ONLY in Tier 1-2 docs (ROADMAP.md, SESSION_CONTEXT.md, DOCUMENTATION_STANDARDS.md, claude.md, maybe 10-15 others). Remove from Tier 3-4 docs entirely. Instead, add single 'See claude.md Section X for instructions' pointer. Create centralized 'Per-Document AI Instructions' section in claude.md that covers all document types and scenarios. Estimated savings: ~4,000 tokens per session (90% reduction in AI Instructions bloat).","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Grep found 57 files. Manual sampling of 5-10 files shows average ~120-200 chars per AI Instructions section. Extrapolate: 57 * 150 chars = 8,550 chars = ~2,137 tokens. HOWEVER: if ~30 are Tier 3-4 (reference only), then unnecessary load = 30 * 150 = 4,500 chars = ~1,125 tokens PER SESSION. Conservative estimate with weighted averaging: ~4,500 tokens waste due to over-distribution of AI Instructions.","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-P001","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-P001","category":"code-quality","severity":"S0","type":"code-smell","file":"/home/user/sonash-v0/.claude/hooks/commit-tracker.js","line":0,"title":"SESSION_CONTEXT.md Session Counter Regex in 5 hooks","description":"Multiple hooks parse **Current Session Count**: using regex /\\*\\*Current Session Count\\*\\*:\\s*(\\d+)/ to extract session numbers. This pattern appears in: commit-tracker.js (line 130), compaction-handoff.js (line 165), check-remote-session-context.js (line 63), pre-compaction-save.js (line 149), and generate-pending-alerts.js (indirectly via check-session-gaps.js line 77). If markdown formatting changes (spacing, capitalization, or bold marker), session counter extraction fails silently, breaking compaction tracking.","recommendation":"Extract to shared utility function with fallback parsing strategies (e.g., case-insensitive, flexible whitespace). Add validation to ensure extracted value is numeric.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"grep found pattern in 5 files; commit-tracker.js line 130 is primary; compaction-handoff.js line 165, check-remote-session-context.js line 63, pre-compaction-save.js line 149, check-session-gaps.js line 77 depend on same pattern","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-P002","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-P002","category":"code-quality","severity":"S0","type":"code-smell","file":"/home/user/sonash-v0/.claude/hooks/auto-save-context.js","line":0,"title":"SESSION_DECISIONS.md Decision Block Regex in auto-save-context.js","description":"auto-save-context.js (line 124) parses recent decisions using regex /^### \\[(\\d{4}-\\d{2}-\\d{2})\\] - (.+?)\\n([\\s\\S]*?)(?=^### \\[|^## |$)/gm. This pattern is brittle: requires exact date format (YYYY-MM-DD), assumes specific header structure with dash separator, and expects newline immediately after header. Any markdown reformatting (adding spaces, changing header level, altering date format) breaks decision extraction, losing session context that survives compaction.","recommendation":"Use more flexible regex with optional whitespace: /^###\\s+\\[(\\d{4}-\\d{2}-\\d{2})\\]\\s*-\\s*(.+?)\\n([\\s\\S]*?)(?=^###|$)/gm. Add guard against empty date/title fields.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Line 124 in auto-save-context.js; used to save session context before compaction; runs every file read (PostToolUse hook)","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-P003","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-P003","category":"code-quality","severity":"S1","type":"code-smell","file":"/home/user/sonash-v0/scripts/check-backlog-health.js","line":0,"title":"AUDIT_FINDINGS_BACKLOG.md markdown parsing in check-backlog-health.js","description":"check-backlog-health.js (lines 160, 179-191) parses backlog items using split(/^### \\[/gm) and multiple regex patterns for severity, status, and CANON-ID extraction. The parser expects exact format: ### [Category] Item Name with specific field formatting (**Severity**: S[0-3], **Status**: PENDING|IN_PROGRESS|DONE|DEFERRED, **CANON-ID**: CANON-\\d+). If fields are reordered, spacing changes, or status values vary, parsing fails to identify critical S0 items, creating blocker detection failures.","recommendation":"Use multiline section parsing with flexible field detection. Support YAML-like format detection. Add fallback to unstructured search for severity keywords. Validate that all required fields exist before processing item.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Lines 160-195 in check-backlog-health.js; called during pre-push hook validation; failure to detect S0 items blocks push but might be bypassed if parsing fails silently","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-P004","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-P004","category":"code-quality","severity":"S1","type":"code-smell","file":"/home/user/sonash-v0/scripts/update-readme-status.js","line":0,"title":"Markdown table parsing in update-readme-status.js with pipe delimiter fragility","description":"update-readme-status.js (lines 156-171, 203) parses markdown tables from ROADMAP.md using regex and split('|'). Line 203 uses split('|') on table rows without escaping for pipe characters in cell content. Pattern expects exact alignment (| header | ... |) but doesn't handle pipes in cell values. Line 156 regex /## 📊 Milestones Overview[\\s\\S]{0,5000}?\\n\\|[^\\n]+\\| requires specific heading emoji; if changed, parsing fails. Table parsing is fragile to format changes.","recommendation":"Detect table by structure (| + separator row) instead of emoji. Parse cells carefully: use regex match on table row including escaped pipes (\\\\|). Validate column count matches header. Consider using markdown parsing library instead of regex.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Lines 156-171 for table detection, line 203 for cell splitting; used in update-readme-status.js which updates README from ROADMAP","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-P005","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-P005","category":"code-quality","severity":"S1","type":"code-smell","file":"/home/user/sonash-v0/scripts/check-session-gaps.js","line":0,"title":"check-session-gaps.js relies on hardcoded Session Context markdown format","description":"check-session-gaps.js (line 59) extracts documented sessions using /\\*\\*Session #(\\d+) Summary\\*\\*/g and current counter using /\\*\\*Current Session Count\\*\\*:\\s*(\\d+)/ (line 77). The pattern is hardcoded to expect exact bold formatting. If SESSION_CONTEXT.md switches to different header style (# Session N Summary, or [Session N]), gap detection fails, missing undocumented sessions and potentially allowing orphaned commits.","recommendation":"Create markdown format abstraction. Support multiple formats: **Session #N Summary**, # Session N Summary, [Session N]. Use case-insensitive matching. Add logging for parsing failures.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Lines 59 and 77 in check-session-gaps.js; used to detect missing session documentation; failure means orphaned commits go untracked","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-P006","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-P006","category":"code-quality","severity":"S1","type":"code-smell","file":"/home/user/sonash-v0/scripts/aggregate-audit-findings.js","line":0,"title":"aggregate-audit-findings.js markdown parsing fragility in multiple functions","description":"aggregate-audit-findings.js has four fragile markdown parsing points: (1) parseMarkdownBacklog (line 322) splits by '|' without handling escaped pipes, assumes fixed column positions; (2) parseAuditFindingsBacklog (line 377) regex /^### \\[([^\\]]+)\\] / expects exact bracket format; (3) section.match() for CANON-ID, Severity, Effort (lines 384-386) expect exact bold format and field names. If backlog markdown structure changes—field reordering, different ID format, heading changes—parsing silently skips items or extracts wrong data.","recommendation":"Implement markdown AST parsing or use remark/unified. Support format variants: ### [Cat] or ### Cat or # Cat/Item. For tables, parse cell-aware (handle escaped pipes). Add schema validation for required fields per item type.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Lines 279-348 (markdown table parsing), 354-399 (section-based parsing); used in master aggregation for all findings; cascading failures affect entire audit pipeline","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-P007","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-P007","category":"code-quality","severity":"S1","type":"code-smell","file":"/home/user/sonash-v0/scripts/generate-pending-alerts.js","line":0,"title":"generate-pending-alerts.js fragile DEFERRED item extraction","description":"generate-pending-alerts.js (lines 45-86) parses AI_REVIEW_LEARNINGS_LOG.md for DEFERRED items using multiple regexes: /\\*\\*DEFERRED \\(Review #(\\d+)\\)\\*\\*/ (line 45), /\\*\\*DEFERRED \\((\\d+)\\):\\*\\*/ (line 67-68). The patterns expect exact formatting with specific punctuation placement (colon inside or outside asterisks). If deferred items are reformatted, patterns fail, causing DEFERRED alerts to be missed entirely—losing visibility of deferred work.","recommendation":"Unify DEFERRED detection with flexible regex: /\\*\\*DEFERRED\\s*\\(\\s*(?:Review\\s*#)?(\\d+)\\s*\\):\\**/i. Test both colon-inside and colon-outside variants. Add logging for detected vs missed items.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Lines 45 and 67-68 in generate-pending-alerts.js; used to surface deferred review items in session start alerts; silent failure means alerts lost","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-P008","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-P008","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/scripts/check-roadmap-health.js","line":0,"title":"check-roadmap-health.js version parsing regex scoped to section only","description":"check-roadmap-health.js (line 56) extracts version header using /\\*\\*Document Version:\\*\\*\\s*(\\d+\\.\\d+)/ but this appears once per document. Line 69 further restricts version history parsing to a specific section using /##\\s*🗓️?\\s*Version History[\\s\\S]*?(?=\\r?\\n##\\s|\\r?\\n---\\s*$|$)/. While scoped (good), the patterns are fragile: emoji optional but section name hardcoded; line number regex assumes specific format. If document structure changes, version validation silently passes or fails incorrectly.","recommendation":"Make section header detection case-insensitive and emoji-agnostic: /##\\s*version\\s*history/i. Support version formats: X.Y, X.Y.Z, vX.Y. Validate at least one version entry exists in history section.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Lines 56, 61-69 in check-roadmap-health.js; health check runs before pushing; silent failures bypass validation","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-P009","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-P009","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/scripts/multi-ai/normalize-format.js","line":0,"title":"Multi-AI normalize-format.js markdown table detection and parsing","description":"normalize-format.js (line 194) detects markdown tables using /\\|[^\\n]+\\|\\s*\\n\\|[-:\\s|]+\\|\\s*\\n/, but this pattern assumes: (1) first row has pipes, (2) separator row immediately follows, (3) separator contains only hyphens/colons/pipes/spaces. If table has leading/trailing spaces, multiple blank lines, or non-standard separators, detection fails. Line 485, 507 split by '|' without handling escaped pipes in content. Multi-AI uses this to parse ANY audit input format; parsing failures cascade to all downstream processing.","recommendation":"Add flexible whitespace: /\\|[^\\n]*\\|\\s*\\n\\s*\\|\\s*[-:\\s|]+\\s*\\|/. Detect separator row by content: all cells match /^\\s*[-:]+\\s*$/. Parse cells aware of escaped pipes: split by unescaped pipes only. Test with real audit markdown examples.","effort":"E2","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Lines 194-196 for detection, 485/507 for cell splitting; this module handles format detection for ALL multi-AI aggregation; failures affect entire pipeline","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-P010","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-P010","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/scripts/verify-sonar-phase.js","line":0,"title":"verify-sonar-phase.js hardcoded security section header detection","description":"verify-sonar-phase.js (line 163) detects security section by exact string match: if (line.startsWith('## 🔒 Security Hotspots')). If emoji changes, section name varies, or spacing differs, detection fails, causing hotspots to be miscategorized as regular issues. Line 203 regex /### 📁 `([^`]+)`/ for file sections also hardcodes emoji; changing it breaks file grouping. Phase verification is used to validate sonar fixes; parsing failure allows miscategorized issues to slip through.","recommendation":"Use regex for section detection: /##\\s+(?:🔒)?\\s*security\\s+hotspots/i. For files: /###\\s+📁?\\s*`([^`]+)`/. Fall back to text search without emoji. Log parse warnings.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Lines 163 and 203 in verify-sonar-phase.js; used to verify phase completion; emoji change breaks categorization","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-D001","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-D001","category":"code-quality","severity":"S0","type":"code-smell","file":"/home/user/sonash-v0/docs/SoNash_Technical_Ideation_Multi_AI 1.20.26.md","line":0,"title":"SoNash_Technical_Ideation_Multi_AI 1.20.26.md - 4.1KB ideation document never linked","description":"Large ideation document (4118 lines) containing multi-AI technical proposals that is never referenced by any script, hook, skill, or other documentation. Listed as orphaned in DOCUMENTATION_INDEX.md.","recommendation":"Move to docs/archive/ or consolidate findings into EXPANSION_EVALUATION_TRACKER.md. The content appears to be exploratory AI-generated technical ideation that should either be integrated into active roadmaps or archived as historical reference.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"DOCUMENTATION_INDEX.md lists as orphaned with ↓0 ↑0 references; grep search for filename returns 14 refs but all are in technical-debt views or archive-related docs, not active docs","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-D002","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-D002","category":"code-quality","severity":"S1","type":"code-smell","file":"/home/user/sonash-v0/docs/HOOKIFY_STRATEGY.md","line":0,"title":"HOOKIFY_STRATEGY.md - 1.1KB implementation plan unused","description":"Hookify Strategy & Implementation Plan (1059 lines) documents a hooks implementation strategy that is never referenced by any active documentation, scripts, or hooks themselves.","recommendation":"Review content and either: (1) integrate strategy into .claude/HOOKS.md, (2) create references from hook files, or (3) move to archive if strategy was superseded. Check if hookification is still planned or completed.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"DOCUMENTATION_INDEX.md orphaned list; zero grep references outside the file itself","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-D003","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-D003","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/docs/RECAPTCHA_REMOVAL_GUIDE.md","line":0,"title":"RECAPTCHA_REMOVAL_GUIDE.md - 745 lines about Firebase configuration rarely used","description":"Comprehensive guide (745 lines) for reCAPTCHA removal and fresh App Check setup. While server-side docs reference it (2 refs), it has zero inbound document references and is primarily a reference/procedural doc.","recommendation":"Integrate into APPCHECK_SETUP.md or SERVER_SIDE_SECURITY.md as a section. Update README or index to reference it, or move obsolete sections to archive if reCAPTCHA removal was already completed.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"DOCUMENTATION_INDEX.md shows ↓0 outbound refs; referenced by 2 server-side docs but not by index or guides","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-D004","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-D004","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/docs/REVIEW_POLICY_INDEX.md","line":0,"title":"REVIEW_POLICY_INDEX.md - 370 lines index without inbound refs","description":"Review Policy Index (370 lines) serves as a directory for review policies but has zero inbound references despite 9 upward references. Not referenced by README, DOCUMENTATION_INDEX, or navigation docs.","recommendation":"Add explicit reference in DOCUMENTATION_INDEX.md index section and link from REVIEW_POLICY_ARCHITECTURE.md. If serving as index, ensure it's discoverable from main navigation (README, DOCUMENTATION_INDEX).","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"DOCUMENTATION_INDEX.md lists as orphaned; found referenced in DOCUMENTATION_INDEX.md and scripts/check-docs-light.js only","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-D005","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-D005","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/docs/PLAN_MAP.md","line":0,"title":"PLAN_MAP.md - 242 lines documentation hierarchy map never referenced","description":"SoNash Documentation Plan Map (242 lines) provides visual hierarchy and relationships but is completely orphaned with zero inbound references.","recommendation":"Either (1) add reference from DOCUMENTATION_INDEX.md as navigation aid, (2) integrate content into README.md or DOCUMENTATION_STANDARDS.md, or (3) move to docs/archive/ if superseded by DOCUMENTATION_INDEX.md.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"DOCUMENTATION_INDEX.md orphaned list; zero external references; grep shows only DOCUMENTATION_INDEX references the filename","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-D006","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-D006","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/docs/MCP_SERVER_AUDIT.md","line":0,"title":"MCP_SERVER_AUDIT.md - 374 lines about MCP consumption never referenced","description":"MCP Server Usage Audit (374 lines) designed to identify MCP servers consuming context but never referenced by any documentation or audit processes.","recommendation":"Link from multi-ai-audit coordinator or create reference in relevant audit plans. If this audit should be run, add to AUDIT_TRACKER.md. Consider if this aligns with actual audit workflows.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"DOCUMENTATION_INDEX.md orphaned list; grep finds only DOCUMENTATION_INDEX reference","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-D007","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-D007","category":"code-quality","severity":"S3","type":"code-smell","file":"/home/user/sonash-v0/docs/MCP_SETUP.md","line":0,"title":"MCP_SETUP.md - 178 lines configuration guide without traction","description":"MCP Server Setup Guide (178 lines) provides configuration instructions but is unused - no references from setup docs, deployment guides, or DEVELOPMENT.md.","recommendation":"Integrate into DEVELOPMENT.md or .claude/REQUIRED_PLUGINS.md. If MCP is critical for setup, ensure onboarding docs reference it. Otherwise archive as legacy.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"DOCUMENTATION_INDEX.md orphaned; DEVELOPMENT.md and onboarding docs do not reference it; zero grep matches in active code","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-D008","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-D008","category":"code-quality","severity":"S3","type":"code-smell","file":"/home/user/sonash-v0/docs/LEARNING_METRICS.md","line":0,"title":"LEARNING_METRICS.md - 84 lines metrics tracking document","description":"Learning Effectiveness Metrics (84 lines) auto-generated tracker showing pattern learning effectiveness but with zero inbound references despite being produced by scripts/analyze-learning-effectiveness.js.","recommendation":"Add reference from AUDIT_TRACKER.md or alerts system. If auto-generated, ensure output is mentioned in the generating script's documentation. Consider if metrics should feed into decision-making workflows.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"DOCUMENTATION_INDEX.md orphaned list; generated by script but not integrated into dashboards or tracking systems","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-D009","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-D009","category":"code-quality","severity":"S3","type":"code-smell","file":"/home/user/sonash-v0/docs/AUTOMATION_AUDIT_REPORT.md","line":0,"title":"AUTOMATION_AUDIT_REPORT.md - 255 lines audit results never integrated","description":"Automation Audit Report (255 lines) appears to be a standalone audit report with no inbound references, likely superseded by newer audit structure in docs/audits/ subdirectory.","recommendation":"Remove duplicate at root level (keep versioned audit in subdirectory). Update references to point to dated audit instance in docs/audits/. Consider if root-level report should be generated or archived.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"DOCUMENTATION_INDEX.md orphaned; newer dated version exists in docs/audits/; no scripts or workflows reference the root-level version","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-D010","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-D010","category":"code-quality","severity":"S1","type":"code-smell","file":"/home/user/sonash-v0/docs/agent_docs/FIX_TEMPLATES.md","line":0,"title":"FIX_TEMPLATES.md - 0 outbound refs for Qodo PR fixes","description":"Fix Templates for Qodo PR Review Findings (docs/agent_docs/FIX_TEMPLATES.md) provides copy-paste templates but is never referenced by code reviewer agents, PR review skills, or documentation.","recommendation":"Link from code-reviewer skill, CODE_PATTERNS.md, and review process documentation. If templates are intended for use, ensure they're discoverable from agent workflows that need them.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"DOCUMENTATION_INDEX.md orphaned list; grep shows zero references from skills or agent configs","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-D011","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-D011","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/docs/agent_docs/SKILL_AGENT_POLICY.md","line":0,"title":"SKILL_AGENT_POLICY.md - 0 refs despite defining usage policy","description":"Skill and Agent Usage Policy (docs/agent_docs/SKILL_AGENT_POLICY.md) defines critical policies for skill/agent creation but has zero inbound references despite having 3 upward references.","recommendation":"Link from agent creation guides, DEVELOPMENT.md, and main agent documentation README. Add to onboarding checklist. Ensure policy is discoverable before agents are created.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"DOCUMENTATION_INDEX.md orphaned; not referenced from main skill/agent docs or onboarding materials","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-D012","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-D012","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/docs/audits/single-session/process/audit-2026-02-09/stage-1*.md","line":0,"title":"Audit inventory stage files (6 files) - generated but unreferenced","description":"Six stage-1 audit inventory files (stage-1a through stage-1f) generated 2026-02-09 but never integrated into audit workflows or referenced by audit aggregation processes.","recommendation":"Either (1) integrate into AUDIT_TRACKER with findings aggregation, or (2) move dated audit outputs to completed audit archive with clear retention policy. If stage outputs are intermediate, don't persist in docs.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"DOCUMENTATION_INDEX.md marks all 6 as orphaned; audit-related grep shows references only in index, not in active audit workflows","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-D013","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-D013","category":"code-quality","severity":"S3","type":"code-smell","file":"/home/user/sonash-v0/docs/decisions/","line":0,"title":"ADR template and decisions/README - decision framework underutilized","description":"Architecture Decision Records framework (docs/decisions/README.md) with template (docs/decisions/TEMPLATE.md) but only one ADR documented; framework appears unused.","recommendation":"Either (1) activate ADR process and link from ARCHITECTURE.md + AI_WORKFLOW.md, or (2) consolidate decision tracking into SESSION_DECISIONS.md format. Clean up if not part of current workflow.","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"DOCUMENTATION_INDEX.md shows ADR README as orphaned (↓0); only one historical ADR exists (ADR-001); no recent decisions recorded","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-D014","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-D014","category":"code-quality","severity":"S2","type":"code-smell","file":"/home/user/sonash-v0/docs/plans/CI_GATES_BLOCKING_PLAN.md and 4 others","line":0,"title":"Plan documents with zero inbound refs - 5 planning files orphaned","description":"Five planning documents (CI_GATES_BLOCKING_PLAN, SESSION_CONTEXT_REDUCTION_PLAN, TRACK_A_MANUAL_TEST_CHECKLIST, alerts-enhancement-plan, and roadmap-assignment-report) all marked orphaned in DOCUMENTATION_INDEX.","recommendation":"For each plan: (1) check if completed and archive to docs/archive/completed-plans/, or (2) if active, add explicit reference from ROADMAP.md and PLAN_MAP.md. Consolidate similar plans (e.g., testing checklists).","effort":"E0","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"DOCUMENTATION_INDEX.md orphaned list includes all 5 files; ROADMAP.md and PLAN_MAP.md do not reference most of them","sources":[],"merged_from":[]}
{"source_id":"audit:OPT-D015","source_file":"docs\\audits\\single-session\\ai-optimization\\audit-2026-02-13\\findings.jsonl","original_id":"OPT-D015","category":"code-quality","severity":"S1","type":"code-smell","file":"/home/user/sonash-v0/docs/technical-debt/views/","line":0,"title":"Technical debt view files - generated views without integration","description":"Three technical debt view files (by-category, by-severity, by-status) plus views/unplaced-items are generated by TDMS but not integrated into monitoring dashboards or alerting systems.","recommendation":"Integrate into alerts system or create monitoring dashboard that references these views. Update TECHNICAL_DEBT_MANAGEMENT_SYSTEM_PLAN.md to document how views feed into workflows. Consider if view files should be excluded from docs and generated-only.","effort":"E1","status":"NEW","roadmap_ref":null,"created":"2026-02-26","verified_by":null,"resolution":null,"evidence":"Views marked orphaned in DOCUMENTATION_INDEX; generated by TDMS but no active consumption in workflows; greps show only TDMS procedure references them","sources":[],"merged_from":[]}
