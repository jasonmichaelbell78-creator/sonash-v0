# Skill Ecosystem Audit — Conversation Notes

<!-- prettier-ignore-start -->
**Document Version:** 1.0
**Last Updated:** 2026-02-24
**Status:** DRAFT
<!-- prettier-ignore-end -->

**Source:** Session #185, 2026-02-24 **Context:** Brainstorming after PR #388
retro action items were applied

---

## Q: What would a skill-ecosystem-audit conceivably look like?

Based on the existing audit pattern (hook, session, PR, TDMS ecosystems all
follow the same 5-domain structure with composite scoring), a
skill-ecosystem-audit would probably look something like:

### 5 Domains

**1. Structural Compliance**

- Frontmatter consistency (name, description, `---` delimiters)
- Version history present and current
- Scope/trigger documentation ("When to Use" / "When NOT to Use")
- Step numbering continuity (no gaps, no duplicates)

**2. Cross-Skill Integration**

- Skills that reference other skills (e.g., pr-retro references pr-review Step
  0.5) — are those references still valid after updates?
- Circular skill dependencies (A invokes B which invokes A)
- Handoff points documented (e.g., pr-review → add-debt → sprint)
- Shared vocabulary consistency (do all skills use "TDMS" vs "debt tracker"
  consistently?)

**3. Coverage & Overlap**

- Duplicate functionality across skills (e.g., code-reviewer vs pr-review —
  scope boundaries clear?)
- Workflow gaps — are there common user tasks with no matching skill?
- Trigger description accuracy — does the skill description in the registry
  match what the skill actually does?

**4. Staleness & Drift**

- Skills referencing deleted files, renamed scripts, or old patterns
- Version history gaps (last update months ago but codebase changed
  significantly)
- Known Churn Patterns sections outdated (e.g., pr-retro patterns referencing
  resolved issues)
- Evidence citations still valid (PR numbers, review numbers, template numbers)

**5. Effectiveness Metrics**

- Skills with high invocation count but low completion rate (user abandons
  mid-skill)
- Action items generated by skills that are never implemented (the retro
  compliance problem)
- Skill output that feeds into other skills — is the pipeline intact?

### Unique Categories (~16-18)

Things the other audits don't cover:

| #   | Category                      | What It Checks                                        |
| --- | ----------------------------- | ----------------------------------------------------- |
| 1   | Frontmatter schema            | Required fields present, valid format                 |
| 2   | Step continuity               | Numbered steps sequential, no orphan references       |
| 3   | Cross-reference integrity     | Skill→skill, skill→template, skill→script links valid |
| 4   | Trigger accuracy              | Description matches actual skill behavior             |
| 5   | Scope boundary clarity        | Overlapping skills have clear differentiation         |
| 6   | Version history currency      | Last update within 30 days of related code changes    |
| 7   | Evidence citation validity    | PR/review/template numbers still exist                |
| 8   | Pattern reference sync        | Known patterns in pr-retro match pr-review pre-checks |
| 9   | Template coverage             | Every known churn pattern has a FIX_TEMPLATE          |
| 10  | Dead skill detection          | Skills in registry but never invoked                  |
| 11  | Dependency chain health       | A→B→C chains all resolve, no broken links             |
| 12  | Output format consistency     | Similar skills produce similar output structures      |
| 13  | Compliance mechanism audit    | Self-validation checklists present and complete       |
| 14  | Update dependency tracking    | "When updating X, also update Y" tables accurate      |
| 15  | Skill registry sync           | SKILL.md descriptions match skill registry entries    |
| 16  | Action item tracking pipeline | Skills that generate action items feed into TDMS      |

### What Would Make It Different

The main insight is that skills are **living documentation that drives
behavior**. Unlike static docs, a stale skill actively produces wrong outputs.
So the audit would focus heavily on **reference integrity** — every time a skill
says "see Template 30" or "check Step 0.5 of pr-review", that reference must
resolve to something real and current.

The pr-retro Known Churn Patterns section is a good example — it now has 10
patterns, each referencing specific templates, skill steps, and PR numbers. A
skill-ecosystem-audit would validate all those cross-references in one pass
rather than discovering broken links one at a time during actual reviews.

That said, it'd be one of the lower-priority audits to build — the existing
audits cover the highest-churn areas already.

---

## Q: For skills that often get updated or really for any skill, what would check for bloat?

### The Core Problem

Skills grow monotonically. Every retro adds a pattern, every PR adds a
pre-check, every fix adds evidence. Nothing triggers removal. The pr-review
SKILL.md is now **830+ lines** — it started at maybe 200.

### Bloat Indicators

**1. Step 0.5 Accumulation (pr-review)** Step 0.5 now has **10 pre-checks**,
each with a trigger condition, evidence block, search patterns, and a table. A
human reviewer would never run all 10 before every push. The pre-checks have
become a reference manual, not an actionable checklist.

- **Detection:** Count `### ` subsections within Step 0.5
- **Signal:** More than 5-6 pre-checks means most are being skipped

**2. Evidence Citation Inflation** Every pattern/template includes "Evidence: PR
#X had Y rounds..." blocks. These are useful when the pattern is new (justifies
the rule) but become dead weight once the pattern is established.

- **Detection:** Count lines matching `**Evidence:**` per skill
- **Signal:** Evidence blocks older than 3-4 PRs are rarely re-read

**3. Known Churn Patterns Growing Without Graduation** pr-retro now has 10 Known
Churn Patterns. Some are resolved (Pattern 1: CC is enforced, Pattern 3: Qodo
suppression works). Resolved patterns still take up space and reading time.

- **Detection:** Patterns with `**Status:** **IMPLEMENTED**` that haven't been
  triggered in 3+ PRs
- **Signal:** Implemented + dormant = candidate for archival

**4. Inline Code Blocks as Reference** Skills embed full code examples, search
patterns, and bash snippets inline. These duplicate what FIX_TEMPLATES already
has.

- **Detection:** Count fenced code blocks per skill; cross-reference with
  FIX_TEMPLATES
- **Signal:** If a code block matches an existing template, replace with
  `See FIX_TEMPLATES #N`

**5. Version History Length** pr-review has 12 version entries, pr-retro has 7.
These are useful for auditing but consume prime real estate at the bottom of
every skill read.

- **Detection:** Version history row count
- **Signal:** More than 10 entries → archive older entries to a changelog file

### Bloat Score Thresholds

| Metric                               | Healthy | Warning | Bloated |
| ------------------------------------ | ------- | ------- | ------- |
| Total lines                          | <300    | 300-500 | >500    |
| Pre-check subsections (Step 0.5)     | <5      | 5-8     | >8      |
| Evidence blocks                      | <8      | 8-15    | >15     |
| Inline code blocks                   | <10     | 10-20   | >20     |
| Resolved patterns still inline       | 0       | 1-2     | >2      |
| Version history entries              | <8      | 8-12    | >12     |
| Duplicate content with FIX_TEMPLATES | 0       | 1-2     | >3      |

### Current State (Quick Eyeball)

| Skill         | Lines | Pre-checks | Evidence Blocks | Verdict                            |
| ------------- | ----- | ---------- | --------------- | ---------------------------------- |
| pr-review     | ~830  | 10         | ~15             | Bloated                            |
| pr-retro      | ~590  | n/a        | ~10             | Warning                            |
| FIX_TEMPLATES | ~1970 | n/a        | ~20             | Bloated (but it's a reference doc) |
| CODE_PATTERNS | ~610  | n/a        | n/a             | Warning                            |

### Remediation Strategies

**Tiered content:** Move detailed reference material out of the main skill flow
into `reference/` subdocs (pr-review already does this for SonarCloud, agents,
TDMS, learning capture). The pre-checks in Step 0.5 are the prime candidate —
keep a 1-line checklist in the main skill, move the full
trigger/evidence/search-pattern blocks to `reference/PRE_PUSH_CHECKS.md`.

**Pattern graduation:** When a Known Churn Pattern has been `IMPLEMENTED` and
hasn't triggered in 3+ PRs, move it to an archive section or separate file. Keep
only the pattern name and "Status: Resolved" in the main skill.

**Evidence expiration:** Evidence blocks older than 5 PRs get reduced to just
the PR number reference, not the full narrative. The full narrative lives in the
retro, not the skill.

**Template dedup:** Any inline code block that matches a FIX_TEMPLATE gets
replaced with a one-line reference.

The real question is whether this becomes an automated check (part of a
skill-ecosystem-audit) or a periodic manual cleanup. Given the pattern of
things-only-get-done-if-automated in this project, probably the former.
