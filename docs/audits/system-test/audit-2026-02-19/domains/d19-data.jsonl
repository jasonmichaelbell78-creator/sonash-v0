{"id":"SYST-2026-02-19-D19-001","domain":19,"domain_name":"Data Integrity & Migration","check_id":"19.8","severity":"S2","effort":"E2","category":"reliability","title":"No automated Firestore backup/export strategy — recovery depends entirely on Google infrastructure","description":"No automated Firestore export, backup schedule, or disaster recovery configuration exists. There are no backup scripts in scripts/, no Cloud Functions for scheduled exports, and no GCS backup bucket configured. The INCIDENT_RESPONSE.md covers cost spikes, security events, and outages but does not document backup/restore procedures or define RTO/RPO targets. Recovery journals, daily logs, and inventory entries have no point-in-time recovery capability beyond Google's built-in multi-zone replication.","recommendation":"Configure scheduled Firestore exports to Cloud Storage using gcloud firestore export or a Cloud Function. Define RTO/RPO targets in INCIDENT_RESPONSE.md.","file":"firebase.json","line":72,"evidence":"firebase.json — no backup configuration\nNo gcloud firestore export commands in scripts/\nNo Cloud Functions for scheduled Firestore exports\nINCIDENT_RESPONSE.md — no backup/restore section, no RTO/RPO targets\nAll user data (journals, daily_logs, inventoryEntries) has no point-in-time recovery","suggested_fix":"Add a scheduled Cloud Function that runs gcloud firestore export daily to a GCS bucket with lifecycle policy (30-day retention). Add a 'Backup & Recovery' section to INCIDENT_RESPONSE.md with restore procedure and RTO/RPO targets (suggested: RTO ≤ 4 hours, RPO ≤ 24 hours).","status":"accepted","suggestion_text":"Accept at S2. For an app handling recovery-sensitive user data (sobriety journals, daily logs), having no backup strategy beyond Google's infrastructure replication is a significant gap.","counter_argument":"Firestore has automatic multi-zone replication and Google's SLA covers data durability. Data loss from Google infrastructure failure is extremely unlikely. The bigger risk is accidental deletion by admin operations, which soft-delete already mitigates.","related_findings":[],"detected_at":"2026-02-19T17:30:00Z","reviewed_at":"2026-02-19T17:35:00Z"}
{"id":"SYST-2026-02-19-D19-002","domain":19,"domain_name":"Data Integrity & Migration","check_id":"19.2","severity":"S2","effort":"E2","category":"correctness","title":"Anonymous user migration uses batch writes without transactions — partial migration possible","description":"migrateAnonymousUserData (functions/src/index.ts:486-765) migrates journal, daily_logs, and inventoryEntries using paginated batch writes (100-doc pages, 499-op batches). While this approach handles Firestore's 500-op transaction limit correctly, it means a failure partway through leaves data partially migrated. The client-side account-linking.ts handles this by returning success:true with a warning ('Some data may not have transferred'), but the user's anonymous account data could become orphaned if the anonymous account is later cleaned up.","recommendation":"Add a migration status document that tracks which collections were successfully migrated, enabling retry of failed collections without re-migrating completed ones.","file":"functions/src/index.ts","line":486,"evidence":"functions/src/index.ts:486-765 — migrateAnonymousUserData uses batch writes, not transactions\nBatch size: 499 operations (just under Firestore 500 limit)\nPage size: 100 documents per page\nlib/auth/account-linking.ts:355-361 — returns success:true with warning on migration failure\nNo migration status tracking document for retry capability","suggested_fix":"Add a migration_status document at users/{targetUid}/migration_status/{migrationId} that records: collections attempted, collections completed, error details. On retry, skip already-completed collections. This makes migration idempotent and resumable.","status":"accepted","suggestion_text":"Accept at S2. Partial migration with success:true response could lead to silent data loss. The batch write approach is correct for scale but lacks idempotency tracking.","counter_argument":"Transactions at this scale are impractical (Firestore 500-op limit, 270s timeout). The current approach handles partial failure gracefully by reporting what was migrated. The warning message alerts users to check their data.","related_findings":[],"detected_at":"2026-02-19T17:30:00Z","reviewed_at":"2026-02-19T17:35:00Z"}
