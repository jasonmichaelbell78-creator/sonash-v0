{"category":"GoldenPath","title":"Potentially missing troubleshooting documentation","fingerprint":"engineering-productivity::docs/TROUBLESHOOTING.md::missing-doc","severity":"S3","effort":"E0","confidence":40,"files":["docs/TROUBLESHOOTING.md","DEVELOPMENT.md"],"line":1,"why_it_matters":"DEVELOPMENT.md has setup instructions but may lack dedicated troubleshooting section for common issues (Firebase connection errors, dependency conflicts, test failures, etc.). Without troubleshooting docs, developers waste time on Stack Overflow or re-installing dependencies. Low confidence because DEVELOPMENT.md may have troubleshooting embedded (didn't read full file).","suggested_fix":"If DEVELOPMENT.md lacks troubleshooting section: Add '## Troubleshooting' section covering common issues: (1) Firebase connection errors (invalid credentials, quota exceeded), (2) Module not found errors (npm install), (3) Port already in use (kill process), (4) Test failures (clear cache), (5) Type errors (npx tsc --noEmit). Alternatively create dedicated docs/TROUBLESHOOTING.md. Link from README.md.","acceptance_tests":["DEVELOPMENT.md has ## Troubleshooting section with 5+ common issues","Each issue has: symptom, cause, solution","Or: docs/TROUBLESHOOTING.md exists with comprehensive guide","README.md links to troubleshooting documentation","Developer feedback: Issues are well-documented"],"evidence":["Read DEVELOPMENT.md:1-100 (partial) - setup instructions present","Did not see dedicated Troubleshooting section in first 100 lines","Need to read full DEVELOPMENT.md to confirm presence/absence","Standard practice: Most projects have troubleshooting docs"]}
{"category":"Testing","title":"Unknown test coverage percentage - no baseline documented","fingerprint":"engineering-productivity::tests/::unknown-coverage","severity":"S3","effort":"E0","confidence":50,"files":["tests/","package.json"],"line":1,"why_it_matters":"Don't know current test coverage percentage. CI uploads coverage report (c8) but no baseline documented in DEVELOPMENT.md or README. Without baseline, can't track if coverage is improving or regressing. Low priority but useful for measuring test quality. Low confidence because coverage may be documented elsewhere (didn't read full docs).","suggested_fix":"Run 'npm run test:coverage' locally and document baseline in DEVELOPMENT.md: '## Test Coverage - Current: XX% (last updated YYYY-MM-DD)'. Set coverage threshold in package.json (c8 config) to prevent regressions. Add coverage badge to README.md if desired. Configure CI to fail if coverage drops below threshold.","acceptance_tests":["Coverage baseline documented in DEVELOPMENT.md","c8 configuration has coverage thresholds (branches, functions, lines, statements)","CI fails if coverage drops below threshold","Coverage report accessible: npm run test:coverage â†’ open coverage/index.html","Team knows current coverage and tracks trends"],"evidence":["package.json has test:coverage script using c8","CI uploads coverage artifact (lines 125-131)","No coverage baseline found in README.md (first 50 lines)","No c8 thresholds configured in package.json (didn't see in read)","Need to check: .c8rc, coverage in package.json"]}
{"category":"Performance","title":"Potentially missing performance monitoring","fingerprint":"engineering-productivity::lib/performance.ts::missing-monitoring","severity":"S3","effort":"E1","confidence":35,"files":["lib/performance.ts","next.config.js"],"line":1,"why_it_matters":"May lack runtime performance monitoring (Core Web Vitals, API latency, render times). Sentry is integrated but primarily for error tracking, not performance. Next.js has built-in performance monitoring but needs configuration. Without performance data, can't identify slow pages or regressions. Very low confidence - monitoring may exist but not obviously named.","suggested_fix":"If performance monitoring missing: (1) Enable Next.js Analytics in next.config.js, (2) Configure Sentry Performance monitoring (already have Sentry), (3) Add Web Vitals tracking with next/web-vitals, (4) Consider Firebase Performance Monitoring for API calls, (5) Add performance budgets in Lighthouse CI. Document baseline metrics in DEVELOPMENT.md.","acceptance_tests":["Performance monitoring configured (Next.js Analytics or Sentry Performance)","Web Vitals tracked: LCP, FID, CLS","API call latency tracked","Dashboard showing performance trends","Performance budgets defined","Documentation: DEVELOPMENT.md explains performance monitoring"],"evidence":["Sentry integrated (seen in DEVELOPMENT.md)","Don't know if Sentry Performance enabled (need to check Sentry init)","No obvious lib/performance.ts or lib/analytics.ts found","Next.js has built-in monitoring but needs opt-in","Need to verify: Sentry config, next.config.js, Firebase Performance"]}