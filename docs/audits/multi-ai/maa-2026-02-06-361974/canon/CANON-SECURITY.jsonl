{"title":"App Check disabled across all Cloud Functions","severity":"S1","category":"security","files":["functions/src/index.ts","functions\\src\\index.ts"],"line":84,"why_it_matters":"All Cloud Functions have requireAppCheck set to false with a comment stating 'TEMPORARILY DISABLED - waiting for throttle to clear'. This disables Firebase App Check verification, which is meant to prevent unauthorized callers and bot abuse. Without App Check, any client that can construct valid Firebase requests can invoke these functions, bypassing a critical defense-in-depth layer. The same pattern is repeated for saveDailyLog (line 84), saveJournalEntry (line 170), softDeleteJournalEntry (line 269), saveInventoryEntry (line 363), and migrateAnonymousUserData (line 506-511). While reCAPTCHA provides some compensating control, App Check was designed to be the primary attestation mechanism.","suggested_fix":"Re-enable App Check verification by setting requireAppCheck to true on all Cloud Functions. If the reCAPTCHA Enterprise throttle issue has been resolved, remove the 'TEMPORARILY DISABLED' comment and restore the App Check enforcement. Consider adding a monitoring alert so this does not remain disabled indefinitely.","confidence":95,"effort":"E1","fingerprint":"security::functions/src/index.ts::d65872ee","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::functions/src/index.ts::d65872ee"},{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::functions\\src\\index.ts::d65872ee"}],"merged_from":["security::functions/src/index.ts::d65872ee","security::functions\\src\\index.ts::d65872ee"],"verified":true,"consensus_score":3,"canonical_id":"CANON-0001","status":"CONFIRMED"}
{"title":"Hardcoded reCAPTCHA site key in server-side code","severity":"S2","category":"security","files":["functions/src/recaptcha-verify.ts","functions\\src\\recaptcha-verify.ts"],"line":66,"why_it_matters":"The reCAPTCHA Enterprise site key is hardcoded as a fallback value on line 66: '6LdeazosAAAAAMDNCh1hTUDKh_UeS6xWY1-85B2O'. While site keys are considered public (they are embedded in frontend HTML), hardcoding them in server-side source code is an anti-pattern. If the key needs to be rotated or environment-specific keys are needed (staging vs production), this fallback could cause the wrong key to be used. Additionally, the code uses process.env for configuration in Cloud Functions, which the project's own security-check.js (SEC-006) flags as a concern -- defineString() from firebase-functions/params is preferred.","suggested_fix":"Remove the hardcoded fallback site key. Use defineString() from firebase-functions/params to configure RECAPTCHA_SITE_KEY as a deployment parameter. Ensure the key is properly configured in each deployment environment (production, staging, emulator).","confidence":83,"effort":"E1","fingerprint":"security::functions/src/recaptcha-verify.ts::33d5fe3e","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::functions/src/recaptcha-verify.ts::33d5fe3e"},{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::functions\\src\\recaptcha-verify.ts::3d2f4030"}],"merged_from":["security::functions/src/recaptcha-verify.ts::33d5fe3e","security::functions\\src\\recaptcha-verify.ts::3d2f4030"],"verified":true,"consensus_score":3,"canonical_id":"CANON-0002","status":"CONFIRMED"}
{"title":"Missing Content-Security-Policy header","severity":"S2","category":"security","files":["firebase.json"],"line":29,"why_it_matters":"The firebase.json hosting configuration sets several security headers (X-Frame-Options, X-Content-Type-Options, HSTS, Referrer-Policy, Permissions-Policy) but is missing a Content-Security-Policy (CSP) header. Without CSP, the application is more vulnerable to XSS attacks because the browser has no policy restricting which scripts, styles, and other resources can be loaded. This is especially important for a health/recovery application that handles sensitive personal data.","suggested_fix":"Add a Content-Security-Policy header to the '**' source block in firebase.json. Start with a restrictive policy that allows only same-origin resources and explicitly whitelists Google/Firebase/reCAPTCHA domains. Example: \"default-src 'self'; script-src 'self' https://www.google.com https://www.gstatic.com; connect-src 'self' https://*.googleapis.com https://*.firebaseio.com; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; font-src 'self'\". Test thoroughly before deploying to production.","confidence":91,"effort":"E1","fingerprint":"security::firebase.json::dbd1ddfc","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::firebase.json::dbd1ddfc"},{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::firebase.json::dbd1ddfc"}],"merged_from":["security::firebase.json::dbd1ddfc","security::firebase.json::dbd1ddfc"],"verified":true,"consensus_score":3,"canonical_id":"CANON-0003","status":"CONFIRMED"}
{"title":"User profile document allows direct client writes without rate limiting","severity":"S2","category":"security","files":["firestore.rules"],"line":26,"why_it_matters":"The Firestore security rule at line 26 allows any authenticated user to read AND write their own profile document at /users/{userId} with 'allow read, write: if isOwner(userId)'. Unlike journal entries, daily logs, and inventory entries (which are routed through Cloud Functions with rate limiting, Zod validation, and App Check), user profile writes bypass all server-side security controls. A malicious client could: (1) rapidly spam profile updates without rate limiting, (2) write arbitrary fields to their profile document (no schema validation), (3) set fields like 'isAdmin', 'privilegeType', or other sensitive fields directly. The client-side lib/db/users.ts uses Zod validation, but this can be trivially bypassed with browser dev tools or a custom Firestore client.","suggested_fix":"Route user profile updates through a Cloud Function with the same security wrapper (withSecurityChecks) used for other operations. Add server-side Zod validation to restrict which fields can be written. At minimum, add Firestore rules to prevent clients from writing sensitive fields like 'isAdmin', 'privilegeType', 'disabled', 'isSoftDeleted', 'migratedFrom'. Example rule: 'allow write: if isOwner(userId) && !request.resource.data.diff(resource.data).affectedKeys().hasAny([\"isAdmin\", \"privilegeType\", \"disabled\", \"isSoftDeleted\"])'.","confidence":90,"effort":"E1","fingerprint":"security::firestore.rules::897fc903","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::firestore.rules::897fc903"},{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::firestore.rules::a650e0bc"}],"merged_from":["security::firestore.rules::897fc903","security::firestore.rules::a650e0bc"],"verified":true,"consensus_score":3,"canonical_id":"CANON-0004","status":"CONFIRMED"}
{"title":"reCAPTCHA token made optional for data migration function","severity":"S2","category":"security","files":["functions/src/index.ts"],"line":516,"why_it_matters":"The migrateAnonymousUserData function (lines 514-530) explicitly makes reCAPTCHA verification optional. When no token is provided, the function logs a warning but continues processing: 'Continue without reCAPTCHA protection - rely on other security layers'. Combined with App Check being disabled (finding #1), this means the migration function relies solely on Firebase authentication and rate limiting. Since anonymous accounts are free to create, an attacker could create many anonymous accounts and attempt migrations to enumerate or probe target UIDs. The rate limit of 5 requests per 5 minutes per user provides some protection, but the user creating the requests is the target user who initiated the migration.","suggested_fix":"Make reCAPTCHA verification mandatory for the migration function. Remove the fallback path that allows processing without a token. If network blocking is a genuine concern for some users, consider implementing an alternative verification mechanism rather than skipping verification entirely.","confidence":82,"effort":"E1","fingerprint":"security::functions/src/index.ts::4815aed4","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::functions/src/index.ts::4815aed4"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0005","status":"CONFIRMED"}
{"title":"Migration function skips reCAPTCHA when token is missing","severity":"S2","category":"security","files":["functions\\src\\index.ts"],"line":516,"why_it_matters":"The migrateAnonymousUserData function (lines 514-530) makes reCAPTCHA verification optional. When the token is missing or empty, it logs a warning but continues processing the request without bot protection. This is in contrast to the withSecurityChecks wrapper (security-wrapper.ts lines 186-212), which properly rejects requests without tokens (except in emulator mode). The migration function handles its own security checks instead of using withSecurityChecks, creating inconsistency. Combined with App Check being disabled, this function has significantly weaker bot protection. OWASP A07:2021 - Identification and Authentication Failures.","suggested_fix":"Refactor migrateAnonymousUserData to use the withSecurityChecks wrapper for consistent security enforcement. If reCAPTCHA must be optional for certain edge cases (network blocking), implement compensating controls such as stricter rate limiting or requiring additional verification for the migration operation.","confidence":82,"effort":"E1","fingerprint":"security::functions\\src\\index.ts::78a53638","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::functions\\src\\index.ts::78a53638"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0006","status":"CONFIRMED"}
{"title":"Journal and inventory entry data field accepts arbitrary objects without depth or size limits","severity":"S2","category":"security","files":["functions\\src\\schemas.ts"],"line":32,"why_it_matters":"The journalEntrySchema (line 32) and inventoryEntrySchema (line 51) both use z.record(z.string(), z.unknown()) for the 'data' field. This accepts any JSON object of any depth and any size without restriction. While the content field in dailyLogSchema has a 50KB max, the data field in journal and inventory entries has no size constraint. A malicious user could send deeply nested objects (prototype pollution risk if consumed carelessly) or very large payloads that consume Firestore document size limits (1MB) and bandwidth. The saveInventoryEntry function does implement a sanitizeData helper with MAX_DEPTH=50 and cycle detection, but saveJournalEntry stores entryData directly without sanitization (line 198 of index.ts). OWASP A03:2021 - Injection.","suggested_fix":"Add size and depth constraints to the data field in Zod schemas. Use z.record(z.string(), z.unknown()).refine(data => JSON.stringify(data).length < 100000, 'Data too large') for size limits. Apply the sanitizeData helper from saveInventoryEntry consistently to saveJournalEntry as well. Consider defining stricter per-type schemas for the data field instead of accepting arbitrary objects.","confidence":80,"effort":"E1","fingerprint":"security::functions\\src\\schemas.ts::aa53e68e","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::functions\\src\\schemas.ts::aa53e68e"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0007","status":"CONFIRMED"}
{"title":"Migration function does not verify source anonymous user is actually anonymous","severity":"S2","category":"security","files":["functions\\src\\index.ts"],"line":565,"why_it_matters":"The migrateAnonymousUserData function checks that the anonymous user document exists in Firestore (line 565-569) but does not verify via Firebase Auth that the source account (anonymousUid) is actually an anonymous account. A malicious user who knows another user's UID could potentially trigger a migration from a non-anonymous account, copying that user's journal entries, daily logs, and inventory entries into their own account. The only authorization check is that the caller must be the target user (line 550), not that they have any relationship to the source. While the rate limit (5 per 5 minutes) provides some protection, a determined attacker could exfiltrate data from multiple accounts over time. OWASP A01:2021 - Broken Access Control.","suggested_fix":"Add a Firebase Auth verification step to confirm the source user is actually anonymous: const sourceAuthUser = await admin.auth().getUser(validatedData.anonymousUid); if (!sourceAuthUser.providerData || sourceAuthUser.providerData.length > 0) { throw new HttpsError('permission-denied', 'Source account is not anonymous'); }. Additionally, consider verifying that the caller was recently authenticated as the anonymous user (e.g., by checking if the anonymous UID matches a recently linked account).","confidence":85,"effort":"E1","fingerprint":"security::functions\\src\\index.ts::744c8d81","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::functions\\src\\index.ts::744c8d81"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0008","status":"CONFIRMED"}
{"title":"CI workflow script injection via unsanitized file names","severity":"S2","category":"security","files":[".github/workflows/ci.yml"],"line":64,"why_it_matters":"Line 64 uses direct interpolation of the changed-files output into a shell command: 'node scripts/check-pattern-compliance.js -- ${{ steps.changed-files.outputs.all_changed_files }}'. While the double-dash prevents flag injection, filenames from pull requests are attacker-controlled (external contributors can create branches/files with arbitrary names). A file named with shell metacharacters (e.g., containing backticks, $(), or semicolons) could lead to command injection in the shell context. The tj-actions/changed-files action is also pinned to a SHA in the CI workflow (good), but the docs-lint.yml and auto-label-review-tier.yml workflows use unpinned 'v46' tags (less secure).","suggested_fix":"Quote the variable expansion: wrap it in double quotes as '\"${{ steps.changed-files.outputs.all_changed_files }}\"'. Better yet, pass files via an environment variable and use proper quoting, or pipe from stdin. Pin all tj-actions/changed-files references to a specific SHA commit hash rather than a version tag to prevent supply chain attacks.","confidence":75,"effort":"E1","fingerprint":"security::.github/workflows/ci.yml::23f51718","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::.github/workflows/ci.yml::23f51718"}],"verified":true,"consensus_score":1.5,"canonical_id":"CANON-0009","status":"SUSPECTED"}
{"title":"Firestore security_logs collection missing from security rules","severity":"S2","category":"security","files":["firestore.rules"],"line":1,"why_it_matters":"The security-logger.ts (line 324) writes security events to a 'security_logs' collection, and the admin functions read from it (adminGetLogs). However, the firestore.rules file has no explicit rule for the security_logs collection. In Firestore, any collection without a matching rule at the root level falls under no default rule, which means access is denied by default. This is actually secure by default for client access, but it also means there is no documented access policy. More critically, the admin_logs and admin_jobs collections referenced in the admin dashboard stats (admin.ts lines 1097, 1123) also lack explicit rules. While Cloud Functions using Admin SDK bypass rules, the lack of explicit deny rules means if a future developer adds a client-side read path, it would silently fail without a clear explanation.","suggested_fix":"Add explicit deny rules for internal collections to document access policy and prevent accidental exposure. Add: match /security_logs/{logId} { allow read, write: if false; } and similarly for admin_logs and admin_jobs. This makes the access policy explicit even though the default behavior is already secure.","confidence":72,"effort":"E1","fingerprint":"security::firestore.rules::721c9993","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::firestore.rules::721c9993"}],"verified":true,"consensus_score":1.5,"canonical_id":"CANON-0010","status":"SUSPECTED"}
{"title":"Unpinned GitHub Actions in multiple workflows","severity":"S3","category":"security","files":[".github/workflows/auto-label-review-tier.yml"],"line":29,"why_it_matters":"Multiple GitHub Actions workflows use unpinned version tags instead of SHA-pinned references. The auto-label-review-tier.yml uses 'tj-actions/changed-files@v46' (line 29), 'actions/checkout@v4' (line 18), 'actions/setup-node@v4' (line 22), and 'actions/github-script@v7' (lines 79, 103). Similarly, docs-lint.yml uses 'tj-actions/changed-files@v46' (line 36). The ci.yml correctly pins tj-actions/changed-files to a SHA (line 45) with a comment referencing CVE-2025-30066, but other workflows do not follow this pattern. Unpinned tags can be force-pushed to point to malicious code, enabling supply chain attacks.","suggested_fix":"Pin all third-party GitHub Actions to specific commit SHAs across all workflow files. The ci.yml already demonstrates the correct pattern: 'uses: tj-actions/changed-files@26a38635fc1173cc5820336ce97be6188d0de9f5 # v46.0.2'. Apply this same approach to all actions/checkout, actions/setup-node, actions/github-script, and tj-actions/changed-files references in auto-label-review-tier.yml, docs-lint.yml, review-check.yml, and deploy-firebase.yml.","confidence":88,"effort":"E1","fingerprint":"security::.github/workflows/auto-label-review-tier.yml::24967bc9","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::.github/workflows/auto-label-review-tier.yml::24967bc9"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0011","status":"CONFIRMED"}
{"title":"Error message in migration validation leaks Zod schema details to client","severity":"S3","category":"security","files":["functions\\src\\index.ts"],"line":545,"why_it_matters":"The migrateAnonymousUserData function (line 545) throws a validation error that includes the raw Zod error messages: throw new HttpsError('invalid-argument', 'Validation failed: ' + errorMessages). This contrasts with the withSecurityChecks wrapper (security-wrapper.ts line 258) which returns a generic 'Invalid input data' message. The detailed Zod messages could reveal internal schema structure (field names, validation rules, expected formats) to an attacker, aiding in crafting bypass payloads. OWASP A04:2021 - Insecure Design.","suggested_fix":"Replace the detailed validation error with a generic message: throw new HttpsError('invalid-argument', 'Invalid migration request. Please check your input.'). Log the detailed Zod errors server-side only for debugging purposes.","confidence":88,"effort":"E1","fingerprint":"security::functions\\src\\index.ts::a8aa979f","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::functions\\src\\index.ts::a8aa979f"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0012","status":"CONFIRMED"}
{"title":"Admin function input validation inconsistency - meetingId and homeId not validated","severity":"S3","category":"security","files":["functions/src/admin.ts"],"line":768,"why_it_matters":"The adminDeleteMeeting function (line 768) and adminDeleteSoberLiving function (line 862) only check if meetingId/homeId is truthy but do not validate the format or length of these IDs. A malicious admin could pass excessively long strings or strings with special characters as document IDs. While Firestore handles most edge cases, very long document IDs (>1500 bytes) would cause Firestore errors, and the raw ID values are included in security log metadata without sanitization (line 779: 'metadata: { meetingId }'). In contrast, the soft-delete functions properly validate UIDs with Zod schemas (line 1513-1516). The adminSaveMeeting function validates the meeting data via meetingSchema.parse() but uses the client-provided 'validated.id' directly as the document ID without format validation.","suggested_fix":"Add Zod schema validation for document IDs in all admin delete and save functions. Apply a consistent pattern: validate that IDs are non-empty strings matching the expected Firestore auto-ID format (alphanumeric, 20 characters). Apply the same pattern used in softDeleteSchema and undeleteSchema to all admin functions.","confidence":78,"effort":"E1","fingerprint":"security::functions/src/admin.ts::e7f71625","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::functions/src/admin.ts::e7f71625"}],"verified":true,"consensus_score":1.5,"canonical_id":"CANON-0013","status":"SUSPECTED"}
{"title":"Firestore security rules missing for security_logs and admin_jobs collections","severity":"S3","category":"security","files":["firestore.rules"],"line":151,"why_it_matters":"The Firestore security rules do not include explicit rules for the security_logs collection (written by Cloud Functions at security-logger.ts:324), admin_jobs collection (written by jobs.ts), or admin_logs collection (read by admin.ts:1098). Firestore's default behavior when no rule matches is to deny access, which means these collections are implicitly denied for client access. However, relying on implicit deny is a security anti-pattern because: (1) it provides no documentation of intent, (2) a future rule change with a wildcard match could accidentally expose these collections, (3) the dev/{document=**} wildcard rule (line 138) demonstrates that broad matching rules exist in this ruleset.","suggested_fix":"Add explicit deny rules for internal collections to document intent and prevent accidental exposure: 'match /security_logs/{docId} { allow read, write: if false; }', 'match /admin_jobs/{docId} { allow read, write: if false; }', 'match /admin_logs/{docId} { allow read, write: if false; }'. This makes the security posture explicit and resistant to future wildcard additions.","confidence":72,"effort":"E1","fingerprint":"security::firestore.rules::fab244b4","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::firestore.rules::fab244b4"}],"verified":true,"consensus_score":1.5,"canonical_id":"CANON-0014","status":"SUSPECTED"}
{"title":"User ID hash truncation reduces collision resistance for privacy-sensitive logs","severity":"S3","category":"security","files":["functions/src/security-logger.ts"],"line":74,"why_it_matters":"The hashUserId function (lines 70-77) truncates SHA-256 hashes to 12 hex characters (48 bits of entropy). While the comment states this provides '~281 trillion combinations', this level of collision resistance may be insufficient for privacy guarantees. With a user base of N users, the birthday paradox means collisions become likely around sqrt(2^48) = ~16.7 million users. More importantly, because Firebase UIDs have a known format (28 alphanumeric characters), and the hash has no salt, an attacker with access to security logs could build a rainbow table by hashing all possible Firebase UIDs to find the original UID from a 12-character hash. Without a salt, the hash is deterministic and reversible for known-format inputs.","suggested_fix":"Add a secret salt to the hashUserId function that is stored in GCP Secret Manager (not in source code). This prevents rainbow table attacks even if the hash algorithm and truncation length are known. Consider using HMAC-SHA256 with a secret key instead of plain SHA-256. If increasing hash length is acceptable, use 16 or 20 characters to improve collision resistance.","confidence":70,"effort":"E1","fingerprint":"security::functions/src/security-logger.ts::e0625254","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::functions/src/security-logger.ts::e0625254"}],"verified":true,"consensus_score":1.5,"canonical_id":"CANON-0015","status":"SUSPECTED"}
{"title":"Service account credentials written to disk in CI deploy workflow","severity":"S3","category":"security","files":[".github/workflows/deploy-firebase.yml"],"line":58,"why_it_matters":"The deploy-firebase.yml workflow writes the FIREBASE_SERVICE_ACCOUNT secret to a file on disk (line 58: 'echo ... > $HOME/gcloud-key.json'), sets file permissions to 600, and later cleans up with 'rm -f'. While the cleanup step uses 'if: always()' to ensure it runs even on failure, writing credentials to disk creates a window of vulnerability. If the runner is compromised or the workflow fails between write and cleanup, the credentials could be exfiltrated. Additionally, the echo command may be captured in runner process logs.","suggested_fix":"Use the google-github-actions/auth action with Workload Identity Federation instead of service account key files. This eliminates the need to store or write any credentials to disk. If key files must be used, consider using a tmpfs/memory-backed filesystem and ensure the cleanup step cannot be skipped. Also consider using 'echo ... | gcloud auth activate-service-account --key-file=-' to pipe directly without writing to disk.","confidence":68,"effort":"E1","fingerprint":"security::.github/workflows/deploy-firebase.yml::0855b57c","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::.github/workflows/deploy-firebase.yml::0855b57c"}],"verified":true,"consensus_score":1.5,"canonical_id":"CANON-0016","status":"SUSPECTED"}
{"title":"No middleware.ts for server-side route protection","severity":"S3","category":"security","files":["next.config.mjs"],"line":13,"why_it_matters":"The application uses Next.js with output: 'export' (static export) and has no middleware.ts file. While this is a conscious architectural decision (Firebase Hosting serves static files), it means there is no server-side route protection, no server-side session validation, and no ability to redirect unauthenticated users before page load. All authentication checks happen client-side in the AuthProvider component. For a statically exported SPA this is the expected pattern, but it means the HTML/JS for all routes (including admin pages) is delivered to every user, and route protection relies entirely on client-side JavaScript. An attacker can view the full admin UI code even without admin privileges (though data access is still protected by Cloud Functions).","suggested_fix":"This is acceptable for the current architecture (static SPA + Firebase), but ensure that no sensitive data is embedded in the static build output. Verify that admin page components do not contain hardcoded secrets or sensitive configuration. Consider using Next.js server-side rendering for admin routes if the application migrates away from static export in the future.","confidence":70,"effort":"E1","fingerprint":"security::next.config.mjs::8f44dc99","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::next.config.mjs::8f44dc99"}],"verified":true,"consensus_score":1.5,"canonical_id":"CANON-0017","status":"SUSPECTED"}
{"title":"Daily quotes collection allows direct admin client writes bypassing Cloud Functions","severity":"S3","category":"security","files":["firestore.rules"],"line":104,"why_it_matters":"The daily_quotes collection (line 104) allows direct writes from users with the admin custom claim: allow write: if isAdmin(). This is inconsistent with the security pattern used for other admin-managed collections (meetings, sober_living) which use 'allow write: if false' and require writes through Cloud Functions (adminSaveMeeting, adminDeleteMeeting, etc.). Direct client writes bypass Cloud Function protections including rate limiting, Zod schema validation, and structured audit logging. The same inconsistency exists for glossary, slogans, quick_links, and prayers collections (lines 109-131).","suggested_fix":"Change the write rules for daily_quotes, glossary, slogans, quick_links, and prayers to 'allow write: if false' and route all writes through admin Cloud Functions with proper validation and audit logging. This ensures consistent defense-in-depth across all admin-writable collections.","confidence":78,"effort":"E1","fingerprint":"security::firestore.rules::b56af95a","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::firestore.rules::b56af95a"}],"verified":true,"consensus_score":1.5,"canonical_id":"CANON-0018","status":"SUSPECTED"}
{"title":"Rate limiter document ID uses unsanitized user input","severity":"S3","category":"security","files":["functions\\src\\firestore-rate-limiter.ts"],"line":82,"why_it_matters":"The Firestore rate limiter constructs document IDs by concatenating user-provided values: const docId = `${key}_${operation}` (line 82), where key includes the userId or IP address. While Firestore document IDs have a 1500-byte limit and accept most UTF-8 characters, the operation parameter comes from hardcoded function names. However, the consumeByIp method uses the raw (normalized) IP address as part of the key. IPv6 addresses can contain colons and other characters. While Firestore handles these characters, extremely long or malformed IP strings could create unexpectedly named documents. The userId is validated by Firebase Auth (always alphanumeric), so the user-based path is safe.","suggested_fix":"Validate or hash the IP address before using it in the document ID. Apply the same FIREBASE_UID_PATTERN validation used in admin.ts, or hash the IP with SHA-256 before constructing the key. This prevents edge cases with unusual IP formats and also avoids storing raw IP addresses in Firestore document IDs (PII concern).","confidence":60,"effort":"E1","fingerprint":"security::functions\\src\\firestore-rate-limiter.ts::431ff93b","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::functions\\src\\firestore-rate-limiter.ts::431ff93b"}],"verified":true,"consensus_score":1.5,"canonical_id":"CANON-0019","status":"SUSPECTED"}
{"title":"Client-side logger may leak sensitive data in development console","severity":"S3","category":"security","files":["lib\\firestore-service.ts"],"line":229,"why_it_matters":"In development mode (line 224-230), the firestore-service.ts logs the full payload to console with console.log, masking only the content field. Other potentially sensitive fields like userId, date, mood, cravings, and used status are logged in plaintext. While this is development-only, developers may share console output in bug reports or screenshots. The userId in particular should be masked consistently. Additionally, the logger.ts redactValue function (line 63) partially redacts strings that look like sensitive IDs (showing first 4 chars), which may be enough for an attacker to correlate users if the logs are exposed.","suggested_fix":"Apply the maskIdentifier helper to the userId field in development debug logging. Consider removing detailed payload logging entirely and relying on Cloud Function server-side logs for debugging. Ensure the development logging is gated behind an additional opt-in flag (e.g., NEXT_PUBLIC_DEBUG_LOGGING=true) rather than automatically enabled for all development builds.","confidence":65,"effort":"E1","fingerprint":"security::lib\\firestore-service.ts::a540fa72","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::lib\\firestore-service.ts::a540fa72"}],"verified":true,"consensus_score":1.5,"canonical_id":"CANON-0020","status":"SUSPECTED"}