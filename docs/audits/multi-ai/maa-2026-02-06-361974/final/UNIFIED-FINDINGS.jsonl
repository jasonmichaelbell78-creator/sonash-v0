{"title":"Security risk: Client-side filtering of sensitive data","severity":"S0","category":"code","files":["hooks\\use-journal.ts"],"line":174,"why_it_matters":"The processJournalDoc function filters out soft-deleted entries on the client (line 174: if (data.isSoftDeleted === true) return null). This means soft-deleted entries are sent over the network to the client, consuming bandwidth and potentially exposing deleted content in network traffic. While the entries are filtered from the UI, they're visible in browser DevTools Network tab and could be extracted by inspecting the Firebase SDK's local cache. This violates the privacy expectation that deleted content is truly removed.","suggested_fix":"Add a Firestore security rule or composite index to exclude isSoftDeleted entries from query results. Update the query in useJournal (line 277-281) to add .where('isSoftDeleted', '==', false). This ensures deleted entries never leave the server. For backward compatibility during deployment, keep the client-side filter as a safety net until the query filter is confirmed working. Then remove client-side filter in a follow-up PR. Same pattern should be applied to any other user-facing queries.","confidence":97,"effort":"E1","fingerprint":"code-quality::hooks\\use-journal.ts::60817d80","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-backend-architect","file":"code-claude-backend-architect.jsonl","original_fingerprint":"code-quality::hooks\\use-journal.ts::60817d80"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0014","status":"CONFIRMED","cross_cutting":false,"categories":["code"],"priority_score":108.5,"unified_id":"UNIFIED-0001"}
{"title":"App Check disabled across all Cloud Functions","severity":"S1","category":"security","files":["functions/src/index.ts","functions\\src\\index.ts"],"line":84,"why_it_matters":"All Cloud Functions have requireAppCheck set to false with a comment stating 'TEMPORARILY DISABLED - waiting for throttle to clear'. This disables Firebase App Check verification, which is meant to prevent unauthorized callers and bot abuse. Without App Check, any client that can construct valid Firebase requests can invoke these functions, bypassing a critical defense-in-depth layer. The same pattern is repeated for saveDailyLog (line 84), saveJournalEntry (line 170), softDeleteJournalEntry (line 269), saveInventoryEntry (line 363), and migrateAnonymousUserData (line 506-511). While reCAPTCHA provides some compensating control, App Check was designed to be the primary attestation mechanism.","suggested_fix":"Re-enable App Check verification by setting requireAppCheck to true on all Cloud Functions. If the reCAPTCHA Enterprise throttle issue has been resolved, remove the 'TEMPORARILY DISABLED' comment and restore the App Check enforcement. Consider adding a monitoring alert so this does not remain disabled indefinitely.","confidence":95,"effort":"E1","fingerprint":"security::functions/src/index.ts::d65872ee","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::functions/src/index.ts::d65872ee"},{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::functions\\src\\index.ts::d65872ee"}],"merged_from":["security::functions/src/index.ts::d65872ee","security::functions\\src\\index.ts::d65872ee"],"verified":true,"consensus_score":3,"canonical_id":"CANON-0001","status":"CONFIRMED","cross_cutting":false,"categories":["security"],"priority_score":63.8,"unified_id":"UNIFIED-0002"}
{"title":"Performance anti-pattern: Excessive re-renders from context composition","severity":"S1","category":"code","files":["components\\providers\\auth-provider.tsx"],"line":43,"why_it_matters":"The AuthProvider calls onUserChange(currentUser) on every auth state change (line 89), which triggers setCurrentUser in the parent (line 40), which re-renders all three provider layers. When user changes, ProfileProvider and DailyLogProvider both receive new user prop, triggering their useEffect hooks (profile-context.tsx line 91, similar in daily-log-context). This cascading effect causes 3+ re-renders per auth change. Additionally, the user object is passed as prop through three layers of nesting, creating unnecessary prop dependencies.","suggested_fix":"Eliminate the user prop passing. Have ProfileProvider and DailyLogProvider consume user directly from AuthContext using useAuthCore(). Remove onUserChange callback and currentUser state from AuthProvider. This breaks the cascading re-render chain: auth changes trigger one re-render in AuthProvider, then ProfileProvider and DailyLogProvider subscribe and update independently. Reduces auth state changes from 3+ renders to 1 render per context.","confidence":93,"effort":"E1","fingerprint":"code-quality::components\\providers\\auth-provider.tsx::80c7a95a","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-backend-architect","file":"code-claude-backend-architect.jsonl","original_fingerprint":"code-quality::components\\providers\\auth-provider.tsx::80c7a95a"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0002","status":"CONFIRMED","cross_cutting":false,"categories":["code"],"priority_score":58.3,"unified_id":"UNIFIED-0003"}
{"title":"Missing input validation on server-generated data","severity":"S1","category":"code","files":["hooks\\use-journal.ts"],"line":172,"why_it_matters":"The processJournalDoc function validates timestamps (lines 177-198) but does not validate other required fields like userId, type, or dateLabel format. It only validates dateLabel format later during grouping (line 219). If a malicious admin or database corruption creates documents with missing userId or invalid type, these entries would pass validation and could cause runtime errors when components assume these fields exist. The validation is also defensive only (skips invalid entries) rather than alerting on data integrity issues.","suggested_fix":"Implement comprehensive Zod schema validation for JournalEntry in processJournalDoc. Import the JournalEntry type schema and validate each document against it. On validation failure, log to Sentry with CRITICAL severity (data integrity issue) and skip the entry. Add a data integrity monitoring dashboard in admin panel to surface these failures. This catches database corruption, manual edits, or migration bugs early.","confidence":89,"effort":"E1","fingerprint":"code-quality::hooks\\use-journal.ts::93453fb4","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-backend-architect","file":"code-claude-backend-architect.jsonl","original_fingerprint":"code-quality::hooks\\use-journal.ts::93453fb4"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0003","status":"CONFIRMED","cross_cutting":false,"categories":["code"],"priority_score":57.3,"unified_id":"UNIFIED-0004"}
{"title":"Data flow violation: Direct Firestore writes in admin components","severity":"S1","category":"code","files":["components\\admin\\dashboard-tab.tsx"],"line":4,"why_it_matters":"Admin components directly call Cloud Functions using httpsCallable (line 732, 755, 782, 806). While this is acceptable for admin operations, it bypasses the service layer pattern used elsewhere. If Cloud Function interfaces change (parameter names, return types), every admin component must be updated manually. Additionally, there's no shared retry logic, error handling, or rate limiting like there is in firestore-service.ts. This creates maintenance burden and inconsistent error UX.","suggested_fix":"Create lib/admin-service.ts that wraps all admin Cloud Functions with consistent error handling, retry logic, and type safety. Export methods like getStorageStats(), getRateLimitStatus(), clearRateLimit(key), etc. Use the same dependency injection pattern as FirestoreService to enable testing. Update all admin components to use AdminService instead of direct httpsCallable calls. This centralizes admin API calls and enables adding features like caching, request deduplication, or optimistic updates.","confidence":86,"effort":"E1","fingerprint":"code-quality::components\\admin\\dashboard-tab.tsx::4d9ed0a3","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-backend-architect","file":"code-claude-backend-architect.jsonl","original_fingerprint":"code-quality::components\\admin\\dashboard-tab.tsx::4d9ed0a3"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0004","status":"CONFIRMED","cross_cutting":false,"categories":["code"],"priority_score":56.5,"unified_id":"UNIFIED-0005"}
{"title":"Missing error boundary coverage for async operations","severity":"S1","category":"code","files":["components\\providers\\error-boundary.tsx"],"line":37,"why_it_matters":"The ErrorBoundary component only catches synchronous render errors and componentDidCatch errors. It does not catch errors from async operations in useEffect hooks, Cloud Function calls, or Firestore queries. For example, in use-journal.ts, Cloud Function failures are caught locally but never bubble to a global error handler. This creates inconsistent error handling where some errors show toasts, some return error objects, and some are silently logged.","suggested_fix":"Implement an async error boundary pattern using React error boundaries for render errors plus a global error context for async errors. Create an ErrorProvider that wraps the app and provides a reportError(error, context) function. Update all async operations (Cloud Functions, Firestore queries) to call reportError on catch. This centralizes error handling and enables consistent user feedback, retry logic, and error reporting to Sentry.","confidence":85,"effort":"E1","fingerprint":"code-quality::components\\providers\\error-boundary.tsx::2fbdc4fa","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-backend-architect","file":"code-claude-backend-architect.jsonl","original_fingerprint":"code-quality::components\\providers\\error-boundary.tsx::2fbdc4fa"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0001","status":"CONFIRMED","cross_cutting":false,"categories":["code"],"priority_score":56.3,"unified_id":"UNIFIED-0006"}
{"title":"Missing cleanup for onSnapshot listener","severity":"S1","category":"code","files":["hooks\\use-journal.ts"],"line":284,"why_it_matters":"The useEffect returns unsubscribeSnapshot for cleanup, but if the component unmounts during the async onSnapshot setup (before the listener is established), the cleanup function may not exist yet, causing a potential memory leak.","suggested_fix":"Track the subscription state: 'let unsubscribe: (() => void) | null = null; const listener = onSnapshot(...); unsubscribe = listener; return () => { unsubscribe?.(); };' to ensure cleanup even if component unmounts early.","confidence":85,"effort":"E1","fingerprint":"code-quality::hooks\\use-journal.ts::b7d063c4","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-code-reviewer","file":"code-claude-code-reviewer.jsonl","original_fingerprint":"code-quality::hooks\\use-journal.ts::b7d063c4"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0006","status":"CONFIRMED","cross_cutting":false,"categories":["code"],"priority_score":56.3,"unified_id":"UNIFIED-0007"}
{"title":"Unvalidated URL construction in GCP links","severity":"S1","category":"code","files":["components\\admin\\logs-tab.tsx"],"line":436,"why_it_matters":"While there's URL validation with isSafeGcpUrl, the validation happens client-side after receiving data from the backend. If the backend is compromised or returns malicious URLs, they could pass the validation if they match the hostname check.","suggested_fix":"Add Content Security Policy headers to restrict navigation targets, and consider using a URL allowlist pattern instead of just hostname validation. Also validate URL paths to prevent navigation to unexpected GCP console sections.","confidence":82,"effort":"E1","fingerprint":"code-quality::components\\admin\\logs-tab.tsx::69e74873","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-code-reviewer","file":"code-claude-code-reviewer.jsonl","original_fingerprint":"code-quality::components\\admin\\logs-tab.tsx::69e74873"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0005","status":"CONFIRMED","cross_cutting":false,"categories":["code"],"priority_score":55.5,"unified_id":"UNIFIED-0008"}
{"title":"API design inconsistency: Mixed return patterns","severity":"S2","category":"code","files":["lib\\firestore-service.ts"],"line":262,"why_it_matters":"FirestoreService methods use inconsistent return patterns. getTodayLog() returns Promise<{log: DailyLog | null, error: unknown}> (line 262), getHistory() returns Promise<{entries: DailyLog[], error: unknown}> (line 301), but saveDailyLog() throws errors instead of returning {success: boolean, error?: Error}. This forces consumers to use try/catch for saves but object destructuring for reads. The use-journal.ts hook wraps Cloud Function calls to return {success, error} objects (line 369), creating yet another pattern.","suggested_fix":"Standardize on a Result<T> type pattern across all service methods. Create lib/types/result.ts with type Result<T> = {success: true, data: T} | {success: false, error: Error}. Update all FirestoreService methods to return Result<T>. This eliminates try/catch patterns, makes error handling explicit in type signatures, and enables consistent error handling across the app. Consider using a library like neverthrow for Result type utilities.","confidence":91,"effort":"E1","fingerprint":"code-quality::lib\\firestore-service.ts::6d2c7787","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-backend-architect","file":"code-claude-backend-architect.jsonl","original_fingerprint":"code-quality::lib\\firestore-service.ts::6d2c7787"},{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::lib\\firestore-service.ts::a540fa72"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0012","status":"CONFIRMED","cross_cutting":true,"categories":["code","security"],"related_findings":[{"id":"CANON-0012","category":"code","title":"API design inconsistency: Mixed return patterns"},{"id":"CANON-0020","category":"security","title":"Client-side logger may leak sensitive data in deve"}],"file_hotspot":"lib\\firestore-service.ts","priority_score":38.7,"unified_id":"UNIFIED-0009"}
{"title":"Missing Content-Security-Policy header","severity":"S2","category":"security","files":["firebase.json"],"line":29,"why_it_matters":"The firebase.json hosting configuration sets several security headers (X-Frame-Options, X-Content-Type-Options, HSTS, Referrer-Policy, Permissions-Policy) but is missing a Content-Security-Policy (CSP) header. Without CSP, the application is more vulnerable to XSS attacks because the browser has no policy restricting which scripts, styles, and other resources can be loaded. This is especially important for a health/recovery application that handles sensitive personal data.","suggested_fix":"Add a Content-Security-Policy header to the '**' source block in firebase.json. Start with a restrictive policy that allows only same-origin resources and explicitly whitelists Google/Firebase/reCAPTCHA domains. Example: \"default-src 'self'; script-src 'self' https://www.google.com https://www.gstatic.com; connect-src 'self' https://*.googleapis.com https://*.firebaseio.com; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; font-src 'self'\". Test thoroughly before deploying to production.","confidence":91,"effort":"E1","fingerprint":"security::firebase.json::dbd1ddfc","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::firebase.json::dbd1ddfc"},{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::firebase.json::dbd1ddfc"}],"merged_from":["security::firebase.json::dbd1ddfc","security::firebase.json::dbd1ddfc"],"verified":true,"consensus_score":3,"canonical_id":"CANON-0003","status":"CONFIRMED","cross_cutting":false,"categories":["security"],"priority_score":34.1,"unified_id":"UNIFIED-0010"}
{"title":"User profile document allows direct client writes without rate limiting","severity":"S2","category":"security","files":["firestore.rules"],"line":26,"why_it_matters":"The Firestore security rule at line 26 allows any authenticated user to read AND write their own profile document at /users/{userId} with 'allow read, write: if isOwner(userId)'. Unlike journal entries, daily logs, and inventory entries (which are routed through Cloud Functions with rate limiting, Zod validation, and App Check), user profile writes bypass all server-side security controls. A malicious client could: (1) rapidly spam profile updates without rate limiting, (2) write arbitrary fields to their profile document (no schema validation), (3) set fields like 'isAdmin', 'privilegeType', or other sensitive fields directly. The client-side lib/db/users.ts uses Zod validation, but this can be trivially bypassed with browser dev tools or a custom Firestore client.","suggested_fix":"Route user profile updates through a Cloud Function with the same security wrapper (withSecurityChecks) used for other operations. Add server-side Zod validation to restrict which fields can be written. At minimum, add Firestore rules to prevent clients from writing sensitive fields like 'isAdmin', 'privilegeType', 'disabled', 'isSoftDeleted', 'migratedFrom'. Example rule: 'allow write: if isOwner(userId) && !request.resource.data.diff(resource.data).affectedKeys().hasAny([\"isAdmin\", \"privilegeType\", \"disabled\", \"isSoftDeleted\"])'.","confidence":90,"effort":"E1","fingerprint":"security::firestore.rules::897fc903","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::firestore.rules::897fc903"},{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::firestore.rules::a650e0bc"}],"merged_from":["security::firestore.rules::897fc903","security::firestore.rules::a650e0bc"],"verified":true,"consensus_score":3,"canonical_id":"CANON-0004","status":"CONFIRMED","cross_cutting":false,"categories":["security"],"priority_score":34,"unified_id":"UNIFIED-0011"}
{"title":"Hardcoded reCAPTCHA site key in server-side code","severity":"S2","category":"security","files":["functions/src/recaptcha-verify.ts","functions\\src\\recaptcha-verify.ts"],"line":66,"why_it_matters":"The reCAPTCHA Enterprise site key is hardcoded as a fallback value on line 66: '6LdeazosAAAAAMDNCh1hTUDKh_UeS6xWY1-85B2O'. While site keys are considered public (they are embedded in frontend HTML), hardcoding them in server-side source code is an anti-pattern. If the key needs to be rotated or environment-specific keys are needed (staging vs production), this fallback could cause the wrong key to be used. Additionally, the code uses process.env for configuration in Cloud Functions, which the project's own security-check.js (SEC-006) flags as a concern -- defineString() from firebase-functions/params is preferred.","suggested_fix":"Remove the hardcoded fallback site key. Use defineString() from firebase-functions/params to configure RECAPTCHA_SITE_KEY as a deployment parameter. Ensure the key is properly configured in each deployment environment (production, staging, emulator).","confidence":83,"effort":"E1","fingerprint":"security::functions/src/recaptcha-verify.ts::33d5fe3e","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::functions/src/recaptcha-verify.ts::33d5fe3e"},{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::functions\\src\\recaptcha-verify.ts::3d2f4030"}],"merged_from":["security::functions/src/recaptcha-verify.ts::33d5fe3e","security::functions\\src\\recaptcha-verify.ts::3d2f4030"],"verified":true,"consensus_score":3,"canonical_id":"CANON-0002","status":"CONFIRMED","cross_cutting":false,"categories":["security"],"priority_score":33.3,"unified_id":"UNIFIED-0012"}
{"title":"God component: dashboard-tab.tsx with excessive state management","severity":"S2","category":"code","files":["components\\admin\\dashboard-tab.tsx"],"line":952,"why_it_matters":"DashboardTab component manages 12+ pieces of state (health, stats, loading, error, storageStats, loadingStorage, storageError, rateLimits, loadingRateLimits, rateLimitsError, collectionStats, loadingCollections, collectionsError, clearingRateLimit). While the component has been refactored to extract subcomponents for rendering, the state management remains centralized in a single component. This creates tight coupling between different concerns (health checks, storage stats, rate limits, collection stats) and makes testing difficult.","suggested_fix":"Apply the reducer pattern or split into multiple context providers (HealthContext, StorageContext, RateLimitsContext, CollectionStatsContext). Each context should manage its own state and API calls. This follows the same pattern already used successfully in auth-provider.tsx where auth, profile, and daily log state are separated into focused contexts.","confidence":95,"effort":"E1","fingerprint":"code-quality::components\\admin\\dashboard-tab.tsx::757dd7f3","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-backend-architect","file":"code-claude-backend-architect.jsonl","original_fingerprint":"code-quality::components\\admin\\dashboard-tab.tsx::757dd7f3"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0007","status":"CONFIRMED","cross_cutting":false,"categories":["code"],"priority_score":29.5,"unified_id":"UNIFIED-0013"}
{"title":"Any type usage in today-page.tsx snapshot handler","severity":"S2","category":"code","files":["components\\notebook\\pages\\today-page.tsx"],"line":507,"why_it_matters":"The docSnap parameter in a callback function uses the 'any' type, which bypasses TypeScript's type safety. This can lead to runtime errors if the snapshot structure changes or contains unexpected data.","suggested_fix":"Replace 'any' with a proper type annotation. Use 'QueryDocumentSnapshot<DocumentData>' or create a specific type for the snapshot data structure.","confidence":95,"effort":"E1","fingerprint":"code-quality::components\\notebook\\pages\\today-page.tsx::c39f8b5b","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-code-reviewer","file":"code-claude-code-reviewer.jsonl","original_fingerprint":"code-quality::components\\notebook\\pages\\today-page.tsx::c39f8b5b"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0015","status":"CONFIRMED","cross_cutting":false,"categories":["code"],"priority_score":29.5,"unified_id":"UNIFIED-0014"}
{"title":"Tight coupling between UI components and Firebase SDK","severity":"S2","category":"code","files":["hooks\\use-journal.ts"],"line":350,"why_it_matters":"The useJournal hook directly imports and calls getFunctions() and httpsCallable() from firebase/functions. While the firestore-service.ts follows the repository pattern with dependency injection for testing, hooks like use-journal.ts tightly couple to Firebase SDK. This makes it impossible to test useJournal without mocking Firebase modules and prevents swapping implementations (e.g., testing with local emulator, using REST API fallback).","suggested_fix":"Extract Cloud Function calls into a CloudFunctionService similar to FirestoreService. Create lib/cloud-function-service.ts with methods like saveJournalEntry(data), softDeleteJournalEntry(id), etc. Use dependency injection pattern like FirestoreService to enable testing. Update useJournal and other hooks to call CloudFunctionService methods instead of direct Firebase SDK calls.","confidence":92,"effort":"E1","fingerprint":"code-quality::hooks\\use-journal.ts::75fad85b","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-backend-architect","file":"code-claude-backend-architect.jsonl","original_fingerprint":"code-quality::hooks\\use-journal.ts::75fad85b"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0009","status":"CONFIRMED","cross_cutting":false,"categories":["code"],"priority_score":29.2,"unified_id":"UNIFIED-0015"}
{"title":"Hardcoded bucket name in Cloud Functions","severity":"S2","category":"code","files":["functions\\src\\jobs.ts"],"line":602,"why_it_matters":"The storage bucket name 'sonash-app.firebasestorage.app' is hardcoded directly in the cleanup function. This makes the code environment-dependent and harder to test or deploy across different environments.","suggested_fix":"Extract bucket name to an environment variable or Firebase Functions config parameter: 'const bucketName = defineString(\"STORAGE_BUCKET\"); const bucket = storage.bucket(bucketName.value());'","confidence":92,"effort":"E1","fingerprint":"code-quality::functions\\src\\jobs.ts::e0007270","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-code-reviewer","file":"code-claude-code-reviewer.jsonl","original_fingerprint":"code-quality::functions\\src\\jobs.ts::e0007270"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0017","status":"CONFIRMED","cross_cutting":false,"categories":["code"],"priority_score":29.2,"unified_id":"UNIFIED-0016"}
{"title":"Inconsistent state management patterns across providers","severity":"S2","category":"code","files":["components\\providers\\auth-provider.tsx"],"line":38,"why_it_matters":"The codebase uses two different state management patterns: (1) Unified provider pattern in auth-provider.tsx that composes multiple contexts with explicit child providers, and (2) Manual composition in profile-context.tsx and daily-log-context.tsx that accept user as a prop. While both work, this inconsistency makes the codebase harder to reason about. The manual composition pattern requires parent components to track and pass user state, creating implicit coupling.","suggested_fix":"Standardize on the composition pattern already used in AuthProvider. Update ProfileProvider and DailyLogProvider to consume user from AuthContext directly using useAuthCore() instead of accepting it as a prop. This eliminates prop drilling and makes the dependency chain explicit through context consumption rather than component nesting.","confidence":90,"effort":"E1","fingerprint":"code-quality::components\\providers\\auth-provider.tsx::0095ed65","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-backend-architect","file":"code-claude-backend-architect.jsonl","original_fingerprint":"code-quality::components\\providers\\auth-provider.tsx::0095ed65"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0008","status":"CONFIRMED","cross_cutting":false,"categories":["code"],"priority_score":29,"unified_id":"UNIFIED-0017"}
{"title":"Anti-pattern: Firestore queries in components instead of service layer","severity":"S2","category":"code","files":["hooks\\use-journal.ts"],"line":277,"why_it_matters":"The useJournal hook directly constructs Firestore queries using collection(), query(), orderBy(), limit() from firebase/firestore (lines 277-281). While writes go through Cloud Functions for validation, reads bypass the repository pattern entirely. This creates inconsistency: writes use firestore-service.ts but reads use direct SDK calls. It also makes query logic untestable without Firebase emulator.","suggested_fix":"Move all Firestore queries to firestore-service.ts. Add methods like getJournalEntries(userId, limit?), getInventoryEntries(userId, limit?), etc. These methods should return the query logic but still use onSnapshot for real-time updates. Update useJournal to call FirestoreService.getJournalEntries() and pass the result to onSnapshot. This maintains real-time updates while centralizing query construction for testing and maintenance.","confidence":88,"effort":"E1","fingerprint":"code-quality::hooks\\use-journal.ts::80279206","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-backend-architect","file":"code-claude-backend-architect.jsonl","original_fingerprint":"code-quality::hooks\\use-journal.ts::80279206"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0011","status":"CONFIRMED","cross_cutting":false,"categories":["code"],"priority_score":28.8,"unified_id":"UNIFIED-0018"}
{"title":"Missing dependency in useEffect for logs refresh","severity":"S2","category":"code","files":["components\\admin\\logs-tab.tsx"],"line":418,"why_it_matters":"The useEffect sets up the initial refresh with a closure capturing the 'active' variable, but the 'refresh' function is in the dependency array. If refresh is recreated, the effect runs again, but the original closure's 'active' flag may already be stale.","suggested_fix":"Remove 'refresh' from the dependency array and add an ESLint disable comment with justification, or restructure to use useRef for the active flag: 'const activeRef = useRef(true);' and check 'activeRef.current' in callbacks.","confidence":88,"effort":"E1","fingerprint":"code-quality::components\\admin\\logs-tab.tsx::941a6413","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-code-reviewer","file":"code-claude-code-reviewer.jsonl","original_fingerprint":"code-quality::components\\admin\\logs-tab.tsx::941a6413"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0018","status":"CONFIRMED","cross_cutting":false,"categories":["code"],"priority_score":28.8,"unified_id":"UNIFIED-0019"}
{"title":"Missing loading state coordination across contexts","severity":"S2","category":"code","files":["hooks\\use-journal.ts"],"line":428,"why_it_matters":"The useJournal hook combines authLoading and journalLoading into a single loading state (line 428). However, this pattern is not consistent across the app. Some components check auth.loading and profile.loading separately, others combine them. The journal-hub.tsx component only checks loading from useAuth (line 39) which combines all three providers' loading states, potentially showing spinner while only auth is loading but profile/daily-log are ready.","suggested_fix":"Create a useLoadingState() hook that provides granular loading states (authLoading, profileLoading, dataLoading) and computed states (isInitializing, isReady). Update all data-fetching hooks to report their loading state to this central coordinator. This enables components to show progressive loading states (e.g., show partial UI when auth is ready but profile is loading) instead of all-or-nothing spinners.","confidence":87,"effort":"E1","fingerprint":"code-quality::hooks\\use-journal.ts::0fd30492","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-backend-architect","file":"code-claude-backend-architect.jsonl","original_fingerprint":"code-quality::hooks\\use-journal.ts::0fd30492"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0010","status":"CONFIRMED","cross_cutting":false,"categories":["code"],"priority_score":28.7,"unified_id":"UNIFIED-0020"}
{"title":"Missing error boundary in inventory form","severity":"S2","category":"code","files":["components\\journal\\entry-forms\\inventory-form.tsx"],"line":38,"why_it_matters":"The addEntry call only logs errors and shows a toast, but doesn't handle the case where the hook might throw an unhandled promise rejection. Error handling relies solely on try/catch without checking the return value structure.","suggested_fix":"Add validation to check if addEntry returns an error in its response object: 'const result = await addEntry(...); if (!result.success) { toast.error(result.error); return; }'","confidence":85,"effort":"E1","fingerprint":"code-quality::components\\journal\\entry-forms\\inventory-form.tsx::cbdef33c","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-code-reviewer","file":"code-claude-code-reviewer.jsonl","original_fingerprint":"code-quality::components\\journal\\entry-forms\\inventory-form.tsx::cbdef33c"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0016","status":"CONFIRMED","cross_cutting":false,"categories":["code"],"priority_score":28.5,"unified_id":"UNIFIED-0021"}
{"title":"Migration function does not verify source anonymous user is actually anonymous","severity":"S2","category":"security","files":["functions\\src\\index.ts"],"line":565,"why_it_matters":"The migrateAnonymousUserData function checks that the anonymous user document exists in Firestore (line 565-569) but does not verify via Firebase Auth that the source account (anonymousUid) is actually an anonymous account. A malicious user who knows another user's UID could potentially trigger a migration from a non-anonymous account, copying that user's journal entries, daily logs, and inventory entries into their own account. The only authorization check is that the caller must be the target user (line 550), not that they have any relationship to the source. While the rate limit (5 per 5 minutes) provides some protection, a determined attacker could exfiltrate data from multiple accounts over time. OWASP A01:2021 - Broken Access Control.","suggested_fix":"Add a Firebase Auth verification step to confirm the source user is actually anonymous: const sourceAuthUser = await admin.auth().getUser(validatedData.anonymousUid); if (!sourceAuthUser.providerData || sourceAuthUser.providerData.length > 0) { throw new HttpsError('permission-denied', 'Source account is not anonymous'); }. Additionally, consider verifying that the caller was recently authenticated as the anonymous user (e.g., by checking if the anonymous UID matches a recently linked account).","confidence":85,"effort":"E1","fingerprint":"security::functions\\src\\index.ts::744c8d81","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::functions\\src\\index.ts::744c8d81"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0008","status":"CONFIRMED","cross_cutting":false,"categories":["security"],"priority_score":28.5,"unified_id":"UNIFIED-0022"}
{"title":"Missing abstraction for real-time subscriptions","severity":"S2","category":"code","files":["hooks\\use-journal.ts"],"line":284,"why_it_matters":"The useJournal hook manually manages Firestore real-time subscriptions with onSnapshot (line 284). It implements loading states, error handling, cleanup, and data processing inline. This pattern is duplicated in profile-context.tsx (line 109) and likely other places. Each implementation has subtle differences in error handling (some log, some set error state, some do both). There's no consistent way to handle reconnection, offline mode, or subscription lifecycle.","suggested_fix":"Create a useFirestoreQuery<T>(query, options) hook that abstracts real-time subscription management. It should handle: loading state, error state, snapshot processing, cleanup, offline detection, and reconnection. Return {data: T[], loading, error, retry}. Update useJournal and ProfileProvider to use this hook. Consider using a library like @tanstack/react-query with Firestore adapter or building a thin wrapper around onSnapshot that handles common patterns.","confidence":84,"effort":"E1","fingerprint":"code-quality::hooks\\use-journal.ts::efeb35af","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-backend-architect","file":"code-claude-backend-architect.jsonl","original_fingerprint":"code-quality::hooks\\use-journal.ts::efeb35af"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0013","status":"CONFIRMED","cross_cutting":false,"categories":["code"],"priority_score":28.4,"unified_id":"UNIFIED-0023"}
{"title":"Firestore timestamp validation inconsistency","severity":"S2","category":"code","files":["hooks\\use-journal.ts"],"line":178,"why_it_matters":"The processJournalDoc function validates timestamps using duck-typing (checking for toMillis function), but doesn't validate that toMillis() returns a valid number. Invalid timestamps could still pass validation and cause runtime errors.","suggested_fix":"Add validation after calling toMillis(): 'const ms = createdAtToMillis(); if (typeof ms !== \"number\" || isNaN(ms) || ms < 0) { return null; }'","confidence":82,"effort":"E1","fingerprint":"code-quality::hooks\\use-journal.ts::74ce9d7c","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-code-reviewer","file":"code-claude-code-reviewer.jsonl","original_fingerprint":"code-quality::hooks\\use-journal.ts::74ce9d7c"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0021","status":"CONFIRMED","cross_cutting":false,"categories":["code"],"priority_score":28.2,"unified_id":"UNIFIED-0024"}
{"title":"reCAPTCHA token made optional for data migration function","severity":"S2","category":"security","files":["functions/src/index.ts"],"line":516,"why_it_matters":"The migrateAnonymousUserData function (lines 514-530) explicitly makes reCAPTCHA verification optional. When no token is provided, the function logs a warning but continues processing: 'Continue without reCAPTCHA protection - rely on other security layers'. Combined with App Check being disabled (finding #1), this means the migration function relies solely on Firebase authentication and rate limiting. Since anonymous accounts are free to create, an attacker could create many anonymous accounts and attempt migrations to enumerate or probe target UIDs. The rate limit of 5 requests per 5 minutes per user provides some protection, but the user creating the requests is the target user who initiated the migration.","suggested_fix":"Make reCAPTCHA verification mandatory for the migration function. Remove the fallback path that allows processing without a token. If network blocking is a genuine concern for some users, consider implementing an alternative verification mechanism rather than skipping verification entirely.","confidence":82,"effort":"E1","fingerprint":"security::functions/src/index.ts::4815aed4","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::functions/src/index.ts::4815aed4"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0005","status":"CONFIRMED","cross_cutting":false,"categories":["security"],"priority_score":28.2,"unified_id":"UNIFIED-0025"}
{"title":"Migration function skips reCAPTCHA when token is missing","severity":"S2","category":"security","files":["functions\\src\\index.ts"],"line":516,"why_it_matters":"The migrateAnonymousUserData function (lines 514-530) makes reCAPTCHA verification optional. When the token is missing or empty, it logs a warning but continues processing the request without bot protection. This is in contrast to the withSecurityChecks wrapper (security-wrapper.ts lines 186-212), which properly rejects requests without tokens (except in emulator mode). The migration function handles its own security checks instead of using withSecurityChecks, creating inconsistency. Combined with App Check being disabled, this function has significantly weaker bot protection. OWASP A07:2021 - Identification and Authentication Failures.","suggested_fix":"Refactor migrateAnonymousUserData to use the withSecurityChecks wrapper for consistent security enforcement. If reCAPTCHA must be optional for certain edge cases (network blocking), implement compensating controls such as stricter rate limiting or requiring additional verification for the migration operation.","confidence":82,"effort":"E1","fingerprint":"security::functions\\src\\index.ts::78a53638","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::functions\\src\\index.ts::78a53638"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0006","status":"CONFIRMED","cross_cutting":false,"categories":["security"],"priority_score":28.2,"unified_id":"UNIFIED-0026"}
{"title":"Journal and inventory entry data field accepts arbitrary objects without depth or size limits","severity":"S2","category":"security","files":["functions\\src\\schemas.ts"],"line":32,"why_it_matters":"The journalEntrySchema (line 32) and inventoryEntrySchema (line 51) both use z.record(z.string(), z.unknown()) for the 'data' field. This accepts any JSON object of any depth and any size without restriction. While the content field in dailyLogSchema has a 50KB max, the data field in journal and inventory entries has no size constraint. A malicious user could send deeply nested objects (prototype pollution risk if consumed carelessly) or very large payloads that consume Firestore document size limits (1MB) and bandwidth. The saveInventoryEntry function does implement a sanitizeData helper with MAX_DEPTH=50 and cycle detection, but saveJournalEntry stores entryData directly without sanitization (line 198 of index.ts). OWASP A03:2021 - Injection.","suggested_fix":"Add size and depth constraints to the data field in Zod schemas. Use z.record(z.string(), z.unknown()).refine(data => JSON.stringify(data).length < 100000, 'Data too large') for size limits. Apply the sanitizeData helper from saveInventoryEntry consistently to saveJournalEntry as well. Consider defining stricter per-type schemas for the data field instead of accepting arbitrary objects.","confidence":80,"effort":"E1","fingerprint":"security::functions\\src\\schemas.ts::aa53e68e","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::functions\\src\\schemas.ts::aa53e68e"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0007","status":"CONFIRMED","cross_cutting":false,"categories":["security"],"priority_score":28,"unified_id":"UNIFIED-0027"}
{"title":"Race condition in parallel file processing","severity":"S2","category":"code","files":["functions\\src\\jobs.ts"],"line":627,"why_it_matters":"In cleanupOrphanedStorageFiles, files are processed in parallel batches with shared mutable state (checked, deleted, errors counters). Multiple concurrent calls to the onError callback could create race conditions in counter increments.","suggested_fix":"Use atomic operations or convert counters to a single state object updated via reduce after Promise.all: 'const results = await Promise.all(...); const totals = results.reduce((acc, r) => ({ deleted: acc.deleted + (r.deleted ? 1 : 0), ... }));'","confidence":78,"effort":"E1","fingerprint":"code-quality::functions\\src\\jobs.ts::08513aef","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-code-reviewer","file":"code-claude-code-reviewer.jsonl","original_fingerprint":"code-quality::functions\\src\\jobs.ts::08513aef"}],"verified":true,"consensus_score":1.5,"canonical_id":"CANON-0023","status":"SUSPECTED","cross_cutting":false,"categories":["code"],"priority_score":25.3,"unified_id":"UNIFIED-0028"}
{"title":"CI workflow script injection via unsanitized file names","severity":"S2","category":"security","files":[".github/workflows/ci.yml"],"line":64,"why_it_matters":"Line 64 uses direct interpolation of the changed-files output into a shell command: 'node scripts/check-pattern-compliance.js -- ${{ steps.changed-files.outputs.all_changed_files }}'. While the double-dash prevents flag injection, filenames from pull requests are attacker-controlled (external contributors can create branches/files with arbitrary names). A file named with shell metacharacters (e.g., containing backticks, $(), or semicolons) could lead to command injection in the shell context. The tj-actions/changed-files action is also pinned to a SHA in the CI workflow (good), but the docs-lint.yml and auto-label-review-tier.yml workflows use unpinned 'v46' tags (less secure).","suggested_fix":"Quote the variable expansion: wrap it in double quotes as '\"${{ steps.changed-files.outputs.all_changed_files }}\"'. Better yet, pass files via an environment variable and use proper quoting, or pipe from stdin. Pin all tj-actions/changed-files references to a specific SHA commit hash rather than a version tag to prevent supply chain attacks.","confidence":75,"effort":"E1","fingerprint":"security::.github/workflows/ci.yml::23f51718","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::.github/workflows/ci.yml::23f51718"}],"verified":true,"consensus_score":1.5,"canonical_id":"CANON-0009","status":"SUSPECTED","cross_cutting":false,"categories":["security"],"priority_score":25,"unified_id":"UNIFIED-0029"}
{"title":"Firestore security_logs collection missing from security rules","severity":"S2","category":"security","files":["firestore.rules"],"line":1,"why_it_matters":"The security-logger.ts (line 324) writes security events to a 'security_logs' collection, and the admin functions read from it (adminGetLogs). However, the firestore.rules file has no explicit rule for the security_logs collection. In Firestore, any collection without a matching rule at the root level falls under no default rule, which means access is denied by default. This is actually secure by default for client access, but it also means there is no documented access policy. More critically, the admin_logs and admin_jobs collections referenced in the admin dashboard stats (admin.ts lines 1097, 1123) also lack explicit rules. While Cloud Functions using Admin SDK bypass rules, the lack of explicit deny rules means if a future developer adds a client-side read path, it would silently fail without a clear explanation.","suggested_fix":"Add explicit deny rules for internal collections to document access policy and prevent accidental exposure. Add: match /security_logs/{logId} { allow read, write: if false; } and similarly for admin_logs and admin_jobs. This makes the access policy explicit even though the default behavior is already secure.","confidence":72,"effort":"E1","fingerprint":"security::firestore.rules::721c9993","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::firestore.rules::721c9993"}],"verified":true,"consensus_score":1.5,"canonical_id":"CANON-0010","status":"SUSPECTED","cross_cutting":false,"categories":["security"],"priority_score":24.7,"unified_id":"UNIFIED-0030"}
{"title":"Unpinned GitHub Actions in multiple workflows","severity":"S3","category":"security","files":[".github/workflows/auto-label-review-tier.yml"],"line":29,"why_it_matters":"Multiple GitHub Actions workflows use unpinned version tags instead of SHA-pinned references. The auto-label-review-tier.yml uses 'tj-actions/changed-files@v46' (line 29), 'actions/checkout@v4' (line 18), 'actions/setup-node@v4' (line 22), and 'actions/github-script@v7' (lines 79, 103). Similarly, docs-lint.yml uses 'tj-actions/changed-files@v46' (line 36). The ci.yml correctly pins tj-actions/changed-files to a SHA (line 45) with a comment referencing CVE-2025-30066, but other workflows do not follow this pattern. Unpinned tags can be force-pushed to point to malicious code, enabling supply chain attacks.","suggested_fix":"Pin all third-party GitHub Actions to specific commit SHAs across all workflow files. The ci.yml already demonstrates the correct pattern: 'uses: tj-actions/changed-files@26a38635fc1173cc5820336ce97be6188d0de9f5 # v46.0.2'. Apply this same approach to all actions/checkout, actions/setup-node, actions/github-script, and tj-actions/changed-files references in auto-label-review-tier.yml, docs-lint.yml, review-check.yml, and deploy-firebase.yml.","confidence":88,"effort":"E1","fingerprint":"security::.github/workflows/auto-label-review-tier.yml::24967bc9","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::.github/workflows/auto-label-review-tier.yml::24967bc9"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0011","status":"CONFIRMED","cross_cutting":false,"categories":["security"],"priority_score":14.7,"unified_id":"UNIFIED-0031"}
{"title":"Inefficient type checking in safeToIso","severity":"S3","category":"code","files":["functions\\src\\admin.ts"],"line":113,"why_it_matters":"The safeToIso function uses duck-typing with 'toDate' in value check, but this could match any object with a toDate property, not just Firestore Timestamps. This may lead to unexpected behavior with user-provided objects.","suggested_fix":"Use instanceof check for FirebaseFirestore.Timestamp: 'if (value instanceof admin.firestore.Timestamp) { return value.toDate().toISOString(); }'","confidence":80,"effort":"E1","fingerprint":"code-quality::functions\\src\\admin.ts::6cc89c14","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-code-reviewer","file":"code-claude-code-reviewer.jsonl","original_fingerprint":"code-quality::functions\\src\\admin.ts::6cc89c14"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0024","status":"CONFIRMED","cross_cutting":false,"categories":["code"],"priority_score":14.5,"unified_id":"UNIFIED-0032"}
{"title":"Unbounded retry loop risk in jobs.ts","severity":"S3","category":"code","files":["functions\\src\\jobs.ts"],"line":529,"why_it_matters":"The cleanupOldDailyLogs function uses 'hasMore' flag to continue pagination, but if the query returns exactly 500 items repeatedly without progressing (e.g., orderBy field not properly indexed), it could loop indefinitely.","suggested_fix":"Add a maximum iteration counter: 'let iterations = 0; const MAX_ITERATIONS = 100; while (hasMore && iterations++ < MAX_ITERATIONS) { ... }' and log a warning if the limit is reached.","confidence":80,"effort":"E1","fingerprint":"code-quality::functions\\src\\jobs.ts::a5b3e203","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-code-reviewer","file":"code-claude-code-reviewer.jsonl","original_fingerprint":"code-quality::functions\\src\\jobs.ts::a5b3e203"}],"verified":true,"consensus_score":2,"canonical_id":"CANON-0025","status":"CONFIRMED","cross_cutting":false,"categories":["code"],"priority_score":14.5,"unified_id":"UNIFIED-0033"}
{"title":"Admin function input validation inconsistency - meetingId and homeId not validated","severity":"S3","category":"security","files":["functions/src/admin.ts"],"line":768,"why_it_matters":"The adminDeleteMeeting function (line 768) and adminDeleteSoberLiving function (line 862) only check if meetingId/homeId is truthy but do not validate the format or length of these IDs. A malicious admin could pass excessively long strings or strings with special characters as document IDs. While Firestore handles most edge cases, very long document IDs (>1500 bytes) would cause Firestore errors, and the raw ID values are included in security log metadata without sanitization (line 779: 'metadata: { meetingId }'). In contrast, the soft-delete functions properly validate UIDs with Zod schemas (line 1513-1516). The adminSaveMeeting function validates the meeting data via meetingSchema.parse() but uses the client-provided 'validated.id' directly as the document ID without format validation.","suggested_fix":"Add Zod schema validation for document IDs in all admin delete and save functions. Apply a consistent pattern: validate that IDs are non-empty strings matching the expected Firestore auto-ID format (alphanumeric, 20 characters). Apply the same pattern used in softDeleteSchema and undeleteSchema to all admin functions.","confidence":78,"effort":"E1","fingerprint":"security::functions/src/admin.ts::e7f71625","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::functions/src/admin.ts::e7f71625"}],"verified":true,"consensus_score":1.5,"canonical_id":"CANON-0013","status":"SUSPECTED","cross_cutting":false,"categories":["security"],"priority_score":12,"unified_id":"UNIFIED-0034"}
{"title":"Daily quotes collection allows direct admin client writes bypassing Cloud Functions","severity":"S3","category":"security","files":["firestore.rules"],"line":104,"why_it_matters":"The daily_quotes collection (line 104) allows direct writes from users with the admin custom claim: allow write: if isAdmin(). This is inconsistent with the security pattern used for other admin-managed collections (meetings, sober_living) which use 'allow write: if false' and require writes through Cloud Functions (adminSaveMeeting, adminDeleteMeeting, etc.). Direct client writes bypass Cloud Function protections including rate limiting, Zod schema validation, and structured audit logging. The same inconsistency exists for glossary, slogans, quick_links, and prayers collections (lines 109-131).","suggested_fix":"Change the write rules for daily_quotes, glossary, slogans, quick_links, and prayers to 'allow write: if false' and route all writes through admin Cloud Functions with proper validation and audit logging. This ensures consistent defense-in-depth across all admin-writable collections.","confidence":78,"effort":"E1","fingerprint":"security::firestore.rules::b56af95a","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::firestore.rules::b56af95a"}],"verified":true,"consensus_score":1.5,"canonical_id":"CANON-0018","status":"SUSPECTED","cross_cutting":false,"categories":["security"],"priority_score":12,"unified_id":"UNIFIED-0035"}
{"title":"Type coercion in generateSearchableText","severity":"S3","category":"code","files":["hooks\\use-journal.ts"],"line":102,"why_it_matters":"The function uses String() coercion for all data fields, which could produce misleading search text for non-string types (e.g., '[object Object]' for nested objects, 'undefined' for missing values). This reduces search quality.","suggested_fix":"Add type guards to handle different data types explicitly: check if value is string/number/boolean before coercion, and recursively flatten nested objects or skip them with a warning.","confidence":75,"effort":"E1","fingerprint":"code-quality::hooks\\use-journal.ts::67f4e2c3","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-code-reviewer","file":"code-claude-code-reviewer.jsonl","original_fingerprint":"code-quality::hooks\\use-journal.ts::67f4e2c3"}],"verified":true,"consensus_score":1.5,"canonical_id":"CANON-0026","status":"SUSPECTED","cross_cutting":false,"categories":["code"],"priority_score":11.9,"unified_id":"UNIFIED-0036"}
{"title":"Firestore security rules missing for security_logs and admin_jobs collections","severity":"S3","category":"security","files":["firestore.rules"],"line":151,"why_it_matters":"The Firestore security rules do not include explicit rules for the security_logs collection (written by Cloud Functions at security-logger.ts:324), admin_jobs collection (written by jobs.ts), or admin_logs collection (read by admin.ts:1098). Firestore's default behavior when no rule matches is to deny access, which means these collections are implicitly denied for client access. However, relying on implicit deny is a security anti-pattern because: (1) it provides no documentation of intent, (2) a future rule change with a wildcard match could accidentally expose these collections, (3) the dev/{document=**} wildcard rule (line 138) demonstrates that broad matching rules exist in this ruleset.","suggested_fix":"Add explicit deny rules for internal collections to document intent and prevent accidental exposure: 'match /security_logs/{docId} { allow read, write: if false; }', 'match /admin_jobs/{docId} { allow read, write: if false; }', 'match /admin_logs/{docId} { allow read, write: if false; }'. This makes the security posture explicit and resistant to future wildcard additions.","confidence":72,"effort":"E1","fingerprint":"security::firestore.rules::fab244b4","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::firestore.rules::fab244b4"}],"verified":true,"consensus_score":1.5,"canonical_id":"CANON-0014","status":"SUSPECTED","cross_cutting":false,"categories":["security"],"priority_score":11.8,"unified_id":"UNIFIED-0037"}
{"title":"User ID hash truncation reduces collision resistance for privacy-sensitive logs","severity":"S3","category":"security","files":["functions/src/security-logger.ts"],"line":74,"why_it_matters":"The hashUserId function (lines 70-77) truncates SHA-256 hashes to 12 hex characters (48 bits of entropy). While the comment states this provides '~281 trillion combinations', this level of collision resistance may be insufficient for privacy guarantees. With a user base of N users, the birthday paradox means collisions become likely around sqrt(2^48) = ~16.7 million users. More importantly, because Firebase UIDs have a known format (28 alphanumeric characters), and the hash has no salt, an attacker with access to security logs could build a rainbow table by hashing all possible Firebase UIDs to find the original UID from a 12-character hash. Without a salt, the hash is deterministic and reversible for known-format inputs.","suggested_fix":"Add a secret salt to the hashUserId function that is stored in GCP Secret Manager (not in source code). This prevents rainbow table attacks even if the hash algorithm and truncation length are known. Consider using HMAC-SHA256 with a secret key instead of plain SHA-256. If increasing hash length is acceptable, use 16 or 20 characters to improve collision resistance.","confidence":70,"effort":"E1","fingerprint":"security::functions/src/security-logger.ts::e0625254","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::functions/src/security-logger.ts::e0625254"}],"verified":true,"consensus_score":1.5,"canonical_id":"CANON-0015","status":"SUSPECTED","cross_cutting":false,"categories":["security"],"priority_score":11.8,"unified_id":"UNIFIED-0038"}
{"title":"No middleware.ts for server-side route protection","severity":"S3","category":"security","files":["next.config.mjs"],"line":13,"why_it_matters":"The application uses Next.js with output: 'export' (static export) and has no middleware.ts file. While this is a conscious architectural decision (Firebase Hosting serves static files), it means there is no server-side route protection, no server-side session validation, and no ability to redirect unauthenticated users before page load. All authentication checks happen client-side in the AuthProvider component. For a statically exported SPA this is the expected pattern, but it means the HTML/JS for all routes (including admin pages) is delivered to every user, and route protection relies entirely on client-side JavaScript. An attacker can view the full admin UI code even without admin privileges (though data access is still protected by Cloud Functions).","suggested_fix":"This is acceptable for the current architecture (static SPA + Firebase), but ensure that no sensitive data is embedded in the static build output. Verify that admin page components do not contain hardcoded secrets or sensitive configuration. Consider using Next.js server-side rendering for admin routes if the application migrates away from static export in the future.","confidence":70,"effort":"E1","fingerprint":"security::next.config.mjs::8f44dc99","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-security-auditor","file":"security-claude-security-auditor.jsonl","original_fingerprint":"security::next.config.mjs::8f44dc99"}],"verified":true,"consensus_score":1.5,"canonical_id":"CANON-0017","status":"SUSPECTED","cross_cutting":false,"categories":["security"],"priority_score":11.8,"unified_id":"UNIFIED-0039"}
{"title":"Service account credentials written to disk in CI deploy workflow","severity":"S3","category":"security","files":[".github/workflows/deploy-firebase.yml"],"line":58,"why_it_matters":"The deploy-firebase.yml workflow writes the FIREBASE_SERVICE_ACCOUNT secret to a file on disk (line 58: 'echo ... > $HOME/gcloud-key.json'), sets file permissions to 600, and later cleans up with 'rm -f'. While the cleanup step uses 'if: always()' to ensure it runs even on failure, writing credentials to disk creates a window of vulnerability. If the runner is compromised or the workflow fails between write and cleanup, the credentials could be exfiltrated. Additionally, the echo command may be captured in runner process logs.","suggested_fix":"Use the google-github-actions/auth action with Workload Identity Federation instead of service account key files. This eliminates the need to store or write any credentials to disk. If key files must be used, consider using a tmpfs/memory-backed filesystem and ensure the cleanup step cannot be skipped. Also consider using 'echo ... | gcloud auth activate-service-account --key-file=-' to pipe directly without writing to disk.","confidence":68,"effort":"E1","fingerprint":"security::.github/workflows/deploy-firebase.yml::0855b57c","acceptance_tests":["Verify fix applied correctly"],"sources":[{"source":"claude-penetration-tester","file":"security-claude-penetration-tester.jsonl","original_fingerprint":"security::.github/workflows/deploy-firebase.yml::0855b57c"}],"verified":true,"consensus_score":1.5,"canonical_id":"CANON-0016","status":"SUSPECTED","cross_cutting":false,"categories":["security"],"priority_score":11.7,"unified_id":"UNIFIED-0040"}