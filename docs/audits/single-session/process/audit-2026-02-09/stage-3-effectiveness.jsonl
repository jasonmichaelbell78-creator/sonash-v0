{"category":"process","title":"Ineffective: audit-s0s1-validator defaults to WARN mode","fingerprint":"process::.claude/hooks/audit-s0s1-validator.js::always-warn","severity":"S2","effort":"E1","confidence":"HIGH","files":[".claude/hooks/audit-s0s1-validator.js:21"],"why_it_matters":"S0/S1 audit findings require strict validation but hook defaults to non-blocking WARN mode, allowing invalid findings to be written. The hook only blocks if AUDIT_S0S1_MODE=BLOCK is explicitly set, which is not the default.","suggested_fix":"Change default mode to BLOCK. Move to WARN mode as opt-out (AUDIT_S0S1_MODE=WARN) rather than opt-in blocking. Rationale: S0/S1 findings represent critical/high severity issues that must have proper verification_steps - this should be enforced by default.","acceptance_tests":["Default mode blocks invalid S0/S1 findings","Hook exits with code 1 when violations found","AUDIT_S0S1_MODE=WARN environment variable can opt-out to warnings"],"file":".claude/hooks/audit-s0s1-validator.js","line":21,"description":"S0/S1 audit findings require strict validation but hook defaults to non-blocking WARN mode, allowing invalid findings to be written. The hook only blocks if AUDIT_S0S1_MODE=BLOCK is explicitly set, which is not the default.","recommendation":"Change default mode to BLOCK. Move to WARN mode as opt-out (AUDIT_S0S1_MODE=WARN) rather than opt-in blocking. Rationale: S0/S1 findings represent critical/high severity issues that must have proper verification_steps - this should be enforced by default.","id":"process::.claude/hooks/audit-s0s1-validator.js::always-warn"}
{"category":"process","title":"Ineffective: pattern-check hook never blocks violations","fingerprint":"process::.claude/hooks/pattern-check.js::always-succeeds","severity":"S2","effort":"E1","confidence":"HIGH","files":[".claude/hooks/pattern-check.js:221"],"why_it_matters":"Pattern compliance hook always exits with 'ok' (line 221) even when violations are detected. Warnings are shown but violations don't prevent writes. This makes the hook informational noise rather than an enforcement mechanism.","suggested_fix":"Implement severity-based blocking: Block on critical (ðŸ”´) pattern violations, warn on non-critical. Add PATTERN_CHECK_MODE env var for gradual rollout (WARN/BLOCK), similar to audit-s0s1-validator but default to BLOCK for critical patterns. Update error message to indicate operation was blocked.","acceptance_tests":["Hook blocks writes containing critical pattern violations","Hook exits with code 1 for critical violations","Non-critical violations show warnings but don't block","PATTERN_CHECK_MODE=WARN allows opt-out"],"file":".claude/hooks/pattern-check.js","line":221,"description":"Pattern compliance hook always exits with 'ok' (line 221) even when violations are detected. Warnings are shown but violations don't prevent writes. This makes the hook informational noise rather than an enforcement mechanism.","recommendation":"Implement severity-based blocking: Block on critical (ðŸ”´) pattern violations, warn on non-critical. Add PATTERN_CHECK_MODE env var for gradual rollout (WARN/BLOCK), similar to audit-s0s1-validator but default to BLOCK for critical patterns. Update error message to indicate operation was blocked.","id":"process::.claude/hooks/pattern-check.js::always-succeeds"}
{"category":"process","title":"Ineffective: Small file bypass in pattern-check","fingerprint":"process::.claude/hooks/pattern-check.js::small-file-bypass","severity":"S3","effort":"E2","confidence":"HIGH","files":[".claude/hooks/pattern-check.js:138"],"why_it_matters":"Pattern check skips files under 100 lines (line 138-165). This creates perverse incentive to keep files artificially small to avoid pattern checks. Critical patterns like hardcoded secrets or auth bypasses can exist in small files.","suggested_fix":"Remove small file bypass or make it configurable. Alternative: Run lightweight pattern checks on all files, reserve expensive checks for large files. Critical security patterns (secrets, auth) should always run regardless of file size. Document rationale if bypass is intentional performance optimization.","acceptance_tests":["Critical security patterns checked on all file sizes","Performance acceptable for files under 100 lines","Pattern check completes in under 500ms for small files"],"file":".claude/hooks/pattern-check.js","line":138,"description":"Pattern check skips files under 100 lines (line 138-165). This creates perverse incentive to keep files artificially small to avoid pattern checks. Critical patterns like hardcoded secrets or auth bypasses can exist in small files.","recommendation":"Remove small file bypass or make it configurable. Alternative: Run lightweight pattern checks on all files, reserve expensive checks for large files. Critical security patterns (secrets, auth) should always run regardless of file size. Document rationale if bypass is intentional performance optimization.","id":"process::.claude/hooks/pattern-check.js::small-file-bypass"}
{"category":"process","title":"Ineffective: Pre-commit bypass conditions too easy","fingerprint":"process::.husky/pre-commit::excessive-bypasses","severity":"S2","effort":"E2","confidence":"HIGH","files":[".husky/pre-commit:46",".husky/pre-commit:122",".husky/pre-commit:137",".husky/pre-commit:158",".husky/pre-commit:193",".husky/pre-commit:245"],"why_it_matters":"Pre-commit hook has 6 easy bypass conditions via environment variables: SKIP_TESTS, SKIP_CROSS_DOC_CHECK, SKIP_DOC_HEADER_CHECK, SKIP_AUDIT_VALIDATION, SKIP_DEBT_VALIDATION, SKIP_DOC_INDEX_CHECK. No audit trail or rate limiting. Developers can habitually bypass checks without visibility.","suggested_fix":"1. Log all bypasses to .claude/hooks/bypass-audit.jsonl with timestamp, user, check type, reason. 2. Require SKIP_REASON environment variable for all bypasses. 3. Add bypass budget: warn if same user bypasses >3 times in 7 days. 4. Make some checks non-bypassable (e.g., SKIP_AUDIT_VALIDATION for S0/S1). 5. Pre-push hook should fail if too many pre-commit bypasses detected.","acceptance_tests":["All bypasses logged to bypass-audit.jsonl","SKIP_REASON required for bypass","Warning shown when bypass budget exceeded","S0/S1 audit validation cannot be bypassed"],"file":".husky/pre-commit","line":46,"description":"Pre-commit hook has 6 easy bypass conditions via environment variables: SKIP_TESTS, SKIP_CROSS_DOC_CHECK, SKIP_DOC_HEADER_CHECK, SKIP_AUDIT_VALIDATION, SKIP_DEBT_VALIDATION, SKIP_DOC_INDEX_CHECK. No audit trail or rate limiting. Developers can habitually bypass checks without visibility.","recommendation":"1. Log all bypasses to .claude/hooks/bypass-audit.jsonl with timestamp, user, check type, reason. 2. Require SKIP_REASON environment variable for all bypasses. 3. Add bypass budget: warn if same user bypasses >3 times in 7 days. 4. Make some checks non-bypassable (e.g., SKIP_AUDIT_VALIDATION for S0/S1). 5. Pre-push hook should fail if too many pre-commit bypasses detected.","id":"process::.husky/pre-commit::excessive-bypasses"}
{"category":"process","title":"Ineffective: Network failures treated as success in pre-push","fingerprint":"process::.husky/pre-push::network-failure-success","severity":"S3","effort":"E1","confidence":"HIGH","files":[".husky/pre-push:107"],"why_it_matters":"npm audit check (lines 92-118) treats network errors as success - if npm registry is unreachable, check is skipped silently. Attacker with network control could bypass vulnerability detection. Same pattern could exist in other network-dependent checks.","suggested_fix":"Distinguish between 'no vulnerabilities' and 'cannot verify'. For network failures: 1. Show clear warning that check was skipped. 2. Log to bypass audit trail. 3. Consider making network checks blocking by default (fail closed), with ALLOW_NETWORK_SKIP=1 opt-out. 4. Cache last successful audit result and warn if stale (>7 days).","acceptance_tests":["Network failures show prominent warning","Bypassed network checks logged to audit trail","Hook fails by default on network errors unless ALLOW_NETWORK_SKIP=1","Last successful audit timestamp cached"],"file":".husky/pre-push","line":107,"description":"npm audit check (lines 92-118) treats network errors as success - if npm registry is unreachable, check is skipped silently. Attacker with network control could bypass vulnerability detection. Same pattern could exist in other network-dependent checks.","recommendation":"Distinguish between 'no vulnerabilities' and 'cannot verify'. For network failures: 1. Show clear warning that check was skipped. 2. Log to bypass audit trail. 3. Consider making network checks blocking by default (fail closed), with ALLOW_NETWORK_SKIP=1 opt-out. 4. Cache last successful audit result and warn if stale (>7 days).","id":"process::.husky/pre-push::network-failure-success"}
{"category":"process","title":"Ineffective: check-write-requirements POST-TASK not enforced","fingerprint":"process::.claude/hooks/check-write-requirements.js::post-task-not-enforced","severity":"S3","effort":"E2","confidence":"MEDIUM","files":[".claude/hooks/check-write-requirements.js:72",".claude/hooks/check-write-requirements.js:80",".claude/hooks/check-write-requirements.js:86"],"why_it_matters":"Hook outputs 'POST-TASK: MUST run code-reviewer' and 'POST-TASK: SHOULD run test-engineer' but these are suggestions only. No enforcement mechanism. No tracking whether suggested agents actually ran. Messages become background noise that users ignore.","suggested_fix":"1. Track suggested agents in .claude/state/required-agents.json. 2. Pre-commit hook checks this file and warns/blocks if required agents not invoked. 3. Agent invocation hooks (track-agent-invocation.js) mark agents as completed. 4. MUST requirements block commit, SHOULD requirements warn. 5. Clear with AGENT_REVIEW_COMPLETE=1 override with reason logging.","acceptance_tests":["Required agents tracked in state file","Pre-commit blocks if MUST requirements not met","Agent completion marks requirements satisfied","Override requires reason and logs to audit trail"],"file":".claude/hooks/check-write-requirements.js","line":72,"description":"Hook outputs 'POST-TASK: MUST run code-reviewer' and 'POST-TASK: SHOULD run test-engineer' but these are suggestions only. No enforcement mechanism. No tracking whether suggested agents actually ran. Messages become background noise that users ignore.","recommendation":"1. Track suggested agents in .claude/state/required-agents.json. 2. Pre-commit hook checks this file and warns/blocks if required agents not invoked. 3. Agent invocation hooks (track-agent-invocation.js) mark agents as completed. 4. MUST requirements block commit, SHOULD requirements warn. 5. Clear with AGENT_REVIEW_COMPLETE=1 override with reason logging.","id":"process::.claude/hooks/check-write-requirements.js::post-task-not-enforced"}
{"category":"process","title":"Ineffective: component-size-check always succeeds","fingerprint":"process::.claude/hooks/component-size-check.js::always-ok","severity":"S3","effort":"E1","confidence":"HIGH","files":[".claude/hooks/component-size-check.js:142"],"why_it_matters":"Hook warns about oversized components (>300 lines) but always exits with 'ok' (line 142). Warnings are easily ignored. No escalation for egregiously large files (e.g., 1000+ lines). Size limits become suggestions rather than architectural constraints.","suggested_fix":"Implement tiered enforcement: 1. >300 lines: WARN (current behavior). 2. >500 lines: WARN with stronger message, add to tech debt tracker. 3. >750 lines: BLOCK unless ALLOW_LARGE_COMPONENT=1 with required explanation. 4. Track component sizes over time - warn if file growing rapidly (>50 lines/week). Form components keep higher limits but require Form suffix in filename.","acceptance_tests":["Files >750 lines blocked by default","Override requires ALLOW_LARGE_COMPONENT=1 and logs reason","Growing files detected and warned","Size metrics tracked for trends"],"file":".claude/hooks/component-size-check.js","line":142,"description":"Hook warns about oversized components (>300 lines) but always exits with 'ok' (line 142). Warnings are easily ignored. No escalation for egregiously large files (e.g., 1000+ lines). Size limits become suggestions rather than architectural constraints.","recommendation":"Implement tiered enforcement: 1. >300 lines: WARN (current behavior). 2. >500 lines: WARN with stronger message, add to tech debt tracker. 3. >750 lines: BLOCK unless ALLOW_LARGE_COMPONENT=1 with required explanation. 4. Track component sizes over time - warn if file growing rapidly (>50 lines/week). Form components keep higher limits but require Form suffix in filename.","id":"process::.claude/hooks/component-size-check.js::always-ok"}
{"category":"process","title":"Ineffective: agent-trigger-enforcer Phase 2/3 not implemented","fingerprint":"process::.claude/hooks/agent-trigger-enforcer.js::phase-not-implemented","severity":"S3","effort":"E3","confidence":"HIGH","files":[".claude/hooks/agent-trigger-enforcer.js:295"],"why_it_matters":"Hook shows phase transition notifications (lines 219-234) recommending upgrade to Phase 2 WARN or Phase 3 BLOCK modes, but these phases are not implemented. Hook always succeeds regardless of phase setting (line 295). Phase transitions are notification theater without actual behavior change.","suggested_fix":"Implement phase enforcement logic: Phase 1 (current): Suggest agents. Phase 2: Warn prominently if required agents not invoked, track to pending-reviews.json. Phase 3: Block Write/Edit if required agent not invoked this session, require SKIP_AGENT_CHECK=1 override with reason. Use state.phase to control behavior. Document phase upgrade process and rollback plan.","acceptance_tests":["Phase 2 creates prominent warnings and tracks violations","Phase 3 blocks operations until agent invoked","Phase config changeable via state file","Rollback to lower phase preserves existing state"],"file":".claude/hooks/agent-trigger-enforcer.js","line":295,"description":"Hook shows phase transition notifications (lines 219-234) recommending upgrade to Phase 2 WARN or Phase 3 BLOCK modes, but these phases are not implemented. Hook always succeeds regardless of phase setting (line 295). Phase transitions are notification theater without actual behavior change.","recommendation":"Implement phase enforcement logic: Phase 1 (current): Suggest agents. Phase 2: Warn prominently if required agents not invoked, track to pending-reviews.json. Phase 3: Block Write/Edit if required agent not invoked this session, require SKIP_AGENT_CHECK=1 override with reason. Use state.phase to control behavior. Document phase upgrade process and rollback plan.","id":"process::.claude/hooks/agent-trigger-enforcer.js::phase-not-implemented"}
{"category":"process","title":"Ineffective: large-context-warning warningShown flag prevents repeated warnings","fingerprint":"process::.claude/hooks/large-context-warning.js::warning-once","severity":"S4","effort":"E1","confidence":"HIGH","files":[".claude/hooks/large-context-warning.js:146"],"why_it_matters":"Hook warns when >15 files read in session (line 146-153) but sets warningShown flag to prevent repeated warnings. After first warning, can read 50+ more files without additional feedback. Warning effectiveness degrades over long sessions. State resets after 30 minutes, allowing warning suppression.","suggested_fix":"Change warning strategy: 1. Warn at thresholds: 15, 30, 50, 100 files (escalating urgency). 2. Show file count in status bar if available. 3. After 30 files, suggest /save-context every 5 files. 4. After 50 files, warn that compaction likely soon. 5. Track context pressure score (files + total lines) not just file count. Don't use warningShown flag for suppression.","acceptance_tests":["Multiple warnings at escalating thresholds","Warning shown every 5 files after 30 files","Context pressure score calculated from files + lines","No single warningShown flag suppressing all warnings"],"file":".claude/hooks/large-context-warning.js","line":146,"description":"Hook warns when >15 files read in session (line 146-153) but sets warningShown flag to prevent repeated warnings. After first warning, can read 50+ more files without additional feedback. Warning effectiveness degrades over long sessions. State resets after 30 minutes, allowing warning suppression.","recommendation":"Change warning strategy: 1. Warn at thresholds: 15, 30, 50, 100 files (escalating urgency). 2. Show file count in status bar if available. 3. After 30 files, suggest /save-context every 5 files. 4. After 50 files, warn that compaction likely soon. 5. Track context pressure score (files + total lines) not just file count. Don't use warningShown flag for suppression.","id":"process::.claude/hooks/large-context-warning.js::warning-once"}
{"category":"process","title":"Ineffective: check-remote-session-context always succeeds","fingerprint":"process::.claude/hooks/check-remote-session-context.js::informational-only","severity":"S4","effort":"E2","confidence":"MEDIUM","files":[".claude/hooks/check-remote-session-context.js:32",".claude/hooks/check-remote-session-context.js:179"],"why_it_matters":"Hook detects when remote branches have newer session context (higher session counter) but always exits with 'ok' even when mismatch found. Warning shown (lines 163-176) but no enforcement. Developers can ignore and work on stale context, leading to lost work or duplicate sessions.","suggested_fix":"Make blocking when session counter difference >5 (likely working on very stale branch): 1. Show warning and suggest merge for small differences (1-2 sessions). 2. Block session start for large differences (>5 sessions) unless ALLOW_STALE_CONTEXT=1. 3. Offer auto-merge or checkout options. 4. Track if user repeatedly ignores warnings (>3 times in 14 days) and escalate to block. 5. continueOnError: true in settings keeps non-blocking for fetch failures.","acceptance_tests":["Large session counter differences block session start","Small differences show actionable warning with merge command","Override requires ALLOW_STALE_CONTEXT=1 with reason","Repeated warning ignoring tracked and escalated"],"file":".claude/hooks/check-remote-session-context.js","line":32,"description":"Hook detects when remote branches have newer session context (higher session counter) but always exits with 'ok' even when mismatch found. Warning shown (lines 163-176) but no enforcement. Developers can ignore and work on stale context, leading to lost work or duplicate sessions.","recommendation":"Make blocking when session counter difference >5 (likely working on very stale branch): 1. Show warning and suggest merge for small differences (1-2 sessions). 2. Block session start for large differences (>5 sessions) unless ALLOW_STALE_CONTEXT=1. 3. Offer auto-merge or checkout options. 4. Track if user repeatedly ignores warnings (>3 times in 14 days) and escalate to block. 5. continueOnError: true in settings keeps non-blocking for fetch failures.","id":"process::.claude/hooks/check-remote-session-context.js::informational-only"}
{"category":"process","title":"Ineffective: audit-s0s1-validator allows parse errors","fingerprint":"process::.claude/hooks/audit-s0s1-validator.js::parse-error-evasion","severity":"S3","effort":"E2","confidence":"MEDIUM","files":[".claude/hooks/audit-s0s1-validator.js:84"],"why_it_matters":"When JSONL parsing fails (lines 79-86), malformed lines are marked with _parseError but validation continues. If S0/S1 finding is in a malformed line, it escapes validation. Attacker or lazy developer could intentionally malform S0/S1 entries to bypass strict verification requirements.","suggested_fix":"Fail validation if any parse errors found in audit file: 1. Count parse errors during JSONL parsing. 2. If parseErrorCount > 0, block with message: 'JSONL file has malformed entries - fix syntax before committing'. 3. Show first 3 malformed lines with line numbers. 4. No override - proper JSON is non-negotiable for audit data. 5. Validate that all S0/S1 findings were successfully parsed (cross-check line count of S0/S1 severity strings vs parsed S0/S1 objects).","acceptance_tests":["Hook blocks files with any JSONL parse errors","Malformed line numbers and content shown in error","All S0/S1 lines confirmed parseable","No bypass for malformed audit files"],"file":".claude/hooks/audit-s0s1-validator.js","line":84,"description":"When JSONL parsing fails (lines 79-86), malformed lines are marked with _parseError but validation continues. If S0/S1 finding is in a malformed line, it escapes validation. Attacker or lazy developer could intentionally malform S0/S1 entries to bypass strict verification requirements.","recommendation":"Fail validation if any parse errors found in audit file: 1. Count parse errors during JSONL parsing. 2. If parseErrorCount > 0, block with message: 'JSONL file has malformed entries - fix syntax before committing'. 3. Show first 3 malformed lines with line numbers. 4. No override - proper JSON is non-negotiable for audit data. 5. Validate that all S0/S1 findings were successfully parsed (cross-check line count of S0/S1 severity strings vs parsed S0/S1 objects).","id":"process::.claude/hooks/audit-s0s1-validator.js::parse-error-evasion"}
{"category":"process","title":"Ineffective: commit-tracker continueOnError makes failures silent","fingerprint":"process::.claude/hooks/commit-tracker.js::continue-on-error","severity":"S4","effort":"E1","confidence":"MEDIUM","files":[".claude/settings.json:251"],"why_it_matters":"commit-tracker.js has continueOnError: true (settings.json line 251) so failures are silent. If state files become corrupted or filesystem has issues, commit tracking silently breaks. Compaction resilience (Session #138) depends on this tracking but failures are invisible.","suggested_fix":"Keep continueOnError: true (appropriate for non-critical tracking) but add failure detection and alerting: 1. If commit-tracker fails 3+ times in session, show warning. 2. Log failures to .claude/hooks/hook-failures.jsonl with timestamp, hook name, error. 3. Session-start hook checks failure log and warns if recent failures (last 7 days). 4. Health check command to verify state files readable/writable. Document that continueOnError is intentional but monitored.","acceptance_tests":["Repeated failures trigger warning","Failures logged to hook-failures.jsonl","Session start checks recent hook failures","Health check command validates state files"],"file":".claude/settings.json","line":251,"description":"commit-tracker.js has continueOnError: true (settings.json line 251) so failures are silent. If state files become corrupted or filesystem has issues, commit tracking silently breaks. Compaction resilience (Session #138) depends on this tracking but failures are invisible.","recommendation":"Keep continueOnError: true (appropriate for non-critical tracking) but add failure detection and alerting: 1. If commit-tracker fails 3+ times in session, show warning. 2. Log failures to .claude/hooks/hook-failures.jsonl with timestamp, hook name, error. 3. Session-start hook checks failure log and warns if recent failures (last 7 days). 4. Health check command to verify state files readable/writable. Document that continueOnError is intentional but monitored.","id":"process::.claude/hooks/commit-tracker.js::continue-on-error"}
{"category":"process","title":"Ineffective: Pre-push SKIP_TRIGGERS bypass has no budget","fingerprint":"process::.husky/pre-push::skip-triggers","severity":"S3","effort":"E2","confidence":"HIGH","files":[".husky/pre-push:123"],"why_it_matters":"SKIP_TRIGGERS=1 bypasses event-based trigger checks (lines 123-152) including security audits. Override logged to scripts/log-override.js but no enforcement of bypass budget. Developer could use SKIP_TRIGGERS=1 on every push to avoid all trigger-based checks including security scans.","suggested_fix":"Implement bypass budget for SKIP_TRIGGERS: 1. Track bypass frequency in .claude/state/bypass-budget.json (user, timestamp, reason). 2. Allow 3 bypasses per 7 days without warning. 3. Warn at 4-5 bypasses in 7 days. 4. Block at 6+ bypasses in 7 days unless BYPASS_BUDGET_OVERRIDE=1 (requires escalation approval or explicit reason). 5. Reset budget weekly. 6. Distinguish security trigger bypasses (stricter budget: 1 per 7 days) from other triggers.","acceptance_tests":["Bypass budget tracked per user","Warnings at 4-5 bypasses in 7 days","Block at 6+ bypasses requires override","Security bypasses have stricter budget (1/week)"],"file":".husky/pre-push","line":123,"description":"SKIP_TRIGGERS=1 bypasses event-based trigger checks (lines 123-152) including security audits. Override logged to scripts/log-override.js but no enforcement of bypass budget. Developer could use SKIP_TRIGGERS=1 on every push to avoid all trigger-based checks including security scans.","recommendation":"Implement bypass budget for SKIP_TRIGGERS: 1. Track bypass frequency in .claude/state/bypass-budget.json (user, timestamp, reason). 2. Allow 3 bypasses per 7 days without warning. 3. Warn at 4-5 bypasses in 7 days. 4. Block at 6+ bypasses in 7 days unless BYPASS_BUDGET_OVERRIDE=1 (requires escalation approval or explicit reason). 5. Reset budget weekly. 6. Distinguish security trigger bypasses (stricter budget: 1 per 7 days) from other triggers.","id":"process::.husky/pre-push::skip-triggers"}
{"category":"process","title":"CI gap: pull_request_target security vulnerability allows untrusted code execution","fingerprint":"process::.github/workflows/deploy-firebase.yml::pull-request-target-risk","severity":"S0","effort":"E2","confidence":"HIGH","files":[".github/workflows/deploy-firebase.yml:7"],"why_it_matters":"Using pull_request_target with code checkout from PR head (line 32) allows malicious PRs to execute arbitrary code with repository secrets access. This is a well-documented GitHub Actions security anti-pattern that could lead to credential theft or repository compromise.","suggested_fix":"Replace pull_request_target with pull_request and use a separate workflow for preview deploys that runs after CI passes. Alternatively, use pull_request_target but only checkout base branch code, then merge PR changes in a sandboxed environment. See GitHub's security hardening guide.","acceptance_tests":["Preview deploys cannot access repository secrets","Malicious PR code cannot execute with elevated permissions","CI must pass before any deployment occurs"],"file":".github/workflows/deploy-firebase.yml","line":7,"description":"Using pull_request_target with code checkout from PR head (line 32) allows malicious PRs to execute arbitrary code with repository secrets access. This is a well-documented GitHub Actions security anti-pattern that could lead to credential theft or repository compromise.","recommendation":"Replace pull_request_target with pull_request and use a separate workflow for preview deploys that runs after CI passes. Alternatively, use pull_request_target but only checkout base branch code, then merge PR changes in a sandboxed environment. See GitHub's security hardening guide.","id":"process::.github/workflows/deploy-firebase.yml::pull-request-target-risk","evidence":[{"type":"code_reference","detail":".github/workflows/deploy-firebase.yml:7"},{"type":"description","detail":"Using pull_request_target with code checkout from PR head (line 32) allows malicious PRs to execute arbitrary code with repository secrets access. This is a well-documented GitHub Actions security anti-pattern that could lead to credential theft or repository compromise."}],"verification_steps":{"first_pass":{"method":"code_search","evidence_collected":[".github/workflows/deploy-firebase.yml:7"]},"second_pass":{"method":"contextual_review","confirmed":true},"tool_confirmation":{"tool":"NONE","result":"confirmed via manual code review","reference":".github/workflows/deploy-firebase.yml:7"}}}
{"category":"process","title":"CI gap: No test coverage thresholds enforced","fingerprint":"process::.github/workflows/ci.yml::no-coverage-thresholds","severity":"S1","effort":"E1","confidence":"HIGH","files":[".github/workflows/ci.yml:115"],"why_it_matters":"Tests run with coverage reporting but there are no minimum thresholds configured. Code with 0% test coverage can pass CI, allowing untested code to merge. This defeats the purpose of coverage tracking.","suggested_fix":"Add c8 configuration with minimum thresholds (e.g., 70% lines, 60% branches). Update ci.yml line 115 to fail if thresholds not met: npm run test:coverage -- --check-coverage --lines 70 --branches 60","acceptance_tests":["CI fails when coverage drops below threshold","Coverage report shows current vs threshold values","Configuration is in version control (.c8rc.json)"],"file":".github/workflows/ci.yml","line":115,"description":"Tests run with coverage reporting but there are no minimum thresholds configured. Code with 0% test coverage can pass CI, allowing untested code to merge. This defeats the purpose of coverage tracking.","recommendation":"Add c8 configuration with minimum thresholds (e.g., 70% lines, 60% branches). Update ci.yml line 115 to fail if thresholds not met: npm run test:coverage -- --check-coverage --lines 70 --branches 60","id":"process::.github/workflows/ci.yml::no-coverage-thresholds","evidence":[{"type":"code_reference","detail":".github/workflows/ci.yml:115"},{"type":"description","detail":"Tests run with coverage reporting but there are no minimum thresholds configured. Code with 0% test coverage can pass CI, allowing untested code to merge. This defeats the purpose of coverage tracking."}],"verification_steps":{"first_pass":{"method":"code_search","evidence_collected":[".github/workflows/ci.yml:115"]},"second_pass":{"method":"contextual_review","confirmed":true},"tool_confirmation":{"tool":"NONE","result":"confirmed via manual code review","reference":".github/workflows/ci.yml:115"}}}
{"category":"process","title":"CI gap: continue-on-error bypasses critical validations","fingerprint":"process::.github/workflows/ci.yml::continue-on-error-abuse","severity":"S2","effort":"E1","confidence":"HIGH","files":[".github/workflows/ci.yml:74",".github/workflows/ci.yml:79",".github/workflows/ci.yml:89",".github/workflows/ci.yml:106"],"why_it_matters":"Four validation steps use continue-on-error: pattern compliance on main (74), documentation check (79), audit validation (89), and technical debt views (106). These failures never block merges, allowing broken patterns, bad docs, invalid audits, and stale debt tracking to accumulate unnoticed.","suggested_fix":"Remove continue-on-error from all steps except known unstable checks. Make pattern compliance blocking for changed files. Add separate non-blocking 'advisory' job for experimental checks. Use required status checks in GitHub branch protection.","acceptance_tests":["Pattern compliance failures block PR merge","Documentation errors block merge","Audit validation errors block merge","Only explicitly marked experimental checks are non-blocking"],"file":".github/workflows/ci.yml","line":74,"description":"Four validation steps use continue-on-error: pattern compliance on main (74), documentation check (79), audit validation (89), and technical debt views (106). These failures never block merges, allowing broken patterns, bad docs, invalid audits, and stale debt tracking to accumulate unnoticed.","recommendation":"Remove continue-on-error from all steps except known unstable checks. Make pattern compliance blocking for changed files. Add separate non-blocking 'advisory' job for experimental checks. Use required status checks in GitHub branch protection.","id":"process::.github/workflows/ci.yml::continue-on-error-abuse"}
{"category":"process","title":"CI gap: Missing secrets cause silent build success","fingerprint":"process::.github/workflows/ci.yml::missing-secrets-silent","severity":"S2","effort":"E1","confidence":"HIGH","files":[".github/workflows/ci.yml:154-159"],"why_it_matters":"Build step uses secrets for Firebase config (lines 154-159). If secrets are missing or misconfigured, environment variables are set to empty strings and build succeeds. This hides configuration issues until runtime in production.","suggested_fix":"Add validation step before build: for secret in NEXT_PUBLIC_FIREBASE_API_KEY ...; do [[ -z $secret ]] && exit 1; done. Or use GitHub's required secrets feature and fail explicitly if not set.","acceptance_tests":["CI fails immediately if required secrets are missing","Build logs clearly indicate which secret is missing","Fork PRs can still build with placeholder values"],"file":".github/workflows/ci.yml","line":154,"description":"Build step uses secrets for Firebase config (lines 154-159). If secrets are missing or misconfigured, environment variables are set to empty strings and build succeeds. This hides configuration issues until runtime in production.","recommendation":"Add validation step before build: for secret in NEXT_PUBLIC_FIREBASE_API_KEY ...; do [[ -z $secret ]] && exit 1; done. Or use GitHub's required secrets feature and fail explicitly if not set.","id":"process::.github/workflows/ci.yml::missing-secrets-silent"}
{"category":"process","title":"CI gap: Pattern compliance only checks changed files in PRs","fingerprint":"process::.github/workflows/ci.yml::pattern-check-incomplete","severity":"S2","effort":"E2","confidence":"HIGH","files":[".github/workflows/ci.yml:58-68"],"why_it_matters":"Line 64 only checks changed files in PRs. If pattern rules are updated, existing violations in unchanged files are never caught. Pattern debt accumulates invisibly until someone touches those files. Also, if someone bypasses the check once, the violation persists forever.","suggested_fix":"Run full pattern check on a schedule (weekly) and post issues for violations. Or run full check on PRs that modify pattern rules themselves. Consider making pattern check blocking only for new violations but report existing ones.","acceptance_tests":["Weekly scheduled job reports all pattern violations","PRs that modify .claude/pattern-rules.jsonl trigger full check","Existing violations are tracked and reported but don't block new PRs"],"file":".github/workflows/ci.yml","line":58,"description":"Line 64 only checks changed files in PRs. If pattern rules are updated, existing violations in unchanged files are never caught. Pattern debt accumulates invisibly until someone touches those files. Also, if someone bypasses the check once, the violation persists forever.","recommendation":"Run full pattern check on a schedule (weekly) and post issues for violations. Or run full check on PRs that modify pattern rules themselves. Consider making pattern check blocking only for new violations but report existing ones.","id":"process::.github/workflows/ci.yml::pattern-check-incomplete"}
{"category":"process","title":"CI gap: Build job re-installs dependencies wastefully","fingerprint":"process::.github/workflows/ci.yml::no-dependency-caching","severity":"S2","effort":"E2","confidence":"MEDIUM","files":[".github/workflows/ci.yml:136-149"],"why_it_matters":"Build job (lines 136-149) runs after lint-typecheck-test but re-installs all dependencies and rebuilds from scratch. This wastes 2-5 minutes per CI run and increases risk of dependency resolution differences between jobs.","suggested_fix":"Cache node_modules as artifact in first job and restore in build job. Or combine jobs into single job with multiple steps. Or use Docker layer caching. Document reason if separate jobs are required.","acceptance_tests":["Build job reuses artifacts from test job","CI runtime reduced by 2+ minutes","Cache hit rate is >90% for typical PRs"],"file":".github/workflows/ci.yml","line":136,"description":"Build job (lines 136-149) runs after lint-typecheck-test but re-installs all dependencies and rebuilds from scratch. This wastes 2-5 minutes per CI run and increases risk of dependency resolution differences between jobs.","recommendation":"Cache node_modules as artifact in first job and restore in build job. Or combine jobs into single job with multiple steps. Or use Docker layer caching. Document reason if separate jobs are required.","id":"process::.github/workflows/ci.yml::no-dependency-caching"}
{"category":"process","title":"CI gap: Race condition in tier label assignment","fingerprint":"process::.github/workflows/auto-label-review-tier.yml::label-race-condition","severity":"S2","effort":"E2","confidence":"MEDIUM","files":[".github/workflows/auto-label-review-tier.yml:77-150"],"why_it_matters":"Label removal (lines 77-100) and addition (101-150) are separate steps. If workflow runs twice concurrently on rapid PR updates, labels can get into inconsistent state (e.g., both tier-2 and tier-3 present, or no tier label at all).","suggested_fix":"Use GitHub API's replaceLabels operation which is atomic. Or add concurrency group keyed on PR number with cancel-in-progress: true. Or use a single API call that removes and adds in one transaction.","acceptance_tests":["Concurrent workflow runs don't create duplicate tier labels","Tier label is always exactly one of tier-0 through tier-4","Race condition testing with rapid PR pushes"],"file":".github/workflows/auto-label-review-tier.yml","line":77,"description":"Label removal (lines 77-100) and addition (101-150) are separate steps. If workflow runs twice concurrently on rapid PR updates, labels can get into inconsistent state (e.g., both tier-2 and tier-3 present, or no tier label at all).","recommendation":"Use GitHub API's replaceLabels operation which is atomic. Or add concurrency group keyed on PR number with cancel-in-progress: true. Or use a single API call that removes and adds in one transaction.","id":"process::.github/workflows/auto-label-review-tier.yml::label-race-condition"}
{"category":"process","title":"CI gap: Inline tier assignment logic creates maintenance drift","fingerprint":"process::.github/workflows/auto-label-review-tier.yml::duplicate-tier-logic","severity":"S2","effort":"E2","confidence":"HIGH","files":[".github/workflows/auto-label-review-tier.yml:60-75"],"why_it_matters":"Lines 60-75 contain inline bash logic that duplicates scripts/assign-review-tier.js. Comment says 'TODO: Uncomment when script is ready' but script exists and is referenced. This technical debt causes maintenance burden and drift between workflow and script logic.","suggested_fix":"Remove TODO placeholder logic and uncomment line 56 to use the actual script. Or if script needs updates, fix it first then switch. Add test that workflow and script produce same tier for sample file sets.","acceptance_tests":["Workflow uses scripts/assign-review-tier.js not inline bash","Tier assignment logic exists in only one place","Tests verify consistency between workflow and script"],"file":".github/workflows/auto-label-review-tier.yml","line":60,"description":"Lines 60-75 contain inline bash logic that duplicates scripts/assign-review-tier.js. Comment says 'TODO: Uncomment when script is ready' but script exists and is referenced. This technical debt causes maintenance burden and drift between workflow and script logic.","recommendation":"Remove TODO placeholder logic and uncomment line 56 to use the actual script. Or if script needs updates, fix it first then switch. Add test that workflow and script produce same tier for sample file sets.","id":"process::.github/workflows/auto-label-review-tier.yml::duplicate-tier-logic"}
{"category":"process","title":"CI gap: Fork PRs completely skip SonarCloud analysis","fingerprint":"process::.github/workflows/sonarcloud.yml::skip-fork-prs","severity":"S2","effort":"E2","confidence":"HIGH","files":[".github/workflows/sonarcloud.yml:22-24"],"why_it_matters":"Lines 22-24 skip SonarCloud analysis for all fork PRs because secrets aren't available. External contributions get zero static analysis, allowing security issues, code smells, and bugs to merge without detection. This is especially risky since forks are more likely to introduce novel bugs.","suggested_fix":"Run SonarCloud on a schedule against main branch to catch issues after merge. Or use pull_request_target carefully to analyze fork code (but see security implications). Or require maintainers to manually trigger analysis before merging fork PRs.","acceptance_tests":["Fork PR code is analyzed within 24 hours of merge","Security hotspots in fork PRs are detected before or soon after merge","Analysis results are visible to PR reviewers"],"file":".github/workflows/sonarcloud.yml","line":22,"description":"Lines 22-24 skip SonarCloud analysis for all fork PRs because secrets aren't available. External contributions get zero static analysis, allowing security issues, code smells, and bugs to merge without detection. This is especially risky since forks are more likely to introduce novel bugs.","recommendation":"Run SonarCloud on a schedule against main branch to catch issues after merge. Or use pull_request_target carefully to analyze fork code (but see security implications). Or require maintainers to manually trigger analysis before merging fork PRs.","id":"process::.github/workflows/sonarcloud.yml::skip-fork-prs"}
{"category":"process","title":"CI gap: Firebase deployment has no success validation","fingerprint":"process::.github/workflows/deploy-firebase.yml::no-deployment-validation","severity":"S2","effort":"E2","confidence":"HIGH","files":[".github/workflows/deploy-firebase.yml:140-147"],"why_it_matters":"Lines 140-147 deploy functions, rules, and hosting but don't verify deployment actually succeeded. Firebase CLI can exit 0 even if deployment partially failed. Broken deployments may go unnoticed until users report issues.","suggested_fix":"Add validation steps after each deploy: query Firebase to confirm functions are deployed and callable, test firestore rules with sample operations, curl hosting URL to verify it returns 200. Fail workflow if validation fails.","acceptance_tests":["Deployment validation catches broken function deploys","Firestore rules are tested after deployment","Hosting URL is accessible and returns expected content","Failed deployments trigger immediate alerts"],"file":".github/workflows/deploy-firebase.yml","line":140,"description":"Lines 140-147 deploy functions, rules, and hosting but don't verify deployment actually succeeded. Firebase CLI can exit 0 even if deployment partially failed. Broken deployments may go unnoticed until users report issues.","recommendation":"Add validation steps after each deploy: query Firebase to confirm functions are deployed and callable, test firestore rules with sample operations, curl hosting URL to verify it returns 200. Fail workflow if validation fails.","id":"process::.github/workflows/deploy-firebase.yml::no-deployment-validation"}
{"category":"process","title":"CI gap: Deployment has no rollback mechanism","fingerprint":"process::.github/workflows/deploy-firebase.yml::no-rollback","severity":"S2","effort":"E3","confidence":"MEDIUM","files":[".github/workflows/deploy-firebase.yml:140-147"],"why_it_matters":"Deployment steps run sequentially (lines 140-147) but if one fails, there's no rollback. A partial deployment could leave production in inconsistent state (e.g., new functions deployed but old hosting, or new rules but old functions).","suggested_fix":"Add rollback step that runs on failure: capture previous deployment SHA before deploy, on failure run firebase deploy with previous version. Or use Firebase's rollback API. Or deploy to staging first, validate, then promote.","acceptance_tests":["Failed deployments automatically roll back to last known good state","Production is never in partially-deployed state","Rollback is tested in staging environment"],"file":".github/workflows/deploy-firebase.yml","line":140,"description":"Deployment steps run sequentially (lines 140-147) but if one fails, there's no rollback. A partial deployment could leave production in inconsistent state (e.g., new functions deployed but old hosting, or new rules but old functions).","recommendation":"Add rollback step that runs on failure: capture previous deployment SHA before deploy, on failure run firebase deploy with previous version. Or use Firebase's rollback API. Or deploy to staging first, validate, then promote.","id":"process::.github/workflows/deploy-firebase.yml::no-rollback"}
{"category":"process","title":"CI gap: Service account credentials written to filesystem","fingerprint":"process::.github/workflows/deploy-firebase.yml::credentials-filesystem-risk","severity":"S2","effort":"E1","confidence":"HIGH","files":[".github/workflows/deploy-firebase.yml:120-124"],"why_it_matters":"Lines 120-124 write service account JSON to $HOME/gcloud-key.json. If subsequent steps fail or are compromised, credentials could be leaked in logs, artifacts, or through file disclosure. File is only cleaned up in always() block which might not run if workflow is cancelled.","suggested_fix":"Use Google's official auth action which handles credentials securely without writing to disk. Or use base64 encode/pipe: echo $SECRET | base64 -d | gcloud auth activate-service-account --key-file=-. Ensure cleanup happens even on workflow cancellation.","acceptance_tests":["Credentials are never written to disk in plain text","Workflow cancellation doesn't leave credentials on runner","Credentials don't appear in any logs or artifacts"],"file":".github/workflows/deploy-firebase.yml","line":120,"description":"Lines 120-124 write service account JSON to $HOME/gcloud-key.json. If subsequent steps fail or are compromised, credentials could be leaked in logs, artifacts, or through file disclosure. File is only cleaned up in always() block which might not run if workflow is cancelled.","recommendation":"Use Google's official auth action which handles credentials securely without writing to disk. Or use base64 encode/pipe: echo $SECRET | base64 -d | gcloud auth activate-service-account --key-file=-. Ensure cleanup happens even on workflow cancellation.","id":"process::.github/workflows/deploy-firebase.yml::credentials-filesystem-risk"}
{"category":"process","title":"CI gap: Deleting functions uses continue-on-error hiding real failures","fingerprint":"process::.github/workflows/deploy-firebase.yml::function-delete-masked","severity":"S3","effort":"E1","confidence":"MEDIUM","files":[".github/workflows/deploy-firebase.yml:131-138"],"why_it_matters":"Line 138 uses continue-on-error for function deletion. This is intended to handle 'function doesn't exist' but also hides real errors like authentication failures, permission issues, or API outages. These failures should block deployment.","suggested_fix":"Check if function exists before deleting: firebase functions:list | grep -q functionName && firebase functions:delete functionName. Or capture error message and only ignore specific 404-style errors. Fail on auth/permission/API errors.","acceptance_tests":["Workflow fails on auth/permission errors during function deletion","Workflow succeeds when function doesn't exist (expected case)","Unexpected errors are surfaced, not hidden"],"file":".github/workflows/deploy-firebase.yml","line":131,"description":"Line 138 uses continue-on-error for function deletion. This is intended to handle 'function doesn't exist' but also hides real errors like authentication failures, permission issues, or API outages. These failures should block deployment.","recommendation":"Check if function exists before deleting: firebase functions:list | grep -q functionName && firebase functions:delete functionName. Or capture error message and only ignore specific 404-style errors. Fail on auth/permission/API errors.","id":"process::.github/workflows/deploy-firebase.yml::function-delete-masked"}
{"category":"process","title":"CI gap: Preview and production use different env var sources","fingerprint":"process::.github/workflows/deploy-firebase.yml::env-var-inconsistency","severity":"S3","effort":"E2","confidence":"HIGH","files":[".github/workflows/deploy-firebase.yml:51",".github/workflows/deploy-firebase.yml:104"],"why_it_matters":"Preview deploy (line 51) uses vars.* (GitHub environment variables) while production (line 104) uses secrets.*. This inconsistency means preview and production builds could have different configurations, making preview testing unreliable and potentially hiding config issues.","suggested_fix":"Use same source for both (either both vars or both secrets). Document why they're different if intentional. Add validation that all required env vars are present in both sources. Consider using a config file instead.","acceptance_tests":["Preview and production use identical env var values","Config differences are documented and intentional","Tests verify preview behaves like production"],"file":".github/workflows/deploy-firebase.yml","line":51,"description":"Preview deploy (line 51) uses vars.* (GitHub environment variables) while production (line 104) uses secrets.*. This inconsistency means preview and production builds could have different configurations, making preview testing unreliable and potentially hiding config issues.","recommendation":"Use same source for both (either both vars or both secrets). Document why they're different if intentional. Add validation that all required env vars are present in both sources. Consider using a config file instead.","id":"process::.github/workflows/deploy-firebase.yml::env-var-inconsistency"}
{"category":"process","title":"CI gap: Backlog check gracefully skips with no replacement validation","fingerprint":"process::.github/workflows/backlog-enforcement.yml::missing-replacement-check","severity":"S3","effort":"E1","confidence":"MEDIUM","files":[".github/workflows/backlog-enforcement.yml:35-42"],"why_it_matters":"Lines 35-42 gracefully skip if AUDIT_FINDINGS_BACKLOG.md doesn't exist (archived per comment), but there's no check that replacement MASTER_DEBT.jsonl exists and is valid. Backlog tracking could silently break if neither file exists.","suggested_fix":"Add elif check: if [ -f docs/technical-debt/MASTER_DEBT.jsonl ]; then run new validation; else fail with error. Or integrate with existing TDMS validation in ci.yml. Ensure one source of truth is always validated.","acceptance_tests":["Workflow fails if neither backlog file exists","MASTER_DEBT.jsonl is validated when present","Migration from old to new system is tracked"],"file":".github/workflows/backlog-enforcement.yml","line":35,"description":"Lines 35-42 gracefully skip if AUDIT_FINDINGS_BACKLOG.md doesn't exist (archived per comment), but there's no check that replacement MASTER_DEBT.jsonl exists and is valid. Backlog tracking could silently break if neither file exists.","recommendation":"Add elif check: if [ -f docs/technical-debt/MASTER_DEBT.jsonl ]; then run new validation; else fail with error. Or integrate with existing TDMS validation in ci.yml. Ensure one source of truth is always validated.","id":"process::.github/workflows/backlog-enforcement.yml::missing-replacement-check"}
{"category":"process","title":"CI gap: Security pattern check runs file-by-file inefficiently","fingerprint":"process::.github/workflows/backlog-enforcement.yml::inefficient-security-loop","severity":"S3","effort":"E2","confidence":"MEDIUM","files":[".github/workflows/backlog-enforcement.yml:147-150"],"why_it_matters":"Lines 147-150 run security-check.js in a loop for each changed file. This is inefficient (spawns N processes), doesn't aggregate results, and could hide failures in earlier iterations. Also prevents batch optimizations in the script.","suggested_fix":"Modify security-check.js to accept multiple files: node scripts/security-check.js --files file1 file2 file3. Or pass all files via stdin. Aggregate results and report summary. Run once instead of N times.","acceptance_tests":["Security check runs once per workflow, not per file","All violations are reported in single summary","Performance improves for PRs with many changed files"],"file":".github/workflows/backlog-enforcement.yml","line":147,"description":"Lines 147-150 run security-check.js in a loop for each changed file. This is inefficient (spawns N processes), doesn't aggregate results, and could hide failures in earlier iterations. Also prevents batch optimizations in the script.","recommendation":"Modify security-check.js to accept multiple files: node scripts/security-check.js --files file1 file2 file3. Or pass all files via stdin. Aggregate results and report summary. Run once instead of N times.","id":"process::.github/workflows/backlog-enforcement.yml::inefficient-security-loop"}
{"category":"process","title":"CI gap: Documentation linting skips archive files entirely","fingerprint":"process::.github/workflows/docs-lint.yml::archives-never-checked","severity":"S3","effort":"E1","confidence":"MEDIUM","files":[".github/workflows/docs-lint.yml:78-81"],"why_it_matters":"Lines 78-81 skip archive files completely. While archives are historical, broken links and formatting issues make them harder to reference. If someone needs to consult archived docs, broken content creates confusion and wastes time.","suggested_fix":"Create separate non-blocking job for archive linting. Report issues but don't block PRs. Or run archive lint on a schedule. Or document that archives are explicitly not maintained and add warning banner to archive docs.","acceptance_tests":["Archive files are linted separately","Archive lint issues are reported but non-blocking","Archive docs have warning banner about potential staleness"],"file":".github/workflows/docs-lint.yml","line":78,"description":"Lines 78-81 skip archive files completely. While archives are historical, broken links and formatting issues make them harder to reference. If someone needs to consult archived docs, broken content creates confusion and wastes time.","recommendation":"Create separate non-blocking job for archive linting. Report issues but don't block PRs. Or run archive lint on a schedule. Or document that archives are explicitly not maintained and add warning banner to archive docs.","id":"process::.github/workflows/docs-lint.yml::archives-never-checked"}
{"category":"process","title":"CI gap: Resolve debt workflow only runs on merged PRs","fingerprint":"process::.github/workflows/resolve-debt.yml::closed-pr-skip","severity":"S3","effort":"E2","confidence":"MEDIUM","files":[".github/workflows/resolve-debt.yml:11"],"why_it_matters":"Line 11 only triggers on merged PRs. If a PR mentions DEBT-123 but is closed without merging, the debt item is never updated to reflect the cancelled work. This causes debt tracking to become stale and inaccurate.","suggested_fix":"Add separate step for closed-without-merge PRs: update debt items to add comment 'PR #123 closed without merging' and revert status if it was changed. Or don't auto-update debt items at all, require manual resolution.","acceptance_tests":["Closed PRs update debt items with closure reason","Debt items track both merged and unmerged attempts","Debt status is accurate regardless of PR outcome"],"file":".github/workflows/resolve-debt.yml","line":11,"description":"Line 11 only triggers on merged PRs. If a PR mentions DEBT-123 but is closed without merging, the debt item is never updated to reflect the cancelled work. This causes debt tracking to become stale and inaccurate.","recommendation":"Add separate step for closed-without-merge PRs: update debt items to add comment 'PR #123 closed without merging' and revert status if it was changed. Or don't auto-update debt items at all, require manual resolution.","id":"process::.github/workflows/resolve-debt.yml::closed-pr-skip"}
{"category":"process","title":"CI gap: Debt resolution skips CI with [skip ci]","fingerprint":"process::.github/workflows/resolve-debt.yml::skip-ci-debt","severity":"S3","effort":"E1","confidence":"HIGH","files":[".github/workflows/resolve-debt.yml:88"],"why_it_matters":"Line 88 includes [skip ci] in commit message. This means debt resolution commits bypass all CI checks including validation of the debt file structure, pattern compliance, and any other checks. Malformed debt commits could merge without detection.","suggested_fix":"Remove [skip ci] and let normal CI run. Debt resolution should be validated like any other commit. If CI is too slow, optimize CI rather than skipping it. Or use more specific skip flag that only skips expensive tests.","acceptance_tests":["Debt resolution commits run through full CI","MASTER_DEBT.jsonl validation catches malformed resolutions","No commits bypass CI except explicitly documented exceptions"],"file":".github/workflows/resolve-debt.yml","line":88,"description":"Line 88 includes [skip ci] in commit message. This means debt resolution commits bypass all CI checks including validation of the debt file structure, pattern compliance, and any other checks. Malformed debt commits could merge without detection.","recommendation":"Remove [skip ci] and let normal CI run. Debt resolution should be validated like any other commit. If CI is too slow, optimize CI rather than skipping it. Or use more specific skip flag that only skips expensive tests.","id":"process::.github/workflows/resolve-debt.yml::skip-ci-debt"}
{"category":"process","title":"CI gap: Debt resolution has race condition on rebase","fingerprint":"process::.github/workflows/resolve-debt.yml::rebase-race","severity":"S3","effort":"E2","confidence":"MEDIUM","files":[".github/workflows/resolve-debt.yml:92"],"why_it_matters":"Line 92 does git pull --rebase to handle case where main moved after checkout. But if another workflow pushes between pull and push, this fails. Multiple merged PRs in quick succession can cause workflow failures and failed debt resolution.","suggested_fix":"Add retry loop like sync-readme.yml (lines 64-78). Or use GitHub's REST API to create commits instead of git push. Or add concurrency group to serialize debt resolution commits.","acceptance_tests":["Concurrent merges don't cause debt resolution failures","Retry logic handles race conditions","Failed debt resolutions are retried automatically"],"file":".github/workflows/resolve-debt.yml","line":92,"description":"Line 92 does git pull --rebase to handle case where main moved after checkout. But if another workflow pushes between pull and push, this fails. Multiple merged PRs in quick succession can cause workflow failures and failed debt resolution.","recommendation":"Add retry loop like sync-readme.yml (lines 64-78). Or use GitHub's REST API to create commits instead of git push. Or add concurrency group to serialize debt resolution commits.","id":"process::.github/workflows/resolve-debt.yml::rebase-race"}
{"category":"process","title":"CI gap: Review trigger check has fragile JSON validation","fingerprint":"process::.github/workflows/review-check.yml::complex-json-parse","severity":"S3","effort":"E2","confidence":"MEDIUM","files":[".github/workflows/review-check.yml:46-50"],"why_it_matters":"Lines 46-50 have complex JSON validation using piped node one-liner. If this fails, output is replaced with error JSON but parsing errors are silently swallowed. Malformed JSON could cause workflow to incorrectly mark PRs as needing review.","suggested_fix":"Simplify validation: use jq or node -p 'JSON.parse(process.argv[1])' $OUTPUT. If validation fails, fail the workflow explicitly rather than substituting error JSON. Log original output for debugging.","acceptance_tests":["Invalid JSON from script fails workflow with clear error","Error messages show actual script output","Review needed determination is accurate"],"file":".github/workflows/review-check.yml","line":46,"description":"Lines 46-50 have complex JSON validation using piped node one-liner. If this fails, output is replaced with error JSON but parsing errors are silently swallowed. Malformed JSON could cause workflow to incorrectly mark PRs as needing review.","recommendation":"Simplify validation: use jq or node -p 'JSON.parse(process.argv[1])' $OUTPUT. If validation fails, fail the workflow explicitly rather than substituting error JSON. Log original output for debugging.","id":"process::.github/workflows/review-check.yml::complex-json-parse"}
{"category":"process","title":"CI gap: Review check uses continue-on-error hiding crashes","fingerprint":"process::.github/workflows/review-check.yml::continue-hides-crashes","severity":"S3","effort":"E1","confidence":"MEDIUM","files":[".github/workflows/review-check.yml:33"],"why_it_matters":"Line 33 has continue-on-error which means if check-review-needed.js crashes (OOM, unhandled exception, etc), workflow continues and treats it as 'review needed'. This creates false positives and alert fatigue. Real errors should be fixed, not hidden.","suggested_fix":"Remove continue-on-error. Let script failures fail the workflow. Fix the script to handle errors gracefully and return proper exit codes. Use workflow retry for transient failures.","acceptance_tests":["Script crashes fail the workflow","Exit codes correctly map to review needed vs not needed","Transient failures are retried automatically"],"file":".github/workflows/review-check.yml","line":33,"description":"Line 33 has continue-on-error which means if check-review-needed.js crashes (OOM, unhandled exception, etc), workflow continues and treats it as 'review needed'. This creates false positives and alert fatigue. Real errors should be fixed, not hidden.","recommendation":"Remove continue-on-error. Let script failures fail the workflow. Fix the script to handle errors gracefully and return proper exit codes. Use workflow retry for transient failures.","id":"process::.github/workflows/review-check.yml::continue-hides-crashes"}
{"category":"process","title":"CI gap: Phase validation workflow is likely dead code","fingerprint":"process::.github/workflows/validate-plan.yml::dead-workflow","severity":"S3","effort":"E1","confidence":"HIGH","files":[".github/workflows/validate-plan.yml:7"],"why_it_matters":"Line 7 only triggers for changes to docs/archive/completed-plans/INTEGRATED_IMPROVEMENT_PLAN.md which is an archived document. This workflow never runs on modern changes. Dead code creates maintenance burden and confusion.","suggested_fix":"Delete the workflow and document in commit message that phase validation is now handled elsewhere. Or update path to current planning documents. Or disable workflow explicitly with if: false.","acceptance_tests":["Dead workflows are removed","Active workflows are documented","Workflow list is reviewed quarterly for dead code"],"file":".github/workflows/validate-plan.yml","line":7,"description":"Line 7 only triggers for changes to docs/archive/completed-plans/INTEGRATED_IMPROVEMENT_PLAN.md which is an archived document. This workflow never runs on modern changes. Dead code creates maintenance burden and confusion.","recommendation":"Delete the workflow and document in commit message that phase validation is now handled elsewhere. Or update path to current planning documents. Or disable workflow explicitly with if: false.","id":"process::.github/workflows/validate-plan.yml::dead-workflow"}
{"category":"process","title":"CI gap: Sync README has fragile retry logic","fingerprint":"process::.github/workflows/sync-readme.yml::fragile-retry","severity":"S3","effort":"E2","confidence":"MEDIUM","files":[".github/workflows/sync-readme.yml:64-78"],"why_it_matters":"Lines 64-78 retry push 3 times with 5-second sleep. This is fragile: assumes conflicts resolve within 5s, doesn't backoff exponentially, and 3 retries may not be enough if multiple workflows queue up. Also mixes pull --rebase with retry which could compound conflicts.","suggested_fix":"Use exponential backoff: sleep $((i * i * 5)). Increase retries to 5. Use GitHub API to create commits instead of git push to avoid git-level races. Or use concurrency group to serialize commits.","acceptance_tests":["Retry logic handles burst of concurrent pushes","Exponential backoff prevents thundering herd","Success rate is >99% for typical concurrent scenarios"],"file":".github/workflows/sync-readme.yml","line":64,"description":"Lines 64-78 retry push 3 times with 5-second sleep. This is fragile: assumes conflicts resolve within 5s, doesn't backoff exponentially, and 3 retries may not be enough if multiple workflows queue up. Also mixes pull --rebase with retry which could compound conflicts.","recommendation":"Use exponential backoff: sleep $((i * i * 5)). Increase retries to 5. Use GitHub API to create commits instead of git push to avoid git-level races. Or use concurrency group to serialize commits.","id":"process::.github/workflows/sync-readme.yml::fragile-retry"}
{"category":"process","title":"CI gap: Sync README uses --no-verify bypassing hooks","fingerprint":"process::.github/workflows/sync-readme.yml::no-verify-bypass","severity":"S3","effort":"E1","confidence":"HIGH","files":[".github/workflows/sync-readme.yml:57"],"why_it_matters":"Line 57 uses --no-verify which bypasses pre-commit hooks. If hooks check for commit message format, trailing whitespace, or other issues, README sync commits could violate standards. This creates inconsistency in commit history.","suggested_fix":"Remove --no-verify unless there's specific reason (document reason if so). Let hooks run to ensure consistency. If hooks are too slow for automation, optimize hooks rather than skipping them.","acceptance_tests":["README sync commits follow same standards as manual commits","Hooks run on all commits except explicitly documented exceptions","Commit history is consistent"],"file":".github/workflows/sync-readme.yml","line":57,"description":"Line 57 uses --no-verify which bypasses pre-commit hooks. If hooks check for commit message format, trailing whitespace, or other issues, README sync commits could violate standards. This creates inconsistency in commit history.","recommendation":"Remove --no-verify unless there's specific reason (document reason if so). Let hooks run to ensure consistency. If hooks are too slow for automation, optimize hooks rather than skipping them.","id":"process::.github/workflows/sync-readme.yml::no-verify-bypass"}
{"category":"process","title":"CI gap: Inconsistent GitHub Action version pinning","fingerprint":"process::.github/workflows/*::inconsistent-pinning","severity":"S3","effort":"E2","confidence":"HIGH","files":[".github/workflows/ci.yml:45",".github/workflows/auto-label-review-tier.yml:29",".github/workflows/backlog-enforcement.yml:18"],"why_it_matters":"Some workflows use SHA pinning for security (ci.yml line 45, backlog-enforcement.yml line 18) while others use semantic versions (auto-label-review-tier.yml line 29 uses @v46). Inconsistent pinning creates security gaps and makes supply chain attacks easier.","suggested_fix":"Adopt consistent pinning strategy: either pin all actions to SHAs with comments showing version, or use Dependabot to keep semantic versions updated. Document strategy in CONTRIBUTING.md.","acceptance_tests":["All critical workflows use SHA pinning","Dependabot keeps action versions updated","Pinning strategy is documented"],"file":".github/workflows/ci.yml","line":45,"description":"Some workflows use SHA pinning for security (ci.yml line 45, backlog-enforcement.yml line 18) while others use semantic versions (auto-label-review-tier.yml line 29 uses @v46). Inconsistent pinning creates security gaps and makes supply chain attacks easier.","recommendation":"Adopt consistent pinning strategy: either pin all actions to SHAs with comments showing version, or use Dependabot to keep semantic versions updated. Document strategy in CONTRIBUTING.md.","id":"process::.github/workflows/*::inconsistent-pinning"}
{"category":"process","title":"CI gap: No validation of Node.js version consistency","fingerprint":"process::.github/workflows/ci.yml::no-node-version-check","severity":"S3","effort":"E1","confidence":"MEDIUM","files":[".github/workflows/ci.yml:21"],"why_it_matters":"Line 21 hardcodes Node 22 but there's no check that this matches package.json engines field or .nvmrc. Developers could use different Node version locally, causing 'works on my machine' issues. CI should enforce version consistency.","suggested_fix":"Add .nvmrc or package.json engines field with required Node version. Change workflow to read version from file: node-version-file: '.nvmrc'. Add pre-commit hook to check local Node version matches.","acceptance_tests":["CI uses same Node version as specified in .nvmrc","Local development enforces correct Node version","Version mismatches are caught before CI"],"file":".github/workflows/ci.yml","line":21,"description":"Line 21 hardcodes Node 22 but there's no check that this matches package.json engines field or .nvmrc. Developers could use different Node version locally, causing 'works on my machine' issues. CI should enforce version consistency.","recommendation":"Add .nvmrc or package.json engines field with required Node version. Change workflow to read version from file: node-version-file: '.nvmrc'. Add pre-commit hook to check local Node version matches.","id":"process::.github/workflows/ci.yml::no-node-version-check"}
{"category":"process","title":"CI gap: Template file exclusion is brittle regex","fingerprint":"process::.github/workflows/docs-lint.yml::template-regex-brittle","severity":"S3","effort":"E1","confidence":"MEDIUM","files":[".github/workflows/docs-lint.yml:72-75"],"why_it_matters":"Lines 72-75 use regex patterns to skip template files: (TEMPLATE|_TEMPLATE)\\.md$. A file named TEMPLATE-proposal.md or my-TEMPLATE.md wouldn't match and would be incorrectly linted. Brittle pattern matching causes false positives.","suggested_fix":"Use more specific paths: if [[ $file =~ ^docs/templates/ ]]; then skip. Or maintain list of template files in config. Or add header to templates that linter detects. Make pattern matching more robust.","acceptance_tests":["All template files are correctly skipped","Non-template files with 'template' in name are linted","Pattern matching is tested with edge cases"],"file":".github/workflows/docs-lint.yml","line":72,"description":"Lines 72-75 use regex patterns to skip template files: (TEMPLATE|_TEMPLATE)\\.md$. A file named TEMPLATE-proposal.md or my-TEMPLATE.md wouldn't match and would be incorrectly linted. Brittle pattern matching causes false positives.","recommendation":"Use more specific paths: if [[ $file =~ ^docs/templates/ ]]; then skip. Or maintain list of template files in config. Or add header to templates that linter detects. Make pattern matching more robust.","id":"process::.github/workflows/docs-lint.yml::template-regex-brittle"}
{"category":"process","title":"CI gap: Markdown injection sanitization incomplete","fingerprint":"process::.github/workflows/docs-lint.yml::markdown-injection-incomplete","severity":"S3","effort":"E2","confidence":"MEDIUM","files":[".github/workflows/docs-lint.yml:91"],"why_it_matters":"Line 91 sanitizes ``` to prevent markdown injection but doesn't handle other vectors like [clickjacking](javascript:alert(1)) or HTML tags. Malicious or buggy docs could inject content into PR comments.","suggested_fix":"Use comprehensive sanitization library or render lint output as code block (which GitHub auto-escapes). Or limit output length and use GitHub's built-in comment rendering which sanitizes HTML.","acceptance_tests":["Malicious markdown in docs doesn't execute in PR comments","All user-controlled content is sanitized","XSS and injection vectors are tested"],"file":".github/workflows/docs-lint.yml","line":91,"description":"Line 91 sanitizes ``` to prevent markdown injection but doesn't handle other vectors like [clickjacking](javascript:alert(1)) or HTML tags. Malicious or buggy docs could inject content into PR comments.","recommendation":"Use comprehensive sanitization library or render lint output as code block (which GitHub auto-escapes). Or limit output length and use GitHub's built-in comment rendering which sanitizes HTML.","id":"process::.github/workflows/docs-lint.yml::markdown-injection-incomplete"}
{"category":"process","title":"CI gap: Changed files detection could miss merge commits","fingerprint":"process::.github/workflows/backlog-enforcement.yml::git-diff-merge-commits","severity":"S3","effort":"E2","confidence":"MEDIUM","files":[".github/workflows/backlog-enforcement.yml:127"],"why_it_matters":"Line 127 uses git diff origin/$BASE...HEAD which could miss files in merge commits depending on git configuration. Three-dot diff shows changes since common ancestor, but merge commits might introduce changes not in either parent.","suggested_fix":"Use two-dot diff: git diff origin/$BASE..HEAD. Or use GitHub's changed files API which is authoritative. Or use tj-actions/changed-files action like other workflows for consistency.","acceptance_tests":["All changed files are detected including merge commits","Changed file detection is consistent across workflows","Edge cases like merge commits are tested"],"file":".github/workflows/backlog-enforcement.yml","line":127,"description":"Line 127 uses git diff origin/$BASE...HEAD which could miss files in merge commits depending on git configuration. Three-dot diff shows changes since common ancestor, but merge commits might introduce changes not in either parent.","recommendation":"Use two-dot diff: git diff origin/$BASE..HEAD. Or use GitHub's changed files API which is authoritative. Or use tj-actions/changed-files action like other workflows for consistency.","id":"process::.github/workflows/backlog-enforcement.yml::git-diff-merge-commits"}
{"category":"process","title":"CI gap: Tier comment spam on every synchronize event","fingerprint":"process::.github/workflows/auto-label-review-tier.yml::comment-on-synchronize","severity":"S4","effort":"E1","confidence":"HIGH","files":[".github/workflows/auto-label-review-tier.yml:186"],"why_it_matters":"Line 186 only posts comment on opened/reopened, not synchronize. This is good for avoiding spam, but if tier changes due to new files added, PR author doesn't get notified. They might miss important tier escalation (e.g., tier 2 -> tier 4).","suggested_fix":"Post comment on synchronize only if tier label changed. Track previous tier in workflow state or by reading PR labels. Notify author when tier increases (escalation) but not when it stays same.","acceptance_tests":["Comment posted when tier changes","No comment spam on every push","Tier escalation notifications are prominent"],"file":".github/workflows/auto-label-review-tier.yml","line":186,"description":"Line 186 only posts comment on opened/reopened, not synchronize. This is good for avoiding spam, but if tier changes due to new files added, PR author doesn't get notified. They might miss important tier escalation (e.g., tier 2 -> tier 4).","recommendation":"Post comment on synchronize only if tier label changed. Track previous tier in workflow state or by reading PR labels. Notify author when tier increases (escalation) but not when it stays same.","id":"process::.github/workflows/auto-label-review-tier.yml::comment-on-synchronize"}
{"category":"process","title":"Bug: check-review-needed.js - getNextDay() fails silently on invalid dates","fingerprint":"process::scripts/check-review-needed.js::getnextday-silent-failure","severity":"S2","effort":"E1","confidence":"MEDIUM","files":["scripts/check-review-needed.js:170","scripts/check-review-needed.js:534","scripts/check-review-needed.js:550"],"why_it_matters":"getNextDay() returns empty string on invalid date (line 176), but callers at lines 534 and 550 don't validate the result. This passes empty string to git commands as --since=\"\" which may not fail but could produce unexpected results, potentially causing incorrect review trigger calculations.","suggested_fix":"Add validation in getNextDay() callers to check for empty string return and handle gracefully: const afterDate = getNextDay(sinceDate); if (!afterDate) { return 0; } // or appropriate fallback","acceptance_tests":["Script handles invalid dates in audit tracker without silent failures","Git commands receive valid date parameters or operations fail explicitly"],"file":"scripts/check-review-needed.js","line":170,"description":"getNextDay() returns empty string on invalid date (line 176), but callers at lines 534 and 550 don't validate the result. This passes empty string to git commands as --since=\"\" which may not fail but could produce unexpected results, potentially causing incorrect review trigger calculations.","recommendation":"Add validation in getNextDay() callers to check for empty string return and handle gracefully: const afterDate = getNextDay(sinceDate); if (!afterDate) { return 0; } // or appropriate fallback","id":"process::scripts/check-review-needed.js::getnextday-silent-failure"}
{"category":"process","title":"Bug: check-cross-doc-deps.js - checkDiffPattern() silently skips rules on git errors","fingerprint":"process::scripts/check-cross-doc-deps.js::checkdiffpattern-silent-skip","severity":"S2","effort":"E1","confidence":"HIGH","files":["scripts/check-cross-doc-deps.js:100"],"why_it_matters":"checkDiffPattern() catches all errors and returns false without warning (lines 110-118). If git diff fails (e.g., binary file, permission issue, corrupted file), the dependency check rule is silently skipped. This could miss required dependent document updates, defeating the purpose of cross-document enforcement.","suggested_fix":"Log errors when git diff fails in non-verbose mode, or collect failed checks and report them in summary. Consider: if (verbose) logVerbose(`Failed to check diff...`) should be if (verbose || diffCheckFailed) log(`Warning: Failed to check...`)","acceptance_tests":["Script reports when git diff operations fail","Dependency checks don't silently skip due to git errors"],"file":"scripts/check-cross-doc-deps.js","line":100,"description":"checkDiffPattern() catches all errors and returns false without warning (lines 110-118). If git diff fails (e.g., binary file, permission issue, corrupted file), the dependency check rule is silently skipped. This could miss required dependent document updates, defeating the purpose of cross-document enforcement.","recommendation":"Log errors when git diff fails in non-verbose mode, or collect failed checks and report them in summary. Consider: if (verbose) logVerbose(`Failed to check diff...`) should be if (verbose || diffCheckFailed) log(`Warning: Failed to check...`)","id":"process::scripts/check-cross-doc-deps.js::checkdiffpattern-silent-skip"}
{"category":"process","title":"Bug: check-cross-doc-deps.js - inconsistent behavior with empty dependency rules","fingerprint":"process::scripts/check-cross-doc-deps.js::empty-rules-inconsistent","severity":"S2","effort":"E1","confidence":"HIGH","files":["scripts/check-cross-doc-deps.js:69"],"why_it_matters":"When config loads with empty rules (line 69), the script exits with error code 2 in normal mode (line 75) but continues in dry-run mode (line 73) and reports success. This inconsistency means --dry-run doesn't accurately simulate normal behavior, and empty config might go unnoticed in testing.","suggested_fix":"Remove the dry-run exemption: if (dependencyRules.length === 0) { log('Error: cross-doc dependency enforcement disabled due to empty rules.', colors.red); process.exit(2); } // No dry-run check","acceptance_tests":["Script fails consistently with empty rules in both normal and dry-run modes","Dry-run mode accurately simulates normal execution behavior"],"file":"scripts/check-cross-doc-deps.js","line":69,"description":"When config loads with empty rules (line 69), the script exits with error code 2 in normal mode (line 75) but continues in dry-run mode (line 73) and reports success. This inconsistency means --dry-run doesn't accurately simulate normal behavior, and empty config might go unnoticed in testing.","recommendation":"Remove the dry-run exemption: if (dependencyRules.length === 0) { log('Error: cross-doc dependency enforcement disabled due to empty rules.', colors.red); process.exit(2); } // No dry-run check","id":"process::scripts/check-cross-doc-deps.js::empty-rules-inconsistent"}
{"category":"process","title":"Bug: security-check.js - getStagedFiles() returns empty array on git failure without error","fingerprint":"process::scripts/security-check.js::getstagedfiles-silent-failure","severity":"S2","effort":"E1","confidence":"HIGH","files":["scripts/security-check.js:310"],"why_it_matters":"getStagedFiles() catch block (line 321-323) returns empty array when git fails (not a git repo, git not installed, permission issues) without logging the error. Main function then prints 'No files to check' which is misleading - the issue is git failure, not absence of files. Users may think security check passed when it silently failed.","suggested_fix":"Log git errors before returning empty array: try { ... } catch (err) { if (!isQuiet) console.error(`Warning: Could not get staged files from git: ${err.message}`); return []; }","acceptance_tests":["Script reports git errors when failing to retrieve staged files","Users can distinguish between 'no staged files' and 'git command failed'"],"file":"scripts/security-check.js","line":310,"description":"getStagedFiles() catch block (line 321-323) returns empty array when git fails (not a git repo, git not installed, permission issues) without logging the error. Main function then prints 'No files to check' which is misleading - the issue is git failure, not absence of files. Users may think security check passed when it silently failed.","recommendation":"Log git errors before returning empty array: try { ... } catch (err) { if (!isQuiet) console.error(`Warning: Could not get staged files from git: ${err.message}`); return []; }","id":"process::scripts/security-check.js::getstagedfiles-silent-failure"}
{"category":"process","title":"Bug: validate-audit.js - wildcard file patterns not validated for existence","fingerprint":"process::scripts/validate-audit.js::wildcard-no-existence-check","severity":"S3","effort":"E1","confidence":"MEDIUM","files":["scripts/validate-audit.js:370"],"why_it_matters":"validateFilePath() checks wildcard patterns (line 370-383) by validating only the prefix path for containment, but doesn't verify if the pattern matches any actual files. A finding with file='src/*.js' passes validation even if no such files exist. This allows ineffective or typo'd patterns to pass validation, reducing audit quality.","suggested_fix":"After containment check for wildcards, optionally use glob library to check if pattern matches at least one file: const matches = glob.sync(finding.file, {cwd: repoRoot}); if (matches.length === 0) { issues.push({type: 'WILDCARD_NO_MATCH', ...}) }","acceptance_tests":["Script warns when wildcard patterns match zero files","Audit findings with typo'd wildcards are flagged during validation"],"file":"scripts/validate-audit.js","line":370,"description":"validateFilePath() checks wildcard patterns (line 370-383) by validating only the prefix path for containment, but doesn't verify if the pattern matches any actual files. A finding with file='src/*.js' passes validation even if no such files exist. This allows ineffective or typo'd patterns to pass validation, reducing audit quality.","recommendation":"After containment check for wildcards, optionally use glob library to check if pattern matches at least one file: const matches = glob.sync(finding.file, {cwd: repoRoot}); if (matches.length === 0) { issues.push({type: 'WILDCARD_NO_MATCH', ...}) }","id":"process::scripts/validate-audit.js::wildcard-no-existence-check"}
{"category":"process","title":"Enhancement: generate-documentation-index.js - no visibility into skipped links","fingerprint":"process::scripts/generate-documentation-index.js::skipped-links-invisible","severity":"S3","effort":"E1","confidence":"MEDIUM","files":["scripts/generate-documentation-index.js:417"],"why_it_matters":"extractLinks() silently skips links that fail path containment (line 422-424) or URL decoding (line 401-404). In verbose mode, there's no count or warning about how many links were skipped. Users can't tell if their documentation has broken links attempting path traversal or malformed URLs, reducing the index quality.","suggested_fix":"Add counter for skipped links and log in verbose mode: let skipped = 0; ... if (resolvedPath === null) { skipped++; if (verbose) logVerbose(`Skipped link in ${currentFile}: ${href} (path traversal)`); continue; } ... if (verbose && skipped > 0) log(`Skipped ${skipped} invalid links in ${currentFile}`)","acceptance_tests":["Script reports count of skipped links in verbose mode","Users can identify documents with path traversal or malformed link attempts"],"file":"scripts/generate-documentation-index.js","line":417,"description":"extractLinks() silently skips links that fail path containment (line 422-424) or URL decoding (line 401-404). In verbose mode, there's no count or warning about how many links were skipped. Users can't tell if their documentation has broken links attempting path traversal or malformed URLs, reducing the index quality.","recommendation":"Add counter for skipped links and log in verbose mode: let skipped = 0; ... if (resolvedPath === null) { skipped++; if (verbose) logVerbose(`Skipped link in ${currentFile}: ${href} (path traversal)`); continue; } ... if (verbose && skipped > 0) log(`Skipped ${skipped} invalid links in ${currentFile}`)","id":"process::scripts/generate-documentation-index.js::skipped-links-invisible"}
{"category":"process","title":"Enhancement: check-pattern-compliance.js - silent filtering of user-provided files","fingerprint":"process::scripts/check-pattern-compliance.js::silent-file-filtering","severity":"S3","effort":"E1","confidence":"MEDIUM","files":["scripts/check-pattern-compliance.js:494"],"why_it_matters":"getFilesToCheck() with explicit FILES argument (line 494-508) applies filtering (path validation, existence checks, global excludes) that can reduce the list to empty. If user provides 'node scripts/check-pattern-compliance.js file1.js file2.js' but both are excluded, the script exits with 'No files to check' without explaining why their specified files were ignored. This is confusing user experience.","suggested_fix":"Track filtering reasons and report them: const filtered = FILES.filter(...).map((f) => ({file: f, reason: null})); // Track reasons during filtering, then: if (filtered.length === 0 && FILES.length > 0) { console.log(`Warning: All ${FILES.length} specified files were excluded`); }","acceptance_tests":["Script explains why user-specified files were filtered out","Users understand difference between 'no files specified' and 'files excluded by rules'"],"file":"scripts/check-pattern-compliance.js","line":494,"description":"getFilesToCheck() with explicit FILES argument (line 494-508) applies filtering (path validation, existence checks, global excludes) that can reduce the list to empty. If user provides 'node scripts/check-pattern-compliance.js file1.js file2.js' but both are excluded, the script exits with 'No files to check' without explaining why their specified files were ignored. This is confusing user experience.","recommendation":"Track filtering reasons and report them: const filtered = FILES.filter(...).map((f) => ({file: f, reason: null})); // Track reasons during filtering, then: if (filtered.length === 0 && FILES.length > 0) { console.log(`Warning: All ${FILES.length} specified files were excluded`); }","id":"process::scripts/check-pattern-compliance.js::silent-file-filtering"}
{"category":"process","title":"Bug: aggregate-audit-findings.js - potential long-running operation with no progress indication","fingerprint":"process::scripts/aggregate-audit-findings.js::no-progress-feedback","severity":"S3","effort":"E2","confidence":"MEDIUM","files":["scripts/aggregate-audit-findings.js:1446"],"why_it_matters":"aggregate() performs complex multi-pass deduplication (lines 1344-1402), cross-referencing (lines 1518-1544), and markdown generation on potentially thousands of findings. In non-verbose mode, there's no progress indication. If processing takes minutes or hangs, users can't tell if the script is working or frozen, leading to premature cancellation or confusion.","suggested_fix":"Add progress indicators for long operations: console.log('Phase 3: Deduplicating findings...'); let passCount = 0; while (didMerge && passCount < MAX_PASSES) { passCount++; if (passCount % 2 === 0) process.stdout.write('.'); ... } console.log(` (${passCount} passes)`)","acceptance_tests":["Script provides progress feedback during long-running operations","Users can distinguish between hung script and slow processing"],"file":"scripts/aggregate-audit-findings.js","line":1446,"description":"aggregate() performs complex multi-pass deduplication (lines 1344-1402), cross-referencing (lines 1518-1544), and markdown generation on potentially thousands of findings. In non-verbose mode, there's no progress indication. If processing takes minutes or hangs, users can't tell if the script is working or frozen, leading to premature cancellation or confusion.","recommendation":"Add progress indicators for long operations: console.log('Phase 3: Deduplicating findings...'); let passCount = 0; while (didMerge && passCount < MAX_PASSES) { passCount++; if (passCount % 2 === 0) process.stdout.write('.'); ... } console.log(` (${passCount} passes)`)","id":"process::scripts/aggregate-audit-findings.js::no-progress-feedback"}
{"category":"process","title":"Skill issue: skill-registry.json does not exist","fingerprint":"process::.claude::missing-skill-registry","severity":"S3","effort":"E1","confidence":"HIGH","files":[".claude:1"],"why_it_matters":"Audit checklist mentions verifying skill-registry.json matches actual skills, but this file doesn't exist. This may be outdated documentation or an incomplete implementation of skill tracking.","suggested_fix":"Either create .claude/skill-registry.json with current skill metadata, or update audit documentation to remove references to this file if it's no longer used.","acceptance_tests":["skill-registry.json exists with valid JSON","OR audit documentation updated to remove references"],"file":".claude","line":1,"description":"Audit checklist mentions verifying skill-registry.json matches actual skills, but this file doesn't exist. This may be outdated documentation or an incomplete implementation of skill tracking.","recommendation":"Either create .claude/skill-registry.json with current skill metadata, or update audit documentation to remove references to this file if it's no longer used.","id":"process::.claude::missing-skill-registry"}
{"category":"process","title":"Skill issue: SKILL_INDEX.md has incorrect skill count","fingerprint":"process::.claude/skills/SKILL_INDEX.md::incorrect-count","severity":"S3","effort":"E0","confidence":"HIGH","files":[".claude/skills/SKILL_INDEX.md:3"],"why_it_matters":"SKILL_INDEX.md claims 50 total skills but directory contains 57 skills (ls -1 .claude/skills/ | wc -l). This misleads users about available capabilities.","suggested_fix":"Update SKILL_INDEX.md line 3 to show correct count: 'Total Skills: 57'. Also review category counts for accuracy.","acceptance_tests":["SKILL_INDEX.md shows correct total (57)","All categories list accurate skill counts"],"file":".claude/skills/SKILL_INDEX.md","line":3,"description":"SKILL_INDEX.md claims 50 total skills but directory contains 57 skills (ls -1 .claude/skills/ | wc -l). This misleads users about available capabilities.","recommendation":"Update SKILL_INDEX.md line 3 to show correct count: 'Total Skills: 57'. Also review category counts for accuracy.","id":"process::.claude/skills/SKILL_INDEX.md::incorrect-count"}
{"category":"process","title":"Skill issue: episodic memory MCP not configured but referenced by 11 skills","fingerprint":"process::.claude::episodic-memory-not-configured","severity":"S2","effort":"E2","confidence":"HIGH","files":["audit-process/SKILL.md:1","audit-security/SKILL.md:1","audit-code/SKILL.md:1","audit-comprehensive/SKILL.md:1","session-begin/SKILL.md:1","code-reviewer/SKILL.md:1","systematic-debugging/SKILL.md:1"],"why_it_matters":"11 skills reference mcp__plugin_episodic_memory for context retrieval from past sessions, but no MCP configuration file (mcp.json*) contains episodic memory setup. Skills will fail when trying to use this feature, leading to confusing errors for Claude.","suggested_fix":"Either: (1) Add episodic-memory MCP server to mcp.json configuration with proper credentials, OR (2) Remove episodic memory search sections from all 11 skills if this feature is not available. Option 2 is faster but loses valuable context-retrieval capability.","acceptance_tests":["episodic-memory configured in mcp.json and functional","OR episodic memory references removed from all skills"],"file":".claude/skills/audit-process/SKILL.md","line":1,"description":"11 skills reference mcp__plugin_episodic_memory for context retrieval from past sessions, but no MCP configuration file (mcp.json*) contains episodic memory setup. Skills will fail when trying to use this feature, leading to confusing errors for Claude.","recommendation":"Either: (1) Add episodic-memory MCP server to mcp.json configuration with proper credentials, OR (2) Remove episodic memory search sections from all 11 skills if this feature is not available. Option 2 is faster but loses valuable context-retrieval capability.","id":"process::.claude::episodic-memory-not-configured"}
{"category":"process","title":"Skill issue: audit skills reference non-existent FALSE_POSITIVES.jsonl","fingerprint":"process::docs/audits::missing-false-positives","severity":"S2","effort":"E1","confidence":"HIGH","files":["audit-process/SKILL.md:172","audit-security/SKILL.md:230","audit-code/SKILL.md:185"],"why_it_matters":"Multiple audit skills instruct Claude to read docs/audits/FALSE_POSITIVES.jsonl to exclude known false positives, but this file doesn't exist. This will cause file read errors during audits and prevent false positive filtering from working.","suggested_fix":"Create docs/audits/FALSE_POSITIVES.jsonl as an empty array [] or with initial structure: {\"category\":\"security\",\"pattern\":\"...\",\"reason\":\"...\",\"expires\":\"YYYY-MM-DD\"}. Update audit skill documentation to note the file should be created during first audit if it doesn't exist.","acceptance_tests":["docs/audits/FALSE_POSITIVES.jsonl exists with valid JSONL format","Audit skills can read the file without errors","File has documented schema in header comment"],"file":".claude/skills/audit-process/SKILL.md","line":172,"description":"Multiple audit skills instruct Claude to read docs/audits/FALSE_POSITIVES.jsonl to exclude known false positives, but this file doesn't exist. This will cause file read errors during audits and prevent false positive filtering from working.","recommendation":"Create docs/audits/FALSE_POSITIVES.jsonl as an empty array [] or with initial structure: {\"category\":\"security\",\"pattern\":\"...\",\"reason\":\"...\",\"expires\":\"YYYY-MM-DD\"}. Update audit skill documentation to note the file should be created during first audit if it doesn't exist.","id":"process::docs/audits::missing-false-positives"}
{"category":"process","title":"Skill issue: gh-fix-ci references non-existent inspect_pr_checks.py","fingerprint":"process::.claude/skills/gh-fix-ci::missing-script","severity":"S1","effort":"E2","confidence":"HIGH","files":[".claude/skills/gh-fix-ci/SKILL.md:36"],"why_it_matters":"gh-fix-ci skill's primary workflow relies on scripts/inspect_pr_checks.py to fetch PR check failures, but this script doesn't exist anywhere in the repository. The skill is completely non-functional without it, and will fail immediately when invoked.","suggested_fix":"Either: (1) Create .claude/skills/gh-fix-ci/scripts/inspect_pr_checks.py implementing the documented API (--repo, --pr, --json flags), OR (2) Update gh-fix-ci skill to use gh CLI commands directly without the wrapper script. Option 2 is simpler but loses abstraction benefits.","acceptance_tests":["inspect_pr_checks.py exists and is executable","Script successfully fetches PR checks for test PR","gh-fix-ci skill completes without script errors"],"file":".claude/skills/gh-fix-ci/SKILL.md","line":36,"description":"gh-fix-ci skill's primary workflow relies on scripts/inspect_pr_checks.py to fetch PR check failures, but this script doesn't exist anywhere in the repository. The skill is completely non-functional without it, and will fail immediately when invoked.","recommendation":"Either: (1) Create .claude/skills/gh-fix-ci/scripts/inspect_pr_checks.py implementing the documented API (--repo, --pr, --json flags), OR (2) Update gh-fix-ci skill to use gh CLI commands directly without the wrapper script. Option 2 is simpler but loses abstraction benefits.","id":"process::.claude/skills/gh-fix-ci::missing-script","evidence":[{"type":"code_reference","detail":".claude/skills/gh-fix-ci/SKILL.md:36"},{"type":"description","detail":"gh-fix-ci skill's primary workflow relies on scripts/inspect_pr_checks.py to fetch PR check failures, but this script doesn't exist anywhere in the repository. The skill is completely non-functional without it, and will fail immediately when invoked."}],"verification_steps":{"first_pass":{"method":"code_search","evidence_collected":[".claude/skills/gh-fix-ci/SKILL.md:36"]},"second_pass":{"method":"contextual_review","confirmed":true},"tool_confirmation":{"tool":"NONE","result":"confirmed via manual code review","reference":".claude/skills/gh-fix-ci/SKILL.md:36"}}}
{"category":"process","title":"Skill issue: systematic-debugging references non-existent superpowers skills","fingerprint":"process::.claude/skills/systematic-debugging::missing-superpowers-refs","severity":"S2","effort":"E1","confidence":"HIGH","files":["systematic-debugging/SKILL.md:229","systematic-debugging/SKILL.md:346"],"why_it_matters":"systematic-debugging references 'superpowers:test-driven-development' and 'superpowers:verification-before-completion' as related skills, but no skills with these names exist. This creates broken references and confuses users trying to follow the skill workflow.","suggested_fix":"Either: (1) Remove the 'superpowers:' prefix and references since these skills don't exist, OR (2) Create these skills if test-driven-development and verification-before-completion are intended features, OR (3) Update references to point to existing equivalent skills if they exist under different names.","acceptance_tests":["References removed or updated to existing skills","OR new skills created matching the referenced names","Skill can be followed end-to-end without missing dependency errors"],"file":".claude/skills/systematic-debugging/SKILL.md","line":229,"description":"systematic-debugging references 'superpowers:test-driven-development' and 'superpowers:verification-before-completion' as related skills, but no skills with these names exist. This creates broken references and confuses users trying to follow the skill workflow.","recommendation":"Either: (1) Remove the 'superpowers:' prefix and references since these skills don't exist, OR (2) Create these skills if test-driven-development and verification-before-completion are intended features, OR (3) Update references to point to existing equivalent skills if they exist under different names.","id":"process::.claude/skills/systematic-debugging::missing-superpowers-refs"}
{"category":"process","title":"Skill issue: code-reviewer scripts may be non-functional templates","fingerprint":"process::.claude/skills/code-reviewer/scripts::placeholder-code","severity":"S3","effort":"E1","confidence":"MEDIUM","files":["code-reviewer/scripts/pr_analyzer.py:1","code-reviewer/scripts/code_quality_checker.py:1","code-reviewer/scripts/review_report_generator.py:1"],"why_it_matters":"code-reviewer skill heavily emphasizes using three Python scripts (pr_analyzer.py, code_quality_checker.py, review_report_generator.py), but these scripts appear to be placeholder/template code based on skill description patterns. If they're not functional implementations, the skill guidance is misleading.","suggested_fix":"Test the three scripts with sample inputs to verify functionality. If they're templates: (1) Add clear 'TEMPLATE - NOT IMPLEMENTED' warnings to skill documentation, (2) Update skill to focus on manual review patterns instead of script automation, OR (3) Implement the scripts properly if automation is the intended workflow.","acceptance_tests":["Scripts successfully execute with valid inputs","OR skill documentation updated to clarify template status","Skill provides value even without automated scripts"],"file":".claude/skills/code-reviewer/scripts/pr_analyzer.py","line":1,"description":"code-reviewer skill heavily emphasizes using three Python scripts (pr_analyzer.py, code_quality_checker.py, review_report_generator.py), but these scripts appear to be placeholder/template code based on skill description patterns. If they're not functional implementations, the skill guidance is misleading.","recommendation":"Test the three scripts with sample inputs to verify functionality. If they're templates: (1) Add clear 'TEMPLATE - NOT IMPLEMENTED' warnings to skill documentation, (2) Update skill to focus on manual review patterns instead of script automation, OR (3) Implement the scripts properly if automation is the intended workflow.","id":"process::.claude/skills/code-reviewer/scripts::placeholder-code"}
{"category":"process","title":"Skill issue: audit-process has complex 7-stage orchestration that may be brittle","fingerprint":"process::.claude/skills/audit-process::complex-orchestration","severity":"S2","effort":"E0","confidence":"HIGH","files":["audit-process/SKILL.md:1"],"why_it_matters":"audit-process orchestrates 22 parallel agents across 7 stages with extensive verification checkpoints and context recovery logic. This complexity increases the risk of agent coordination failures, variable loss during context compaction, and difficult debugging when stages fail. The skill itself acknowledges this with extensive recovery procedures.","suggested_fix":"Consider simplifying to fewer stages (e.g., 3-4 instead of 7) or providing a 'lite' mode that runs sequentially with simpler orchestration for smaller codebases. Add automated testing for the orchestration logic itself.","acceptance_tests":["Skill completes successfully on test repository","Context compaction recovery procedures tested and work","Alternative simplified mode available for basic audits"],"file":".claude/skills/audit-process/SKILL.md","line":1,"description":"audit-process orchestrates 22 parallel agents across 7 stages with extensive verification checkpoints and context recovery logic. This complexity increases the risk of agent coordination failures, variable loss during context compaction, and difficult debugging when stages fail. The skill itself acknowledges this with extensive recovery procedures.","recommendation":"Consider simplifying to fewer stages (e.g., 3-4 instead of 7) or providing a 'lite' mode that runs sequentially with simpler orchestration for smaller codebases. Add automated testing for the orchestration logic itself.","id":"process::.claude/skills/audit-process::complex-orchestration"}
{"category":"process","title":"Skill issue: multiple audit skills have duplicate functionality in pre-audit steps","fingerprint":"process::.claude/skills::duplicate-pre-audit","severity":"S3","effort":"E2","confidence":"HIGH","files":["audit-process/SKILL.md:100","audit-security/SKILL.md:149","audit-code/SKILL.md:114","audit-comprehensive/SKILL.md:143"],"why_it_matters":"All audit skills (process, security, code, comprehensive) have nearly identical Step 0 (episodic memory search), baseline gathering, and false positives loading. This duplication means updates must be applied to 4+ files, increasing maintenance burden and risk of inconsistency.","suggested_fix":"Extract common pre-audit steps into a shared skill or reference document (.claude/skills/_audit-common/pre-audit-steps.md) that all audit skills import or reference. This creates a single source of truth for audit initialization.","acceptance_tests":["Common pre-audit documentation created","All audit skills reference the shared steps","Updates to pre-audit flow only require changing one file"],"file":".claude/skills/audit-process/SKILL.md","line":100,"description":"All audit skills (process, security, code, comprehensive) have nearly identical Step 0 (episodic memory search), baseline gathering, and false positives loading. This duplication means updates must be applied to 4+ files, increasing maintenance burden and risk of inconsistency.","recommendation":"Extract common pre-audit steps into a shared skill or reference document (.claude/skills/_audit-common/pre-audit-steps.md) that all audit skills import or reference. This creates a single source of truth for audit initialization.","id":"process::.claude/skills::duplicate-pre-audit"}
{"category":"process","title":"Skill issue: session-begin references deprecated TECHNICAL_DEBT_MASTER.md filename","fingerprint":"process::.claude/skills/session-begin::outdated-filename-reference","severity":"S3","effort":"E0","confidence":"HIGH","files":["session-begin/SKILL.md:301"],"why_it_matters":"session-begin skill refers to 'TECHNICAL_DEBT_MASTER.md' but the actual file is 'MASTER_DEBT.jsonl' (JSONL format, not Markdown). This will cause file-not-found errors when following the skill checklist.","suggested_fix":"Update session-begin/SKILL.md line 301 and any other references to use correct filename: 'docs/technical-debt/MASTER_DEBT.jsonl' instead of 'TECHNICAL_DEBT_MASTER.md'.","acceptance_tests":["All filename references corrected to MASTER_DEBT.jsonl","session-begin skill completes without file-not-found errors"],"file":".claude/skills/session-begin/SKILL.md","line":301,"description":"session-begin skill refers to 'TECHNICAL_DEBT_MASTER.md' but the actual file is 'MASTER_DEBT.jsonl' (JSONL format, not Markdown). This will cause file-not-found errors when following the skill checklist.","recommendation":"Update session-begin/SKILL.md line 301 and any other references to use correct filename: 'docs/technical-debt/MASTER_DEBT.jsonl' instead of 'TECHNICAL_DEBT_MASTER.md'.","id":"process::.claude/skills/session-begin::outdated-filename-reference"}
