{"id":"HOOK-001","category":"ClaudeHooks","severity":"S1","effort":"E2","file":".claude/hooks/session-start.js","line":437,"title":"Unvalidated JSON parsing from alerts file without size limits","description":"The session-start.js hook reads and parses pending-alerts.json at line 441 without validating file size before JSON.parse(). A maliciously large or deeply nested JSON file could cause memory exhaustion or parsing timeouts, degrading session startup performance. The hook does wrap in try/catch but doesn't pre-validate file bounds.","recommendation":"Add a file size check before parsing (e.g., max 1MB for alerts file). Implement a streaming JSON parser or validate schema with size limits using Zod for the alerts structure. Example: const stats = fs.statSync(alertsFile); if (stats.size > 1024*1024) throw new Error('alerts file too large');"}
{"id":"HOOK-002","category":"ClaudeHooks","severity":"S1","effort":"E2","file":".claude/hooks/auto-save-context.js","line":96,"title":"Line counting inefficiency creates quadratic string operations","description":"In large-context-warning.js (mirrored logic in auto-save-context.js), the line counting uses split('\\n').length which creates a full array in memory. For files with millions of lines, this wastes memory. The pattern-check.js hook uses a more efficient loop-based approach (lines 158-161) that avoids array allocation.","recommendation":"Replace 'content.split(\"\\n\").length' with loop-based counting as used in pattern-check.js lines 158-161: let lineCount = 1; for (let i = 0; i < content.length; i++) { if (content.charCodeAt(i) === 10) lineCount++; }"}
{"id":"HOOK-003","category":"ClaudeHooks","severity":"S2","effort":"E1","file":".claude/hooks/agent-trigger-enforcer.js","line":188,"title":"Session key generation uses only date, loses granularity for same-day reruns","description":"At line 188, the session key is generated as 'new Date().toISOString().split(\"T\")[0]' (YYYY-MM-DD). If the agent enforcer runs multiple times in the same day (e.g., different sessions), it reuses the same suggestedAgents key, preventing fresh suggestions from appearing on session restarts within the same calendar day.","recommendation":"Include time component for better session granularity: const sessionKey = new Date().toISOString().slice(0, 13); // YYYY-MM-DDTHH for hourly grouping. Alternatively, generate unique session IDs via the session-state.json currentSessionId already created in session-start.js line 116."}
{"id":"HOOK-004","category":"ClaudeHooks","severity":"S1","effort":"E2","file":".claude/hooks/auto-save-context.js","line":213,"title":"Race condition in context metrics tracking across concurrent hooks","description":"The auto-save-context.js and large-context-warning.js both read/write .context-tracking-state.json file. If multiple hooks fire concurrently (e.g., multiple file reads in rapid succession), the last-write-wins pattern causes lost metrics and inaccurate file read counts. No locking mechanism prevents concurrent modification.","recommendation":"Implement atomic operations using fs.mkdtempSync for lock files or use a single trusted hook to coordinate metrics. Alternatively, use process locking: fs.writeFileSync with atomic rename pattern. See: https://nodejs.org/api/fs.html#fs_fs_renamesync_oldpath_newpath"}
{"id":"HOOK-005","category":"GitHooks","severity":"S1","effort":"E3","file":".husky/pre-commit","line":54,"title":"Glob pattern for config files misses critical build-breaking files","description":"Line 54 uses grep -Eq with pattern '^(package\\.json|package-lock\\.json|...)' but this only matches files at repo root. Nested config changes like 'functions/package.json', 'apps/web/tsconfig.json', or monorepo configs are not caught, allowing config changes that break builds to bypass the test gate.","recommendation":"Update pattern to catch nested configs: grep -Eq '(^|\\/)(package(-lock)?\\.json|tsconfig.*\\.json|next\\.config|vitest|jest\\.config)' to use word boundaries instead of start-of-line anchors. Or: check both root and common subdirectories like functions/, apps/*, etc."}
{"id":"HOOK-006","category":"ClaudeHooks","severity":"S2","effort":"E1","file":".claude/hooks/firestore-write-block.js","line":150,"title":"Global regex lastIndex not reset causes false negatives on repeated hook invocations","description":"At line 150-154, the code resets pattern.lastIndex = 0 in a loop, but the pattern variable is reused across iterations. If execution is interrupted or the hook is called twice with cached patterns, lastIndex pollution could skip violations. The fix is already there (line 152) but could be documented better and isn't used consistently across all pattern checks in other hooks.","recommendation":"Document the lastIndex reset requirement in code comments. Create a utility function for safe global regex matching: function findAllMatches(pattern, content) { const matches = []; let m; while ((m = pattern.exec(content))) matches.push(m); pattern.lastIndex = 0; return matches; } Reuse across hooks."}
{"id":"HOOK-007","category":"LintStaged","severity":"S2","effort":"E1","file":"package.json","line":65,"title":"Lint-staged config only runs Prettier, missing critical formatting/linting stages","description":"The lint-staged config at line 65-66 only runs 'prettier --write' for all file types. ESLint, security checks, and TypeScript compilation are NOT run via lint-staged, only in the pre-commit hook. This creates divergence: files can be staged after pre-commit but before git commit (e.g., via --no-verify), bypassing staged checks. The separation also means no auto-fixing of ESLint issues during staging.","recommendation":"Expand lint-staged config to include ESLint with auto-fix and type checking: {'*.{js,jsx,ts,tsx}': ['eslint --fix', 'prettier --write'], '*.json': 'prettier --write', '*.md': 'prettier --write'}. This ensures consistency between pre-commit and pre-push stages. Document the current flow in docs/HOOKIFY_STRATEGY.md."}
{"id":"HOOK-008","category":"ClaudeHooks","severity":"S2","effort":"E2","file":".claude/hooks/large-context-warning.js","line":138,"title":"Pagination detection logic uses unreliable limit parameter heuristic","description":"At line 137, the hook skips the large-file warning if 'limit' parameter is truthy, assuming the user requested pagination. However, the limit parameter comes from hook arguments which may not reflect actual tool usage (e.g., Read tool with limit=1 followed by Read tool without limit both trigger the hook). This creates false negatives where large files with pagination flags bypass warnings.","recommendation":"Instead of checking limit parameter, track actual pagination usage via tool call history in .context-tracking-state.json. Add a 'paginatedReads' array to track which files were read with offset/limit, and only skip warnings for those. Example: if (!state.paginatedReads?.includes(filePath)) { warn }"}
{"id":"HOOK-009","category":"GitHooks","severity":"S1","effort":"E3","file":".husky/pre-push","line":55,"title":"Security check loop silently drops errors due to subshell redirection","description":"Lines 40-65 in pre-push use a here-document (EOF) loop to iterate changed files and run security checks. If the security-check.js script fails but stdout/stderr are not properly captured, the error message is lost due to the subshell context. Additionally, the loop uses IFS=read without the -t option, potentially causing hangs on malformed filenames.","recommendation":"Replace here-document with safer approach: git diff --name-only ... | while IFS= read -r file; done. Or use array: mapfile -t files < <(git diff ...) && for file in \"${files[@]}\"; do ...; done. This prevents subshell issues and properly inherits errexit behavior. Capture output explicitly: out=$(... 2>&1) to ensure stderr is included."}
{"id":"HOOK-010","category":"ClaudeHooks","severity":"S2","effort":"E2","file":".claude/hooks/pattern-check.js","line":138,"title":"Small file optimization threshold (8KB/100 lines) may skip legitimate pattern violations in tiny but critical files","description":"Lines 143-165 skip pattern checking for files under 8KB or 100 lines. This is a performance optimization, but it misses violations in small critical files like configuration helpers, utility functions, or server-side security code that might contain high-impact anti-patterns despite small size. A 50-line file with a direct Firestore write is still a critical violation.","recommendation":"Implement smart skipping based on file type, not just size. Create a whitelist of file patterns that are safe to skip: if (/\\.test\\.|test-utils|__mocks__/i.test(relPath)) { skip; } else { check; }. For non-test files, check regardless of size. This preserves performance while catching violations in small critical files."}
