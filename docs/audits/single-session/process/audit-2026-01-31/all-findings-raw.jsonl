{"severity":"S0","category":"Critical Gap","finding":"Backlog enforcement workflow checks non-existent file","description":"backlog-enforcement.yml checks AUDIT_FINDINGS_BACKLOG.md which was archived 2026-01-31 in TDMS Phase 2. The workflow gracefully exits with code 0 when file is missing, meaning backlog enforcement is COMPLETELY BYPASSED in CI.","impact":"Zero backlog health enforcement. S0/S1 debt items can accumulate indefinitely without CI blocking PRs.","file":".github/workflows/backlog-enforcement.yml","line":"35-43","evidence":"Lines 35-43: if [ ! -f \"docs/AUDIT_FINDINGS_BACKLOG.md\" ]; then echo \"total=0\" >> $GITHUB_OUTPUT; exit 0; fi","remediation":"Update workflow to check docs/technical-debt/MASTER_DEBT.jsonl instead. Use scripts/debt/validate-schema.js for enforcement.","verification_steps":["Create PR with S0 item in MASTER_DEBT.jsonl","Verify backlog-enforcement workflow blocks the PR","Verify threshold enforcement (25 item limit) works"],"canon_id":"CI-001"}
{"severity":"S1","category":"Continue-on-error Abuse","finding":"CI allows pattern compliance failures on main branch","description":"ci.yml line 75 uses continue-on-error: true for pattern compliance check on push to main. This means pattern violations can be merged to main without blocking.","impact":"Pattern violations accumulate in main branch. Anti-patterns documented in CODE_PATTERNS.md (230+ patterns) are not enforced post-merge.","file":".github/workflows/ci.yml","line":"71-76","evidence":"Lines 71-76: Pattern compliance check (push to main) ... continue-on-error: true ... run: npm run patterns:check-all","remediation":"Remove continue-on-error OR document explicit exceptions in CLAUDE.md. Pattern violations should block main branch.","verification_steps":["Introduce pattern violation in file","Push to main branch directly","Verify CI fails (not just warns)"],"canon_id":"CI-002"}
{"severity":"S1","category":"Continue-on-error Abuse","finding":"Documentation check is non-blocking in CI","description":"ci.yml line 78-81 runs npm run docs:check with continue-on-error: true. Comment says 'templates/stubs have expected issues', but this allows ANY doc issue to slip through.","impact":"Broken cross-references, missing required sections, stale dates can merge without detection.","file":".github/workflows/ci.yml","line":"78-81","evidence":"Lines 78-81: Documentation check ... continue-on-error: true ... run: npm run docs:check","remediation":"Split docs:check into --strict (block on active docs) and --lenient (warn on templates). Only use continue-on-error for templates.","verification_steps":["Break cross-reference in active doc (e.g., ROADMAP.md)","Create PR","Verify CI fails (not just warns)"],"canon_id":"CI-003"}
{"severity":"S1","category":"Continue-on-error Abuse","finding":"Audit validation non-blocking in CI","description":"ci.yml line 90 runs audit:validate with continue-on-error: true. Pre-commit hook (line 193-224) BLOCKS on S0/S1 violations, but CI does not.","impact":"Developers can bypass pre-commit with SKIP_AUDIT_VALIDATION=1 and merge broken audit files.","file":".github/workflows/ci.yml","line":"87-91","evidence":"Lines 87-91: Validate audit files ... continue-on-error: true ... run: npm run audit:validate -- --all","remediation":"Remove continue-on-error for audit validation. If template files need exemption, use --exclude-templates flag.","verification_steps":["Create audit JSONL with S0 item missing verification_steps","Set SKIP_AUDIT_VALIDATION=1 in pre-commit","Push to PR","Verify CI blocks (not pre-commit bypass)"],"canon_id":"CI-004"}
{"severity":"S1","category":"Validation Gap","finding":"Pre-commit runs pattern check on changed files only, CI runs on all files","description":"Pre-commit hook (line 33-42) runs npm run patterns:check (default file list). CI runs patterns:check on PR changed files (line 59-65) BUT patterns:check-all on main push. This creates inconsistency - developers test subset locally, CI checks everything post-merge.","impact":"Developers get false confidence from local pre-commit pass. Pattern violations in unchanged files only caught post-merge.","file":".husky/pre-commit","line":"33-42","evidence":"Pre-commit line 33-42 runs 'npm run patterns:check' (14 critical files per .husky/pre-commit). CI line 59-65 checks changed files only on PR.","remediation":"Align pre-commit and CI: both check changed files on PR, full check only on scheduled weekly run.","verification_steps":["Introduce pattern violation in non-critical file","Run pre-commit (should pass)","Create PR (CI should catch violation)"],"canon_id":"CI-005"}
{"severity":"S1","category":"Race Condition","finding":"No concurrency control on most workflows","description":"Only sync-readme.yml has concurrency control (line 6-8). Other workflows (ci.yml, backlog-enforcement.yml, docs-lint.yml, review-check.yml) can run concurrently on rapid pushes, creating race conditions in PR comments/labels.","impact":"Duplicate PR comments, label thrashing, wasted CI minutes. review-check.yml and docs-lint.yml both upsert comments - concurrent runs can create duplicates.","file":".github/workflows/*.yml","line":"N/A","evidence":"sync-readme.yml has 'concurrency: group: sync-readme-main' but ci.yml, backlog-enforcement.yml, docs-lint.yml lack concurrency groups.","remediation":"Add concurrency groups to all PR workflows: concurrency: { group: 'ci-${{ github.head_ref }}', cancel-in-progress: true }","verification_steps":["Push 2 commits rapidly to PR","Check Actions tab for concurrent runs","Verify only latest run executes after fix"],"canon_id":"CI-006"}
{"severity":"S2","category":"Testing Gap","finding":"Tests fail but CI passed on recent commit","description":"npm test shows 1 failing test (phase-complete-check.test.js) but recent commit e5bde5b merged successfully. Either tests are flaky or continue-on-error is hiding failures.","impact":"Broken functionality can merge if tests are flaky or CI doesn't enforce test failures.","file":".github/workflows/ci.yml","line":"115-125","evidence":"Local test run shows: 'ℹ pass 280 ℹ fail 1' but commit e5bde5b 'fix: address Qodo review suggestions (batch 5) + audit logging' merged to main.","remediation":"Investigate test flakiness. Add test retry logic (max 2 retries) OR mark flaky tests as skipped with JIRA ticket.","verification_steps":["Run npm test 3 times locally","Document which tests fail inconsistently","Add retry logic to CI workflow"],"canon_id":"CI-007"}
{"severity":"S2","category":"Continue-on-error Abuse","finding":"Technical debt validation non-blocking in CI","description":"ci.yml lines 98-111 check ROADMAP debt references and view staleness with continue-on-error: true. Pre-commit (line 242-259) BLOCKS on schema issues but not view staleness.","impact":"MASTER_DEBT.jsonl and generated views can drift. Developers can merge with stale views, breaking TDMS Phase 8 guarantees.","file":".github/workflows/ci.yml","line":"98-111","evidence":"Lines 98-111: Check ROADMAP debt references ... continue-on-error: true ... Verify technical debt views current ... continue-on-error: true","remediation":"Make view staleness check blocking. Add npm script: 'debt:check-views' that fails if git diff detects changes after regeneration.","verification_steps":["Modify MASTER_DEBT.jsonl without regenerating views","Create PR","Verify CI fails (not just warns)"],"canon_id":"CI-008"}
{"severity":"S2","category":"Validation Gap","finding":"Pre-commit skips tests for doc-only commits, CI always runs tests","description":"Pre-commit (line 67-89) skips tests if all staged files match doc patterns (*.md, *.jsonl, docs/, .claude/). CI (line 115-125) always runs full test suite. This creates inconsistency.","impact":"Developers expect fast doc-only commits locally but CI takes 20+ seconds running tests. Also creates potential bypass - commit JSON config as .jsonl to skip tests.","file":".husky/pre-commit","line":"67-89","evidence":"Lines 71-74: if [ -z \"$NON_DOC_FILES\" ]; then DOC_ONLY_COMMIT=1; echo \"⏭️ Skipping tests (doc-only commit)\"; fi","remediation":"Align pre-commit and CI: if PR only changes docs/*, skip tests in CI too. Use paths filter in ci.yml.","verification_steps":["Create doc-only PR (only *.md changes)","Verify CI skips test job","Modify .jsonl file, verify tests still run"],"canon_id":"CI-009"}
{"severity":"S2","category":"Validation Gap","finding":"docs-lint.yml only checks markdown files, misses broken refs in code comments","description":"docs-lint.yml (line 37-42) only checks **.md files. Code comments in TS/JS files often link to docs (e.g., 'See ARCHITECTURE.md#schema') but these aren't validated.","impact":"Code comments can have broken doc links. Developers follow stale references, wasting time.","file":".github/workflows/docs-lint.yml","line":"37-42","evidence":"Lines 37-42: files: | **/*.md | docs/**/*.md (no .ts, .tsx, .js files)","remediation":"Extend docs-lint to check code comments. Use AST parser to extract JSDoc/TSDoc links and validate them.","verification_steps":["Add broken doc link in JSDoc comment (e.g., @see MISSING.md)","Create PR","Verify CI warns about broken link"],"canon_id":"CI-010"}
{"severity":"S2","category":"Validation Gap","finding":"Pre-push checks security patterns but pre-commit does not","description":"Pre-push hook (line 37-79) runs security-check.js on changed files. Pre-commit hook does NOT run security checks. This means developers can commit insecure code locally, only blocked at push.","impact":"Insecure code sits in local commits. If developer force-pushes or bypasses pre-push, security issues merge.","file":".husky/pre-commit","line":"N/A","evidence":"Pre-commit runs: ESLint (line 7-16), patterns:check (line 33-42), but NO security:check. Pre-push runs security:check (line 37-79).","remediation":"Move security:check to pre-commit (fast - only checks changed files). Keep blocking in pre-push as backup.","verification_steps":["Add execSync with template literal (SEC-001 violation)","Run git commit (should block)","Verify pre-commit catches security issue"],"canon_id":"CI-011"}
{"severity":"S2","category":"Missing Validation","finding":"No CI check for DOCUMENTATION_INDEX.md staleness","description":"Pre-commit (line 133-153) blocks if .md files change but DOCUMENTATION_INDEX.md not updated. CI has no equivalent check.","impact":"Developers can bypass pre-commit with SKIP_DOC_INDEX_CHECK=1 and merge with stale index.","file":".github/workflows/ci.yml","line":"N/A","evidence":"Pre-commit line 133-153 blocks on stale index. No equivalent in ci.yml.","remediation":"Add step to ci.yml: 'Check doc index staleness' - regenerate index, check git diff, fail if different.","verification_steps":["Add new .md file, skip doc index update","Set SKIP_DOC_INDEX_CHECK=1 in pre-commit","Create PR","Verify CI blocks (not pre-commit bypass)"],"canon_id":"CI-012"}
{"severity":"S2","category":"Unclear Enforcement","finding":"review-check.yml is continue-on-error but doesn't actually enforce anything","description":"review-check.yml (line 31-34) runs check-review-needed.js with continue-on-error: true. The workflow only comments/labels, never blocks. This is informational only, not enforcement.","impact":"Misleading workflow name 'Review Trigger Check' implies enforcement. Developers ignore warnings, merge without human review on Tier 3/4 changes.","file":".github/workflows/review-check.yml","line":"31-34","evidence":"Lines 31-34: Run review trigger check ... continue-on-error: true (never fails workflow, only comments)","remediation":"Rename to 'review-recommendation.yml' OR make blocking for Tier 4 changes (firebase.json, workflows, package.json).","verification_steps":["Modify firebase.json (Tier 4 change)","Create PR","Verify workflow either blocks OR clearly labeled as recommendation"],"canon_id":"CI-013"}
{"severity":"S2","category":"Job Dependency Gap","finding":"Build job depends on lint-typecheck-test but not on other validation jobs","description":"ci.yml line 137 shows 'build' job needs: lint-typecheck-test. But backlog-health and security-patterns jobs (in backlog-enforcement.yml) are independent. Build can succeed while backlog/security jobs fail.","impact":"PR shows green checkmark from 'build' success even if backlog/security jobs failed. Misleading status.","file":".github/workflows/ci.yml","line":"134-137","evidence":"Lines 134-137: build: ... needs: lint-typecheck-test (no dependency on backlog-enforcement.yml jobs)","remediation":"Use required status checks in branch protection rules. Require ALL jobs (ci.yml, backlog-enforcement.yml, docs-lint.yml) to pass.","verification_steps":["Check branch protection rules on main","Verify backlog-health is required status check","Create PR that fails backlog check, verify merge blocked"],"canon_id":"CI-014"}
{"severity":"S3","category":"Optimization","finding":"CI runs npm ci twice (lint job + build job)","description":"ci.yml line 25 runs npm ci, then build job (line 150) runs npm ci again. Dependencies are cached but still takes 10-15s per job.","impact":"Wasted CI time. ~20-30s per PR that could be saved by sharing node_modules artifact.","file":".github/workflows/ci.yml","line":"25, 150","evidence":"Lines 25 and 150 both run 'npm ci' independently.","remediation":"Upload node_modules as artifact in lint job, download in build job. OR use Docker layer caching.","verification_steps":["Check CI run time before/after optimization","Verify build job still has correct dependencies"],"canon_id":"CI-015"}
{"severity":"S3","category":"Maintenance","finding":"validate-plan.yml only triggers on specific file path, likely stale","description":"validate-plan.yml (line 6-7) only triggers on changes to docs/archive/completed-plans/INTEGRATED_IMPROVEMENT_PLAN.md. This file is archived - workflow is likely dead code.","impact":"Dead workflow wastes maintenance effort. Confuses contributors about which validations run.","file":".github/workflows/validate-plan.yml","line":"6-7","evidence":"Lines 6-7: paths: - 'docs/archive/completed-plans/INTEGRATED_IMPROVEMENT_PLAN.md' (archived file, never changes)","remediation":"Delete validate-plan.yml OR update to check active planning docs (SESSION_CONTEXT.md, ROADMAP.md).","verification_steps":["Check git history - when was validate-plan.yml last triggered","Archive or update workflow"],"canon_id":"CI-016"}
{"severity":"S2","category":"documentation","file":".claude/skills/code-reviewer/SKILL.md","line":22,"title":"Code-reviewer skill references non-functional Python scripts","description":"The code-reviewer skill (lines 22-30) references three Python scripts (pr_analyzer.py, code_quality_checker.py, review_report_generator.py) that appear to be placeholder templates rather than functional code review tools. The scripts exist but contain generic boilerplate code without actual review logic.","recommendation":"Either: (1) Implement the Python scripts with actual code review functionality, or (2) Remove references to these scripts and update the skill to use existing Node.js-based review tools like patterns:check, lint, etc.","evidence":["Script at .claude/skills/code-reviewer/scripts/pr_analyzer.py is a template with placeholder methods","SKILL.md lines 22-84 describe features that don't match actual script implementation","No Python dependencies in package.json for code review tools"]}
{"severity":"S3","category":"documentation","file":".claude/skills/code-reviewer/references/code_review_checklist.md","line":1,"title":"Code-reviewer reference files contain only placeholder content","description":"The reference files (code_review_checklist.md, coding_standards.md, common_antipatterns.md) referenced in the code-reviewer skill contain generic placeholder content without actual code review patterns or standards specific to this project.","recommendation":"Either: (1) Populate these files with actual project-specific code review patterns from CODE_PATTERNS.md and CLAUDE.md, or (2) Update code-reviewer skill to reference existing docs/agent_docs/CODE_PATTERNS.md instead.","evidence":["code_review_checklist.md lines 1-117 are generic placeholders","No references to Next.js, Firebase, or project-specific patterns","Existing CODE_PATTERNS.md has 230+ actual patterns"]}
{"severity":"S2","category":"functionality","file":".claude/skills/session-begin/SKILL.md","line":201,"title":"Session-begin auto-run scripts may fail silently","description":"Lines 201-223 specify that three scripts (patterns:check, review:check, lessons:surface) must run automatically during session-begin. However, there's no error handling guidance if scripts fail, and the skill says to 'note it as N/A in audit' without specifying where this audit is or how to track failures.","recommendation":"Add specific error handling steps: (1) If script fails, display error to user immediately (hook output is collapsed), (2) Save failure status to .claude/session-state.json, (3) Specify which audit file should track script execution (likely session-end audit).","evidence":["Lines 216-220 say 'If any script fails... note as N/A in audit' but no audit file specified","No reference to error display mechanism","Hook output is collapsed per CLAUDE.md line 10"]}
{"severity":"S3","category":"documentation","file":".claude/skills/session-begin/SKILL.md","line":229,"title":"Session-begin references potentially inconsistent TECHNICAL_DEBT_MASTER.md","description":"Line 229 references TECHNICAL_DEBT_MASTER.md as the single source of truth for tech debt, but the actual canonical source is docs/technical-debt/MASTER_DEBT.jsonl (JSONL format). The markdown file may be a view generated from the JSONL.","recommendation":"Verify the relationship between TECHNICAL_DEBT_MASTER.md and MASTER_DEBT.jsonl. Update skill documentation to clarify which is canonical and which is a generated view. Reference the TDMS documentation at docs/technical-debt/PROCEDURE.md.","evidence":["Line 229 references TECHNICAL_DEBT_MASTER.md","Multiple debt skills reference MASTER_DEBT.jsonl as canonical","TDMS uses JSONL as source of truth per add-manual-debt and verify-technical-debt skills"]}
{"severity":"S2","category":"consistency","file":".claude/skills/alerts/SKILL.md","line":81,"title":"Alerts skill references MCP memory functions that may not be available","description":"Lines 81-82 reference mcp__memory__read_graph() as a session context check, but MCP tools availability varies by environment. The skill doesn't handle the case where MCP memory server is unavailable.","recommendation":"Add conditional logic: (1) Check if MCP memory server is available before calling, (2) Gracefully handle unavailability (skip check rather than fail), (3) Document in skill that this check is optional if MCP unavailable.","evidence":["Line 81 lists MCP memory status check as required","No error handling for unavailable MCP servers","save-context skill also assumes MCP availability"]}
{"severity":"S3","category":"documentation","file":".claude/skills/audit-code/SKILL.md","line":299,"title":"Audit-code references validate:canon script without explaining CANON concept","description":"Line 299 references 'npm run validate:canon' and mentions 'CANON files' without explanation. New users or sessions won't know what CANON schema is or which files it applies to.","recommendation":"Add brief inline explanation or link to CANON documentation. For example: 'CANON files (standardized audit/debt schemas in docs/technical-debt/) must pass validation...'","evidence":["Line 299 assumes reader knows what CANON is","No link to schema documentation","Script exists in package.json but concept is undefined in skill"]}
{"severity":"S2","category":"process","file":".claude/skills/systematic-debugging/SKILL.md","line":307,"title":"Systematic-debugging references superpowers skills that don't exist in SKILL_INDEX","description":"Lines 307-310 reference 'superpowers:test-driven-development' and 'superpowers:verification-before-completion' skills, but these don't appear in SKILL_INDEX.md. May be outdated references or missing skills.","recommendation":"Either: (1) Create the referenced superpowers skills if they're needed, (2) Remove references and inline the guidance, or (3) Update to reference existing skills like webapp-testing or session-begin verification steps.","evidence":["SKILL_INDEX.md lists 49 skills, none named superpowers:*","Lines 307, 310 reference skills that don't exist","using-superpowers exists but is different (Claude superpowers guide)"]}
{"severity":"S3","category":"documentation","file":".claude/skills/pr-review/SKILL.md","line":79,"title":"PR-review tiered access pattern references archive location without validation","description":"Line 79 references docs/archive/REVIEWS_1-40.md for historical reviews. While this file exists, the tiered access model may be outdated if reviews have been further archived or consolidated.","recommendation":"Verify current archive state and update tiered access documentation. Check if archival criteria in lines 414-422 are current and if review archive locations are accurate.","evidence":["File exists but may not be current","Archival criteria specify 1500 lines + 10 reviews but don't specify current threshold","Line 79 assumes single archive file for reviews 1-40"]}
{"severity":"S2","category":"functionality","file":".claude/skills/verify-technical-debt/SKILL.md","line":126,"title":"Verify-technical-debt references resolve-item.js script without validating existence","description":"Lines 126-139 provide examples using 'node scripts/debt/resolve-item.js' but don't validate the script exists before instructing usage. If script is missing or renamed, skill will fail.","recommendation":"Add validation step at beginning of skill: Check if required scripts exist (resolve-item.js, generate-views.js) and provide clear error if missing. Alternatively, make script paths configurable.","evidence":["Lines 126-139 assume script exists","Script was confirmed to exist during audit","No error handling if script missing or moved"]}
{"severity":"S2","category":"documentation","file":".claude/skills/SKILL_INDEX.md","line":3,"title":"SKILL_INDEX shows last updated 2026-01-31 but may be stale","description":"Header claims 'Last Updated: 2026-01-31' (today) and 'Total Skills: 49', but verification is needed to ensure all listed skills actually exist and new skills haven't been added.","recommendation":"Add automated validation: Create a script that counts actual skills in .claude/skills/ directory and compares against SKILL_INDEX.md count. Run during session-begin to detect drift.","evidence":["Manual count shows 49 directories in .claude/skills (matches index)","Index maintenance section (lines 130-136) is manual process","No automated validation of skill count or descriptions"]}
{"severity":"S3","category":"documentation","file":".claude/skills/add-manual-debt/SKILL.md","line":95,"title":"Debt intake scripts lack validation for duplicate DEBT-XXXX IDs","description":"Lines 92-97 describe intake-manual.js script behavior including 'Assigns next available DEBT-XXXX ID' but don't specify how conflicts are handled if MASTER_DEBT.jsonl is edited externally or corrupted.","recommendation":"Document or implement: (1) ID conflict detection and resolution, (2) Validation that assigned ID doesn't already exist, (3) Recovery procedure if JSONL corruption causes duplicate IDs.","evidence":["Line 95 says 'Assigns next available DEBT-XXXX ID'","No mention of conflict resolution","JSONL format is manually editable, vulnerable to corruption"]}
{"severity":"S3","category":"consistency","file":".claude/skills/session-end/SKILL.md","line":35,"title":"Session-end skill is very minimal compared to session-begin","description":"Session-end skill is only 43 lines with minimal checklist (5 items), while session-begin is 279 lines with extensive checks. This asymmetry may lead to incomplete session cleanup and documentation drift.","recommendation":"Review session-end checklist for completeness. Consider adding: (1) Verify all TodoWrite items completed or documented, (2) Check for uncommitted changes, (3) Update SESSION_CONTEXT.md with session summary, (4) Run alerts to catch issues before leaving.","evidence":["session-end SKILL.md is 43 lines vs session-begin 279 lines","No TodoWrite check in session-end","No verification that session-begin checklist items were completed"]}
{"severity":"S2","category":"documentation","file":"CLAUDE.md","line":19,"title":"CLAUDE.md Session Start Protocol references pending-alerts.json without format spec","description":"CLAUDE.md lines 19-20 instruct to read .claude/pending-alerts.json and tell user about alerts, but don't specify the JSON schema or how to interpret alert severity/types.","recommendation":"Add inline example or link to alerts skill documentation. Specify JSON schema expected: {deferred_pr: [], backlog: [{severity, title}], ...}","evidence":["Lines 19-20 say 'read pending-alerts.json' without format info","File exists but schema undefined in CLAUDE.md","alerts skill has schema but not referenced from CLAUDE.md"]}
{"severity":"S3","category":"process","file":".claude/skills/audit-code/SKILL.md","line":40,"title":"Audit-code suggests querying SonarCloud MCP but doesn't validate availability","description":"Lines 40-46 describe querying SonarCloud via MCP (mcp__sonarcloud__get_issues) as optional 'if available', but don't provide fallback guidance if MCP unavailable. May cause confusion during audit execution.","recommendation":"Clarify: (1) Is SonarCloud MCP required or truly optional? (2) If optional, provide alternative data source or note to skip this step. (3) Document what 'available' means (environment variable? tool check?).","evidence":["Line 40 says 'if MCP available'","No check procedure for MCP availability","No fallback if unavailable"]}
{"id":"EH-001","severity":"S1","category":"Error Handling","file":"scripts/debt/intake-audit.js","line":334,"title":"Silent failure in execFileSync - generate-views failure not propagated","description":"The generate-views.js execution is wrapped in try-catch that swallows errors with only a warning. If generate-views.js fails, this critical step silently continues, leaving views stale and allowing corrupted state to persist.","recommendation":"Either make view regeneration blocking with exit(1) on error, or validate that views were successfully generated before returning.","evidence":["execFileSync call at line 333 without proper error handling","console.warn used at line 335-337 instead of propagating error","Function returns normally at line 341 even if views generation failed"],"confidence":"HIGH","cross_ref":"CLAUDE.md Security Rules"}
{"id":"EH-002","severity":"S1","category":"Error Handling","file":"scripts/debt/intake-manual.js","line":335,"title":"Silent failure in execSync for view regeneration","description":"View regeneration wraps execSync in try-catch with only a warning. Script continues successfully even if critical views become stale. This masks failures and allows downstream corruption.","recommendation":"Add exit(1) in catch block when regenerate-views fails, or implement validation that views match expected state before returning.","evidence":["execSync call at line 335 without error propagation","Catch block at line 336 contains only console.warn","Script exits 0 at line 342 regardless of whether catch executed"],"confidence":"HIGH","cross_ref":"Pattern repeated in sync-sonarcloud.js and intake-audit.js"}
{"id":"EH-003","severity":"S1","category":"Error Handling","file":"scripts/debt/sync-sonarcloud.js","line":469,"title":"Silent catch block in view regeneration - critical step masked","description":"execFileSync wrapped in try-catch with only console.warn. If views fail to regenerate after syncing SonarCloud issues, script exits with 0 (success) anyway. This allows corrupted state where MASTER_DEBT.jsonl is updated but views are stale.","recommendation":"Fail with exit(1) on view regeneration error, or validate views match current state before allowing successful completion.","evidence":["execFileSync at line 466 for view generation","catch block at line 469 contains only warn message, no error propagation","Script summary at line 476 printed regardless of error status"],"confidence":"HIGH","cross_ref":"Critical file operation pattern"}
{"id":"EH-004","severity":"S1","category":"Error Handling","file":".husky/pre-commit","line":333,"title":"Missing error propagation in pre-commit hook - view regeneration silently fails","description":"execFileSync call wrapped in try-catch at line 333-337 warns and continues instead of failing pre-commit. This is a critical gate that should block commits when infrastructure failures occur.","recommendation":"Exit with code 1 in catch block to block commit when views regeneration fails. Pre-commit hooks are automated gates that cannot silently fail.","evidence":["execFileSync call at line 333 in try-catch","console.warn at line 335-337 instead of exit(1)","Pre-commit allows commits to proceed at line 273 despite possible catch block execution"],"confidence":"HIGH","cross_ref":"Husky hook best practices"}
{"id":"EH-005","severity":"S1","category":"Error Handling","file":"scripts/check-pattern-compliance.js","line":576,"title":"Overly broad exception handling in git diff call","description":"execSync for git diff wrapped in try-catch that logs warning and returns empty array for any error. This conflates 'not a git repo' (acceptable) with actual git errors (should surface). Caller cannot distinguish cases.","recommendation":"Separate error types: (1) If 'not a git repo' message, return empty silently, (2) If other git error, re-throw or return error state so caller can decide.","evidence":["execSync at line 567 with git diff command","catch block at line 576 logs warning and returns []","No error differentiation between different failure modes"],"confidence":"MEDIUM","cross_ref":"CODE_PATTERNS.md#error-sanitization"}
{"id":"EH-006","severity":"S1","category":"Exit Code","file":"scripts/debt/intake-audit.js","line":295,"title":"Incorrect exit code semantics - cannot distinguish empty input from valid no-op","description":"When input file is empty (validation error at line 221) vs when all items are duplicates (valid state at line 295), both exit 0. Caller cannot distinguish error from success.","recommendation":"Exit(1) when input is invalid/empty, exit(0) when valid but no new items. Document exit code semantics in header.","evidence":["Line 221: process.exit(0) when inputLines.length === 0 (ERROR - empty input)","Line 295: process.exit(0) when newItems.length === 0 (OK - all duplicates)","Both treated identically by exit code"],"confidence":"HIGH","cross_ref":"scripts/debt/intake-manual.js has same issue"}
{"id":"EH-007","severity":"S1","category":"Error Handling","file":"scripts/debt/intake-manual.js","line":273,"title":"Exit 0 on duplicate found - success exit for error condition","description":"When duplicate is detected (validation failure), script exits with 0. Client sees success status when item was NOT added. This makes error handling ambiguous.","recommendation":"Exit with code 2 for validation failures (item not added). Document that exit(0) = item added, exit(1) = error, exit(2) = validation skip.","evidence":["Line 271-273: Duplicate detected, item not added, exit(0) called","Caller cannot distinguish 'added successfully' from 'skipped as duplicate'"],"confidence":"MEDIUM","cross_ref":"intake-audit.js has different handling - inconsistent"}
{"id":"EH-008","severity":"S1","category":"Error Handling","file":"scripts/validate-audit.js","line":743,"title":"Silent catch block in cross-reference check - eslint validation fails silently","description":"crossReferenceEslint try-catch at line 743 catches all errors and returns unvalidated findings without warning to caller. If npm lint fails, entire cross-reference phase silently skipped.","recommendation":"Log the specific error to console.warn so user knows eslint check failed. Consider failing validation if cross-reference tools are unavailable.","evidence":["Line 743: catch block with only comment","Line 745: returns empty unvalidated array when eslint fails","User has no way to know eslint cross-check was skipped"],"confidence":"MEDIUM","cross_ref":"crossReferenceNpmAudit uses similar pattern at line 662"}
{"id":"EH-009","severity":"S1","category":"Shell Script","file":".husky/pre-commit","line":101,"title":"Shell script swallows errors from append-hook-warning with 2>/dev/null || true","description":"Line 101: node scripts/append-hook-warning.js wrapped with '2>/dev/null || true' silently suppresses all errors. If script fails, pre-commit gate has no visibility into warning capture failures.","recommendation":"Capture stderr to variable, check exit code, and warn user if append-hook-warning fails, but don't block commit (it's informational).","evidence":["Line 101: 'node scripts/append-hook-warning.js ... 2>/dev/null || true'","Lines 113, 238, 269 have similar error suppression patterns"],"confidence":"MEDIUM","cross_ref":"4 instances in pre-commit hook"}
{"id":"EH-010","severity":"S1","category":"Error Handling","file":"scripts/debt/validate-schema.js","line":285,"title":"All errors caught with single exit code - cannot distinguish error types","description":"main().catch() at line 285 treats all errors identically with exit(2). File not found errors are conflated with validation logic errors or file permission issues.","recommendation":"Distinguish error types: file access errors exit(2), validation errors exit(1), logic errors exit(3). Document exit codes.","evidence":["Line 285-288: Single catch block for all exceptions","Exit code 2 for all failures per header L16-17","No error type discrimination"],"confidence":"MEDIUM","cross_ref":"EXIT_CODE documentation"}
{"id":"EH-011","severity":"S2","category":"Workflow Configuration","file":".github/workflows/ci.yml","line":39","title":"Excessive continue-on-error usage reduces CI signal quality","description":"Lines 39, 75, 80, 90, 101, 107: Six instances of 'continue-on-error: true' allow legitimate failures to be silenced. While intended as 'non-blocking', this creates false confidence in CI results.","recommendation":"Evaluate each continue-on-error: (1) Is failure truly acceptable? (2) Can test be made less strict? (3) Should this be separate workflow? (4) Should this fail but not block merge?","evidence":["L39: deps:unused marked non-blocking","L75: patterns:check-all marked non-blocking","L80: docs:check marked non-blocking","L90: audit:validate marked non-blocking","L101, 107: debt checks marked non-blocking"],"confidence":"LOW","cross_ref":"CLAUDE.md Section 4: continueOnError overuse"}
{"id":"EH-012","severity":"S2","category":"Error Handling","file":"scripts/debt/extract-audits.js","line":150,"title":"JSON parse error in file read loop - error message not included in output","description":"At line 150 and similar locations, JSON.parse failures are caught but error.message not included in logged errors. Makes debugging malformed JSONL difficult.","recommendation":"Include full error message from catch block in validation output so users can identify which line is malformed.","evidence":["Line 150: catch block logs error but filtering/processing may lose details"],"confidence":"LOW","cross_ref":"loadFalsePositives pattern shows better error handling"}
{"id":"EH-013","severity":"S1","category":"Error Handling","file":"scripts/check-pattern-compliance.js","line":770,"title":"existsSync check gives false security - doesn't prevent race conditions","description":"Pattern at line 771: existsSync check before readFileSync creates false confidence about file safety. Race condition can still occur where file is deleted between check and read.","recommendation":"Remove existsSync check - rely entirely on try-catch. Document that try-catch handles all file access failures including TOCTOU races.","evidence":["Line 771: existsSync check before read","Line 774-781: readFileSync in try-catch is actual protection","Redundant check creates dangerous false security"],"confidence":"MEDIUM","cross_ref":"CODE_PATTERNS.md warns about readfilesync without try"}
{"id":"EH-014","severity":"S1","category":"Error Handling","file":"scripts/debt/intake-pr-deferred.js","line":334,"title":"execSync error handling missing in view regeneration","description":"Line 335: execSync call for generate-views.js has no error handling. If it fails, script exits with non-zero but error context is lost.","recommendation":"Wrap in try-catch with proper error message, or use try-finally to ensure cleanup happens.","evidence":["Line 335: execSync('node scripts/debt/generate-views.js', { stdio: 'inherit' })","No try-catch wrapper around this critical call"],"confidence":"HIGH","cross_ref":"Similar to EH-002 but missing try-catch entirely"}
{"id":"EH-015","severity":"S1","category":"Error Handling","file":".husky/pre-commit","line":199,"title":"Pipe in shell script creates subshell - variable assignment not propagated","description":"Line 197-211: Comment at L198 correctly identifies subshell issue from pipes, but solution uses temp file. However, AUDIT_TMPFILE cleanup at line 201 overwrites existing trap, risking file leak if earlier trap already set.","recommendation":"Use trap chaining: append new trap commands to existing trap rather than overwriting with new trap statement.","evidence":["Line 200: mktemp creates AUDIT_TMPFILE","Line 201: trap 'rm -f ... overwrites line 57 trap for TEST_TMPFILE","If trap at 57 executes, AUDIT_TMPFILE won't be cleaned"],"confidence":"MEDIUM","cross_ref":"Shell script best practices - Review #204 mentions this"}
EOF
{"canonical_id":"CANON-0001","severity":"S1","title":"Regex Pattern State Leak in sanitize-error.js","category":"OWASP-A05","file":"scripts/lib/sanitize-error.js","line":89,"description":"In the sanitizeError function, regex patterns with the /g flag are reused in a loop without proper state reset. While lastIndex IS reset on line 90, there is a critical issue: if any pattern match fails or the loop is interrupted, subsequent patterns in the iteration may see an invalid lastIndex state.","cwe":["CWE-1321"],"owasp_top_10":["A05:2021-Broken Access Control"],"risk":"An attacker providing crafted error messages with specific Unicode patterns could cause pattern state corruption, leading to failed sanitization of subsequent error messages, exposing sensitive paths in logs.","affected_input":"error parameter with specific pattern sequences","impact":"Information disclosure through error message leakage","proof_of_concept":"Error with multiple paths: 'Error at /home/user/project: /etc/passwd access denied' - the regex lastIndex reset may not properly reset between patterns if patterns have state modifications.","pattern_reference":"CODE_PATTERNS.md #44 - Regex state leak reset lastIndex before each iteration","remediation":"The current implementation correctly resets lastIndex on line 90 before each pattern.replace(). STATUS: RESOLVED - No finding.","status":"RESOLVED","confidence":"HIGH"}
{"canonical_id":"CANON-0002","severity":"S2","title":"Overly Broad Error Sanitization in security-helpers.js","category":"General","file":"scripts/lib/security-helpers.js","line":"26-31","description":"The sanitizeError function uses aggressive regex replacements that match file paths using /g flag with patterns like /\\/g and /^[^\\s]*\/[^\\s]+/g. These patterns are not properly anchored and may match legitimate error content that should be preserved.","cwe":["CWE-176"],"owasp_top_10":["A01:2021-Broken Access Control"],"risk":"Overly sanitized error messages may make debugging difficult and hide important error context. The pattern /\\/[^\\s]*\\/[^\\s]+/g is too broad and may match URLs, regular expressions in error messages, or other content.","affected_input":"Any error message containing Unix paths or forward slashes","impact":"Reduced debugging capability, information loss in error logging","proof_of_concept":"Error message: 'Failed to parse file:/etc/config.json at /home/user' becomes 'Failed to parse [PATH] at [PATH]' - losing the file:// URL context that might be important.","pattern_reference":"CODE_PATTERNS.md #34 - Relative path logging should be targeted, not overly broad","remediation":"Review sanitization patterns to be more targeted. Current patterns in line 26-31 are too broad. Recommend using more specific patterns that target only known sensitive paths (/home/, /Users/, C:\\\\Users\\\\) rather than general Unix path matching.","status":"OPEN","confidence":"MEDIUM"}
{"canonical_id":"CANON-0003","severity":"S1","title":"Missing NUL Byte Validation in security-helpers.js validatePathInDir","category":"CWE-158","file":"scripts/lib/security-helpers.js","line":"104-118","description":"The validatePathInDir function does not validate for NUL bytes (\\x00) before path operations. NUL bytes can cause path resolution to be silently truncated in some contexts, leading to path traversal vulnerabilities.","cwe":["CWE-158","CWE-22"],"owasp_top_10":["A01:2021-Broken Access Control"],"risk":"A path like 'valid/path\\x00../../../etc/passwd' may be partially validated and then truncated, allowing traversal outside the base directory.","affected_input":"userPath parameter with embedded NUL bytes","impact":"Path traversal leading to unauthorized file access","proof_of_concept":"validatePathInDir('/project', 'docs\\x00../../../etc/passwd') may pass validation and then path.resolve() would operate on 'docs' after truncation.","pattern_reference":"CODE_PATTERNS.md #108 - Security: Reject NUL bytes","remediation":"Add NUL byte check: if (userPath.includes('\\x00')) { throw new Error(...); } before path resolution.","status":"OPEN","confidence":"HIGH"}
{"canonical_id":"CANON-0004","severity":"S2","title":"Insufficient CLI Argument Validation in security-helpers.js parseCliArgs","category":"CWE-89","file":"scripts/lib/security-helpers.js","line":"287-292","description":"In parseCliArgs, the number parsing uses parseInt(next, 10) without proper radix parameter consistency. More critically, there is no validation that the parsed number is finite or checking for Infinity/NaN results before range validation.","cwe":["CWE-89","CWE-1025"],"owasp_top_10":["A01:2021-Broken Access Control"],"risk":"Inputs like 'Infinity', 'NaN', or very large numbers could bypass range validation. Example: parseInt('1e10', 10) returns 1, but 'Infinity' returns NaN which would fail the isNaN check correctly, but 'null' or undefined in parseInt edge cases.","affected_input":"--count argument with special numeric strings","impact":"Potential for argument validation bypass","proof_of_concept":"parseCliArgs(['--count', '1e10']) with min:1 max:100 - parseInt('1e10', 10) returns 1 (correct), but needs Number.isFinite() check.","pattern_reference":"CODE_PATTERNS.md #332 - Number.parseInt radix parameter","remediation":"Change to: if (!Number.isFinite(num)) { errors.push(...); continue; } after parseInt.","status":"OPEN","confidence":"MEDIUM"}
{"canonical_id":"CANON-0005","severity":"S1","title":"Path Traversal in validate-paths.js validateFilePath - Insufficient Control Character Filtering","category":"CWE-22","file":"scripts/lib/validate-paths.js","line":"88","description":"The control character validation excludes tab (0x09), newline (0x0A), and carriage return (0x0D) per comment on line 86. However, this creates a gap: newline characters can be used in path traversal when combined with specific filesystem behaviors. The validation does check for \\n and \\r on lines 100-104, which is good, but the comment is misleading about what's being checked.","cwe":["CWE-22","CWE-158"],"owasp_top_10":["A01:2021-Broken Access Control"],"risk":"Low - the subsequent explicit check for \\n and \\r on line 100 catches this. However, the code is confusing and could be misinterpreted by future maintainers.","affected_input":"filePath with newline characters","impact":"Code clarity issue, not a direct vulnerability due to explicit newline checks","proof_of_concept":"Path like 'file.txt\\nmalicious' is correctly rejected by lines 100-104.","pattern_reference":"CODE_PATTERNS.md #98 - Multiline path rejection","remediation":"Simplify by removing the misleading comment on line 86 and consolidating control character rejection into a single clear block.","status":"OPEN","confidence":"LOW"}
{"canonical_id":"CANON-0006","severity":"S2","title":"TOCTOU Race Condition in validate-paths.js verifyContainment","category":"CWE-367","file":"scripts/lib/validate-paths.js","line":"160-162","description":"The verifyContainment function calls fs.realpathSync() on both fullPath and projectDir separately. Between these two calls, symlinks or permissions could change, causing a TOCTOU (Time-of-check-time-of-use) race condition where the first path is validated as contained, but the second realpath call results in a different base directory.","cwe":["CWE-367"],"owasp_top_10":["A01:2021-Broken Access Control"],"risk":"In scenarios with rapidly changing symlinks or permissions, the containment check could be bypassed.","affected_input":"File paths in directories with changing symlink structure","impact":"Path traversal via race condition","proof_of_concept":"Attacker modifies symlinks between realpathSync(fullPath) on line 161 and realpathSync(projectDir) on line 162, causing projectDir to resolve to a different location.","pattern_reference":"CODE_PATTERNS.md #22 - Fail-closed realpath and #367 TOCTOU races","remediation":"Resolve projectDir once at function entry and cache it. Document that projectDir must be stable during the call. Alternative: use stat() to detect changes, or accept the TOCTOU window as acceptable for hook/CI operations (document this decision).","status":"OPEN","confidence":"MEDIUM"}
{"canonical_id":"CANON-0007","severity":"S2","title":"Information Disclosure in sanitizeFilesystemError - Incomplete Path Sanitization","category":"CWE-532","file":"scripts/lib/validate-paths.js","line":"22-46","description":"The sanitizeFilesystemError function attempts to redact system paths but has incomplete coverage. Notably, paths containing dots in directory names (e.g., /home/user.old/project) may not be properly redacted if the user name contains special characters. The regex /C:\\\\Users\\\\[^\\n\\r]+/g will match, but the subsequent general patterns may re-expose parts.","cwe":["CWE-532"],"owasp_top_10":["A01:2021-Broken Access Control"],"risk":"Sensitive filesystem paths may still appear in logs.","affected_input":"Error messages with user home directories containing dots or special chars","impact":"Information disclosure of directory structure","proof_of_concept":"Path: 'C:\\\\Users\\\\first.last' is sanitized to '[HOME]', but complex nested paths might leave partial information.","pattern_reference":"CODE_PATTERNS.md #321 - Windows path sanitize with gi flag","remediation":"Add gi flags to Windows path patterns for case-insensitive matching. Verify all sensitive base directories are covered (add /var/lib, /srv, /opt patterns).","status":"OPEN","confidence":"LOW"}
{"canonical_id":"CANON-0008","severity":"S1","title":"Command Injection in safeGitAdd - Arguments Array Properly Used but No Deep Validation","category":"CWE-78","file":"scripts/lib/security-helpers.js","line":"171-182","description":"While safeGitAdd correctly uses execFileSync with argument arrays (preventing shell interpolation on line 181), it does not validate the git binary path or verify that git is actually being executed. An attacker who can modify PATH could cause a different 'git' executable to be invoked.","cwe":["CWE-78"],"owasp_top_10":["A03:2021-Injection"],"risk":"Low-medium if PATH can be controlled by unprivileged users in the hook execution environment.","affected_input":"repoRoot parameter and system PATH","impact":"Arbitrary code execution as the hook user if PATH is controlled","proof_of_concept":"If a hook runs with an attacker-controlled environment where /tmp/git is a malicious script, and /tmp is in PATH before /usr/bin, the fake git would be invoked.","pattern_reference":"CODE_PATTERNS.md #244 - execFileSync should use full path for untrusted systems","remediation":"Consider using the full path to git (e.g., '/usr/bin/git' on Unix, 'C:\\\\Program Files\\\\Git\\\\bin\\\\git.exe' on Windows) or document that this function expects PATH to be clean. Alternatively, use 'where.cmd git' on Windows or 'which git' on Unix to resolve the git binary path.","status":"OPEN","confidence":"MEDIUM"}
{"canonical_id":"CANON-0009","severity":"S3","title":"Magic String in safeGitCommit - Hardcoded PID/Timestamp Format","category":"General","file":"scripts/lib/security-helpers.js","line":"193","description":"The temporary filename construction uses process.pid and Date.now() but does not validate the temp directory is actually writable or that collisions are impossible. On systems with PID reuse and high concurrency, multiple processes could generate identical filenames simultaneously.","cwe":[],"owasp_top_10":[],"risk":"Low - the wx flag will catch collisions with EEXIST error, but the error handling could be clearer.","affected_input":"Concurrent invocations of safeGitCommit","impact":"Possible temporary file collision leading to commit failure (not data loss due to wx flag)","proof_of_concept":"Two processes with the same PID after wraparound + same Date.now() millisecond precision collision (extremely unlikely but theoretically possible).","pattern_reference":"General - Temporary file naming collision avoidance","remediation":"Use crypto.randomUUID() in the filename: `COMMIT_MSG_${crypto.randomUUID()}.txt` for guaranteed uniqueness.","status":"OPEN","confidence":"LOW"}
{"canonical_id":"CANON-0010","severity":"S2","title":"Regex DoS (ReDoS) Potential in maskEmail - Unbounded Domain Splitting","category":"CWE-1333","file":"scripts/lib/security-helpers.js","line":"436-459","description":"The maskEmail function splits on '@' and then '.' without length limits. If an attacker provides an email with thousands of dots in the domain part, the split arrays could be large, and subsequent array operations could be inefficient.","cwe":["CWE-1333"],"owasp_top_10":["A05:2021-Broken Access Control"],"risk":"Moderate - not a ReDoS in the regex sense, but algorithmic DoS through unbounded array operations.","affected_input":"email parameter with many dots, e.g., 'user@a.b.c.d.e....(4000 more)....z'","impact":"CPU exhaustion from large email processing","proof_of_concept":"maskEmail('user@' + '.'.repeat(5000) + '.com') would create a 5000+ element array.","pattern_reference":"CODE_PATTERNS.md #245 - Large input guards to prevent DoS/UI freeze","remediation":"Add a length check: if (email.length > 254) { return '[REDACTED]'; } Email RFC 5321 specifies maximum lengths.","status":"OPEN","confidence":"MEDIUM"}
{"canonical_id":"CANON-0011","severity":"S3","title":"Missing Error Handling in refuseSymlinkWithParents - Potential Null Reference","category":"CWE-476","file":"scripts/lib/security-helpers.js","line":"78-93","description":"The refuseSymlinkWithParents function uses path.dirname() in a loop but does not validate that existsSync() is correctly checking permissions. If a directory exists but cannot be read due to permissions, lstatSync() on line 83 could throw EACCES, which is not caught.","cwe":["CWE-476"],"owasp_top_10":[],"risk":"Low - the function is designed to reject symlinks, and permission errors would cause the function to throw (fail-safe), preventing unsafe writes. However, the error message would not be sanitized.","affected_input":"Symlink paths in restricted permission directories","impact":"Unsanitized error messages containing full paths in exceptions","proof_of_concept":"Directory /root/.config (if running as non-root) would throw 'EACCES: permission denied' with full path in error.","pattern_reference":"CODE_PATTERNS.md #105 - lstatSync wrapped in try-catch for permission denied","remediation":"Wrap the lstatSync call in try-catch: try { const st = lstatSync(current); ... } catch(e) { if (e.code === 'EACCES') throw new Error('Permission denied'); else throw e; }","status":"OPEN","confidence":"LOW"}
{"canonical_id":"CANON-0012","severity":"S1","title":"Input Length DoS in validateFilePath - No Maximum Enforcement for Large Inputs","category":"CWE-400","file":"scripts/lib/validate-paths.js","line":"62-75","description":"While the code does cap projectDir and filePath at 4096 characters (lines 62-75), there is no validation that these are reasonable defaults for actual filesystem paths. More critically, if this function is called in a loop (e.g., validating 1000 files), 4096 * 1000 = 4MB of memory could be consumed. On line 78, filePath.trim() is called which creates a copy.","cwe":["CWE-400"],"owasp_top_10":["A05:2021-Broken Access Control"],"risk":"Moderate - in a loop context, attackers could cause memory exhaustion.","affected_input":"Multiple calls to validateFilePath with maximum length paths","impact":"Memory exhaustion leading to DoS","proof_of_concept":"Loop calling validateFilePath 100,000 times with 4096-char paths = 400MB+ memory allocation.","pattern_reference":"CODE_PATTERNS.md #256 - Input length DoS cap projectDir and filePath at 4096","remediation":"Code is already compliant. Consider documenting that callers should not use this in tight loops without batching. Add a note in comments.","status":"RESOLVED","confidence":"MEDIUM"}
{"canonical_id":"CANON-0013","severity":"S2","title":"Incomplete URL Validation in validateUrl - Port Bypass Vulnerability","category":"CWE-94","file":"scripts/lib/security-helpers.js","line":"352-389","description":"The validateUrl function validates the hostname and protocol but does not check the port. A URL like 'https://api.github.com:6379' (pointing to attacker-controlled Redis on a hijacked port) would be allowed. The function also doesn't validate query parameters or fragments which could contain command injection payloads.","cwe":["CWE-94"],"owasp_top_10":["A01:2021-Broken Access Control"],"risk":"Moderate - if URL is used to make HTTP requests, attacker could redirect to internal services on different ports.","affected_input":"urlString parameter with malicious port or query string","impact":"SSRF (Server-Side Request Forgery) to internal services, parameter injection","proof_of_concept":"validateUrl('https://api.github.com:6379?cmd=flushdb', ['api.github.com']) returns valid despite port 6379 being Redis.","pattern_reference":"CODE_PATTERNS.md #241 - URL protocol allowlist - validates protocol + host but PORT should also be checked","remediation":"Add port validation: if (url.port && url.port !== '443') { return { valid: false, error: 'Custom ports not allowed' }; }","status":"OPEN","confidence":"HIGH"}
{"canonical_id":"CANON-0014","severity":"S2","title":"Regex Pattern Injection in validateUrl - Hostname Pattern Mismatch","category":"CWE-1025","file":"scripts/lib/security-helpers.js","line":"376","description":"The IP address validation regex on line 376 uses /^(\\d{1,3}\\.){3}\\d{1,3}$/ which is intended to match IPv4 but is incomplete. It does not validate that each octet is 0-255, so 999.999.999.999 would pass and only fail at network layer. More critically, hostname.startsWith('[') on the same line is a poor check for IPv6.","cwe":["CWE-1025"],"owasp_top_10":["A01:2021-Broken Access Control"],"risk":"Low-medium - the subsequent network layer will reject invalid IPs, but the intent of blocking IPs should be more robust.","affected_input":"URL with invalid IP-like hostnames or IPv6 addresses","impact":"Bypassed IP validation, potential internal network access","proof_of_concept":"validateUrl('https://999.999.999.999', ['example.com']) would pass validation but fail at HTTP level. IPv6 URLs like 'https://[::ffff:127.0.0.1]' might have parsing issues.","pattern_reference":"CODE_PATTERNS.md #235 - IPv6-safe IP parsing","remediation":"Replace IP check with: function isIPAddress(hostname) { try { new URL('http://' + hostname); } catch { return false; } return /^\\d+\\.\\d+\\.\\d+\\.\\d+$/.test(hostname) || /^\\[.*:\\.*\\]$/.test(hostname); }","status":"OPEN","confidence":"MEDIUM"}
{"canonical_id":"CANON-0015","severity":"S3","title":"Markdown Escaping in sanitizeDisplayString - Backtick Injection Possible","category":"CWE-94","file":"scripts/lib/security-helpers.js","line":"46-47","description":"The sanitizeDisplayString function removes code blocks with backticks but does not account for template literal backticks (`) in the final escaped output. If a string contains backticks within it, the escapeMd function on line 68 will escape them, but sanitizeDisplayString is called first, potentially losing context.","cwe":["CWE-94"],"owasp_top_10":["A03:2021-Injection"],"risk":"Low - the escapeMd function does include backticks in its character set (line 68), so this is mitigated. However, the order of operations could be clearer.","affected_input":"Display strings with backticks or template literal markers","impact":"Markdown injection if escapeMd is not called after sanitizeDisplayString","proof_of_concept":"sanitizeDisplayString('User: `whoami`') returns 'User: [CODE]', then escapeMd is called by caller, so backticks are lost. If caller only calls sanitizeDisplayString, injection is possible.","pattern_reference":"CODE_PATTERNS.md #268 - Markdown char escaping - create escapeMd()","remediation":"Document that sanitizeDisplayString should be followed by escapeMd, or combine them into a single function: sanitizeAndEscapeMd(str) { return escapeMd(sanitizeDisplayString(str)); }","status":"OPEN","confidence":"LOW"}
{"id":"IMPROVEMENT-001","category":"Hook Consolidation","severity":"S3","title":"Duplicate Pattern Check Runs","description":"npm run patterns:check runs 3 times in pre-commit hook (on failure, success check, and again). Should cache result and reuse.","impact":"Reduces pre-commit time by 2-3s per check","files":[".husky/pre-commit"],"recommendation":"Store patterns:check output in variable and reuse result","estimated_time_savings":"6-9s per commit"}
{"id":"IMPROVEMENT-002","category":"Hook Consolidation","severity":"S3","title":"Multiple Script Invocations for Same Check","description":"npm run lint executes twice in pre-commit (line 9 for validation, line 11 for output). Runs command multiple times.","impact":"Reduces pre-commit time by 1-2s","files":[".husky/pre-commit"],"recommendation":"Capture output once, check exit code, display if needed","estimated_time_savings":"2-4s per commit"}
{"id":"IMPROVEMENT-003","category":"CI Optimization","severity":"S3","title":"Missing npm Install Cache Optimization","description":"CI workflows install dependencies 5+ times across separate jobs but don't use node cache effectively. Backlog enforcement and docs-lint both npm ci without checking cache hit rates.","impact":"CI pipeline could be 15-20% faster","files":[".github/workflows/ci.yml",".github/workflows/backlog-enforcement.yml",".github/workflows/docs-lint.yml"],"recommendation":"Add cache-hit conditional to skip npm ci if cache was hit","estimated_time_savings":"45-60s per CI run"}
{"id":"IMPROVEMENT-004","category":"Hook Consolidation","severity":"S3","title":"npm run validate:canon Runs Twice","description":"CANON validation runs in pre-commit hook and also in CI (separate job). Pattern is: check once locally, report errors immediately.","impact":"Reduces pre-commit time by 1s","files":[".husky/pre-commit",".github/workflows/ci.yml"],"recommendation":"Only run in CI; local check is informational duplicate","estimated_time_savings":"1-2s per commit"}
{"id":"IMPROVEMENT-005","category":"Manual Process Automation","severity":"S3","title":"Review Needed Detection Could Be Pre-commit","description":"npm run review:check runs only in CI (review-check.yml) but could run in pre-push hook to provide instant feedback before pushing.","impact":"Catch review needs before remote push","files":[".github/workflows/review-check.yml"],"recommendation":"Add npm run review:check to pre-push hook with early warning","estimated_time_savings":"Saves failed CI runs and feedback loops"}
{"id":"IMPROVEMENT-006","category":"CI Optimization","severity":"S3","title":"Pattern Compliance Check Runs Full Suite Then Changed Files","description":"Pattern check runs with --all on main push, but also on PRs with changed files only. Two separate runs = duplicate effort.","impact":"Reduces CI time by 8-10s per push","files":[".github/workflows/ci.yml"],"recommendation":"Use single run: check changed files (PR) OR all (main), not both patterns","estimated_time_savings":"8-10s per CI run"}
{"id":"IMPROVEMENT-007","category":"Error Message Improvement","severity":"S3","title":"Inconsistent Error Message Quality","description":"Some checks show tail output, others show grep filtered output. Makes debugging harder. Pattern compliance shows only 15 lines which may truncate important context.","impact":"Better developer experience, faster debugging","files":[".husky/pre-commit",".husky/pre-push"],"recommendation":"Standardize error output: show context, line numbers, and full message","estimated_time_savings":"Saves 5-10min per error debugging session"}
{"id":"IMPROVEMENT-008","category":"Script Consolidation","severity":"S3","title":"Overlapping Validation Scripts","description":"validate-audit.js (980 lines) duplicates checks also in audit:validate npm script. check-pattern-compliance.js has pattern definitions repeated in other scripts. sanitize-error.js exists in both .js and .ts versions.","impact":"Reduces codebase complexity, improves maintainability","files":["scripts/validate-audit.js","scripts/check-pattern-compliance.js","scripts/lib/sanitize-error.js","scripts/lib/sanitize-error.ts"],"recommendation":"Single source of truth for each validator. Remove .ts duplicate of sanitize-error.js","estimated_time_savings":"Reduces maintenance overhead by 10-15%"}
{"id":"IMPROVEMENT-009","category":"Hook Consolidation","severity":"S3","title":"Skill Validation Only Checks on Skill File Changes","description":"npm run skills:validate only runs when .claude/skills or .claude/commands files change. But changed skill can break builds in non-obvious ways.","impact":"Might catch skill-related issues earlier","files":[".husky/pre-commit"],"recommendation":"Always run skills:validate or run on broader file changes","estimated_time_savings":"Prevention: potential time saved from build failures"}
{"id":"IMPROVEMENT-010","category":"Manual Process Automation","severity":"S3","title":"Documentation Index Updates Are Manual Gate","description":"Pre-commit requires manual docs:index run when md files change. Could auto-run and stage the output.","impact":"Eliminates one manual step per doc change","files":[".husky/pre-commit"],"recommendation":"Auto-run npm run docs:index and git add DOCUMENTATION_INDEX.md when md files detected","estimated_time_savings":"30-60s per documentation update"}
{"id":"IMPROVEMENT-011","category":"CI Optimization","severity":"S3","title":"Tests Run Multiple Times Across Hook and CI","description":"Tests run in pre-commit hook (for config changes), then again in CI. Creates duplicate effort for same code.","impact":"Pre-commit takes 40-60s on first commit, CI adds another 50s","files":[".husky/pre-commit",".github/workflows/ci.yml"],"recommendation":"Run tests only in CI; trust local dev workflow. Or: skip CI tests if pre-commit passed.","estimated_time_savings":"40-60s per CI run"}
{"id":"IMPROVEMENT-012","category":"Hook Tools","severity":"S3","title":"No Built-in Hook Time Measurement","description":"No visibility into which hook step is slowest. Developers don't know if its tests (40s) or patterns (8s) or typescript (12s).","impact":"Better optimization targeting","files":[".husky/pre-commit",".husky/pre-push"],"recommendation":"Add timestamp logging to show per-check timing. Use date +%s%N for nanosecond precision.","estimated_time_savings":"Enables data-driven optimization"}
{"id":"IMPROVEMENT-013","category":"Script Consolidation","severity":"S3","title":"Overlapping Learnings Analysis","description":"analyze-learning-effectiveness.js (1271 lines) and check-pattern-compliance.js both process learnings from AI reviews. Can consolidate logic.","impact":"Reduces complexity, single algorithm for pattern matching","files":["scripts/analyze-learning-effectiveness.js","scripts/check-pattern-compliance.js"],"recommendation":"Extract common learning-parsing logic to lib/learning-analyzer.js","estimated_time_savings":"Reduces complexity by 200+ lines"}
{"id":"IMPROVEMENT-014","category":"Error Message Improvement","severity":"S3","title":"Unhelpful Pre-push Hook Messages","description":"Pre-push shows 15 lines of grep filtered output for pattern violations, losing context. User does not know what line violates which pattern.","impact":"Faster error resolution","files":[".husky/pre-push"],"recommendation":"Show full error with file:line:column format. Use npm run patterns:check output directly.","estimated_time_savings":"Saves 10-15min debugging per pattern error"}
{"id":"IMPROVEMENT-015","category":"Hook Consolidation","severity":"S3","title":"Security Check Runs in Pre-push But Not Pre-commit","description":"npm run security:check only in pre-push, not pre-commit. Security issues could be caught earlier (dev cycle is faster).","impact":"Catch security issues before push attempt","files":[".husky/pre-push"],"recommendation":"Add lightweight security:check to pre-commit (or use changed files only for speed)","estimated_time_savings":"Earlier feedback loop, prevents remote rejection"}
{"id":"IMPROVEMENT-016","category":"CI Optimization","severity":"S3","title":"Dependency Check (Knip) Has No Cache","description":"npm run deps:unused (knip) runs without caching and takes 3-5s. Can cache knip results or skip on non-package-change commits.","impact":"Saves 3-5s on CI runs when no deps changed","files":[".github/workflows/ci.yml"],"recommendation":"Skip deps:unused check if package.json/lock not in PR changes","estimated_time_savings":"3-5s per CI run (50% of runs)"}
{"id":"IMPROVEMENT-017","category":"Manual Process Automation","severity":"S3","title":"Cross-Doc Dependency Check Has No Auto-Fix","description":"npm run crossdoc:check blocks commit with cryptic dependency errors but provides no guidance to fix. Requires manual doc edits.","impact":"Better DX, faster resolution","files":["scripts/check-cross-doc-deps.js"],"recommendation":"Add --auto-fix flag to automatically update dependent docs or suggest changes","estimated_time_savings":"Saves 5-10min per cross-doc violation"}
{"id":"IMPROVEMENT-018","category":"Hook Consolidation","severity":"S3","title":"Document Header Check Only Runs on New Files","description":"npm run docs:headers only runs on NEW markdown files (git diff-filter=A). Modified files skip header validation. Headers can degrade.","impact":"Maintain documentation header consistency","files":[".husky/pre-commit"],"recommendation":"Check headers on Added AND Modified files (diff-filter=AM)","estimated_time_savings":"Prevents documentation quality degradation"}
{"id":"IMPROVEMENT-019","category":"CI Optimization","severity":"S3","title":"Sonarcloud Trigger on Every Push","description":"Sonarcloud analysis runs on every push and PR, but often skipped for fork PRs. Runs fetch-depth: 0 unnecessarily on some branches.","impact":"Save CI resource usage","files":[".github/workflows/sonarcloud.yml"],"recommendation":"Only run on main branch or PRs from original repo; skip on pushes to feature branches","estimated_time_savings":"5-10s per feature branch commit"}
{"id":"IMPROVEMENT-020","category":"Manual Process Automation","severity":"S3","title":"Pattern Fixes Are Manual","description":"npm run patterns:check detects violations but suggests only generic run patterns:check help. Should show specific fixes for each pattern type.","impact":"Faster error resolution for developers","files":["scripts/check-pattern-compliance.js"],"recommendation":"Add --suggest flag to show specific fix examples for each violation found","estimated_time_savings":"Saves 10-20min per pattern violation"}
{"id": "DUP-001", "locations": ["scripts/lib/sanitize-error.js", "scripts/lib/security-helpers.js", "scripts/lib/validate-paths.js"], "type": "duplicate_function", "description": "sanitizeError() function implemented identically in 3 files with same patterns (path regex, credential masking, redaction)", "severity": "S2", "recommendation": "extract to shared lib - consolidate into scripts/lib/sanitize-error.js as source of truth"}
{"id": "DUP-002", "locations": [".claude/hooks/auto-save-context.js", ".claude/hooks/track-agent-invocation.js", ".claude/hooks/check-mcp-servers.js"], "type": "duplicate_function", "description": "loadJson() and readState() helper functions with identical try/catch patterns for JSON.parse(readFileSync()) across multiple hooks", "severity": "S2", "recommendation": "extract to shared hooks/lib/file-helpers.js for reuse"}
{"id": "DUP-003", "locations": [".claude/hooks/auto-save-context.js", ".claude/hooks/track-agent-invocation.js", ".claude/hooks/session-start.js"], "type": "similar_logic", "description": "Path containment validation using path.relative() + startsWith/regex checks repeated 3+ times with identical logic patterns", "severity": "S2", "recommendation": "extract validatePathContainment() to shared hooks/lib/path-helpers.js"}
{"id": "DUP-004", "locations": ["scripts/debt/validate-schema.js", "scripts/debt/intake-audit.js", "scripts/debt/extract-audits.js"], "type": "duplicate_function", "description": "Identical validation logic for VALID_CATEGORIES, VALID_SEVERITIES, VALID_TYPES, VALID_STATUSES, VALID_EFFORTS across 3 debt scripts", "severity": "S2", "recommendation": "consolidate schema definitions into scripts/debt/lib/schema.js"}
{"id": "DUP-005", "locations": ["scripts/check-document-sync.js", "scripts/check-docs-light.js"], "type": "similar_logic", "description": "Markdown link pattern detection and validation logic with bounded regex [([^]]{1,200})]([^)]{1,500}) in both files", "severity": "S3", "recommendation": "extract to scripts/lib/markdown-validation.js"}
{"id": "DUP-006", "locations": ["scripts/debt/intake-audit.js", "scripts/debt/extract-audits.js", "scripts/debt/normalize-all.js"], "type": "copy_paste", "description": "normalizeFilePath() function with identical Windows backslash handling and drive letter preservation logic", "severity": "S2", "recommendation": "consolidate into scripts/debt/lib/path-helpers.js"}
{"id": "DUP-007", "locations": ["scripts/lib/security-helpers.js", "scripts/lib/validate-paths.js"], "type": "copy_paste", "description": "sanitizeFilesystemError() logic for path redaction ([HOME], [DRIVE], [TMP]) repeated with minor variations", "severity": "S2", "recommendation": "use unified implementation from sanitize-error.js"}
{"id": "DUP-008", "locations": [".claude/hooks/auto-save-context.js", ".claude/hooks/track-agent-invocation.js"], "type": "duplicate_function", "description": "writeState() and saveJson() atomic write pattern using temp files + rename across hooks", "severity": "S2", "recommendation": "extract to hooks/lib/file-helpers.js as atomic write utility"}
{"id": "DUP-009", "locations": ["scripts/debt/intake-audit.js", "scripts/debt/extract-audits.js"], "type": "duplicate_function", "description": "getSourceId() and ID field extraction logic (trying multiple field names) in audit processing", "severity": "S3", "recommendation": "consolidate into scripts/debt/lib/id-helpers.js"}
{"id": "DUP-010", "locations": ["scripts/check-pattern-compliance.js", "scripts/pattern-check.js", ".claude/hooks/pattern-check.js"], "type": "duplicate_function", "description": "Global regex compile with state reset pattern (pattern.lastIndex = 0) before exec() loops appears 15+ times across codebase", "severity": "S1", "recommendation": "create scripts/lib/regex-helpers.js with safeRegexExec() wrapper"}
{"id": "DUP-011", "locations": [".claude/hooks/check-edit-requirements.js", ".claude/hooks/check-write-requirements.js"], "type": "similar_logic", "description": "Identical project directory validation and path.relative() containment check patterns", "severity": "S2", "recommendation": "extract validateProjectPath() to hooks/lib/path-helpers.js"}
{"id": "DUP-012", "locations": ["scripts/lib/security-helpers.js", "scripts/lib/validate-paths.js", ".claude/hooks/check-mcp-servers.js"], "type": "copy_paste", "description": "Path traversal prevention regex /^..(?:[\\\\/]|$)/ implemented identically in 3+ locations", "severity": "S1", "recommendation": "define once in scripts/lib/constants.js as PATH_TRAVERSAL_PATTERN"}
{"id": "DUP-013", "locations": ["scripts/debt/intake-audit.js", "scripts/debt/validate-schema.js", "scripts/debt/check-phase-status.js"], "type": "duplicate_function", "description": "ensureValid() and validation helper with identical pattern to filter values against VALID_* sets", "severity": "S2", "recommendation": "consolidate into scripts/debt/lib/validation-helpers.js"}
{"id": "DUP-014", "locations": [".claude/hooks/auto-save-context.js", ".claude/hooks/track-agent-invocation.js", ".claude/hooks/audit-s0s1-validator.js"], "type": "copy_paste", "description": "Session state file reading from .claude/hooks/.session-state.json with identical try/catch blocks", "severity": "S2", "recommendation": "extract getSessionState() to hooks/lib/session-helpers.js"}
{"id": "DUP-015", "locations": ["scripts/check-docs-light.js", "scripts/check-document-sync.js", "scripts/validate-audit.js"], "type": "similar_logic", "description": "Date parsing and staleness checking with identical logic for >90 days threshold", "severity": "S3", "recommendation": "extract checkStaleness() to scripts/lib/date-helpers.js"}
{"id": "DUP-016", "locations": ["scripts/debt/extract-audits.js", "scripts/debt/extract-reviews.js", "scripts/debt/extract-sonarcloud.js"], "type": "duplicate_function", "description": "normalizeCategory() and normalizeEffort() mapping functions with identical category/effort maps", "severity": "S2", "recommendation": "consolidate into scripts/debt/lib/normalization.js"}
{"id": "DUP-017", "locations": [".claude/hooks/auto-save-context.js", ".claude/hooks/check-mcp-servers.js"], "type": "copy_paste", "description": "Output truncation and sanitization logic (substring(0, maxLen) + '...') repeated identically", "severity": "S3", "recommendation": "extract truncateOutput() to scripts/lib/output-helpers.js"}
{"id": "DUP-018", "locations": ["scripts/lib/security-helpers.js", "scripts/lib/validate-paths.js", "scripts/check-docs-light.js"], "type": "copy_paste", "description": "Platform-specific path normalization for Windows (backslash to forward slash) and relative path checks", "severity": "S2", "recommendation": "create scripts/lib/path-normalization.js with normalizePathForComparison()"}
{"id": "DUP-019", "locations": ["scripts/debt/intake-audit.js", "scripts/debt/intake-manual.js", "scripts/debt/intake-pr-deferred.js"], "type": "duplicate_function", "description": "Content hash generation for deduplication using crypto.createHash with identical file path normalization", "severity": "S2", "recommendation": "consolidate into scripts/debt/lib/hash-helpers.js as generateContentHash()"}
{"id": "DUP-020", "locations": [".claude/hooks/alerts-reminder.js", ".claude/hooks/auto-save-context.js", ".claude/hooks/generate-pending-alerts.js"], "type": "copy_paste", "description": "JSON alert parsing with identical try/catch + fallback empty array pattern across 3+ alert hooks", "severity": "S3", "recommendation": "extract loadAlerts() to hooks/lib/alert-helpers.js"}
{"id": "UNUSED-001", "file": "package.json", "item": "docs:archive", "type": "unused_script", "evidence": "npm script defined but never called from workflows, hooks, or documentation", "severity": "S3", "recommendation": "remove"}
{"id": "UNUSED-002", "file": "package.json", "item": "docs:sync-check", "type": "unused_script", "evidence": "Defined in scripts but has no automatic triggers in CI/CD or git hooks", "severity": "S3", "recommendation": "investigate"}
{"id": "UNUSED-003", "file": "package.json", "item": "review:check", "type": "unused_script", "evidence": "npm script never invoked; separate 'check-review-needed.js' is called directly from workflow", "severity": "S3", "recommendation": "remove"}
{"id": "UNUSED-004", "file": "package.json", "item": "lessons:surface", "type": "unused_script", "evidence": "Exported from script but never called in any automation or documentation", "severity": "S3", "recommendation": "remove"}
{"id": "UNUSED-005", "file": ".env.local.example", "item": "CONTEXT7_API_KEY", "type": "unused_env", "evidence": "Environment variable defined but never read in code; only referenced in MCP example config and documentation", "severity": "S3", "recommendation": "document"}
{"id": "UNUSED-006", "file": ".env.local.example", "item": "NEXT_PUBLIC_RECAPTCHA_SITE_KEY", "type": "unused_env", "evidence": "Defined but marked for removal (RECAPTCHA_REMOVAL_GUIDE.md exists); deprecated feature", "severity": "S2", "recommendation": "remove"}
{"id": "UNUSED-007", "file": ".env.local.example", "item": "NEXT_PUBLIC_APPCHECK_DEBUG_TOKEN", "type": "unused_env", "evidence": "Optional variable never referenced in code; appears to be legacy commented field", "severity": "S3", "recommendation": "remove"}
{"id": "UNUSED-008", "file": "package.json", "item": "learning:analyze, learning:dashboard, learning:detailed, learning:category, learning:since", "type": "unused_script", "evidence": "5 learning-related npm scripts defined but never invoked by any workflow or hook", "severity": "S3", "recommendation": "document"}
{"id": "UNUSED-009", "file": "package.json", "item": "consolidation:check", "type": "unused_script", "evidence": "Defined but only 'consolidation:run' is used in documentation; check variant is never called", "severity": "S3", "recommendation": "investigate"}
{"id": "UNUSED-010", "file": "package.json", "item": "session:log, session:summary", "type": "unused_script", "evidence": "Session activity logging scripts defined but not integrated into any automatic workflow trigger", "severity": "S3", "recommendation": "investigate"}
{"id": "UNUSED-011", "file": ".github/workflows/validate-plan.yml", "item": "validate-plan trigger", "type": "never_triggers", "evidence": "Triggers on archived completed-plans file path; file location suggests historical/archived content rarely modified", "severity": "S3", "recommendation": "investigate"}
{"id": "UNUSED-012", "file": "scripts/ai-review.js", "item": "ai-review", "type": "unused_export", "evidence": "Script created for manual use but never invoked from any npm script or workflow; only documented in examples", "severity": "S3", "recommendation": "document"}
{"id": "UNUSED-013", "file": "scripts/verify-sonar-phase.js", "item": "_LEARNINGS_FILE variable", "type": "dead_code", "evidence": "Variable assigned at line 27 but never used; prefixed with underscore indicating intentional dead code", "severity": "S3", "recommendation": "remove"}
{"id": "UNUSED-014", "file": "scripts/assign-review-tier.js", "item": "TODO placeholder logic", "type": "dead_code", "evidence": "Lines 55-56 contain commented placeholder with TODO: Uncomment when script is ready - never implemented", "severity": "S2", "recommendation": "implement"}
{"id": "UNUSED-015", "file": "package.json", "item": "verify-skill-usage", "type": "unused_script", "evidence": "Defined script but only 'skills:validate' is used in pre-commit hook; verify variant never called", "severity": "S3", "recommendation": "investigate"}
{"id": "UNUSED-016", "file": "package.json", "item": "lighthouse, lighthouse:desktop", "type": "unused_script", "evidence": "Lighthouse audit scripts defined but only referenced in LIGHTHOUSE_INTEGRATION_PLAN.md; never automatically triggered", "severity": "S3", "recommendation": "investigate"}
{"id": "UNUSED-017", "file": "package.json", "item": "hooks:test, hooks:health", "type": "unused_script", "evidence": "Hook testing and health check scripts defined but no automatic triggers; scripts/check-hook-health.js is directly invoked instead", "severity": "S3", "recommendation": "investigate"}
{"id": "PERF-HOOK-001", "file": ".claude/hooks/session-start.js", "issue": "Synchronous child_process.execSync calls in sequence with no parallelization", "impact": "slow session startup (10-20s). Multiple npm install, build, and test commands run serially", "severity": "S2", "recommendation": "Use Promise.all() with execAsync to parallelize independent operations like npm ci for root and functions in parallel, and pattern-check with backlog-health check in parallel"}
{"id": "PERF-HOOK-002", "file": ".claude/hooks/session-start.js", "issue": "Reads and computes hashes of lockfiles synchronously on every startup - no cache between sessions", "impact": "slow session startup. fs.readFileSync on package-lock.json and functions/package-lock.json happens every startup", "severity": "S3", "recommendation": "Cache computed hashes in .env or filesystem across sessions. Compare only if hashes differ, skip re-read if within last 24 hours"}
{"id": "PERF-HOOK-003", "file": ".claude/hooks/large-context-warning.js", "issue": "Reads entire file into memory and splits on newlines for every Read/Glob operation - O(n) memory for file content", "impact": "slow on large files. Memory usage scales with file size (5000+ line files hit memory allocation cost)", "severity": "S3", "recommendation": "Use streaming or line-counting loop instead of split(). Count newlines with charCodeAt(i) === 10 without storing lines array"}
{"id": "PERF-HOOK-004", "file": ".claude/hooks/large-context-warning.js", "issue": "Reads JSON state file on every Read/Glob operation - multiple fs.readFileSync calls per session", "impact": "slow reads. State file accessed for every file read tracked", "severity": "S3", "recommendation": "Cache state in memory with periodic flush (every 10 files), only read on session-start and write once per 30 seconds"}
{"id": "PERF-HOOK-005", "file": ".claude/hooks/pattern-check.js", "issue": "Calls external spawnSync(node scripts/check-pattern-compliance.js) for every file - spawning child process overhead", "impact": "slow edits. 30-100ms per file edit just to spawn and run pattern checker", "severity": "S2", "recommendation": "Move pattern-check logic into hook (fs.readFileSync + regex checks) to avoid subprocess overhead. Use lazy evaluation - only check if file >100 lines (already implemented but subprocess overhead remains)"}
{"id": "PERF-HOOK-006", "file": ".claude/hooks/pattern-check.js", "issue": "Calls fs.realpathSync() to resolve real paths before pattern check - filesystem traversal overhead", "impact": "slow edits. realpathSync is blocking and resolves symlinks which is expensive on some filesystems", "severity": "S3", "recommendation": "Skip realpathSync for pattern check - use relative path directly. Containment validation is already done via path.relative() earlier in code"}
{"id": "PERF-HOOK-007", "file": ".claude/hooks/agent-trigger-enforcer.js", "issue": "Reads and writes JSON state file on every PostToolUse - frequent file I/O for tracking", "impact": "slow tool use. Adds 100ms+ per file modification to read state, update, write state", "severity": "S3", "recommendation": "Batch state updates. Only write state once per 10 files modified or once per minute, not on every invocation"}
{"id": "PERF-HOOK-008", "file": ".claude/hooks/component-size-check.js", "issue": "Reads entire component file into memory and splits on newline to count lines for every .tsx write", "impact": "slow component edits. Line counting via split() creates large intermediate array", "severity": "S2", "recommendation": "Use streaming line count or charCodeAt loop instead of split(). File read is unavoidable but processing can be optimized"}
{"id": "PERF-HOOK-009", "file": ".claude/hooks/firestore-write-block.js", "issue": "Uses regex exec() with /g flag in loop without proper lastIndex reset between iterations", "impact": "potential infinite loop or incorrect behavior. Multiple FIRESTORE_WRITE_PATTERNS.forEach with pattern.exec() during global flag processing", "severity": "S1", "recommendation": "Reset pattern.lastIndex = 0 before each exec() loop, or use String.match() instead of pattern.exec()"}
{"id": "PERF-HOOK-010", "file": ".claude/hooks/repository-pattern-check.js", "issue": "Iterates through component file line-by-line checking regex patterns for every Firestore method", "impact": "slow .tsx edits. O(n * m) complexity where n=lines, m=method patterns (14 methods). No early exit per line", "severity": "S2", "recommendation": "Use single regex with alternation: /\\b(collection|doc|query|getDocs|...)/g instead of looping methods. Early exit after first match per line"}
{"id": "PERF-HOOK-011", "file": ".claude/hooks/typescript-strict-check.js", "issue": "Iterates all lines checking 5 regex patterns for any type - O(n*5) complexity per .ts file", "impact": "slow typescript edits. Each line checked against 5 ANY_PATTERNS without combining patterns", "severity": "S2", "recommendation": "Combine into single regex: /:\\s*any(?:\\s*[;,)\\]}]|\\s*$)|(\\s+as\\s+any|<any>|any\\[\\])/  to avoid repeated iteration"}
{"id": "PERF-HOOK-012", "file": ".claude/hooks/auto-save-context.js", "issue": "Uses execSync child process operations for context preservation - blocking subprocess calls", "impact": "slow reads. Blocks for git operations when saving context to MCP memory", "severity": "S3", "recommendation": "Make context save async via Promise.all() with execFile. Defer to next idle moment, don't block user operations"}
{"id": "PERF-HOOK-013", "file": ".claude/hooks/check-remote-session-context.js", "issue": "Runs multiple git commands via execFileSync sequentially - blocking subprocess calls in series", "impact": "slow session start. git fetch, git branch -r, git show all block in sequence", "severity": "S2", "recommendation": "Parallelize git commands: git fetch + git branch -r in parallel, then sequential git show only if needed. Add timeout <30s total"}
{"id": "PERF-HOOK-014", "file": ".claude/hooks/session-start.js", "issue": "execSync commands lack uniform timeout settings - some commands may hang indefinitely", "impact": "slow session startup. npm install, build, test commands can hang if subprocess has issues", "severity": "S2", "recommendation": "Add timeout parameter to all execSync calls. Default 120s for install/build, 30s for checks. Kill process if timeout exceeded"}
{"id": "PERF-HOOK-015", "file": ".claude/hooks/analyze-user-request.js", "issue": "Loops through 7 priority categories with word matching - no early return on first match", "impact": "slow on user prompts. Continues checking all patterns even after security pattern matches (should exit early)", "severity": "S3", "recommendation": "Add early return in priority order. Return immediately after finding first match in security check instead of continuing to lower priorities"}
{"id": "PERF-HOOK-016", "file": ".claude/hooks/alerts-reminder.js", "issue": "Reads 5 separate JSON files on every UserPromptSubmit (PostToolUse) - multiple synchronous fs.readFileSync calls", "impact": "slow prompt submission. Adds 50-100ms per user message just to read state files", "severity": "S2", "recommendation": "Cache alerts and context in memory. Only refresh from disk on first read and every 30 seconds, not on every prompt"}
{"id": "PERF-HOOK-017", "file": ".claude/hooks/decision-save-prompt.js", "issue": "Loops through SIGNIFICANT_KEYWORDS (18 items) for every question with .some() - no string index optimization", "impact": "moderate on decisions. O(n*m) where n=questions, m=keywords. No compiled pattern or trie structure", "severity": "S3", "recommendation": "Compile keyword set into single regex /\\b(architecture|design|...)/i for one-pass matching instead of .some() loop"}
{"id": "PERF-HOOK-018", "file": ".claude/hooks/plan-mode-suggestion.js", "issue": "Checks 7 implementation keywords and 14 complexity indicators separately - duplicated pattern compilation", "impact": "moderate on long prompts (>50 words). Two separate filter operations on keyword/pattern arrays", "severity": "S3", "recommendation": "Combine keyword checks into single compiled regex. Use && operator for short-circuit evaluation instead of separate checks"}
{"id": "PERF-HOOK-019", "file": ".claude/hooks/stop-serena-dashboard.js", "issue": "Spawns PowerShell (Windows) or execFileSync(lsof) for process lookup - heavyweight subprocess overhead", "impact": "slow session startup on Windows. PowerShell startup time ~500ms, execFileSync lsof ~100ms on Unix", "severity": "S2", "recommendation": "Use native Node.js library like pidof-node or process-list. Cache recent PIDs to avoid repeated lookups within 30s"}
{"id": "PERF-HOOK-020", "file": ".claude/hooks/stop-serena-dashboard.js", "issue": "Polls process existence in 250ms intervals with Atomics.wait - inefficient polling loop for 5s timeout", "impact": "slow process termination. 5s timeout with 250ms intervals = 20 iterations with blocking wait", "severity": "S3", "recommendation": "Use platform-specific event APIs: inotify on Linux, FSEvents on macOS, WaitForSingleObject on Windows. Or reduce poll interval to 100ms max"}
{"id": "PERF-HOOK-021", "file": ".claude/hooks/audit-s0s1-validator.js", "issue": "Parses JSONL line-by-line without streaming - loads entire file into memory via split() then parses each line", "impact": "slow on large audit files. Memory scales with file size (10MB file = significant memory overhead)", "severity": "S2", "recommendation": "Stream JSONL parsing using readline module for line-by-line reading without loading entire file into memory"}
{"id": "PERF-HOOK-022", "file": ".claude/hooks/audit-s0s1-validator.js", "issue": "Validates against 7+ Set collections and 2+ regex patterns for every S0/S1 finding - repeated validation checks", "impact": "moderate on large audits. O(n*m) validation where n=findings, m=validation types. No caching", "severity": "S3", "recommendation": "Compile validation into single pass with combined logic. Cache compiled patterns outside finding loop for reuse"}
{"id": "PERF-HOOK-023", "file": ".claude/hooks/track-agent-invocation.js", "issue": "Uses atomic write pattern with temp files (write to .tmp then rename) - doubles filesystem operations", "impact": "slow agent tracking. Adds 2 syscalls (write + rename) for every agent invocation to ensure atomicity", "severity": "S3", "recommendation": "Use writeFile with atomic flag if available. For this low-risk state, skip atomic write or cache in memory with periodic flush"}
{"id": "PERF-HOOK-024", "file": ".claude/hooks/session-start.js", "issue": "Runs console.log for every build step sequentially - unbuffered output causes synchronization overhead", "impact": "slow session startup visually. Console.log formatting and synchronization overhead compounds over many steps", "severity": "S3", "recommendation": "Buffer output and log once after all steps complete, or use single progress indicator instead of per-step console.log"}
{"id": "PERF-HOOK-025", "file": ".claude/hooks/check-mcp-servers.js", "issue": "Reads and parses JSON file on every SessionStart - no caching across sessions", "impact": "moderate on session startup. MCP server list parsed every time even if .mcp.json unchanged", "severity": "S3", "recommendation": "Cache server names in memory per session. Only refresh if .mcp.json mtime newer than cached version"}
{"id": "PERF-CI-001", "file": ".github/workflows/ci.yml", "issue": "Missing Next.js build cache in build job", "impact": "slow CI - build job recomputes from scratch every run (est. 60-90 seconds per build)", "severity": "S2", "recommendation": "Add 'actions/cache@v4' with key for .next directory. Cache key: 'nextjs-build-${{ hashFiles('**/package-lock.json') }}-${{ github.ref }}'. Restore keys: ['nextjs-build-', 'nextjs-']. Paths: '.next/cache'"}
{"id": "PERF-CI-002", "file": ".github/workflows/ci.yml", "issue": "npm install dependencies cached but not TypeScript compilation cache", "impact": "slow CI - tsc --noEmit recompiles all files (est. 30-45 seconds)", "severity": "S3", "recommendation": "Add cache for tsc output. Use actions/cache with key 'tsc-cache-${{ hashFiles('**/tsconfig.json', '**/package-lock.json') }}' and restore-keys pattern. Preserve tsconfig.tsbuildinfo if present."}
{"id": "PERF-CI-003", "file": ".github/workflows/ci.yml", "issue": "Test build and coverage recompile TypeScript each run - no artifact reuse between test:build and test:coverage", "impact": "wasted resources - tsc runs twice for test compilation (est. 30-45 seconds duplicated)", "severity": "S2", "recommendation": "Refactor test:build into separate 'Build Tests' step that caches dist-tests/ output. Share compiled artifacts between test and test:coverage steps. Use actions/cache or upload-artifact for dist-tests/."}
{"id": "PERF-CI-004", "file": ".github/workflows/ci.yml", "issue": "Build job depends on lint-typecheck-test (sequential), but could run in parallel on different runners", "impact": "slow CI - critical path extends by full lint time (est. 2-3 minutes added latency)", "severity": "S2", "recommendation": "Remove 'needs: lint-typecheck-test' from build job. Run both jobs in parallel. Add separate 'lint-gates' job that blocks on 'build' completion to ensure quality gates pass before merge."}
{"id": "PERF-CI-005", "file": ".github/workflows/ci.yml", "issue": "Coverage artifact retention set to 14 days (default), but never used in CI", "impact": "wasted resources - coverage artifacts consume storage for 2 weeks without value", "severity": "S3", "recommendation": "Reduce retention-days to 1 (or set on-demand). Or integrate into SonarCloud upload step to automatically delete local after upload. Consider generating HTML reports and uploading to GitHub Pages instead."}
{"id": "PERF-CI-006", "file": ".github/workflows/ci.yml", "issue": "Pattern compliance check runs changed-files action, but requires full git checkout - no shallow clone", "impact": "slow CI - unnecessary bandwidth for full history (est. 10-15 seconds saved)", "severity": "S3", "recommendation": "Add 'fetch-depth: 0' only for 'push to main' case. For PR, use shallow clone (fetch-depth: 1) and get changed-files from github.event.pull_request context instead of git diff."}
{"id": "PERF-CI-007", "file": ".github/workflows/deploy-firebase.yml", "issue": "Next.js build lacks persistent .next cache - rebuilds on every deployment", "impact": "slow CI - deployment adds 60-90 seconds for redundant build (est. 5-7 minutes per deploy)", "severity": "S2", "recommendation": "Add actions/cache@v4 for .next/ before 'Build Next.js app' step. Use same cache key strategy as ci.yml build job. Also enable incremental builds with 'NEXT_INCREMENTAL_BUILD=1' env var."}
{"id": "PERF-CI-008", "file": ".github/workflows/deploy-firebase.yml", "issue": "Functions build recompiles TypeScript from scratch - no tsc cache", "impact": "slow CI - functions tsc compilation (est. 15-25 seconds per deploy)", "severity": "S3", "recommendation": "Add cache for functions/lib/ (compiled output). Cache key: 'tsc-functions-${{ hashFiles('functions/tsconfig.json', 'functions/package-lock.json') }}'. Also add '--incremental' flag to functions/tsconfig.json."}
{"id": "PERF-CI-009", "file": ".github/workflows/deploy-firebase.yml", "issue": "Two separate package-lock.json caches (root + functions/) but resolved after root install completes", "impact": "wasted resources - sequential npm ci (can parallelize)", "severity": "S2", "recommendation": "Install root and functions dependencies in parallel using 'npm install' in background job or split into separate jobs with '&'. Or use monorepo tool (npm workspaces) to install both with single 'npm ci' pass."}
{"id": "PERF-CI-010", "file": ".github/workflows/docs-lint.yml", "issue": "No early exit for files with no markdown changes - still runs changed-files action", "impact": "slow CI - unnecessary git operations (est. 5-10 seconds)", "severity": "S3", "recommendation": "Add early 'Check if markdown files changed' step that exits with 0 immediately if no *.md files changed. Use 'if: steps.check.outputs.has_md_changes != 'true'' for later steps."}
{"id": "PERF-CI-011", "file": ".github/workflows/review-check.yml", "issue": "Full npm ci required just for Node.js environment to run single script - no caching for this workflow", "impact": "wasted resources - installing all deps (120+ packages) takes est. 30-40 seconds for lightweight script", "severity": "S2", "recommendation": "Add 'cache: npm' to setup-node step. Consider splitting scripts to run without full node_modules (use tsx/node directly on single file). Or cache node_modules explicitly with actions/cache."}
{"id": "PERF-CI-012", "file": ".github/workflows/auto-label-review-tier.yml", "issue": "No cache: npm in setup-node, requires full npm ci even though script is lightweight", "impact": "wasted resources - node_modules install takes est. 30-40 seconds for simple file pattern matching", "severity": "S2", "recommendation": "Add 'cache: npm' to setup-node step. Script could run without deps - consider reducing scope or using shell-native tools."}
{"id": "PERF-CI-013", "file": ".github/workflows/sonarcloud.yml", "issue": "No fail-fast or timeout for SonarCloud analysis - can hang or run indefinitely if token fails", "impact": "slow CI - SonarCloud can block PR for hours if service is slow (est. 15-30 min typical)", "severity": "S2", "recommendation": "Add 'timeout-minutes: 30' to job. Add explicit error handling and retry logic. Set SONARCLOUD_TIMEOUT env var if supported. Consider skipping for non-main branches in fork PRs (already done but no timeout)."}
{"id": "PERF-CI-014", "file": ".github/workflows/backlog-enforcement.yml", "issue": "Backlog check job runs without npm cache even though it uses npm ci and node script", "impact": "wasted resources - est. 30-40 seconds per backlog check for install + script", "severity": "S2", "recommendation": "Add 'cache: npm' to setup-node step. Security patterns job also missing cache. Both workflows should use '--prefer-offline --no-audit --no-fund' flags (already in backlog job) but need cache enabled."}
{"id": "PERF-SCRIPT-001", "file": "scripts/debt/dedup-multi-pass.js", "lines": "302-410", "issue": "O(n²) Nested Loops in Deduplication - All four deduplication passes use nested loops comparing every item with every other item", "impact": "slow execution - Each pass runs O(n²) comparisons. With 1000+ items, creates 500k+ comparisons", "severity": "S2", "recommendation": "Pre-bucket items by file/category before comparing to reduce comparison set size"}
{"id": "PERF-SCRIPT-002", "file": "scripts/debt/dedup-multi-pass.js", "lines": "91-161", "issue": "stringSimilarity() calls levenshtein() which runs O(m*n) matrix operations for every pair without memoization", "impact": "slow execution - Levenshtein distance recalculated identically for same title pairs across Pass 2, 3, and 4", "severity": "S2", "recommendation": "Cache similarity results in a Map with key '${a.title}|${b.title}'"}
{"id": "PERF-SCRIPT-003", "file": "scripts/debt/normalize-all.js", "lines": "152-170", "issue": "Synchronous file reads in loop - fs.readFileSync for each file in sequence, not parallelized", "impact": "slow execution - Waits for each file I/O to complete before starting the next, blocking event loop", "severity": "S3", "recommendation": "Use Promise.all() with fs.promises.readFile() for parallel reads"}
{"id": "PERF-SCRIPT-004", "file": "scripts/aggregate-audit-findings.js", "lines": "1489-1512", "issue": "Large array built via repeated .push() then JSON.stringify().join() - creates many intermediate strings", "impact": "memory pressure - Each JSON.stringify creates temp string, then join() creates another. With 5000+ findings doubles memory", "severity": "S3", "recommendation": "Use streaming writes or write in chunks for large datasets"}
{"id": "PERF-SCRIPT-005", "file": "scripts/aggregate-audit-findings.js", "lines": "202", "issue": ".includes() in loop for array search creates O(n²) complexity with roadmapByDescription.get().some()", "impact": "slow execution - For 200+ roadmap items with synonym expansion, each word check scans the full list", "severity": "S3", "recommendation": "Use Set instead of array: const roadmapSet = new Set(roadmapByDescription.get(word).map(i => i.id)) then check with .has()"}
{"id": "PERF-SCRIPT-006", "file": "scripts/check-pattern-compliance.js", "lines": "713-742", "issue": "Global regex with /g flag in findPatternMatches() function - exec() in loop has stateful lastIndex", "impact": "slow execution|potential bugs - /g flag maintains state, fragile when pattern reused across files", "severity": "S2", "recommendation": "Clone regex on each file check or use String.match() instead of pattern.exec()"}
{"id": "PERF-SCRIPT-007", "file": "scripts/debt/generate-views.js", "lines": "214-223", "issue": "Repeated field filtering without caching - builds bySeverity, byCategory, byStatus by iterating items 3 times separately", "impact": "slow execution - O(3n) instead of O(n). With 5000 items, unnecessary 10k additional iterations", "severity": "S3", "recommendation": "Combine into single loop that populates all three maps in one pass"}
{"id": "PERF-SCRIPT-008", "file": "scripts/check-pattern-compliance.js", "lines": "587-639", "issue": "Glob pattern too broad - walk() traverses entire repo including node_modules/.next before hitting ignore checks", "impact": "slow execution - Unnecessary directory traversals before ignore checks at line 615", "severity": "S3", "recommendation": "Check for ignore directories BEFORE recursing: if (ignoreDirs.includes(entry)) continue before lstat.isDirectory()"}
{"id": "PERF-SCRIPT-009", "file": "scripts/aggregate-audit-findings.js", "lines": "1141", "issue": "Array Index Lookup in Loop - .filter((v, i, a) => a.indexOf(v) === i) classic O(n²) dedup pattern", "impact": "slow execution - indexOf() scans from start each time for evidence array deduplication", "severity": "S3", "recommendation": "Use Set: [...new Set(evidence)] instead of .filter((v, i, a) => a.indexOf(v) === i)"}
{"id": "PERF-SCRIPT-010", "file": "scripts/debt/dedup-multi-pass.js", "lines": "219-231", "issue": "Synchronous JSON Parse without streaming - reads entire file then splits by newlines and parses each", "impact": "slow execution|memory pressure - Full file in memory, all lines parsed, invalid ones discarded. No streaming or early exit", "severity": "S2", "recommendation": "For large files (>50MB), use streaming parser or chunk-based processing"}
