{"id": "OPT-F001", "category": "format", "severity": "S1", "effort": "E2", "title": "ROADMAP.md milestone tracking tables", "description": "ROADMAP.md contains 270 lines of markdown tables tracking milestones, status, progress %, phases, and priorities. Large structure with frequent updates during sprint work.", "file": "/home/user/sonash-v0/ROADMAP.md", "currentState": "Markdown tables: Milestones Overview (86-100), Progress tracking, status fields, metadata headers", "recommendation": "Extract milestone data to milestones.jsonl with schema: {id, name, status, progress, phase, priority, items, relatedDocs}. Keep ROADMAP.md as narrative + embedded reference. Add npm script to sync ROADMAP.md from milestones.jsonl.", "impact": "tokens|speed", "evidence": "Sprint-focused: SESSION_CONTEXT.md reads ROADMAP.md to extract current priorities; scripts/velocity/track-session.js uses readFileSync on markdown; updated almost every session (Session #156 is latest); 270 table rows parsing fragile to formatting changes"}
{"id": "OPT-F002", "category": "format", "severity": "S1", "effort": "E2", "title": "AUDIT_TRACKER.md audit log tables", "description": "AUDIT_TRACKER.md contains 96 table rows tracking audit completion dates, commits covered, findings, and threshold reset status across 7 audit categories. Updated after each audit cycle (Session #143 shows 258 findings).", "file": "/home/user/sonash-v0/docs/AUDIT_TRACKER.md", "currentState": "Markdown tables: Current Thresholds (46-55), Single-Session Audit Log (80-138), Multi-AI Audit Log (150-159), Master Issue Aggregation (165-170)", "recommendation": "Extract to audits.jsonl with schema: {auditType, date, session, commitsCount, filesCount, findingsRaw, findingsUnique, findingsBySeverity, resetThreshold, relatedFile}. Create views by category and date for faster querying.", "impact": "tokens|speed|accuracy", "evidence": "Directly queried by audit workflow; Expansion Evaluation Tracker cross-references audit status; Manual table maintenance error-prone (Session #116 showed date misalignment that had to be fixed); thresholds reset frequently"}
{"id": "OPT-F003", "category": "format", "severity": "S1", "effort": "E3", "title": "EXPANSION_EVALUATION_TRACKER.md decision log with 280 ideas", "description": "Tracks evaluation of ~280 expansion ideas across 21 modules (F1-F12, T1-T9) with decision logs, placement metadata, milestone assignments, insertion points, and relationships. Complex multi-session tracking document.", "file": "/home/user/sonash-v0/docs/EXPANSION_EVALUATION_TRACKER.md", "currentState": "Markdown with embedded decision logs, placement metadata (Placement, Insert After, Relationship fields) for ~85 items staged for ROADMAP. Quick Resume section summarizes status.", "recommendation": "Extract decisions to decisions.jsonl with schema: {moduleId, ideaNum, title, decision, rationale, milestone, insertAfter, relationship, stagedDate, decidedInSession, tags}. Keep EXPANSION_EVALUATION_TRACKER.md as UI summary with aggregates. AI processes decisions.jsonl directly.", "impact": "tokens|speed|accuracy", "evidence": "AI-intensive: /expansion-evaluation skill reads/writes this document; 280 items across 21 modules creates parsing overhead; Session #152 shows merging of IMS into TDMS \u2014 cross-document sync required; placement metadata mandatory for all items but stored inline as prose"}
{"id": "OPT-F004", "category": "format", "severity": "S1", "effort": "E2", "title": "AUDIT_TRACKER.md threshold matrix and version history", "description": "Contains 2 tables tracking threshold configuration (46 rows) and version history (12 rows). Thresholds reset after each audit; version history appended frequently.", "file": "/home/user/sonash-v0/docs/AUDIT_TRACKER.md", "currentState": "Markdown tables: Single-Session Thresholds (lines 46-55), Multi-AI Thresholds (59-63), Version History (242-260)", "recommendation": "Extract to thresholds.jsonl and versions.jsonl. Thresholds schema: {category, lastAudit, commitsSince, filesSince, triggerAt, resetScript}. Allows automation of threshold checks via npm scripts. Version history is append-only log.", "impact": "speed|tokens", "evidence": "scripts/reset-audit-triggers.js manipulates thresholds but reads from markdown; Manual table updates (Session #143 added new category; Session #152 merged IMS); Version history now 260+ lines"}
{"id": "OPT-F005", "category": "format", "severity": "S2", "effort": "E2", "title": "DOCUMENT_DEPENDENCIES.md sync status tracking", "description": "Tracks 43 rows of template-instance relationships, sync status, and last-synced dates. Manual sync protocol requires regex parsing to detect drift (placeholder detection patterns).", "file": "/home/user/sonash-v0/docs/DOCUMENT_DEPENDENCIES.md", "currentState": "Markdown tables: Template\u2192Instance Relationships (62-95), Sync Protocols description, Automated Validation script references, Manual Validation section (192-205)", "recommendation": "Extract to doc-sync-status.jsonl with schema: {templatePath, instancePath, lastSynced, syncStatus, driftDetected, issuesFound}. Enhance scripts/check-document-sync.js to read/write this file. Enables automated validation with clear history.", "impact": "tokens|speed|accuracy", "evidence": "scripts/check-document-sync.js (Session #35) validates sync status using regex patterns; >90 day staleness checks require parsing markdown dates; Session #140 removed 6 archived instances \u2014 requires manual table cleanup; Session #144 shows drift detection complexity"}
{"id": "OPT-F006", "category": "format", "severity": "S2", "effort": "E1", "title": "SESSION_CONTEXT.md quick status table", "description": "Contains 8-row status tracking table (lines 118-128) for track status (Operational Visibility, Track A/B/C, GRAND PLAN, milestones). Updated frequently at session start/end.", "file": "/home/user/sonash-v0/SESSION_CONTEXT.md", "currentState": "Markdown table: Quick Status (118-128) with Item, Status, Progress columns. 8 rows updated every session.", "recommendation": "Extract to session-status.jsonl with schema: {item, status, progress, percent, lastUpdated, session}. Keep SESSION_CONTEXT.md <300 lines (current instruction). Allow automated session startup to read/write status atomically.", "impact": "speed|tokens", "evidence": "SESSION_CONTEXT.md reads during every session (Session #156 latest); scripts/velocity/track-session.js explicitly reads this file via readFileSync; frequent updates (Session-to-session); 8 rows \u00d7 156 sessions = massive token overhead"}
{"id": "OPT-F007", "category": "format", "severity": "S2", "effort": "E2", "title": "DOCUMENT_DEPENDENCIES.md cross-document update triggers matrix", "description": "48-row trigger matrix (lines 309-342) mapping document changes to dependent documents. Used to coordinate cross-document sync but stored as markdown table.", "file": "/home/user/sonash-v0/docs/DOCUMENT_DEPENDENCIES.md", "currentState": "Markdown table: 48 rows with When/Check These/Reason/Enforced columns. Manual lookup during document editing.", "recommendation": "Extract to doc-triggers.jsonl with schema: {sourceDoc, triggerCondition, targetDocs[], reason, enforced, blockingLevel}. Integrate into pre-commit hook to auto-warn on dependent document changes (currently 'Manual' enforcement in 35/48 rows).", "impact": "speed|accuracy", "evidence": "Session #152 shows IMS merged into TDMS requiring widespread trigger updates; only 2/48 triggers are \u2705 BLOCK enforced; 35 are Manual enforcement = high error rate; Pre-commit hook currently doesn't use this matrix"}
{"id": "OPT-F008", "category": "format", "severity": "S2", "effort": "E2", "title": "ROADMAP.md detailed milestone specifications embedded", "description": "ROADMAP.md contains narrative milestone details mixed with data (status, progress %, priority, items count). Detailed specifications for M1.5-M10 hardcoded inline with dependency references.", "file": "/home/user/sonash-v0/ROADMAP.md", "currentState": "Markdown text: Milestone sections (100+) with embedded metadata, task lists, dependencies marked inline. Hard to diff, refactor, or cross-reference programmatically.", "recommendation": "Create milestones-detail.jsonl with schema: {milestoneId, phase, priority, description, itemCount, dependencies[], risks[], successCriteria[], dependencies}. ROADMAP.md becomes curated narrative referencing milestones.jsonl data via embedded tables regenerated from data.", "impact": "tokens|speed|accuracy", "evidence": "Session #151 shows ROADMAP_FUTURE.md manually split from ROADMAP.md; ROADMAP.md is 3164 lines, heavily cross-referenced; Expansion Evaluation Tracker references placement in ROADMAP but can't parse it reliably; dependencies[].blockedBy structure suggests structured data buried in prose"}
{"id": "OPT-F009", "category": "format", "severity": "S2", "effort": "E1", "title": "PR_WORKFLOW_CHECKLIST.md version history table", "description": "Version history table (lines 443-447) tracking 3 versions with dates and changes. Append-only log stored as markdown.", "file": "/home/user/sonash-v0/docs/PR_WORKFLOW_CHECKLIST.md", "currentState": "Markdown table: Version, Date, Changes, Author. 3 versions documented (2.0, 1.1, 1.0).", "recommendation": "Extract to doc-versions.jsonl (append-only) with schema: {doc, version, date, changes, author}. All documentation version history consolidates to single source. Enables automated change tracking per document.", "impact": "tokens", "evidence": "Every document has version history table (PR_WORKFLOW_CHECKLIST.md, DOCUMENT_DEPENDENCIES.md, SESSION_CONTEXT.md, PLAN_MAP.md show pattern); Manual maintenance; Lines 240-260+ in many docs; Could be centralized"}
{"id": "OPT-F010", "category": "format", "severity": "S2", "effort": "E2", "title": "EXPANSION_EVALUATION_TRACKER.md command reference table", "description": "Command reference table (lines 81-99) documenting 11 commands with descriptions. Static reference data embedded as markdown.", "file": "/home/user/sonash-v0/docs/EXPANSION_EVALUATION_TRACKER.md", "currentState": "Markdown table: Command, Description, Parameters. Documents /expansion-evaluation sub-commands and decision actions.", "recommendation": "Extract to .claude/skills/expansion-evaluation/commands.jsonl with schema: {command, subcommands[], parameters, description, example}. Centralize skill command documentation to single source; .claude/COMMAND_REFERENCE.md references it.", "impact": "tokens", "evidence": "Duplicated in COMMAND_REFERENCE.md (Session #140 update adds expansion-evaluation skill); Single source of truth in skills/ directory reduces cross-sync burden; Complex sub-command taxonomy (accept/defer/reject/merge/discuss)"}
{"id": "OPT-F011", "category": "format", "severity": "S3", "effort": "E1", "title": "SESSION_CONTEXT.md recent session summaries", "description": "3 session summaries (lines 82-112) capturing major work completed. Append-only archive with manual rotation to SESSION_HISTORY.md every session.", "file": "/home/user/sonash-v0/SESSION_CONTEXT.md", "currentState": "Markdown text: Session #155-153 summaries with bullet-point work items. Instructions say 'keep last 3 sessions, archive older to SESSION_HISTORY.md'.", "recommendation": "Extract to session-summaries.jsonl with schema: {sessionNum, date, title, workItems[], impact, nextSteps}. SESSION_CONTEXT.md reads latest 3 automatically. /session-end skill handles archive rotation. Centralize all session history.", "impact": "tokens", "evidence": "Manual rotation (Session #149 shows archival from SESSION_CONTEXT to SESSION_HISTORY); 3-session limit = rotating window; /session-end explicitly handles this archival step; Could be automated"}
{"id": "OPT-F012", "category": "format", "severity": "S3", "effort": "E1", "title": "PLAN_MAP.md version history table", "description": "Version history table (lines 228-242) tracking 14 versions. Append-only log with dates, descriptions, authors.", "file": "/home/user/sonash-v0/docs/PLAN_MAP.md", "currentState": "Markdown table: 14 version entries from 2026-02-12 back to 2026-01-20. Version, Date, Description, Author columns.", "recommendation": "Extract to doc-versions.jsonl (see OPT-F009 for consolidation). PLAN_MAP.md can remove version history table entirely.", "impact": "tokens", "evidence": "All 30+ markdown files have version history tables; Centralized version tracking reduces duplication; Could be auto-generated from git history"}
{"id": "OPT-F013", "category": "format", "severity": "S3", "effort": "E2", "title": "AI_REVIEW_LEARNINGS_LOG.md large append-only learning journal (317KB)", "description": "Large document (1587 lines, 317KB) containing review-level learning entries. Used by /pr-review skill but stored as markdown prose without structured extraction.", "file": "/home/user/sonash-v0/docs/AI_REVIEW_LEARNINGS_LOG.md", "currentState": "Markdown document with 'Review #NNN' sections containing narrative learnings, patterns, decisions. Searchable via grep but not structured for querying.", "recommendation": "Parallel reviews.jsonl with schema: {reviewNum, prNum, date, category, finding, rationale, pattern, linkedDocs[], status}. Keep AI_REVIEW_LEARNINGS_LOG.md as human-readable summary; skill reads from structured reviews.jsonl for automation.", "impact": "tokens|speed|accuracy", "evidence": "Scripts/add-false-positive.js references AI_REVIEW_LEARNINGS_LOG.md#review-NNN format in comments; Session #142 shows learnings being added; /pr-review skill processes learnings; 317KB markdown = massive token cost when read into context; Narrative prose harder to aggregate/cross-reference than structured data"}
{"id": "OPT-F014", "category": "format", "severity": "S3", "effort": "E1", "title": "ROADMAP_LOG.md completed items history (31KB, 1,129 lines)", "description": "Archive of completed milestones and features in markdown. Append-only log with dates, completion summaries, version history.", "file": "/home/user/sonash-v0/ROADMAP_LOG.md", "currentState": "Markdown: Completed milestones M0-M1, historical entries with dates, narrative descriptions of what was completed.", "recommendation": "Create roadmap-history.jsonl (append-only) with schema: {completedItem, completedDate, milestone, summary, session, commits, impact}. ROADMAP_LOG.md becomes human-readable narrative referencing jsonl data. Allows automated timeline generation.", "impact": "tokens", "evidence": "1129 lines of append-only history; Used as reference for context but rarely updated (append-only); Could be auto-generated from milestone completion dates + commit history"}
{"id": "OPT-S001", "category": "dead-script", "severity": "S2", "effort": "E0", "title": "ai-review.js - Unused AI review prompt applicator", "description": "Script applies specialized AI review prompts to different artifact types. Despite having security features (sensitive file detection), it is never invoked from package.json, workflows, hooks, skills, or documentation. Only historical archive references exist in REVIEWS_42-60.md.", "file": "/home/user/sonash-v0/scripts/ai-review.js", "currentState": "407 lines of functional code with --type and --staged CLI flags defined but unreachable", "recommendation": "Either add npm script entry or remove. If planned for future AI-driven reviews, add to DEVELOPMENT.md with clear invocation pattern.", "impact": "tokens", "evidence": "Not found in package.json, .claude/settings.json, .github/workflows/*.yml, .husky/*, or skill references. Only archive mentions of past security reviews."}
{"id": "OPT-S002", "category": "dead-script", "severity": "S3", "effort": "E0", "title": "check-review-triggers.sh - Dead shell script for multi-AI triggers", "description": "Bash script checks git commit/file counts to determine if code review triggers are active. Appears to duplicate functionality of check-triggers.js (which IS referenced in package.json). Script prints colored output to console but has no output targets.", "file": "/home/user/sonash-v0/scripts/check-review-triggers.sh", "currentState": "Functional bash script with color-coded trigger detection logic, never invoked", "recommendation": "Remove in favor of the active check-triggers.js npm script. Consolidate shell logic into Node.js for consistency.", "impact": "tokens", "evidence": "check-triggers.js is referenced in package.json as 'npm run triggers:check'. This .sh file is never called from any configuration or workflow."}
{"id": "OPT-S003", "category": "dead-script", "severity": "S2", "effort": "E1", "title": "create-canonical-findings.js - Unused canonical findings generator", "description": "Script converts net-new findings from docs/aggregation/net-new-findings.jsonl into canonical format with ROADMAP placement mapping. References deprecated ROADMAP_INTEGRATION logic. 340 lines with clear purpose but never executed.", "file": "/home/user/sonash-v0/scripts/create-canonical-findings.js", "currentState": "Complete implementation that reads net-new aggregated findings and writes to MASTER_FINDINGS.jsonl", "recommendation": "Add to package.json scripts if part of audit pipeline (e.g., 'npm run canon:create'), or consolidate into aggregate-audit-findings.js workflow. Currently blocks on file that depends on aggregate-audit-findings.js output.", "impact": "tokens", "evidence": "Referenced in no npm scripts, workflows, or hooks. audit/validate-audit-integration.js mentions 'aggregate-audit-findings.js' but not create-canonical-findings.js."}
{"id": "OPT-S004", "category": "dead-script", "severity": "S2", "effort": "E0", "title": "generate-pending-alerts.js - Unused session-start alert generator", "description": "Script scans AI_REVIEW_LEARNINGS_LOG.md and AUDIT_FINDINGS_BACKLOG.md for DEFERRED/S1+ items to write pending-alerts.json for Claude session start. Functional but never called. Depends on legacy backlog files (now archived to MASTER_DEBT.jsonl).", "file": "/home/user/sonash-v0/scripts/generate-pending-alerts.js", "currentState": "Scans 3 sources (learnings log, backlog, hook warnings) to generate .claude/pending-alerts.json, references archived backlog", "recommendation": "Either add to session-start hook or remove. If needed for alerts, update file paths to use MASTER_DEBT.jsonl instead of archived AUDIT_FINDINGS_BACKLOG.md.", "impact": "tokens", "evidence": "Not referenced in package.json, workflows, or .claude/settings.json hooks. Mentioned in skill markdown but not as actual command invocation."}
{"id": "OPT-S005", "category": "dead-script", "severity": "S3", "effort": "E1", "title": "generate-placement-report.js - Unused roadmap placement suggester", "description": "Reads net-new findings from docs/aggregation/net-new-findings.jsonl and generates roadmap placement suggestions in NET_NEW_ROADMAP_PLACEMENT.md. Depends on external file that may or may not exist. Complements create-canonical-findings.js.", "file": "/home/user/sonash-v0/scripts/generate-placement-report.js", "currentState": "86 lines reading net-new findings and categorizing by severity with ROADMAP placement metadata", "recommendation": "Remove or consolidate into create-canonical-findings.js. If placement suggestions are valuable, add explicit npm script and document workflow.", "impact": "speed", "evidence": "No references in any configuration, npm scripts, workflows, hooks, or documentation. Depends on aggregation pipeline output but has no consumer."}
{"id": "OPT-S006", "category": "dead-script", "severity": "S2", "effort": "E1", "title": "migrate-existing-findings.js - Unused legacy findings migration tool", "description": "One-time migration script to move ROADMAP findings to canonical location (docs/audits/canonical/MASTER_FINDINGS.jsonl). References obsolete file structures (REFACTOR_BACKLOG.md). Clear one-off purpose but permanently left in codebase.", "file": "/home/user/sonash-v0/scripts/migrate-existing-findings.js", "currentState": "~100+ lines of migration logic for Session #116 canonicalization project, no ongoing use case", "recommendation": "Move to docs/archive/scripts/ or remove entirely. One-time migration utilities should be archived after successful migration to prevent accidental re-runs.", "impact": "tokens", "evidence": "Never called from npm scripts, workflows, or hooks. Clear 'Session #116' marker indicates one-time use."}
{"id": "OPT-S007", "category": "dead-script", "severity": "S3", "effort": "E2", "title": "redeploy-admin-dashboard.sh - Firebase deployment helper for admin functions", "description": "Shell script for deleting and redeploying admin dashboard Cloud Functions (adminHealthCheck, adminGetDashboardStats) to ensure clean App Check configuration. Hardcoded to 'sonash-app' Firebase project. 20 lines.", "file": "/home/user/sonash-v0/scripts/redeploy-admin-dashboard.sh", "currentState": "Functional deployment script with hardcoded project name 'sonash-app', no way to invoke except manual execution", "recommendation": "Either parameterize Firebase project and add to npm scripts, or document as manual troubleshooting tool with clear prerequisites.", "impact": "speed", "evidence": "Not in package.json, workflows, .husky/, or any configuration. Appears to be manual maintenance script left behind after deployment debugging."}
{"id": "OPT-S008", "category": "dead-script", "severity": "S2", "effort": "E1", "title": "regenerate-findings-index.js - Unused canonical findings index rebuilder", "description": "Reads MASTER_FINDINGS.jsonl and regenerates MASTER_FINDINGS_INDEX.md with severity/category grouping. ~80 lines with clear, single-purpose functionality. Related to Session #116 canonicalization but never invoked in workflows.", "file": "/home/user/sonash-v0/scripts/regenerate-findings-index.js", "currentState": "Functional index generator that groups findings by severity and category with ROADMAP placement metadata", "recommendation": "Add to npm scripts (e.g., 'npm run canon:index') or consolidate into debt management workflow. If MASTER_FINDINGS.jsonl is auto-updated, add regenerate-findings-index to post-intake hooks.", "impact": "tokens", "evidence": "No references in package.json npm scripts, workflows, or hooks. Appears to be utility for canonical audit system that was never wired into automation."}
{"id": "OPT-S009", "category": "dead-script", "severity": "S3", "effort": "E0", "title": "seed-commit-log.js - One-time commit log backfill utility", "description": "One-time script to initialize .claude/state/commit-log.jsonl with recent git commits for commit tracking system. Self-documenting with clear 'only run once' semantics. Part of Session #138 state persistence setup.", "file": "/home/user/sonash-v0/scripts/seed-commit-log.js", "currentState": "Functional one-time backfill utility that checks for existing entries before overwriting, includes --force flag", "recommendation": "Document as one-time setup script in DEVELOPMENT.md or move to docs/setup/. No need to run again unless --force is used. Safe to leave but consider archiving.", "impact": "tokens", "evidence": "Not in npm scripts, workflows, or hooks. Self-identifies as 'one-time backfill utility' with guard against double-execution."}
{"id": "OPT-S010", "category": "dead-script", "severity": "S1", "effort": "E1", "title": "sync-claude-settings.js - Unused Claude Code settings synchronization utility", "description": "Syncs Claude Code settings between local ~/.claude/ and repository .claude/ for cross-platform portability. 508 lines with --export, --import, --diff flags. REFERENCED IN DOCUMENTATION but never called from automation. Listed in DEVELOPMENT.md table but not in package.json scripts. Users expected to run manually.", "file": "/home/user/sonash-v0/scripts/sync-claude-settings.js", "currentState": "Fully functional settings sync tool with path containment validation (Review #224) and selective key exclusion. Documented in DEVELOPMENT.md but not in npm scripts.", "recommendation": "Add npm script entry 'npm run settings:sync' with sensible default (--diff or --import). Or remove from codebase if manual invocation via 'node scripts/...' is sufficient. Currently confusing: documented but not in package.json scripts.", "impact": "accuracy", "evidence": "Referenced 3 times in DEVELOPMENT.md (lines mentioning '--import', '--export', '--diff') but NOT in package.json npm scripts section or any workflow/hook. Creates user confusion about how to invoke."}
{"id": "OPT-S011", "category": "dead-script", "severity": "S2", "effort": "E1", "title": "update-legacy-lines.js - Unused legacy findings line number updater", "description": "One-time script to backfill line numbers for legacy findings (DEDUP-XXXX, EFF-XXX, PERF-XXX, M-series IDs). Hardcoded mapping of 50+ finding IDs to file locations. Session #116 artifact, 100+ lines.", "file": "/home/user/sonash-v0/scripts/update-legacy-lines.js", "currentState": "Complete hardcoded mapping table for legacy finding line numbers, reads/writes MASTER_FINDINGS.jsonl", "recommendation": "Move to docs/archive/scripts/ or remove. One-time canonicalization utility with no ongoing use. If legacy findings are still updated, consolidate logic into update script.", "impact": "tokens", "evidence": "Not in any npm scripts, workflows, hooks. Hardcoded data suggests one-time execution completed in Session #116."}
{"id": "OPT-H001", "category": "hook", "severity": "S1", "effort": "E2", "title": "Write/Edit/MultiEdit share 8 redundant hooks (~530ms overhead)", "description": "Write, Edit, and MultiEdit tools execute nearly identical hook chains with 8 shared hooks (pattern-check, component-size-check, firestore-write-block, test-mocking-validator, app-check-validator, typescript-strict-check, repository-pattern-check, agent-trigger-enforcer). Only difference: Write uses check-write-requirements (test-first) vs Edit/MultiEdit use check-edit-requirements (security-first). This causes ~530ms latency on every file write operation.", "file": ".claude/settings.json", "currentState": "Write: 10 hooks, Edit: 9 hooks, MultiEdit: 9 hooks with 8 duplicated", "recommendation": "Consolidate to single validation pipeline with tool-aware conditional logic. Create unified hook that checks file type once, then runs all applicable validators in sequence. Reuse file content across validators instead of re-reading.", "impact": "speed", "evidence": "Analyzed hook array definitions in settings.json. Each of Write/Edit/MultiEdit has identical command chains except first hook. Total cumulative time: pattern-check(100ms) + typescript-strict(100ms) + agent-trigger(100ms) + repository-pattern(80ms) + app-check(60ms) + firestore-block(50ms) + test-mocking(30ms) + component-size(10ms) = ~530ms per operation"}
{"id": "OPT-H002", "category": "hook", "severity": "S0", "effort": "E1", "title": "pattern-check.js spawns subprocess every Write/Edit/MultiEdit (~100ms latency)", "description": "pattern-check.js runs spawnSync to execute scripts/check-pattern-compliance.js on EVERY Write/Edit/MultiEdit operation, adding 100ms latency. File has pre-filters (only runs on .js/.ts/.sh files >100 lines) but subprocess spawn is expensive. Non-blocking warning only.", "file": ".claude/hooks/pattern-check.js", "currentState": "Spawns subprocess via spawnSync with 30s timeout on every applicable write. Pre-filters on file extension and line count.", "recommendation": "Cache pattern checker state or use native regex validation for common patterns. Add session-level cache of recently-checked files. Skip re-validation on already-validated files this session. Consider moving to async hook if possible.", "impact": "speed", "evidence": "pattern-check.js lines 181-186 show spawnSync call. Combined with agent-trigger-enforcer (100ms) and typescript-strict-check (100ms), every Write/Edit now incurs 300ms just from these three hooks"}
{"id": "OPT-H003", "category": "hook", "severity": "S1", "effort": "E1", "title": "check-write-requirements vs check-edit-requirements duplication", "description": "Two nearly identical hooks with different priority orders. check-write-requirements (Write only) checks tests first, then security. check-edit-requirements (Edit/MultiEdit) checks security first. Both perform identical path validation and file classification but in different order. Adds 10ms overhead per tool call.", "file": ".claude/hooks/check-write-requirements.js, .claude/hooks/check-edit-requirements.js", "currentState": "Two separate 106-line scripts with ~95% identical code but different keyword priority order in lines 69-103", "recommendation": "Merge into single check-requirements.js hook that accepts tool parameter and applies correct priority. Use conditional branches for tool-specific behavior rather than duplicate files.", "impact": "tokens", "evidence": "Both files implement identical security validation (lines 40-68 in both), identical file parsing (lines 20-32 in both), but differ only in priority order (security-first vs test-first)"}
{"id": "OPT-H004", "category": "hook", "severity": "S2", "effort": "E2", "title": "agent-trigger-enforcer.js runs on every code file edit with double-write overhead", "description": "Runs on every Write/Edit/MultiEdit (100ms latency) to track file modifications and suggest agents. Loads config from disk every invocation. Uses double-write pattern: writes .claude/hooks/.agent-trigger-state.json AND potentially .claude/state/pending-reviews.json. Only matters for code files matching AGENT_TRIGGERS patterns, but runs unconditionally then does pattern matching.", "file": ".claude/hooks/agent-trigger-enforcer.js", "currentState": "Lines 189-321: reads state, increments counters, writes state file, then conditionally loads and writes review queue if code-reviewer agent applies. No early exit check for applicable agents before file I/O.", "recommendation": "Add early check for applicable agent patterns BEFORE reading state file. Cache AGENT_TRIGGERS config at hook initialization. Batch state writes: consolidate review queue write into single atomic operation instead of separate writeJson call.", "impact": "speed", "evidence": "Loads config at lines 34-43, reads state at line 189, writes at line 214, then reads/writes review queue at lines 258-321. For non-code files, could skip entire state read/write cycle."}
{"id": "OPT-H005", "category": "hook", "severity": "S2", "effort": "E2", "title": "Three Read hooks contend for .context-tracking-state.json state file", "description": "large-context-warning.js, auto-save-context.js, and compaction-handoff.js all read/write .claude/hooks/.context-tracking-state.json on every Read operation. Multiple hooks doing atomic writes (temp file + rename) creates contention and potential race conditions. State resets if >30 minutes old (large-context-warning line 98).", "file": ".claude/hooks/large-context-warning.js, .claude/hooks/auto-save-context.js, .claude/hooks/compaction-handoff.js", "currentState": "Each hook independently reads context-tracking-state.json, modifies it, and does atomic write. large-context-warning resets if stale (line 98). No coordination between hooks.", "recommendation": "Consolidate context tracking into single hook that: 1) reads state once, 2) updates all needed metrics, 3) writes once. Or create state-utils-based shared handler. Have large-context-warning handle reset logic for all three hooks.", "impact": "speed", "evidence": "large-context-warning: lines 92-131 (read/write cycle), auto-save-context: lines 107-113 (read filesRead), compaction-handoff: lines 242-248 (read filesRead). All three do their own atomic write operations"}
{"id": "OPT-H006", "category": "hook", "severity": "S2", "effort": "E1", "title": "State file sprawl across .claude/hooks/ and .claude/state/", "description": "10 separate state files created by hooks: 6 in .claude/hooks/ (.session-state, .context-tracking-state, .auto-save-state, .handoff-state, .commit-tracker-state, .agent-trigger-state) and 4 in .claude/state/ (handoff.json, pending-reviews.json, commit-log.jsonl, agent-invocations.jsonl). Some files only read/written by single hook (redundant). No schema documentation.", "file": ".claude/state/, .claude/hooks/", "currentState": "State files: .claude/hooks/.session-state.json (session-start, commit-tracker, compaction-handoff), .claude/hooks/.context-tracking-state.json (3 hooks), .claude/hooks/.auto-save-state.json (1 hook), .claude/hooks/.commit-tracker-state.json (1 hook), .claude/hooks/.handoff-state.json (1 hook), .claude/state/handoff.json (1 hook), .claude/state/pending-reviews.json (1 hook), .claude/state/commit-log.jsonl (1 hook)", "recommendation": "Consolidate single-use state files. Establish clear naming convention: .claude/state/ for session-surviving data (compaction-safe), .claude/hooks/ for ephemeral session state. Create state-schema.md documenting all state files, their consumers, and retention policy.", "impact": "tokens", "evidence": "agent-trigger-enforcer uses 2 state files, compaction-handoff reads 4 files, commit-tracker uses 2. Many files created but single-purposed (e.g., .auto-save-state.json only used by auto-save-context.js)"}
{"id": "OPT-H007", "category": "hook", "severity": "S2", "effort": "E2", "title": "validation hooks could share file read to reduce I/O", "description": "Multiple validation hooks on Write/Edit/MultiEdit independently read file content: component-size-check, firestore-write-block, test-mocking-validator, app-check-validator, typescript-strict-check, repository-pattern-check all do fs.readFileSync on same file. Pattern-check also reads file. No caching between hooks.", "file": ".claude/hooks/component-size-check.js, firestore-write-block.js, test-mocking-validator.js, app-check-validator.js, typescript-strict-check.js, repository-pattern-check.js", "currentState": "Each hook independently: 1) checks path format, 2) reads file content from disk, 3) validates against patterns. Example: typescript-strict-check reads file at line 108, repository-pattern-check at line 127, firestore-write-block at line 118.", "recommendation": "Implement hook file cache: pass file content through hook environment or temp file. Or create composite validator hook that reads file once and runs all applicable validators. At minimum, share path validation results.", "impact": "speed", "evidence": "6 hooks \u00d7 fs.readFileSync per Write/Edit = significant I/O overhead. Each does similar path containment checks, file existence checks, and security validation before actual logic."}
{"id": "OPT-H008", "category": "hook", "severity": "S1", "effort": "E3", "title": "audit-s0s1-validator.js only triggers on audit files but runs full validation on Write", "description": "audit-s0s1-validator.js (lines 216-218) only processes docs/audits/*.jsonl files but is registered on PostToolUse Write hook, meaning it runs on every file write operation. Does JSON parsing of file argument and path matching checks (~10-15ms wasted) on ~99% of writes that don't match audit file pattern.", "file": ".claude/hooks/audit-s0s1-validator.js", "currentState": "Registered globally on Write tool. Lines 216-218 check isAuditFile() pattern match. Non-blocking WARN mode (Phase 1).", "recommendation": "Create separate matcher condition in settings.json for audit files (similar to how Read, Bash, Task have matchers). Only register this hook when file path matches audit pattern. Or use very fast path-only check at top of hook before any other processing.", "impact": "speed", "evidence": "Hook does quick exit at line 218 for non-audit files, but all overhead (path normalization, argument parsing, linting checks) still happens. Runs on ~99% of writes unnecessarily."}
{"id": "OPT-H009", "category": "hook", "severity": "S1", "effort": "E2", "title": "Read hooks have no execution order guarantee - context tracking race condition potential", "description": "large-context-warning, auto-save-context, and compaction-handoff run in arbitrary order on every Read. They all touch .context-tracking-state.json. If one fails/timeout, state could be corrupt or get reset by another hook. Large-context-warning resets state if >30min old (line 98), which could wipe data another hook just wrote.", "file": ".claude/hooks/large-context-warning.js, .claude/hooks/auto-save-context.js, .claude/hooks/compaction-handoff.js", "currentState": "Settings.json lists Read hooks in order: large-context-warning, auto-save-context, compaction-handoff. Each does atomic write to shared state file. large-context-warning unconditionally loads and potentially resets state (line 96-100).", "recommendation": "Establish clear execution order (orchestrate in single hook or specify in settings). Have one hook be state authority that handles reset logic. Others read-only or use state-utils shared module. Document dependency order.", "impact": "accuracy", "evidence": "large-context-warning lines 96-103 show potential reset. If large-context-warning runs after auto-save-context in some scenarios, it could reset context that was just saved. Atomic writes don't prevent logical race conditions."}
{"id": "OPT-H010", "category": "hook", "severity": "S3", "effort": "E1", "title": "Bash hook (commit-tracker) does fast-path regex on every command but mostly bails (~1ms overhead)", "description": "commit-tracker.js runs on every Bash command but uses COMMIT_COMMAND_REGEX (line 50) to bail out fast for non-commit commands. Estimated ~1ms overhead per Bash call for non-commit operations (regex + argument parsing). Non-critical since bail-out is very fast.", "file": ".claude/hooks/commit-tracker.js", "currentState": "Lines 156-160 do fast regex check and exit. Only commits (~5% of bash calls) proceed to git operations (execFileSync).", "recommendation": "Move regex check to settings matcher instead of hook code. Create specific 'git commit' matcher rather than catching all Bash and bailing out. Would eliminate overhead entirely.", "impact": "speed", "evidence": "commit-tracker.js line 157: 'if (!COMMIT_COMMAND_REGEX.test(command))' - regex test happens on every bash call even though mostly bails. Matcher in settings could avoid hook invocation entirely."}
{"id": "OPT-H011", "category": "hook", "severity": "S3", "effort": "E1", "title": "check-write-requirements and check-edit-requirements could be unified with tool parameter", "description": "Both hooks (106 lines each) contain ~95% identical code. Only difference is keyword priority order (test-first vs security-first). Could merge into single hook that accepts tool name parameter and applies correct priority matrix.", "file": ".claude/hooks/check-write-requirements.js, .claude/hooks/check-edit-requirements.js", "currentState": "Two separate hook files with identical structure: line 70-103 defines priority order differently. check-write-requirements: tests\u2192security\u2192code\u2192markdown\u2192config. check-edit-requirements: security\u2192tests\u2192code\u2192markdown.", "recommendation": "Create single unified hook: check-file-requirements.js. Accept tool parameter. Build priority array based on tool. Use loop through priority array instead of separate if-blocks for each type. Saves 1 file and reduces maintenance burden.", "impact": "tokens", "evidence": "Lines 70-103 in both files show priority order is only real difference. Everything else (argument parsing, path validation, filename extraction) is identical."}
{"id": "OPT-H012", "category": "hook", "severity": "S2", "effort": "E2", "title": "session-start.js does heavy work at SessionStart (builds, installs, checks) - could be async", "description": "session-start.js (561 lines) runs synchronously at SessionStart and does heavy I/O: npm install, npm ci, build commands (up to 120s timeout each), pattern checks, consolidation checks, TDMS metrics. Blocks session start if any step hangs. SessionStart is synchronous hook context.", "file": ".claude/hooks/session-start.js", "currentState": "Uses execSync for all command execution (lines 316, 339, 352, 365, 372, 390, 481). Timeouts specified per command (60-120s) but entire sequence blocks session start. One timeout blocks whole session.", "recommendation": "Split session-start into critical-path (check secrets, load alerts) and background tasks (npm install, build, pattern check). Document which steps are blocking vs can be skipped if time-constrained. Consider if builds should happen at all during hook vs on-demand.", "impact": "speed", "evidence": "session-start.js total execution: npm ci (potentially 30-60s) + functions npm ci (30-60s) + build (60s) + pattern check (5-10s) + consolidation (5-10s) + TDMS check (5s) = potential 150+ seconds blocking session start"}
{"id": "OPT-H013", "category": "hook", "severity": "S2", "effort": "E1", "title": "Auto-save-context hook reads 4 files per Read operation to find recent decisions", "description": "auto-save-context.js reads SESSION_DECISIONS.md and processes it with regex on every Read operation to extract recent decisions (line 119-138). File could be large. Regex does full content scan. Only saves if thresholds exceeded (~15min interval), but reads every time.", "file": ".claude/hooks/auto-save-context.js", "currentState": "Lines 119-138: opens SESSION_DECISIONS.md, uses regex to match all decision blocks, filters for last 3. Does full file scan on every Read hook invocation.", "recommendation": "Cache recent decisions with timestamp. Only re-read SESSION_DECISIONS.md if modification time changed. Store cache in .auto-save-state.json. Reduces I/O from every Read to periodic (file-change-based).", "impact": "speed", "evidence": "getRecentDecisions() is called line 253 on every Read hook invocation, but auto-save only happens per SAVE_INTERVAL_MINUTES (line 24 = 15min). Doing full file read/parse on every invocation is wasteful."}
{"id": "OPT-H014", "category": "hook", "severity": "S3", "effort": "E1", "title": "TypeScript strict check runs on every Write/Edit/MultiEdit but skips for small files", "description": "typescript-strict-check.js (100ms cost) runs on every Write/Edit/MultiEdit but skips test files (.test.ts), .d.ts files, and scripts/ directory. Still does full file read even for pre-filtered file types.", "file": ".claude/hooks/typescript-strict-check.js", "currentState": "Lines 93-103 skip test files and scripts early. But still reads file at line 108 even for non-TS files (line 81 checks extension but still reads for files >100 lines).", "recommendation": "Move file read behind secondary filter check. Check file extension AND skip patterns before fs.readFileSync. Add cache for recently-checked files so repeated edits don't re-scan.", "impact": "speed", "evidence": "Hook reads file for every .ts/.tsx file (line 108 fs.readFileSync) even though some will be skipped. Could add extension-based cache key to avoid re-reading same file multiple times in one session."}
{"id": "OPT-H015", "category": "hook", "severity": "S2", "effort": "E2", "title": "SessionStart hook chain is sequential with no parallelization", "description": "session-start.js runs npm install, npm ci, builds, and checks sequentially (lines 312-410). Each command waits for previous. Node installations could run in parallel. Build after install requires wait, but pattern check and consolidation check could run in parallel.", "file": ".claude/hooks/session-start.js", "currentState": "Lines 314-327 (root npm install), lines 333-361 (functions npm install + build), lines 365 (test build), lines 372 (pattern check), lines 390 (consolidation). Each execSync blocks until completion.", "recommendation": "Use Promise.all() for parallelizable steps: npm install root + functions can run in parallel. Pattern check + consolidation check can run parallel. Build must wait for install. Requires async/await refactor but could cut session startup time by 40-50%.", "impact": "speed", "evidence": "Current sequential: npm (30-60s) + functions npm (30-60s) + build (60s) = 150s+ total. Parallel: Math.max(npm, functions npm) + build = ~100-120s potential savings."}
{"id": "OPT-K001", "category": "skill", "severity": "S1", "effort": "E1", "title": "Multiple audit skills with overlapping domain coverage", "description": "audit-code, audit-security, audit-performance, audit-refactoring, audit-documentation, audit-process, and audit-engineering-productivity are individual audits that are also orchestrated together via audit-comprehensive. audit-enhancements is an enhancement-specific audit that partially overlaps functionality.", "file": ".claude/skills/audit-*/SKILL.md", "currentState": "7 domain-specific audit skills + 1 comprehensive orchestrator + 1 enhancement auditor = 9 total audit-related skills", "recommendation": "Clarify the relationship: are individual audits meant to be standalone or only called from comprehensive? Consider consolidating orchestration logic or creating a more explicit hierarchy to prevent confusion about when to use which.", "impact": "accuracy", "evidence": "audit-comprehensive explicitly calls audit-code, audit-security, audit-performance, audit-refactoring, audit-documentation, audit-process. Each individual audit also stands alone with full execution instructions. audit-enhancements does similar discovery but for enhancements vs fixes."}
{"id": "OPT-K002", "category": "skill", "severity": "S2", "effort": "E1", "title": "Skill overlap: docs-sync vs docs-update vs doc-optimizer", "description": "Three skills appear to address documentation updates/synchronization. Without reading full content (files are empty/minimal in search), unclear if there's genuine overlap or specialization.", "file": ".claude/skills/docs-sync/SKILL.md, docs-update/SKILL.md, doc-optimizer/SKILL.md", "currentState": "Three separate skills with similar-sounding names and likely overlapping purposes", "recommendation": "Verify the specialization of each: if docs-sync is for keeping docs in sync, docs-update is for content changes, and doc-optimizer is for quality, that's clear. If not, consolidate.", "impact": "accuracy", "evidence": "Names suggest overlapping responsibility: sync, update, optimize all deal with documentation. Audit-documentation skill also modifies docs."}
{"id": "OPT-K003", "category": "skill", "severity": "S1", "effort": "E1", "title": "Senior specialist skills vs audit-comprehensive coverage", "description": "6 senior-* skills (architect, backend, devops, frontend, fullstack, qa) may duplicate functionality already covered by audit-comprehensive and its 7 domain audits.", "file": ".claude/skills/senior-*/SKILL.md", "currentState": "6 senior specialist skills exist alongside audit-code, audit-performance, etc. Unclear how senior-* roles relate to audit findings.", "recommendation": "Clarify: Are senior-* skills meant for code review/consultation vs automated audits? If they're for architectural review, they should have distinct scope from audits. If they're redundant, consider consolidating review logic into audits.", "impact": "accuracy", "evidence": "Audit skills find issues; senior-* skills presumably review code. Possible that senior-* are deprecated or should be renamed to 'review-*' instead."}
{"id": "OPT-K004", "category": "skill", "severity": "S2", "effort": "E0", "title": "Empty or minimal SKILL.md descriptions", "description": "Many skills have description fields with empty or placeholder values: developer-growth-analysis, excel-analysis, find-skills, frontend-design, etc.", "file": ".claude/skills/[multiple]/SKILL.md", "currentState": "At least 15+ skills have missing or empty descriptions in their SKILL.md frontmatter", "recommendation": "Complete all description fields. Even a one-sentence summary helps users understand when to use each skill. This is a quick fix with high clarity benefit.", "impact": "accuracy", "evidence": "Grep output shows 'description:' with nothing after it for many skills. Users cannot understand purpose from skill index."}
{"id": "OPT-K005", "category": "skill", "severity": "S2", "effort": "E1", "title": "Skill overlap: debt tracking skills (add-deferred-debt, add-manual-debt, verify-technical-debt, sync-sonarcloud-debt)", "description": "Four skills handle technical debt in different ways. add-deferred-debt and add-manual-debt both add debt but from different sources. verify-technical-debt verifies. sync-sonarcloud-debt imports from SonarCloud.", "file": ".claude/skills/add-deferred-debt/SKILL.md, add-manual-debt/SKILL.md, verify-technical-debt/SKILL.md, sync-sonarcloud-debt/SKILL.md", "currentState": "4 separate skills managing one system (MASTER_DEBT.jsonl)", "recommendation": "These may be appropriately specialized by source (deferred from PR, manual discovery, SonarCloud import, verification workflow). Verify each has distinct trigger criteria. If overlapping, consolidate intake logic.", "impact": "accuracy", "evidence": "All route to MASTER_DEBT.jsonl via intake-audit.js. Overlap is in the 'add' step; deferred vs manual is a valid distinction by source."}
{"id": "OPT-K006", "category": "skill", "severity": "S2", "effort": "E1", "title": "Skill overlap: PR and review skills (pr-review, pr-retro, code-reviewer, requesting-code-review)", "description": "Four skills handle pull requests and code review. pr-review is a comprehensive review skill. pr-retro does retrospective analysis. code-reviewer is a general code review tool. requesting-code-review initiates code review.", "file": ".claude/skills/pr-review/SKILL.md, pr-retro/SKILL.md, code-reviewer/SKILL.md, requesting-code-review/SKILL.md", "currentState": "4 PR/review-related skills with overlapping names and likely overlapping functionality", "recommendation": "Clarify workflow: Does requesting-code-review trigger pr-review? Is pr-retro a post-PR analysis? Is code-reviewer the general tool used by pr-review? Map the relationships clearly.", "impact": "accuracy", "evidence": "All four deal with pull requests, code quality, and review processes. Names suggest a workflow but hierarchy is unclear."}
{"id": "OPT-K007", "category": "skill", "severity": "S1", "effort": "E1", "title": "Unclear relationship: audit-validation-wrapper vs audit-comprehensive", "description": "audit-validation-wrapper 'wraps' audit-comprehensive but also serves as a standalone alternative. Uncertain if it should always run with comprehensive or be independent.", "file": ".claude/skills/audit-validation-wrapper/SKILL.md", "currentState": "audit-validation-wrapper presented as both a wrapper and independent entry point. Recommended workflow in documentation is to run wrapper before comprehensive.", "recommendation": "Clarify: Is audit-validation-wrapper the authoritative entry point (call audit-comprehensive from it) or should they be independent? Current doc creates ambiguity about which to invoke.", "impact": "accuracy", "evidence": "SKILL.md shows both 'Manual Integration' and 'Automated Wrapper (Recommended)' workflows, suggesting uncertainty about the primary flow."}
{"id": "OPT-K008", "category": "skill", "severity": "S3", "effort": "E0", "title": "Placeholder skills with minimal utility (using-superpowers, task-next, validate-claude-folder)", "description": "Several skills appear to be utilities or helpers with limited scope. using-superpowers presumably activates advanced features. task-next shows next task. validate-claude-folder validates .claude folder.", "file": ".claude/skills/using-superpowers/SKILL.md, task-next/SKILL.md, validate-claude-folder/SKILL.md", "currentState": "3 lightweight utility skills mixed with 50+ other skills in the skill index", "recommendation": "These are fine as utilities, but ensure they're documented clearly. Consider a separate 'utilities' section in skill index to avoid confusion with major skills.", "impact": "speed", "evidence": "These skills are helper functions, not major workflows. They're useful but shouldn't be at the same priority level as audit-comprehensive."}
{"id": "OPT-K009", "category": "skill", "severity": "S2", "effort": "E1", "title": "Potential deprecation: skill-creator, skill-related skills in favor of ai-native workflow", "description": "skill-creator and find-skills manage skills as artifacts. But skills may be better managed through evolving the codebase or agent instructions rather than as files.", "file": ".claude/skills/skill-creator/SKILL.md, find-skills/SKILL.md", "currentState": "2 skills devoted to creating and finding skills suggest skill-based architecture is manual and ad-hoc", "recommendation": "Evaluate whether skill-creator and find-skills can be automated or replaced by better skill discovery mechanisms. If skill management is becoming a bottleneck, consider refactoring.", "impact": "speed", "evidence": "skill-creator and find-skills exist to manage skills manually. If this is frequently needed, it suggests the skill system itself needs improvement."}
{"id": "OPT-K010", "category": "skill", "severity": "S3", "effort": "E0", "title": "Session lifecycle skills (session-begin, session-end, checkpoint) could be consolidated", "description": "Three skills handle session management: session-begin starts sessions, session-end ends sessions, checkpoint saves state. These are tightly coupled.", "file": ".claude/skills/session-begin/SKILL.md, session-end/SKILL.md, checkpoint/SKILL.md", "currentState": "3 separate skills for session lifecycle management", "recommendation": "Consider consolidating into a single 'session-management' skill with subcommands for begin/end/checkpoint. This reduces skill index clutter.", "impact": "speed", "evidence": "These three skills are procedurally coupled (always used in session-begin \u2192 work \u2192 checkpoint \u2192 session-end order). One unified skill would reduce invocation overhead."}
{"id": "OPT-K011", "category": "skill", "severity": "S1", "effort": "E2", "title": "Audit skill explosion: 9 audit-related skills with inconsistent parameterization", "description": "audit-code, audit-security, audit-performance, audit-refactoring, audit-documentation, audit-process, audit-engineering-productivity, audit-comprehensive, audit-enhancements + audit-validation-wrapper and audit-aggregator = 11 audit-related skills", "file": ".claude/skills/audit-*/SKILL.md", "currentState": "11 skills devoted to auditing across different domains, dimensions (single/comprehensive/enhancements), and validation phases", "recommendation": "Evaluate consolidation: Could these be one 'audit' skill with domain parameters (e.g., /audit --domain code,security,performance)? Or are the individual skills appropriately specialized for standalone use? Current approach creates high cognitive load.", "impact": "accuracy", "evidence": "57 total skills, 11 are audits (19% of skill portfolio). This is a significant portion devoted to one pattern. Consolidation could free up skill slots for new functionality."}
{"id": "OPT-K012", "category": "skill", "severity": "S2", "effort": "E1", "title": "Skill naming inconsistency: enhancement vs audit-enhancements, process vs audit-process", "description": "Most audits are prefixed 'audit-' (audit-code, audit-security) but audit-enhancements uses 'enhancement' alone. audit-process is standalone but part of audit-comprehensive.", "file": ".claude/skills/audit-enhancements/SKILL.md, audit-process/SKILL.md", "currentState": "Inconsistent naming convention for audit-related skills", "recommendation": "Standardize: Either all audit skills are audit-* (audit-enhancements, audit-process are correct) or domain names are standalone (code, security, enhancements are correct). Pick one pattern.", "impact": "accuracy", "evidence": "audit-code, audit-security, audit-performance, audit-refactoring, audit-documentation, audit-process, audit-engineering-productivity use 'audit-' prefix. audit-enhancements doesn't. Inconsistent."}
{"id": "OPT-K013", "category": "skill", "severity": "S2", "effort": "E0", "title": "Marketing-focused skills in technical codebase (content-research-writer, market-research-reports, ux-researcher-designer)", "description": "Three skills are marketing/content/design focused and may be out of scope for a technical codebase audit toolkit.", "file": ".claude/skills/content-research-writer/SKILL.md, market-research-reports/SKILL.md, ux-researcher-designer/SKILL.md", "currentState": "3 content/marketing skills mixed with 54 technical skills in the skill portfolio", "recommendation": "Verify these belong in the codebase. If the project is web-based with UX concerns, keep them. If purely backend/technical, consider moving to separate skill repository or marking as optional.", "impact": "accuracy", "evidence": "content-research-writer helps with articles/newsletters. market-research-reports does market research. ux-researcher-designer does UX research. These are orthogonal to code audits, debt tracking, and technical skills."}
{"id": "OPT-K014", "category": "skill", "severity": "S2", "effort": "E1", "title": "Undefined skill descriptions create discovery problem (50% of skills missing meaningful descriptions)", "description": "At least 25+ skills have empty description fields, preventing skill discovery via /find-skills or skill index searches.", "file": ".claude/skills/*/SKILL.md", "currentState": "Description field is empty for: developer-growth-analysis, excel-analysis, expand-evaluation, find-skills, frontend-design, gh-fix-ci, market-research-reports, markitdown, mcp-builder, multi-ai-audit, pre-commit-fixer, quick-fix, requesting-code-review, save-context, senior-architect, senior-backend, senior-devops, senior-frontend, senior-fullstack, senior-qa, skill-creator, sonarcloud, sonarcloud-sprint, sync-sonarcloud-debt, systematic-debugging, webapp-testing, and more.", "recommendation": "Populate all descriptions with 1-2 sentence summaries. This is foundational metadata for a 57-skill portfolio.", "impact": "accuracy", "evidence": "Grep output shows 'description:' with no value for ~50% of skills. Users cannot discover these skills via automated tools."}
{"id": "OPT-K015", "category": "skill", "severity": "S1", "effort": "E1", "title": "Deprecated or unclear purpose: artifacts-builder, markitdown, mcp-builder, expansion-evaluation, systematic-debugging", "description": "Five skills have unclear or potentially deprecated purposes: artifacts-builder (build HTML artifacts), markitdown (convert markdown), mcp-builder (build MCP servers), expansion-evaluation (evaluate expansions), systematic-debugging (debug systematically).", "file": ".claude/skills/artifacts-builder/SKILL.md, markitdown/SKILL.md, mcp-builder/SKILL.md, expansion-evaluation/SKILL.md, systematic-debugging/SKILL.md", "currentState": "5 specialized utility skills with niche use cases or potentially outdated purposes", "recommendation": "Audit usage: Are these actually used? If artifacts-builder is for creating Claude artifacts, verify it's still needed post-api-changes. If MCP-builder is for custom MCP servers, verify it's maintained. Mark deprecated if not actively used.", "impact": "accuracy", "evidence": "markitdown description mentions 'convert to markdown' but unclear from what. expansion-evaluation is unexplained. systematic-debugging has no description. These need clarity or deprecation notices."}
{"id": "OPT-A001", "category": "ai-instructions", "severity": "S1", "effort": "E2", "title": "57 documents with duplicate/inconsistent AI Instructions sections", "description": "Audit found 57 markdown files containing 'AI Instructions' sections. Many are duplicated across docs with similar guidance (e.g., APPCHECK_SETUP.md, RECAPTCHA_REMOVAL_GUIDE.md both have App Check-specific instructions that could be consolidated). Each section ranges from ~100-800 chars (25-200 tokens). Total estimated token waste: ~4,500+ tokens per session load.", "file": "docs/**/*.md, SESSION_CONTEXT.md, AUDIT_TRACKER.md, PLAN_MAP.md (and 54 others)", "currentState": "57 separate AI Instructions sections scattered across documentation. Common patterns: 1) Process instructions (check this first, do X, then Y), 2) Scope instructions (this is for X only), 3) Validation instructions (verify before committing)", "recommendation": "Consolidate AI Instructions into 3-4 canonical sections in claude.md: (1) Universal Meta-Instructions (placement, format, scope), (2) Per-Document-Type Instructions (planning docs vs process docs vs setup guides), (3) Safety/Compliance Checks. Reference from docs using 'See claude.md Section X.Y' instead of duplicating.", "impact": "tokens", "evidence": "grep found 57 files with '^## AI Instructions' pattern. Sample: APPCHECK_SETUP.md (line 318/343=92% down), DOCUMENTATION_STANDARDS.md (line 57/864=6% up), INCIDENT_RESPONSE.md (line 283/300=94% down). DOCUMENTATION_STANDARDS.md itself mandates 'AI Instructions MUST be near top' but 30% of docs violate this."}
{"id": "OPT-A002", "category": "ai-instructions", "severity": "S1", "effort": "E1", "title": "AI Instructions placement violates own DOCUMENTATION_STANDARDS", "description": "DOCUMENTATION_STANDARDS.md (line 57-67) explicitly states: 'AI Instructions section MUST be near the top (after title and metadata)' with rationale that 'LLMs read top-to-bottom; instructions at bottom are often missed'. However, at least 8 sampled docs place AI Instructions at 90%+ through the document (APPCHECK_SETUP.md at line 318/343, INCIDENT_RESPONSE.md at line 283/300), making instructions invisible to most LLM attention spans.", "file": "docs/DOCUMENTATION_STANDARDS.md, docs/APPCHECK_SETUP.md, docs/INCIDENT_RESPONSE.md, docs/SONARCLOUD_CLEANUP_RUNBOOK.md (and others)", "currentState": "Self-contradictory standard: Document prescribes instruction placement near top, but enforcement is absent. Pre-commit hook check-docs-light.js exists but doesn't validate AI Instructions placement.", "recommendation": "(1) Add check to pre-commit hook: validate AI Instructions at line <50 for docs >100 lines. (2) Audit all 57 docs for placement violation. (3) Move misplaced instructions to line 20-30 (post-metadata).", "impact": "tokens|accuracy", "evidence": "DOCUMENTATION_STANDARDS.md lines 63-66 state placement rule. Grep shows APPCHECK_SETUP.md, INCIDENT_RESPONSE.md, SONARCLOUD_CLEANUP_RUNBOOK.md all >90% through their files. Compare: MCP_SETUP.md correctly places at line 16/178 (9%), DOCUMENTATION_STANDARDS.md at line 57/864 (6%)."}
{"id": "OPT-A003", "category": "ai-instructions", "severity": "S2", "effort": "E2", "title": "Redundant App Check instructions across 3 documents", "description": "App Check setup guidance appears in 3 separate files: (1) APPCHECK_SETUP.md (tier 3 setup guide), (2) RECAPTCHA_REMOVAL_GUIDE.md (tier 3 procedure), (3) claude.md Section 2 (security rule about App Check Required). Each has overlapping instructions: check env var \u2192 verify config \u2192 test deployment. Estimated 3-5 tokens wasted per session per doc.", "file": "docs/APPCHECK_SETUP.md, docs/RECAPTCHA_REMOVAL_GUIDE.md, claude.md", "currentState": "Three sources of truth: (1) APPCHECK_SETUP.md AI Instructions say 'First check NEXT_PUBLIC_FIREBASE_APPCHECK_RECAPTCHA_SITE_KEY' (2) RECAPTCHA_REMOVAL_GUIDE.md AI Instructions say 'For fresh setup: Use Monitor mode first' (3) claude.md Section 2 states App Check as mandatory security rule", "recommendation": "Keep only one authoritative guide (APPCHECK_SETUP.md). Remove App Check instructions from RECAPTCHA_REMOVAL_GUIDE.md and cross-reference. Simplify claude.md Section 2 security rule to: 'App Check Required - see APPCHECK_SETUP.md for troubleshooting' (reduce from current advisory to single pointer).", "impact": "tokens", "evidence": "Sampled 3 App Check docs: all have setup guidance. Cross-references not present. DOCUMENTATION_STANDARDS.md at line 200-207 defines 'sync triggers' but no sync trigger exists for App Check instructions."}
{"id": "OPT-A004", "category": "ai-instructions", "severity": "S2", "effort": "E1", "title": "Outdated IMS references in SESSION_HISTORY.md and AI_REVIEW_LEARNINGS_LOG.md", "description": "Session #152 (2026-02-12) merged IMS (Improvement Management System) into TDMS (Technical Debt Management System). Multiple documents contain historical references to 'IMS', 'docs/improvements/', and 'MASTER_IMPROVEMENTS.jsonl' that are now obsolete. While SESSION_HISTORY.md correctly documents the merge in version history, the operational guidance hasn't been updated. Risk: AI agents reading outdated session logs may attempt to reference deleted systems.", "file": "docs/SESSION_HISTORY.md (lines 25-50), docs/AI_REVIEW_LEARNINGS_LOG.md (lines with 'IMS\u2192TDMS'), docs/AUDIT_TRACKER.md (version 2.6-2.7)", "currentState": "PLAN_MAP.md v2.1 (2026-02-12) documents: 'IMS merged into TDMS \u2014 removed docs/improvements/ hierarchy, updated refs'. Verified: /home/user/sonash-v0/docs/improvements/ does not exist (deleted). However, historical entries in SESSION_HISTORY.md still reference IMS operations. No AI Instructions updated to reflect post-merge state.", "recommendation": "(1) Update SESSION_HISTORY.md entries for Sessions #150-152 to add post-merge callout: [IMS DEPRECATED - see Session #152 for merger details]. (2) Update AI Instructions in AUDIT_TRACKER.md to reference TDMS exclusively. (3) Add one-time cross-reference in SESSION_DECISIONS.md: 'IMS merged to TDMS in Session #152 - historical refs may be outdated'.", "impact": "accuracy", "evidence": "docs/improvements/ does not exist (verified). AUDIT_TRACKER.md version history shows merge (2.6\u21922.7). PLAN_MAP.md v2.1 explicitly documents removal. Historical session logs still reference old system."}
{"id": "OPT-A006", "category": "ai-instructions", "severity": "S3", "effort": "E1", "title": "Inconsistent AI Instructions format across document tiers", "description": "Different document tiers use different AI Instructions formats: (1) Tier 2 docs (setup guides) use numbered lists with actions (e.g., APPCHECK_SETUP.md), (2) Tier 4 docs (references) use bullet lists with guidelines (e.g., REVIEW_POLICY_QUICK_REF.md), (3) Some use 'When X do Y' format, others use 'Rules are', others use 'Do not'. DOCUMENTATION_STANDARDS.md doesn't prescribe a format for AI Instructions subsections. This inconsistency costs ~50-100 tokens per doc as LLMs must re-parse format variations.", "file": "docs/*.md (all 57 files)", "currentState": "Sampled formats: APPCHECK_SETUP.md (4 numbered action steps), DOCUMENTATION_STANDARDS.md (4 bulleted guidelines), GLOBAL_SECURITY_STANDARDS.md (3 rules), HOOKIFY_STRATEGY.md (4 bulleted practices), SESSION_CONTEXT.md (6 numbered steps). No canonical format.", "recommendation": "Add Section 5 to DOCUMENTATION_STANDARDS.md: 'AI Instructions Format Spec'. Prescribe: (1) Use bulleted list (not numbered) for generality, (2) Start each bullet with imperative verb: 'Check/Validate/Review/When/Always/Never', (3) Keep <15 words per bullet, (4) Max 5-8 bullets per section, (5) Example: '- Check file status before modifying\n- Validate with npm run docs:check\n- Reference ROADMAP.md for sync triggers'.", "impact": "tokens", "evidence": "Sampled 5 files show 5 different formats. No DOCUMENTATION_STANDARDS.md section covers format. Format variations add parsing overhead without benefit."}
{"id": "OPT-A007", "category": "ai-instructions", "severity": "S3", "effort": "E2", "title": "Disconnected AI Instructions from actual automation - TESTING_PLAN.md example", "description": "TESTING_PLAN.md AI Instructions (line ~1050) say 'First run npm test to check automated test status'. But there is no automatic test runner integrated into the documented workflow. The instruction assumes synchronous CLI execution, while modern SoNash uses async /test-suite skill. The instruction is not obsolete but outdated (pre-skill era). Similar issue in 3-5 other docs.", "file": "docs/TESTING_PLAN.md, docs/SONARCLOUD_CLEANUP_RUNBOOK.md, docs/RECAPTCHA_REMOVAL_GUIDE.md", "currentState": "TESTING_PLAN.md AI Instructions reference direct 'npm test' execution. Modern workflow uses /test-suite skill (created Session #141). Docs list both paths but AI Instructions anchor to old path only.", "recommendation": "(1) Update TESTING_PLAN.md AI Instructions: 'Use /test-suite skill (recommended) or npm test for local verification'. (2) Add 'Preferred Automation' subsection to claude.md Section 7 that lists 10 core skills with their trigger contexts. (3) Mark AI Instructions with version (['Updated Session #X'] to help AI understand freshness.", "impact": "accuracy|speed", "evidence": "TESTING_PLAN.md created ~Session #110, /test-suite skill created Session #141. Session #141 notes say 'comprehensive testing suite'. But TESTING_PLAN.md AI Instructions never updated to recommend new skill. Compare: TESTING_USER_MANUAL.md (Session #141) correctly references /test-suite."}
{"id": "OPT-A008", "category": "ai-instructions", "severity": "S3", "effort": "E1", "title": "AI Instructions in SESSION_CONTEXT.md creates circular reference risk", "description": "SESSION_CONTEXT.md AI Instructions (line 7-43) prescribe 6 steps for session start and 5 rules for updating, concluding with 'Check Navigation' section that links to ROADMAP.md, AI_WORKFLOW.md, etc. These links then loop back and reference SESSION_CONTEXT.md. While not contradictory, this creates a 3-hop dependency (SESSION_CONTEXT \u2192 AI_WORKFLOW \u2192 ROADMAP \u2192 SESSION_CONTEXT) that costs tokens every session load and makes updates harder.", "file": "SESSION_CONTEXT.md, AI_WORKFLOW.md, ROADMAP.md", "currentState": "SESSION_CONTEXT.md reads: 'Check Roadmap \u2192 /ROADMAP.md' (line 49). ROADMAP.md has no explicit 'return' link but SESSION_CONTEXT.md documentation calls it central. AI_WORKFLOW.md (not examined but mentioned) likely also references SESSION_CONTEXT.md.", "recommendation": "(1) Establish clear hierarchy: ROADMAP.md is canonical, SESSION_CONTEXT.md is current-state read-only snapshot, AI_WORKFLOW.md is navigation. (2) Simplify SESSION_CONTEXT.md AI Instructions to 3 points: 'Read first \u2192 check Next Session Goals \u2192 see ROADMAP for priorities'. Remove internal navigation links. (3) Move navigation links to ai-navigation section in claude.md.", "impact": "tokens", "evidence": "SESSION_CONTEXT.md lines 45-51 (Navigation section) create 3-hop links. Actual reading order is SESSION_CONTEXT \u2192 ROADMAP (for goals) \u2192 ROADMAP_LOG (for history) \u2192 back to SESSION_CONTEXT (for current session). Circular dependency confirmed."}
{"id": "OPT-A009", "category": "ai-instructions", "severity": "S0", "effort": "E0", "title": "CRITICAL: 57 separate AI Instructions sections = ~4,500+ unnecessary tokens per session", "description": "COMPREHENSIVE FINDING: The project maintains 57 separate 'AI Instructions' sections across documentation. At ~80 tokens per section average (320-1,200 chars / 4 chars per token), this represents ~4,500+ tokens loaded per session. However, claudee.md (118 lines, ~30 tokens) is the only file that MUST be loaded every session for AI context. The other 56 sections are redundantly included in documentation that's selectively read. Token waste estimate: 90% of AI Instructions are never referenced in a given session (only 1-2 docs are read per session on average). This violates the project's own principle (claude.md line 10-13: 'Kept minimal (~120 lines) to reduce token waste').", "file": "All 57 files with AI Instructions sections", "currentState": "DOCUMENTATION_STANDARDS.md prescribes: 'Tier 1 = essential, Tier 5 = archive'. Tier 1-2 (high-priority) docs should have AI Instructions; Tier 3-4 (reference) should not. Current count: Tier 1-2 docs with instructions: ~15-20 (justified). Tier 3-4 docs with instructions: ~30-37 (unjustified bloat).", "recommendation": "IMMEDIATE: Audit all 57 docs by tier. Keep AI Instructions ONLY in Tier 1-2 docs (ROADMAP.md, SESSION_CONTEXT.md, DOCUMENTATION_STANDARDS.md, claude.md, maybe 10-15 others). Remove from Tier 3-4 docs entirely. Instead, add single 'See claude.md Section X for instructions' pointer. Create centralized 'Per-Document AI Instructions' section in claude.md that covers all document types and scenarios. Estimated savings: ~4,000 tokens per session (90% reduction in AI Instructions bloat).", "impact": "tokens|all", "evidence": "Grep found 57 files. Manual sampling of 5-10 files shows average ~120-200 chars per AI Instructions section. Extrapolate: 57 * 150 chars = 8,550 chars = ~2,137 tokens. HOWEVER: if ~30 are Tier 3-4 (reference only), then unnecessary load = 30 * 150 = 4,500 chars = ~1,125 tokens PER SESSION. Conservative estimate with weighted averaging: ~4,500 tokens waste due to over-distribution of AI Instructions."}
{"id": "OPT-P001", "category": "parsing", "severity": "S0", "effort": "E1", "title": "SESSION_CONTEXT.md Session Counter Regex in 5 hooks", "description": "Multiple hooks parse **Current Session Count**: using regex /\\*\\*Current Session Count\\*\\*:\\s*(\\d+)/ to extract session numbers. This pattern appears in: commit-tracker.js (line 130), compaction-handoff.js (line 165), check-remote-session-context.js (line 63), pre-compaction-save.js (line 149), and generate-pending-alerts.js (indirectly via check-session-gaps.js line 77). If markdown formatting changes (spacing, capitalization, or bold marker), session counter extraction fails silently, breaking compaction tracking.", "file": "/home/user/sonash-v0/.claude/hooks/commit-tracker.js", "currentState": "Hardcoded regex expecting exact markdown format: **Current Session Count**: N (with specific spacing)", "recommendation": "Extract to shared utility function with fallback parsing strategies (e.g., case-insensitive, flexible whitespace). Add validation to ensure extracted value is numeric.", "impact": "accuracy|tokens", "evidence": "grep found pattern in 5 files; commit-tracker.js line 130 is primary; compaction-handoff.js line 165, check-remote-session-context.js line 63, pre-compaction-save.js line 149, check-session-gaps.js line 77 depend on same pattern"}
{"id": "OPT-P002", "category": "parsing", "severity": "S0", "effort": "E1", "title": "SESSION_DECISIONS.md Decision Block Regex in auto-save-context.js", "description": "auto-save-context.js (line 124) parses recent decisions using regex /^### \\[(\\d{4}-\\d{2}-\\d{2})\\] - (.+?)\\n([\\s\\S]*?)(?=^### \\[|^## |$)/gm. This pattern is brittle: requires exact date format (YYYY-MM-DD), assumes specific header structure with dash separator, and expects newline immediately after header. Any markdown reformatting (adding spaces, changing header level, altering date format) breaks decision extraction, losing session context that survives compaction.", "file": "/home/user/sonash-v0/.claude/hooks/auto-save-context.js", "currentState": "Regex expects: ### [YYYY-MM-DD] - Title\\n followed by content. No flexibility for spacing or format variations.", "recommendation": "Use more flexible regex with optional whitespace: /^###\\s+\\[(\\d{4}-\\d{2}-\\d{2})\\]\\s*-\\s*(.+?)\\n([\\s\\S]*?)(?=^###|$)/gm. Add guard against empty date/title fields.", "impact": "accuracy|tokens", "evidence": "Line 124 in auto-save-context.js; used to save session context before compaction; runs every file read (PostToolUse hook)"}
{"id": "OPT-P003", "category": "parsing", "severity": "S1", "effort": "E2", "title": "AUDIT_FINDINGS_BACKLOG.md markdown parsing in check-backlog-health.js", "description": "check-backlog-health.js (lines 160, 179-191) parses backlog items using split(/^### \\[/gm) and multiple regex patterns for severity, status, and CANON-ID extraction. The parser expects exact format: ### [Category] Item Name with specific field formatting (**Severity**: S[0-3], **Status**: PENDING|IN_PROGRESS|DONE|DEFERRED, **CANON-ID**: CANON-\\d+). If fields are reordered, spacing changes, or status values vary, parsing fails to identify critical S0 items, creating blocker detection failures.", "file": "/home/user/sonash-v0/scripts/check-backlog-health.js", "currentState": "Uses split(/^### \\[/gm) and section.match(/\\*\\*Severity\\*\\*:\\s*(S[0-3])/i) patterns. Relies on exact field names and format. Exit code 0 indicates health OK, but missing S0 detection means blocker violations go undetected.", "recommendation": "Use multiline section parsing with flexible field detection. Support YAML-like format detection. Add fallback to unstructured search for severity keywords. Validate that all required fields exist before processing item.", "impact": "accuracy|speed", "evidence": "Lines 160-195 in check-backlog-health.js; called during pre-push hook validation; failure to detect S0 items blocks push but might be bypassed if parsing fails silently"}
{"id": "OPT-P004", "category": "parsing", "severity": "S1", "effort": "E2", "title": "Markdown table parsing in update-readme-status.js with pipe delimiter fragility", "description": "update-readme-status.js (lines 156-171, 203) parses markdown tables from ROADMAP.md using regex and split('|'). Line 203 uses split('|') on table rows without escaping for pipe characters in cell content. Pattern expects exact alignment (| header | ... |) but doesn't handle pipes in cell values. Line 156 regex /## \ud83d\udcca Milestones Overview[\\s\\S]{0,5000}?\\n\\|[^\\n]+\\| requires specific heading emoji; if changed, parsing fails. Table parsing is fragile to format changes.", "file": "/home/user/sonash-v0/scripts/update-readme-status.js", "currentState": "Regex requires: ## \ud83d\udcca Milestones Overview followed by pipe-delimited table. split('|') assumes pipes only as delimiters, not content. No escaping of pipes within cells.", "recommendation": "Detect table by structure (| + separator row) instead of emoji. Parse cells carefully: use regex match on table row including escaped pipes (\\\\|). Validate column count matches header. Consider using markdown parsing library instead of regex.", "impact": "accuracy|tokens", "evidence": "Lines 156-171 for table detection, line 203 for cell splitting; used in update-readme-status.js which updates README from ROADMAP"}
{"id": "OPT-P005", "category": "parsing", "severity": "S1", "effort": "E1", "title": "check-session-gaps.js relies on hardcoded Session Context markdown format", "description": "check-session-gaps.js (line 59) extracts documented sessions using /\\*\\*Session #(\\d+) Summary\\*\\*/g and current counter using /\\*\\*Current Session Count\\*\\*:\\s*(\\d+)/ (line 77). The pattern is hardcoded to expect exact bold formatting. If SESSION_CONTEXT.md switches to different header style (# Session N Summary, or [Session N]), gap detection fails, missing undocumented sessions and potentially allowing orphaned commits.", "file": "/home/user/sonash-v0/scripts/check-session-gaps.js", "currentState": "Hardcoded regex: /\\*\\*Session #(\\d+) Summary\\*\\*/ expects exact bold format. Fails if heading level, format, or number syntax changes.", "recommendation": "Create markdown format abstraction. Support multiple formats: **Session #N Summary**, # Session N Summary, [Session N]. Use case-insensitive matching. Add logging for parsing failures.", "impact": "accuracy", "evidence": "Lines 59 and 77 in check-session-gaps.js; used to detect missing session documentation; failure means orphaned commits go untracked"}
{"id": "OPT-P006", "category": "parsing", "severity": "S1", "effort": "E2", "title": "aggregate-audit-findings.js markdown parsing fragility in multiple functions", "description": "aggregate-audit-findings.js has four fragile markdown parsing points: (1) parseMarkdownBacklog (line 322) splits by '|' without handling escaped pipes, assumes fixed column positions; (2) parseAuditFindingsBacklog (line 377) regex /^### \\[([^\\]]+)\\] / expects exact bracket format; (3) section.match() for CANON-ID, Severity, Effort (lines 384-386) expect exact bold format and field names. If backlog markdown structure changes\u2014field reordering, different ID format, heading changes\u2014parsing silently skips items or extracts wrong data.", "file": "/home/user/sonash-v0/scripts/aggregate-audit-findings.js", "currentState": "Uses hardcoded regex patterns for: category headers (### [Cat]), table columns (split by |), field extraction (**CANON-ID**: CANON-\\d+). Multiple single-point-of-failure patterns with no fallback.", "recommendation": "Implement markdown AST parsing or use remark/unified. Support format variants: ### [Cat] or ### Cat or # Cat/Item. For tables, parse cell-aware (handle escaped pipes). Add schema validation for required fields per item type.", "impact": "accuracy|tokens", "evidence": "Lines 279-348 (markdown table parsing), 354-399 (section-based parsing); used in master aggregation for all findings; cascading failures affect entire audit pipeline"}
{"id": "OPT-P007", "category": "parsing", "severity": "S1", "effort": "E1", "title": "generate-pending-alerts.js fragile DEFERRED item extraction", "description": "generate-pending-alerts.js (lines 45-86) parses AI_REVIEW_LEARNINGS_LOG.md for DEFERRED items using multiple regexes: /\\*\\*DEFERRED \\(Review #(\\d+)\\)\\*\\*/ (line 45), /\\*\\*DEFERRED \\((\\d+)\\):\\*\\*/ (line 67-68). The patterns expect exact formatting with specific punctuation placement (colon inside or outside asterisks). If deferred items are reformatted, patterns fail, causing DEFERRED alerts to be missed entirely\u2014losing visibility of deferred work.", "file": "/home/user/sonash-v0/scripts/generate-pending-alerts.js", "currentState": "Two separate regex patterns for DEFERRED detection: one expecting (Review #N) and another expecting (N): with colon position mattering. No unified pattern or fallback.", "recommendation": "Unify DEFERRED detection with flexible regex: /\\*\\*DEFERRED\\s*\\(\\s*(?:Review\\s*#)?(\\d+)\\s*\\):\\**/i. Test both colon-inside and colon-outside variants. Add logging for detected vs missed items.", "impact": "accuracy", "evidence": "Lines 45 and 67-68 in generate-pending-alerts.js; used to surface deferred review items in session start alerts; silent failure means alerts lost"}
{"id": "OPT-P008", "category": "parsing", "severity": "S2", "effort": "E1", "title": "check-roadmap-health.js version parsing regex scoped to section only", "description": "check-roadmap-health.js (line 56) extracts version header using /\\*\\*Document Version:\\*\\*\\s*(\\d+\\.\\d+)/ but this appears once per document. Line 69 further restricts version history parsing to a specific section using /##\\s*\ud83d\uddd3\ufe0f?\\s*Version History[\\s\\S]*?(?=\\r?\\n##\\s|\\r?\\n---\\s*$|$)/. While scoped (good), the patterns are fragile: emoji optional but section name hardcoded; line number regex assumes specific format. If document structure changes, version validation silently passes or fails incorrectly.", "file": "/home/user/sonash-v0/scripts/check-roadmap-health.js", "currentState": "Emoji-optional in section header (\ud83d\uddd3\ufe0f?), but section name 'Version History' is hardcoded. Version format assumes X.Y (digits.digits).", "recommendation": "Make section header detection case-insensitive and emoji-agnostic: /##\\s*version\\s*history/i. Support version formats: X.Y, X.Y.Z, vX.Y. Validate at least one version entry exists in history section.", "impact": "speed", "evidence": "Lines 56, 61-69 in check-roadmap-health.js; health check runs before pushing; silent failures bypass validation"}
{"id": "OPT-P009", "category": "parsing", "severity": "S2", "effort": "E2", "title": "Multi-AI normalize-format.js markdown table detection and parsing", "description": "normalize-format.js (line 194) detects markdown tables using /\\|[^\\n]+\\|\\s*\\n\\|[-:\\s|]+\\|\\s*\\n/, but this pattern assumes: (1) first row has pipes, (2) separator row immediately follows, (3) separator contains only hyphens/colons/pipes/spaces. If table has leading/trailing spaces, multiple blank lines, or non-standard separators, detection fails. Line 485, 507 split by '|' without handling escaped pipes in content. Multi-AI uses this to parse ANY audit input format; parsing failures cascade to all downstream processing.", "file": "/home/user/sonash-v0/scripts/multi-ai/normalize-format.js", "currentState": "Markdown table detection requires: header row | separator row with no gaps. Pipe-splitting (lines 485, 507) naive: split('|') assumes pipes only delimit columns.", "recommendation": "Add flexible whitespace: /\\|[^\\n]*\\|\\s*\\n\\s*\\|\\s*[-:\\s|]+\\s*\\|/. Detect separator row by content: all cells match /^\\s*[-:]+\\s*$/. Parse cells aware of escaped pipes: split by unescaped pipes only. Test with real audit markdown examples.", "impact": "accuracy|tokens", "evidence": "Lines 194-196 for detection, 485/507 for cell splitting; this module handles format detection for ALL multi-AI aggregation; failures affect entire pipeline"}
{"id": "OPT-P010", "category": "parsing", "severity": "S2", "effort": "E1", "title": "verify-sonar-phase.js hardcoded security section header detection", "description": "verify-sonar-phase.js (line 163) detects security section by exact string match: if (line.startsWith('## \ud83d\udd12 Security Hotspots')). If emoji changes, section name varies, or spacing differs, detection fails, causing hotspots to be miscategorized as regular issues. Line 203 regex /### \ud83d\udcc1 `([^`]+)`/ for file sections also hardcodes emoji; changing it breaks file grouping. Phase verification is used to validate sonar fixes; parsing failure allows miscategorized issues to slip through.", "file": "/home/user/sonash-v0/scripts/verify-sonar-phase.js", "currentState": "Hardcoded section headers with emoji: '## \ud83d\udd12 Security Hotspots' (line 163), '### \ud83d\udcc1 `file`' (line 203). String startsWith() instead of regex; no flexibility.", "recommendation": "Use regex for section detection: /##\\s+(?:\ud83d\udd12)?\\s*security\\s+hotspots/i. For files: /###\\s+\ud83d\udcc1?\\s*`([^`]+)`/. Fall back to text search without emoji. Log parse warnings.", "impact": "accuracy", "evidence": "Lines 163 and 203 in verify-sonar-phase.js; used to verify phase completion; emoji change breaks categorization"}
{"id": "OPT-D001", "category": "dead-doc", "severity": "S0", "effort": "E0", "title": "SoNash_Technical_Ideation_Multi_AI 1.20.26.md - 4.1KB ideation document never linked", "description": "Large ideation document (4118 lines) containing multi-AI technical proposals that is never referenced by any script, hook, skill, or other documentation. Listed as orphaned in DOCUMENTATION_INDEX.md.", "file": "/home/user/sonash-v0/docs/SoNash_Technical_Ideation_Multi_AI 1.20.26.md", "currentState": "4,118-line document exists at docs/SoNash_Technical_Ideation_Multi_AI 1.20.26.md; marked as orphaned (\u21930 \u21910 references)", "recommendation": "Move to docs/archive/ or consolidate findings into EXPANSION_EVALUATION_TRACKER.md. The content appears to be exploratory AI-generated technical ideation that should either be integrated into active roadmaps or archived as historical reference.", "impact": "tokens", "evidence": "DOCUMENTATION_INDEX.md lists as orphaned with \u21930 \u21910 references; grep search for filename returns 14 refs but all are in technical-debt views or archive-related docs, not active docs"}
{"id": "OPT-D002", "category": "dead-doc", "severity": "S1", "effort": "E0", "title": "HOOKIFY_STRATEGY.md - 1.1KB implementation plan unused", "description": "Hookify Strategy & Implementation Plan (1059 lines) documents a hooks implementation strategy that is never referenced by any active documentation, scripts, or hooks themselves.", "file": "/home/user/sonash-v0/docs/HOOKIFY_STRATEGY.md", "currentState": "1,059-line document at docs/HOOKIFY_STRATEGY.md; marked orphaned (\u21930 \u21910)", "recommendation": "Review content and either: (1) integrate strategy into .claude/HOOKS.md, (2) create references from hook files, or (3) move to archive if strategy was superseded. Check if hookification is still planned or completed.", "impact": "tokens", "evidence": "DOCUMENTATION_INDEX.md orphaned list; zero grep references outside the file itself"}
{"id": "OPT-D003", "category": "dead-doc", "severity": "S2", "effort": "E0", "title": "RECAPTCHA_REMOVAL_GUIDE.md - 745 lines about Firebase configuration rarely used", "description": "Comprehensive guide (745 lines) for reCAPTCHA removal and fresh App Check setup. While server-side docs reference it (2 refs), it has zero inbound document references and is primarily a reference/procedural doc.", "file": "/home/user/sonash-v0/docs/RECAPTCHA_REMOVAL_GUIDE.md", "currentState": "745-line standalone guide at docs/RECAPTCHA_REMOVAL_GUIDE.md; DOCUMENTATION_INDEX shows \u21930 \u21912", "recommendation": "Integrate into APPCHECK_SETUP.md or SERVER_SIDE_SECURITY.md as a section. Update README or index to reference it, or move obsolete sections to archive if reCAPTCHA removal was already completed.", "impact": "tokens", "evidence": "DOCUMENTATION_INDEX.md shows \u21930 outbound refs; referenced by 2 server-side docs but not by index or guides"}
{"id": "OPT-D004", "category": "dead-doc", "severity": "S2", "effort": "E0", "title": "REVIEW_POLICY_INDEX.md - 370 lines index without inbound refs", "description": "Review Policy Index (370 lines) serves as a directory for review policies but has zero inbound references despite 9 upward references. Not referenced by README, DOCUMENTATION_INDEX, or navigation docs.", "file": "/home/user/sonash-v0/docs/REVIEW_POLICY_INDEX.md", "currentState": "370-line document at docs/REVIEW_POLICY_INDEX.md; \u21930 \u21919 (referenced by policy docs but not from main docs)", "recommendation": "Add explicit reference in DOCUMENTATION_INDEX.md index section and link from REVIEW_POLICY_ARCHITECTURE.md. If serving as index, ensure it's discoverable from main navigation (README, DOCUMENTATION_INDEX).", "impact": "accuracy", "evidence": "DOCUMENTATION_INDEX.md lists as orphaned; found referenced in DOCUMENTATION_INDEX.md and scripts/check-docs-light.js only"}
{"id": "OPT-D005", "category": "dead-doc", "severity": "S2", "effort": "E0", "title": "PLAN_MAP.md - 242 lines documentation hierarchy map never referenced", "description": "SoNash Documentation Plan Map (242 lines) provides visual hierarchy and relationships but is completely orphaned with zero inbound references.", "file": "/home/user/sonash-v0/docs/PLAN_MAP.md", "currentState": "242-line document at docs/PLAN_MAP.md; \u21930 \u21910 (completely isolated)", "recommendation": "Either (1) add reference from DOCUMENTATION_INDEX.md as navigation aid, (2) integrate content into README.md or DOCUMENTATION_STANDARDS.md, or (3) move to docs/archive/ if superseded by DOCUMENTATION_INDEX.md.", "impact": "tokens", "evidence": "DOCUMENTATION_INDEX.md orphaned list; zero external references; grep shows only DOCUMENTATION_INDEX references the filename"}
{"id": "OPT-D006", "category": "dead-doc", "severity": "S2", "effort": "E0", "title": "MCP_SERVER_AUDIT.md - 374 lines about MCP consumption never referenced", "description": "MCP Server Usage Audit (374 lines) designed to identify MCP servers consuming context but never referenced by any documentation or audit processes.", "file": "/home/user/sonash-v0/docs/MCP_SERVER_AUDIT.md", "currentState": "374-line document at docs/MCP_SERVER_AUDIT.md; \u21930 \u21910", "recommendation": "Link from multi-ai-audit coordinator or create reference in relevant audit plans. If this audit should be run, add to AUDIT_TRACKER.md. Consider if this aligns with actual audit workflows.", "impact": "speed", "evidence": "DOCUMENTATION_INDEX.md orphaned list; grep finds only DOCUMENTATION_INDEX reference"}
{"id": "OPT-D007", "category": "dead-doc", "severity": "S3", "effort": "E0", "title": "MCP_SETUP.md - 178 lines configuration guide without traction", "description": "MCP Server Setup Guide (178 lines) provides configuration instructions but is unused - no references from setup docs, deployment guides, or DEVELOPMENT.md.", "file": "/home/user/sonash-v0/docs/MCP_SETUP.md", "currentState": "178-line document at docs/MCP_SETUP.md; \u21930 \u21910", "recommendation": "Integrate into DEVELOPMENT.md or .claude/REQUIRED_PLUGINS.md. If MCP is critical for setup, ensure onboarding docs reference it. Otherwise archive as legacy.", "impact": "speed", "evidence": "DOCUMENTATION_INDEX.md orphaned; DEVELOPMENT.md and onboarding docs do not reference it; zero grep matches in active code"}
{"id": "OPT-D008", "category": "dead-doc", "severity": "S3", "effort": "E0", "title": "LEARNING_METRICS.md - 84 lines metrics tracking document", "description": "Learning Effectiveness Metrics (84 lines) auto-generated tracker showing pattern learning effectiveness but with zero inbound references despite being produced by scripts/analyze-learning-effectiveness.js.", "file": "/home/user/sonash-v0/docs/LEARNING_METRICS.md", "currentState": "84-line document at docs/LEARNING_METRICS.md; \u21930 \u21910; auto-generated by scripts/analyze-learning-effectiveness.js", "recommendation": "Add reference from AUDIT_TRACKER.md or alerts system. If auto-generated, ensure output is mentioned in the generating script's documentation. Consider if metrics should feed into decision-making workflows.", "impact": "accuracy", "evidence": "DOCUMENTATION_INDEX.md orphaned list; generated by script but not integrated into dashboards or tracking systems"}
{"id": "OPT-D009", "category": "dead-doc", "severity": "S3", "effort": "E0", "title": "AUTOMATION_AUDIT_REPORT.md - 255 lines audit results never integrated", "description": "Automation Audit Report (255 lines) appears to be a standalone audit report with no inbound references, likely superseded by newer audit structure in docs/audits/ subdirectory.", "file": "/home/user/sonash-v0/docs/AUTOMATION_AUDIT_REPORT.md", "currentState": "255-line document at docs/AUTOMATION_AUDIT_REPORT.md; \u21930 \u21910; similar content exists at docs/audits/single-session/process/audit-2026-02-09/AUTOMATION_AUDIT_REPORT.md", "recommendation": "Remove duplicate at root level (keep versioned audit in subdirectory). Update references to point to dated audit instance in docs/audits/. Consider if root-level report should be generated or archived.", "impact": "tokens", "evidence": "DOCUMENTATION_INDEX.md orphaned; newer dated version exists in docs/audits/; no scripts or workflows reference the root-level version"}
{"id": "OPT-D010", "category": "dead-doc", "severity": "S1", "effort": "E0", "title": "FIX_TEMPLATES.md - 0 outbound refs for Qodo PR fixes", "description": "Fix Templates for Qodo PR Review Findings (docs/agent_docs/FIX_TEMPLATES.md) provides copy-paste templates but is never referenced by code reviewer agents, PR review skills, or documentation.", "file": "/home/user/sonash-v0/docs/agent_docs/FIX_TEMPLATES.md", "currentState": "Agent docs file at docs/agent_docs/FIX_TEMPLATES.md; \u21930 \u21910", "recommendation": "Link from code-reviewer skill, CODE_PATTERNS.md, and review process documentation. If templates are intended for use, ensure they're discoverable from agent workflows that need them.", "impact": "accuracy", "evidence": "DOCUMENTATION_INDEX.md orphaned list; grep shows zero references from skills or agent configs"}
{"id": "OPT-D011", "category": "dead-doc", "severity": "S2", "effort": "E0", "title": "SKILL_AGENT_POLICY.md - 0 refs despite defining usage policy", "description": "Skill and Agent Usage Policy (docs/agent_docs/SKILL_AGENT_POLICY.md) defines critical policies for skill/agent creation but has zero inbound references despite having 3 upward references.", "file": "/home/user/sonash-v0/docs/agent_docs/SKILL_AGENT_POLICY.md", "currentState": "Policy doc at docs/agent_docs/SKILL_AGENT_POLICY.md; \u21930 \u21913 (referenced by policies but not from discoverable locations)", "recommendation": "Link from agent creation guides, DEVELOPMENT.md, and main agent documentation README. Add to onboarding checklist. Ensure policy is discoverable before agents are created.", "impact": "accuracy", "evidence": "DOCUMENTATION_INDEX.md orphaned; not referenced from main skill/agent docs or onboarding materials"}
{"id": "OPT-D012", "category": "dead-doc", "severity": "S2", "effort": "E0", "title": "Audit inventory stage files (6 files) - generated but unreferenced", "description": "Six stage-1 audit inventory files (stage-1a through stage-1f) generated 2026-02-09 but never integrated into audit workflows or referenced by audit aggregation processes.", "file": "/home/user/sonash-v0/docs/audits/single-session/process/audit-2026-02-09/stage-1*.md", "currentState": "6 generated markdown files, all with \u21930 \u21910 in DOCUMENTATION_INDEX; date-stamped as 2026-02-09", "recommendation": "Either (1) integrate into AUDIT_TRACKER with findings aggregation, or (2) move dated audit outputs to completed audit archive with clear retention policy. If stage outputs are intermediate, don't persist in docs.", "impact": "tokens", "evidence": "DOCUMENTATION_INDEX.md marks all 6 as orphaned; audit-related grep shows references only in index, not in active audit workflows"}
{"id": "OPT-D013", "category": "dead-doc", "severity": "S3", "effort": "E0", "title": "ADR template and decisions/README - decision framework underutilized", "description": "Architecture Decision Records framework (docs/decisions/README.md) with template (docs/decisions/TEMPLATE.md) but only one ADR documented; framework appears unused.", "file": "/home/user/sonash-v0/docs/decisions/", "currentState": "ADR framework present but dormant; README marked \u21930 \u21911; TEMPLATE marked \u21931 \u21910", "recommendation": "Either (1) activate ADR process and link from ARCHITECTURE.md + AI_WORKFLOW.md, or (2) consolidate decision tracking into SESSION_DECISIONS.md format. Clean up if not part of current workflow.", "impact": "accuracy", "evidence": "DOCUMENTATION_INDEX.md shows ADR README as orphaned (\u21930); only one historical ADR exists (ADR-001); no recent decisions recorded"}
{"id": "OPT-D014", "category": "dead-doc", "severity": "S2", "effort": "E0", "title": "Plan documents with zero inbound refs - 5 planning files orphaned", "description": "Five planning documents (CI_GATES_BLOCKING_PLAN, SESSION_CONTEXT_REDUCTION_PLAN, TRACK_A_MANUAL_TEST_CHECKLIST, alerts-enhancement-plan, and roadmap-assignment-report) all marked orphaned in DOCUMENTATION_INDEX.", "file": "/home/user/sonash-v0/docs/plans/CI_GATES_BLOCKING_PLAN.md and 4 others", "currentState": "5 plan files with \u21930 \u21910 or minimal refs; mixed completion status", "recommendation": "For each plan: (1) check if completed and archive to docs/archive/completed-plans/, or (2) if active, add explicit reference from ROADMAP.md and PLAN_MAP.md. Consolidate similar plans (e.g., testing checklists).", "impact": "tokens", "evidence": "DOCUMENTATION_INDEX.md orphaned list includes all 5 files; ROADMAP.md and PLAN_MAP.md do not reference most of them"}
{"id": "OPT-D015", "category": "dead-doc", "severity": "S1", "effort": "E1", "title": "Technical debt view files - generated views without integration", "description": "Three technical debt view files (by-category, by-severity, by-status) plus views/unplaced-items are generated by TDMS but not integrated into monitoring dashboards or alerting systems.", "file": "/home/user/sonash-v0/docs/technical-debt/views/", "currentState": "4 view files generated, updated 2026-02-13, marked \u21930-1 \u21910-2 in DOCUMENTATION_INDEX; appear to be output-only files", "recommendation": "Integrate into alerts system or create monitoring dashboard that references these views. Update TECHNICAL_DEBT_MANAGEMENT_SYSTEM_PLAN.md to document how views feed into workflows. Consider if view files should be excluded from docs and generated-only.", "impact": "speed", "evidence": "Views marked orphaned in DOCUMENTATION_INDEX; generated by TDMS but no active consumption in workflows; greps show only TDMS procedure references them"}
